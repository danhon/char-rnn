From: danhon <dan@danhon.com>
Subject: s2e18: Sequencing; Spectrum
Date: August 13, 2015 at 10:05:43 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-snw1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

21:31 Central Time, August 13, 2015
16-Asilomar osDarwin 0z4:xnu/RELEASE_ARM dm: 3-Azimuth
... Instantiation successful.

> look

You are sitting at a dining table in the farmhouse. There are two computers in front of you.

> look at computers

To the left, there is an black Gateway laptop. To the right, there is a silver Apple MacBook Pro. 

> examine black Gateway laptop

The black Gateway laptop looks like it is running Windows 7. It is covered in stickers that tell you that it has an Intel processor inside. There appears to be a lot of malware on it, and it looks like someone has installed a remote login program typically used by scammers pretending to be Microsoft support. 

> sigh

I know, right?

1.0 Sequencing

Apparently we've only just got around to sequencing the octopus genome and there's a whole bunch of super interesting stuff in there[0, 1]. This shouldn't really be a surprise because observation and experiments have shown that octopuses are a) very smart, b) very flexible, c) really alien looking because have you seen what they do with those suckers and those chromatophores. And that's before we even get started with the squid! So anyway, we haven't even *finished* sequencing *a* octopus genome yet and we've already discovered what we think are thousands of new genes[2]. If you're like me, the last time you thought really hard about genes was probably when you were around 14-18 years old and learning science or biology at school, so it's refreshing to know that *we still aren't really sure what genes are* because although it's true that they're regions of DNA that code for, well, *things happening*, they don't even have to be regions of DNA that are adjacent to each other because although one bit describes, well, the gene-y bit, another bit of DNA controls how it's regulated[2]! 

Anyway, that's a digression. Octopuses. We don't even know what we don't know. We haven't even sequenced a whole octopus genome yet - they come in at around 2.7 million bases long, which is near enough to the roughly 3 million bases in the human genome, and we're only done sequencing about 83% of those bases. 

So if you *want* to introduce some germ-line therapy to introduce chromatophores into your skin or to go even a bit more crazy and go with a radial symmetry body plan, then you're going to need to chuck a lot more money at the marine genetic biologists who're busy figuring out how octopuses work. 

[0] The octopus genome and the evolution of cephalopod neural and morphological novelties : Nature
[1] Octopus’ sophistication driven by hundreds of previously unknown genes | Ars Technica
[2] Gene - Wikipedia, the free encyclopedia

2.0 Spectrum

Every so often I go spelunking in Spectrum, the magazine of the institute of electrical and electronics engineers, to see what's up in the, uh, world of electrical and electronic engineering. Here's the stuff that caught my attention and will probably bubble up somewhere else through my head in a few weeks time: 

 - Here's a good writeup of the 2015 Blackhat presentation that explains how Charlie Miller and Chris Valasek remotely controlled that jeep through the internet: Jeep Hacking 101

 - Our children (well, to be perfectly honest, the study uses Japanese children so we need to replicate, right?) are being mean to robots, so robots are learning how to run away from children: Children Beating Up Robot Inspires New Escape Maneuver System

 - I think this means that if you buy two off-the-shelf FPGA transceivers - or anything else that can function as a software-defined radio, right? - you can get either a) Superman x-ray vision wherever there's good wifi coverage or b) vision like Robocop used in the first movie to find the bad guys through the wall, but either way, we now know the maths to use the passive radiation from ambient wifi (2.4 and 5GHz bands) and GSM and LTE (no idea which frequency bands) to pick out moving subjects through 25 centimeters worth of masonry. So expect to see this as an app on a phone within about 18 months: See Through Walls by the Glow of Your Wi-Fi

 - DARPA, the Defense Advanced Research Projects Agency that amongst other things was responsible for the system of tubes through which you're receiving this newsletter, is like a bratty kid who writes unreasonable descriptions of things in its Christmas list. It now wants a spaceplane that can fly 10 times in 10 days, fly faster than Mach 10, carry about 2,200 kilograms and costs less than $5 million per flight. For reference, current launches cost about $50 million per flight. Billionaire genius playboy philanthropist Tony Stark^W^WElon  Musk *isn't* involved in this particular competition, but Boeing (with Jeff Bezos' Blue Origin), Northrop Grumman (with Scaled Composites and Virgin Galactic) and Masten Space Science Systems (with XCOR) are. Oh, right, and they want to fly the prototype in about 3 years time. That's about when the iPhone 8 will come out. DARPA Funds Stage 2 of XS-1 Spaceplane Design Competition

 - Terahertz rays are cool and we might have figured out how to make them, also we get to call them T-rays. Simple Device Could Convert DC Electric Field To Terahertz Radiation

 - Supercomputers have stopped getting fast as fast as they used to be getting fast, so now instead of getting an exascale computer around 2020, we might have to wait until 2023. Some people think this is because of Moore's law, some other people think this is because no-one wants to pay for it. China still has the fastest supercomputer, also, they're mining a lot of bitcoin but those two things are totally unrelated. Why Aren't Supercomputers Getting Faster Like They Used To?

 - This one has nothing to do with IEEE Spectrum but the nVidia DIGITS dev box is in my mind what a Silicon Graphics Indy looked to me as a 14 year old: kick-ass workstations with unreasonable amounts of power are now not used just to render graphics, they're used to simulate or run giant neural networks to increase the number of slugs we can find in photos uploaded to the internet. The specs on the box look completely crazy and I just wish it had similarly awesome industrial design and didn't just look like a high-end gaming PC or a first-generation glowing green Xbox. Because if you're going to have that much computing power, you need to make sure that it looks like a Gibson pizza box or whatever. NVIDIA® DIGITS™ DevBox

--

OK, that's it for today. I'm still glaring at that Windows 7 laptop. Odds on having imposed a new Mac on the father-in-law by the end of the week are unsurprisingly high. 

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e17: Shockwave; The Top Priorities; Engagement; A Hostile Environment
Date: August 12, 2015 at 11:43:51 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-smpl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

10:59pm central daylight time on Wednesday, 12 August 2015,  at the undisclosed family farm location in rural Missouri. We just came in from lying down outside looking up at the Perseids and in the last hour seeing about three brilliant lines momentarily etched across the sky, like a sort of scratch test on our planet's atmosphere. It's the first time I've ever really *seen* a meteor shower - I mean, I've seen meteors before, but not like this, not in the middle of nowhere where there's no light pollution and you can just step outside and *see* the milky way. Not like a line that covers two thirds the sky a bit like a literal punctuation mark but rotated around the sort of axis you'd need to write on the planet: a big long slash and then that explosive dot at the end. 

Meteors. Pretty cool. Four stars (would have given five stars but you had to wait ages before seeing them and also the developer only releases them at certain times and hasn't responded to feedback. Also there were literal bugs when I was using the Meteors and now I am scratchy and itchy).

A short one today. I'm officially on vacation.

1.0 Shockwave

Those videos - which I'm not going to link to, you can look for them and watch them if you want, but be warned that they're not necessarily safe for lunch or mental health if you're able to empathise with other people in tragic situations - of the explosion and then subsequent shockwave and blast front in Tianjin[0] juxtaposed with lying down in the rural midwest and looking up at the sky seeing debris that if it were a bit bigger would be a different kind of exclamation point, the kind that happens to a species when it looks up and then everything stops. The discussions and comments on the internet of other people watching the videos, of talking at and shouting at and telling the people in them to *get away from the window* and to *stop filming* because the pretty fireball is just the light show, the pressure wave is coming and that's going to literally hit you. And then you see it literally hit people. 

That, but on a planetary scale.

And then: looking for the signals - strong, weak, anything in between - of civilization-ending events[1]. A sort of stupendously scientific way of taking what we're able to learn at a distance about a) stars, b) the planets that we infer exist around those stars, c) the type of life that might exist on those planets, d) based on what we know about ourselves, possible failure modes, e) the sorts of signals that those failure modes would emit. The title of the paper itself, "Observational Signatures of Self-Destructive Civilisations" sounds you could twist it just so and then rewrite as a really bad Glamour article[2]: The 7 Signs The Civilization Next Door Is Acting Self-Destructively (And How You Can Intervene). 

But then, by the time you see the gamma ray burst that's heading in your direction, by the time you're doing the planetary equivalent of pointing all your cameras at it and livestreaming it to ten billion people - it's too late, right? There's no running away. You can't step away from a shockwave that's going to completely obliterate your planet. 

There's a potential answer to the Fermi paradox, I suppose. The reason why it's so quiet out there is that industrial accidents and failure to apply proper safety protocol keep sterilizing life. 

PS. Which one of you is starting http://jackpot.index/, hm? 

[0] China blasts: fireball from Tianjin explosions injures hundreds and kills at least 17 – latest updates | World news | The Guardian
[1] [1507.08530] Observational Signatures of Self-Destructive Civilisations
[2] How to Make Men Love You: Taking Apart a Ridiculous 'Glamour' Article That the Whole UK Is Upset About | VICE | United States

2.0 The Top Priorities

I got an email about a conference to do with Government Technology but I won't say who the conference is being run by suffice to say that you can look at the capitalized words in this sentence and try and guess. It was an invitation to either attend or sponsor (it wasn't completely clear, to be honest) a conference about the top IT priorities for Washington State (to be clear: the bit of America that Seattle is in, not the bit of America that is a District and that gets blown up by invading aliens). I'd normally really want to go because now I'm quite interested in the top IT priorities of governments (or, at least, I get angry when I hear about the top IT priorities of governments because let's politely and in a politic manner say that I believe that many of those priorities are what we call "misaligned" - and some people who've known me in a previous life will know what I get like when I get angry and start asking pointed questions with the training of a lawyer in a public forum), but I can't, because it's happening at the same time as some big work do[0].

Anyway. Here are the top IT priorities of Washington State as communicated to me through the medium of an unsolicited marketing email: 
Cyber security / Privacy
Digital evidence
Cloud
Citizen engagement strategies
Wearables and The Internet of Everything
Big Data
Smart Cities
Infrastructure-as-a-Service
Workforce development
Mobility
Enterprise architecture
Some of those are interesting. "Citizen engagement strategies," for example. Which you might call "Encouraging people to get involved in local government". The rest of them seem mostly like buzzwords intended to act as dogwhistles for, I dunno, "vendors" and again, after having been infected with the "meet user needs" memeplex as recently and forcefully delivered by the GDS lot, none of the things in the priority list feel particularly important compared to: "IT that helps people get things done". Big Data: not focussed on outcome. Workforce development: maybe? Enterprise architecture: for what? Smart cities: how about ones that just work better? Cloud: *Seriously*. Wearables and The Internet of Everything: YOUR POLICE SEEM NEEDLESSLY MILITARISTIC. Digital evidence: YOU HAVE ENOUGH PROBLEMS WITH PHYSICAL EVIDENCE WHY COMPLICATE MATTERS. Cyber security: yes! Things that should be secure, should be secure! Privacy: This is a different thing from security! Mobility: THIS WORD DOESN'T MEAN ANYTHING WHEN YOU USE IT LIKE THAT.

*sigh*

[0] The CFA Summit — Code for America - hey look it's the Code for America summit that you should totally come to if you a) think government should work, b) should be better at technology and c) should serve its users. I *think* I might even be able to help with a coupon code or something. So if you're genuinely interested or would like to come meet me and other people and talk about how we're actually doing something about this, send me a note. See? That didn't even feel like shilling, because it was *important*. 

3.0 Engagement

Trigger warning 1: this is basically just another link to a Russell Davies blog post. Sorry.

Trigger warning 2: I suppose this has something to do with advertising. Sorry not sorry.  

There are people who think they get to have conversations like this in their job and that they're helping but the truth of the matter is that more often than not, engagement doesn't actually help get anything done[0]. 
Bryan: I don't know who you are. I don't know what you want. If you are looking for money, I can tell you I don't have any. But what I do have are a very particular set of skills, skills I have acquired over a very long career. Skills that make me a nightmare for people like you. If you hire me now, that'll be the end of it. I will not look for you, I will not pursue you. But if you don't, I will look for you, I will find you, and I will start the biggest social media mobile-enabled hashtag campaign you have ever seen. 
[0] Russell Davies: You can't fix services with engagement

4.0 A Hostile Environment

I got a few notes in response to the last - admittedly hastily written - piece on battlesuits and cities and other things that might be battlesuits to help people deal with and function in the environment they find themselves in. First: yes, I massively underestimated and maligned the science of urban planning. If you are an urban planner, I am sorry. If you are not an urban planner, I am sorry. 

Second: the thought - thank you, Adrian McEwan - that had never occurred to me which was that some people might not want battlesuits. That the point is that we're supposed to live in a civil society now and that perhaps not looking at everything in terms of being in an environment where both the landscape and actors and entities in it are actively trying to kill you, or at least, aren't acting in your interests, doesn't sound like a particularly fun one. You don't want a battlesuit, you want, I don't know. Just a nice suit. Some nice clothes. You want to not have to put on a suit of armor just to engage with the world. You don't need an aggressive or adversarial outlook, you just need one that's more collaborative than necessarily combative. This fires off a connection with Scott Alexander's thoughts[0] on the thrive/survive theory of the political spectrum where left-leaning policies and people can be explained by optimizing for comfortable, safe environments where of course you'd want everyone to have a safety net and education and be able to maximise their own potential. Versus an environment where everything is out to get you and you could lose it all and it's everyone for their own fucking selves. (Alexander's piece is worth reading just for the thought experiment on what happens to liberal people - and I'd count myself as one - when the zombie apocalypse has actually happened. Practically speaking, what do your ideologies lead you to then?)  

So. The battlesuit is something that's needed in the increasingly brutish environment of postcapitalism[1]. You only get no-battlesuits when there's enough of a safe environment for no-one to need a battlesuit because the existence of a battlesuit is competitive advantage, unfortunately. Which is all a bit depressing. 

[0] A Thrive/Survive Theory Of The Political Spectrum | Slate Star Codex
[1] Bella Caledonia independence – autonomy – self-determination - a review of Paul Mason's Post-Capitalism by Irvine Welsh

-- 

I got lots of notes in response to the last episode that were basically calling bullshit on my lack of citation in asserting that the industrial revolution had no marketing and you're all right: the industrial revolution had a shit-tonne of marketing. I think I still have a valid thought there but obviously one that I didn't express right, and definitely one that I obviously haven't thought through. So I'll keep thinking about that one.

In other news, I'm very pleased to have had a proposal on empathy in design accepted for the O'Reilly Design Conference in January 2016. So I'm already freaking out about writing the talk. Expect more meandering thoughts about empathy and all that business over the next few months, probably.

I am about a quarter of the way through setting up a recurrent neural network and feeding it all of my newsletter output so that I can have a shadow me generating newsletters that I can then mine for inspiration. This would be *literally* spinning up another instance of a thought vector machine in a kind of weird crippled centaur-writing hybrid that I'm totally excited about. 

I AM ONLY THINKING OUT LOUD, NO ONE TELL ANYONE AT WIEDEN ABOUT THIS BUT IF YOU WERE IN THE LODGE YOU SHOULD TOTALLY SET UP A RNN AND FEED IT ALL OF THE MANIFESTO SCRIPTS EVER WRITTEN EVER AND MAYBE THE CONTENTS OF A FEW COPYWRITER'S EMAIL INBOXES AND THEN SEE WHAT HAPPENS LA LA LA IGNORE THIS BIT IF YOU DON'T CARE ABOUT ADVERTISING. 

11:39pm and 2,021 words, which is about fifty words a minute which still is THINKING TOO MUCH which is evidently SLOWING DOWN TYPING.

--

Send notes, etc.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e15: What Twitter Should Do; CXO vs CUO; Shilling
Date: August 4, 2015 at 11:51:13 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-sdd5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
 
12:20pm on Tuesday 4th August 2015, lunchtime at the Code for America office in San Francisco. I was walking back from lunch and thought I might do a What Dan Would Do kind of collection of things today. I'm still a bit buzzing from Foo and this whole concept of just going out and actually doing/delivering the things (ha, the strategy is *delivery*, you see. The strategy is pointedly *not* delivering newsletters) instead of reckoning about them. So, today, a bit of Alternate Timeline where these are some of the things I'm doing. Maybe.
 
1.0 What Twitter Should Do
 
Let's try and do this quickly, in bullet points.
 
 * The Ev Williams era of Twitter back in mumble mumble (it doesn't matter, just that it was pre-iPhone and SMS texting was a thing) as a microblogging service. Twitter was a *bit* mobile, but not *very* mobile.
 
 * This is Twitter as in democratization of publishing - a way to talk to the world and to have conversation. Tweeter shall tweet unto tweeter. This has done some undeniably amazing things, because networks because lowering barriers to communication and also, eventually, because mobile.
 
 * Then, after a while, post Mobile Explosion That's Still Happening Or In Other Ways Has Happened Enough, you get a valid Jack Dorsey view, of Twitter as a genuinely useful window onto the world[0]. In other words, Twitter-the-platform has gotten big enough to now do two things for two different types of users: be useful enough for a) people who want to have a conversation, and b) people who want to know what's going on.
 
 * This is pretty much two products. It's the conversational Twitter that a whole bunch of hardcore users are on about where they don't want their timeline fucked up. These people are, arguably, producing the work-for-free value and contributing content to the network. They're doing it because people like feedback. 
 
 * Then there's everyone else: and if we just take as read that the rough 1:9:90[1] rule of participation continues to hold even when networks scale to unprecedented rates (e.g. Facebook sizes, and I suspect it does), then there's *way more* people who just want to look at Twitter - the lurkers - than want to to use it as a microphone.
 
 * So: your conversational product that's optimized toward making the best, clearest, simplest, fastest microphone as possible, with a little bit of listening to help those users find the conversations that they want to take part in. That's probably Twitter.app that already exists. You've just got a clearer direction and vision for it now.
 
 * And then the new one. I have no idea whether it's anything like Project Lightning[2] is going to be anything like this, but it's already weird that it's being billed as a new "feature" of Twitter that's going to be in the Twitter app, as opposed to a separate thing that really clearly and simply does the separate thing of helping people find out about what's happening. 
 
* *This* product - not the existing Twitter.app - should be totally optimized toward finding stuff that's happening - and in that respect it makes some of the profile page product decision (ie: no longer being a simple reverse-chronological list) make sense (if you're trying to tell a story as to why Twitter might have done that). Reverse-chronological *might not be* the best way to help someone figure out the most important thing that is happening. 
 
* In other words, don't try to make a weird microphone-window hybrid. Make a great microphone and make a great window. 
 
[0] The Case for Jack Dorsey, Twitter CEO - Stratechery by Ben Thompson
[1] 1% rule (Internet culture) - Wikipedia, the free encyclopedia
[2] This Is Twitter's Top Secret Project Lightning - BuzzFeed News
 
2.0 CXO vs CUO
 
I tweeted earlier in the day that, during a conversation with Rebecca Coelius, our literally awesome Director of Health at Code for America (seriously: she's an MD, a Fulbright Fellow and before Code for America was Medical Officer for Innovation at the Department of Health and Human Services), I'd had to inevitably explain what I thought was the distinction between a Chief Patient Officer and a Chief Experience Officer.
 
I was making my case for why I thought healthcare groups should have a Chief Patient Officer - someone with the responsibility to improve the end-to-end patient, er, "experience", as it were, and therefore remit to cut across silos in order to meet that responsibility. Because there are some Chief Experience Officers in hospitals and medical systems and practices already, and I think the point that I made (and I should stress that this wasn't an argument - it was just a request for clarification) was that, if you're just looking at the terminology of the job title, the problem with a title like Chief Experience Officer is that - well - whose experience? What for? I mean, we're all having experiences all the time, right? 
 
For me, the distinction is in the purpose, and I might just be primed because I've been thinking about the idea for the last few months. But the point of a Chief Patient Officer is a bit like a Reader's Editor, or an Ombudsman - someone who's looking out for the customer or the audience or, as is being emphasised (to pretty good effect), the user. 
 
I suppose the analogy to draw would be how the UK Government's Digital Service successfully created the role of Chief Digital Officers - whose responsibility is to focus on digital service delivery to users - as opposed to Innovation Officers or User Experience because there's more of a focus on the "so that". Part of this, I suppose, is an attempt to carve out a sort of space or end run to explicitly make user needs (or, in this case, a specific class of user's needs) important. You could also make the argument that having a Chief Patient Officer means focussing on patients-as-users to the detriment of Every Other Damn User In The Hospital, of which there are Seriously, A Whole Damn Load, in which case I'd counter with the fact that concentrating on the Patient User has the second-order effect of making it service-providers-as-users needs important, so they can actually do a good job of meeting the patient's user needs. 
 
So, that's what I'd do: I'd look at the stupendous amount of money being spent in the American healthcare system and I'd go to either Sand Hill Road or private equity with a long-term gameplan and say: hey, see Kaiser and those other integrated healthcare systems? Would be an awful shame if someone came along and did a substantially better job for less money and out-competed them. Because the thing is, Kaiser, one of the better-performing healthcare systems, is doing well because it’s (from what I understand, at least), pretty well vertically integrated. They get to do things like preventative care well because they’re an insurer and a provider and they do everything: because preventative care saves them money. But one place where they’re not doing well is in software because they’re stuck with the same options as Every Other Damn Healthcare System In The Entire World right now, which is that you get to choose between shitty option (a), which is Epic, or shitty option (b) which is Cerner. So Kaiser has to spend about a billion dollars (really), buying a new software system, and the DOD has to spend around *nine* billion dollars, over the project’s lifetime, buying a new software system. Both of which are bits of legacy software that date back to the 70s and grew to include workflow and electronic health records out of the most important bit of American healthcare, which was billing. And this isn’t even coming anywhere near the fact that most of the hardware and medical devices in healthcare systems are still pretty shittily designed! So yeah, that’s what other me would do: build a brand new integrated healthcare system with technologists because software can eat the provision of medical care, too. 
 
Of course, this is one of those stupid plans that is too stupid and too naive for me to understand all the numerous holes that can be shot into it, which is precisely why someone should do it. And part of the plan relies instead of just being a software shop that sells in software to go for the even stupider bigger part of the pie, which is the whole. damn. hospital. system. 
 
Oh, and it doesn’t even matter if there’s more than one competitor in the market! The American healthcare market is too big and too insane anyway! There’s lots of room at the top of American healthcare. 
 
Part of this is a sort of irrational exuberance that is still in my system post Foo Camp which is that this shit needs to be built and it doesn’t look like there are enough people doing it. So you can either complain about it or get off your damn ass and stop writing newsletters.   How much does it cost to build a hospital system anyway?  (I think I might have buried the lede in the title for this section. It probably should've just been called Insanely And Naively Disrupt The Hospital System)
 
3.0 Shilling
 
So I’m doing the closing keynote at the HOW Interactive Design Conference in Chicago later this year. This is terrifying because there are a whole bunch of other people who are speaking who are super smart and actually know things. You probably want to listen to them talk about the UK’s Government Digital Service, how Buzzfeed, NPR and Lynda do design and some new startup called Slack that’s all weird because it’s got liberal arts majors in it or something. And then there’s me right at the end, so people can leave early. If you want to listen to all the smart people, then you can get $50 off the registration fee by using the code HON50 which is my last name with the number 50 and not MYLASTNAME50 and definitely not HON50’); DROP TABLE USERS. 
 
So. Come see people smarter than me (like that chap Russell Davies I keep going on about) talk about awesome things they’ve done and save $50 bucks[0]. 
 
[0] http://www.howinteractiveconference.com/index.php/register - use HON50
 
—
 
9:45pm and we’re wheels down in PDX. 
 
Send me notes. I like them.
 
Best,
 
Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: s2e14: What You'll Reap; Foo Thoughts; The Next Generation
Date: August 4, 2015 at 12:06:21 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-sbwx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Sitrep  9:30pm on Monday, August 3, 2015 in San Francisco. I've been in Sebastopol for the weekend after having been invited to take part in the nth annual O'Reilly Foocamp[0]. It was my second: the first was sometime back in something like 2006 or 2007, and I have to admit it was a very nice ego stroke to be invited back again. This time, though, I very firmly resolved to not do what I did the first time, which was to be starstruck and intimidated and a) cling like a limpet mine to the people who I did know, and b) hide. Probably the best experience of that first Foo was having the courage to ask Zoe Keating for a 'cello lesson (having hit Grade 8 when I was 18 and then not really done anything with the 'cello since then) and then actually *having* a 'cello lesson with Zoe Keating, and playing Werewolf with Jane McGonigal.   This time, I decided that I had No Fucks Left To Give, and would pretty much go in all guns blazing with a loud mouth and not give a shit about voicing my opinion about things. And, I think, it worked out very nicely: unlike last time, I proposed two sessions, the first one had more people in it than there were chairs, and the second one just turned into a nice, small conversation. And I met people I didn't know, and got to talk to them. All in all, just the right level of stimulation: not too much, and not too little.   In other news, some of you are very funny wags indeed and pointed out that the Watsons from last episode had made the amazing step forward in artificial intelligence of being able to do cold readings[1] and a passable attempt at producing horoscopes. So there's that.   Lastly, I'm going to try and do a thing and write a whole week's worth of newsletters and *not mention advertising at all*. I know, right. We'll see how *that* goes.  [0] Foo Camp - Wikipedia, the free encyclopedia [1] Cold reading - Wikipedia, the free encyclopedia   1.0 What You'll Reap  My son is now at the age where I don't just have to assume that he's acting out because he misses me when I'm away traveling because he'll just out and out tell us. I hadn't really noticed or figured out yet that the reason why he didn't want to say bye-bye or give me a hug and kiss on Facetime was because he *didn't actually want to acknowledge me being around* because I'm really dense and totally not picking up the cues. But now he's just saying it: I miss you, daddy.  So, my super smart stupid idea was to deflect and do something that, as described by my wife, is just the stereotypical setup to a short science fiction story with a somewhat allegorical ending. The deal is this: I'm friends with and advise Makieworld[0], a company that amongst other things lets you design a doll in your browser or in an app and then get it 3D printed. I have one that looks like me[1] and that I dressed up for at Halloween once. OK, the doll actually looks way more like me when it's wearing glasses, which I got as an (3D printed) accessory later. But anyway, the point is that the doll looks like me and my son knows it looks like me because he's pointed at it, sitting up on a far away windowsill and said that it looks like daddy.  So, I say, hey: I think you're big enough and you're careful enough that you can play with the daddy doll. Which, you know, he does, and gives it a big hug and kisses and plays with it and wants to show it all the things. Which means that we're in Supertoys Last All Summer Long warning klaxon mode because the *other* thing about these Makie dolls is that they're designed to be *just about right* and in just the right way for you to start putting batteries and computing infrastructure in them. This is, of course, the point at which my wife effectively tells me that a terrible science fiction short story is unfolding on her mark; *mark*.   The other thing about this, the thing about technologically mediated artifacts and kids is this: once I had a toddler in the house I started being super conscious of what was going on because the damn things have minds like sponges. Ben Hammersley has a great example of this in Possible Problems of Persona Politeness[2] where just *one* of the points that he has to make is that unlike Siri, Amazon Echo/Alexa is designed as a servile female voice that you can be curt, abrupt and bark imperatives to because she doesn't respond in a hey-this-thing-is-like-a-human-mirror-neuron-triggering-way. As Hammersley points out, Alexa doesn't say thank you. She just, well, "meets your user need". So Hammersley ends up being progressively more curt and abrupt and impolite to her until the exact moment that he realises that his daughter is hoovering up every nuance of her father's interaction with the world and the people and objects in it: 
 
My daughter is too young to speak yet, but she does see and hear all of our interactions with Alexa. I worry what sort of precedent we are setting for her, in terms of her own future interactions with bots and AIs as well as with people, if she hears me being forced into impolite conversations because of the limitations of her household AI's interface. It's the computing equivalent of being rude to waitresses. We shouldn't allow it, and certainly not by lack of design. Worries about toddler screen time are nothing, compared to future worries about not inadvertently teaching your child to be rude to robots.[2]

Some more anecdata for you, which if you're a parent is probably completely unsurprising. My son, completely unprompted, has started trying to ask Siri to "play Shake It Off" but because he's about two and a half, his enunciation is fine for a human to deal with but not quite good enough for Siri to deal with. So he gets a little bit frustrated. My yoga teachers four and five year olds, though, heavily invested in the universe of Minecraft and aware, in a different way, of what Siri can do for them, are now *spending time improving their enunciation* because a Siri that understands them and what they're saying is massively empowering to them. They know the words, they just need to pronounce them right to unlock access to practically infinite knowledge.  So this is the deal: like Hammersley, I'm not even that bothered about screen time for toddlers and children anymore. I'm now skipping down further the timestream into: shit, badly designed conversational interfaces have even more of a potential effect in changing social norms or providing adaptation pressure. It's hard enough getting my son to say please and to ask nicely when he's talking to *me*, and I'd quite like it if there weren't more things in the world that were indifferent to his manners.   On top of all this - and as a result of chatting about it with Erin McKean over tea and coffee - there's the whole issue of things like:    - my Xbox 360 with Kinect needed me, at the beginning, to speak in an American English accent (ie: "Xbawks!") because the system locale was set to America because the number of people with non-majority system locale accents is an edge case, right?  - I seem to remember that if your iPhone locale is set to British, then you get British Siri Idiot Dude, but then British Siri can't do American Siri things and, maybe, expects you to speak to him in British English?   - How does that work for a Scottish accent?  - Is Siri as good at understanding Spanish-accented American English when the phone locale is set to American, but the language also set to American? What if the language is set to Spanish but the locale is set to American?  - What about people who stutter?  - And that's without even talking about the fact that Alexa's voice is by default female *and you don't even have to be nice to her*
[0] Design your own doll! | Makies
[1] The Adventures of Ad Nerd | Flickr - Photo Sharing!
[2] Possible Problems of Persona Politeness — Ben Hammersley

2.0 Foo Thoughts

A quick list of thoughts after Foo:

 - there are some problems that Silicon Valley has, I think demonstrated that it does not want to solve, or would like you to know that it is not sufficiently incentivised to solve. Not least of which is the fact that *some* leaders in the Valley *do* think that there should be a social safety net but aren't expending any combination of money/time/effort into making the social safety net work clearer/simpler/faster/more efficient and instead are working on the problem of making sure you can get a cab within two minutes
 - I still don't understand Bitcoin with a capital B as the currency. The blockchain, sure, totally, but Bitcoin is still batshit crazy. I mean, the idea of actual value accruing from nigh-on worthless processing. And I still don't see how you get from *here* - where here includes free-to-access advertising funded content to *there*, where there is a place where magical unicorns make a reasonable amount of money using magical unicorn low-transaction-processing-cost micropayments for the work that they do
 - I wish there were more people talking about gut flora 
 - Design isn't just solving problems, it's a point of view - thank *fuck* for that, because I've got points of view coming out of my ears, down my arms, through my fingers and into this keyboard right here
 - a lot more people were interested and wanted to talk about empathy than I thought, which was very, very reassuring and filled me with a bunch of hope
 - trying to figure out if there's actually a sustainable model for agency-style work in product strategy, design and delivery
 - coming away with the somewhat unshakeable feeling that if you want things to actually change, then you should damn well go out and change them instead of, say, writing about them in a newsletter. Which was... (and still is, to be perfectly honest) disconcerting. 

3.0 The Next Generation

So, Mike Bracken is moving on[0]. There's a pretty good summation of at least the big parts of how I feel about this over here[1].

[0] Onwards! | Government Digital Service
[1] Thank you, Mike Bracken - Code for America

--

OK. 10:04pm. More tomorrow. As ever, send notes! And if you liked this newsletter and you think you know other people who might like it, let them know. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: s2e13: The Watsons; 2015 (2)
Date: August 1, 2015 at 2:45:54 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-s8m5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Technically, it's Saturday 1 August, at 12:36am. But because I haven't gone to sleep yet (which itself is because of all the caffeine), this still counts as Friday July 31st's newsletter. So there. A short one today, because Foocamp. 

Content and trigger warning: Low. There are zero or trace references to advertising in this episode.

1.0 The Watsons

IBM has a thing called Watson Developer Cloud[0] that "uses cognitive computing to solve complex problems". I tried giving it yesterday's episode to see what its personality insights[1] and tone analyzer[2] would make of my off-the-cuff writing. 

Here's how the Watsons described my personality:
Your Personality*

You are inner-directed, skeptical and can be perceived as inconsiderate.

You are unconcerned with art: you are less concerned with artistic or creative activities than most people who participated in our surveys. You are intermittent: you have a hard time sticking with difficult tasks for a long period of time. And you are empathetic: you feel what others feel and are compassionate towards them.

Your choices are driven by a desire for efficiency.

You are relatively unconcerned with tradition: you care more about making your own path than following what others have done. You consider independence to guide a large part of what you do: you like to set your own goals to decide how to best achieve them.

*Compared to most people who participated in our surveys.  
For tone - and even after reading the docs, I'm still not quite sure how to read the results - the Watsons thought that 88% of yesterday's newsletter was in "social tone", of which I was "open", "agreeable" and "conscientious", and then 8% of it was in "writing tone" (240 analytical words, 28 confident words, 115 tentative ones) and only 2% "emotional" (71 cheerful words, 25 negative words and 11 anger words) which I have to admit seems a bit surprising given that I was writing about advertising, but there you go. 

If you know me, feel free to send me a note as to how right you think the Watsons were.

[0] http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/
[1] https://watson-pi-demo.mybluemix.net
[2] https://tone-analyzer-demo.mybluemix.net

x.0 2015 (2)

People are wearing tiny computers on their wrists that instantly tell them if the security of any of their online accounts has been breached[0]. A new software framework based on a distributed ledger that enforces contracts and payments has launched with a tutorial that includes creating a democratic autonomous organization[1]. Computer security is still hard, which means that the network-enabled computer in a sniper rifle has been exploited to allow remote control[2]. Aggregated location data from smartphones now helps people understand when businesses are busiest[3]. A concert was shut down because it posed a significant public safety risk despite the performer appearing via hologram[4]. We might be closer to figuring out how people who were born with 95% of their brain matter missing able to lead normal lives and score IQs over 100[5]. The U.S. Department of Defense has awarded a USD 4.3 billion contract to rebuild medical records[5]; about double the total venture funding that the world's biggest social network received[6]. A well-known actor is funding a private effort to use satellite imagery to monitor human rights abuses in Sudan[7].

[0] http://macrumors.com/2015/07/30/dashlane-one-tap-password-changer/
[1] https://www.ethereum.org
[2] http://www.wired.com/2015/07/hackers-can-disable-sniper-rifleor-change-target/
[3] https://plus.google.com/+google/posts/QY1c97V25Tz
[4] http://www.chicagotribune.com/news/local/breaking/ct-chief-keef-hologram-concert-20150725-story.html
[5] http://www.rifters.com/crawl/?p=6116
[6] https://www.crunchbase.com/organization/facebook
[7] http://www.satsentinel.org

OK. 12:45am. Bedtime. Up early for super busy weekend.

Notes, as ever, welcomed.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e12: On Advertising. Again.
Date: July 31, 2015 at 1:32:00 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-s7ap=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Thursday, 30 July, 2015. My computers are telling me that other computers think it is going to be 102 degrees fahrenheit in Portland today, which in celsius is 38.9 degrees and in English is known as "too hot, stay inside".

I'm heading down to San Francisco and then up to Sebastopol for Foo camp this weekend - if you're going to be at Foo, say hi! - and then back in the office in SF for a couple days on Monday and Tuesday before heading home. 

1.0 On Advertising. Again. 

Three things to kick this strand off. One: the amount of money spent in the UK on advertising in the first quarter of 2015 hit a record high of GBP 4.7 billion[0], of which GBP 0.5 billion was in mobile advertising  was . Two: Marketing Week thinks brands should "[focus] on the benefits of investing in digital technology rather than simply pushing money into digital advertising"[1]. Three, and this one just happened to be the most recent "traditional ad agencies are dead" article in my line of fire: why the traditional ad agency is a dying breed[2].

The first piece on the amount of money spent on advertising is just an anchor to remind myself of the sheer amount of money that's spent on advertising (4.7 billion GBP!). In the US, just *digital* ad spending is projected to hit USD 60 billion in total this year[3]. To put *that* figure in context, a back-of-the-envelope guess for a lower bound of US government technology spending (you know, for all those mediocre digital services), is around USD 80 billion (it's probably a lot, lot more).

In other words: lots of money is spent on advertising, and lots of money is spent on marketing. Let's just agree that. And the amount of money that's being spent is, broadly speaking, going up. Some people think that this is good news: in a quote that says exactly what you'd expect it to say, Tim Lefroy, chief exec of the Advertising Association says that a growing advertising spend is "to the benefit of our digital economy, creative industries and UK plc."[0]

The problem is, or, I guess, the *opportunity* here is that all that money spent on marketing and advertising (and specifically advertising and its associated media cost, I guess) is money that *isn't* being spent on making better products. 

Which is where I sheepishly just point back to Russell Davies' 2013(!) tantalising teaser that one of the implications of what's been achieved by the Government Digital Service was this concept of The Product is the Service is the Marketing[4]. 

The broad thinking behind this is made up of a few pieces. First, for the last fifty years or so, the western world has been mainly focussed on making products and then making sure that they stick out - that they're differentiated so you can tell the difference between them - using marketing[4], which has ended up with a sort of Red Queen race to win your attention so that you'll notice the products in the first place. 

There were two things going for this approach. At the start, coming up with good products was relatively hard (not that it doesn't continue to be hard, but I'd argue that it's become somewhat easier in part because of the side-effects of globalization and that technological progress has lowered the barrier to entry in most areas over the last fifty years). But it wasn't that hard to differentiate using marketing: hell, popular consensus now is that Don Draper walked into a room, smoked something, drank something, made an astute observation and the client left with a new-founded appreciation as to how their cigarettes were awesome because they were toasted. In other words, with a naive audience *and* limited avenues for attention, it was pretty easy to get those marketing messages through *and* for those messages to be acted upon.  The sheeple would see a Burma Shave outdoor ad on the drive home and then magically buy Burma Shave. 

And then slowly and inevitably, everything collapsed. Attention can't really be bought now because it's shattered and splintered and you can't just buy it from one place. On top of that, fifty years of ruthless capitalist progress and competition (of a sort) has honed the art of creative advertising to the extent that it's quite hard to do something really new that will create culture, or even worse, that it's as easy for *anyone* to do something really new that will create culture because technology only went and democratised and lowered the barrier to audiences while  you weren't looking at what the kids were doing with YouTube. What's worse is that because of those YouTubes and Twitters and Facebooks and the fact that it's easier than ever before for culture to speak unto culture, and now subculture to speak unto subculture, you can't even borrow, steal or beg from one group of people and transfer it to the other as easily as you could before because *people will notice* and won't stand for it, or will just see straight through it these days. 

So: all this money is going into marketing and advertising. And thanks to digital, it looks like even *more* money is going into marketing and advertising because now there are way more ways to market and advertise! And they promise data! Sometimes that data is real! And sometimes it isn't! But anyway: got to keep differentiating. Got to keep that edge. And marketing is easier from a business's point of view because you can always blame the agency if the marketing doesn't work. Easier to just switch agencies, right? Or easy to blame it on the shifting media landscape and blame the media partner. Or easy to blame it on Facebook. Or Google, for those text ads. Or YouTube for not having a rich enough advertising platform. 

But then there's all these upstarts. These silicon valley companies with their Facebooks and their Googles and their Apples who, a few years back, started scaring the shit out of formerly unassailable companies that were used to sitting in the top five of charts of brand recognition because they'd spent the last thirty years spending a lot of money and time on making sure that they were the coolest on the planet. And these companies were scared shitless because some dicky *computer* company that made a *website* was suddenly *cooler* than they were. Or if they weren't cooler, they were within spitting distance of being equally cool. I mean, they didn't even have celebrity endorsements or superbowl ads!

Because this is what happened: at some point, there was a discontinuity and digitally distributed technology thanks to the cheap net reached enough people. A sort of minimum-viable-userbase. We didn't quite have it in the late 90s. We started getting it in the mid 2000s, but even then it wasn't clear because the way that most people were getting online in the mid 2000s was through computers, and computers were totally still a middle class thing and not essential, not like having a phone. Until computers got cheap enough and powerful enough and - crucially - usable enough - to hide inside a phone and before you know it, everyone who had a phone ended up with a computer in their pocket connected to a giant worldwide network. Oops.

And the reason why Facebook was cool was because it served a need and it did it well (or, rather, it continues to do it *well enough* - I'm not entirely sure you could get people to agree that Facebook is "so good that people prefer to use it", if only because there aren't any viable alternatives) and that it turns out that a) twentysomethings are pretty social, plus they're totally legally allowed to do all the sex and the drinking and b) by and large, the rest of humanity is pretty social and loves talking to other people as well, even if they're younger than twentysomething or older than twentysomething. 

And it turned out that there were a bunch of things about how the world was set up that were, well, just not as great. Or, rather, not as simple, or clear, or fast as they could be. Sometimes this was just down to choice: you had to go down to the record store and then see if the album you wanted was in stock and then you had to buy it and then you had to go home to listen to it and then you couldn't really listen to it whenever you wanted. Turned out digital technology let you make it simpler and faster to listen to whatever music you wanted, whenever you wanted. You wouldn't even have to get out of bed. And this kind of stuff happened slowly: at some point, people realized that *in some cases* it actually *is* quite convenient and nice to be able to order a physical book from your bed and have it just turn up at your house *and* for it to be a bit cheaper than going to the store. Sure, you could go to the store and get it *right now*, but you'd have to stand up! And look for the car keys! Here was a brand new option that you'd never had before and the book would still turn up tomorrow. And then it turned out that a few years later it got cheap enough for you to get an electronic copy of the book in a special electronic book reading thing. And you could read whatever you wanted *straight away*! How convenient was that?! And you could *still* get a hardback copy if you wanted. 

There's nuance here. No one is saying that there's nothing nice or that there's no value in browsing a bookstore and serendipitously finding a book and being able to pick it up and leaf through it and then look at the cover and then wander over and buy it and start reading it straight away. But in some cases, where you know what you want, it's pretty simple and fast to "get a book" using a digital service, starting from the first delivery service that Amazon launched with.

I don't know how many more ways there are to say it, but software *will* eat the world, in part because people are lazy. That's not to say that they'll never go to the shops anymore, for example. Just that going to the shops will become a bit like, I don't know, sport. Or going to the theater. Or opera. Maybe in five years people will dress up to go for shopping  and there'll be special restaurants near shops so you can have a nice meal as well. But it's not just shopping: there's a whole bunch of stuff that we do, that we *have* to do, that could be easier, that could be simpler, that could be faster, now that we have this stupendous network pervasively floating around us and that is getting cheaper and cheaper to access. 

Digital is a brand new opportunity for companies - and governments and non-profits and, well, everyone - to deliver better products and services. Because digital is immediate, mostly doesn't care where you are (or can care where you are in quite a lot of detail) and works in both directions, it is easier than ever before to find out what people want (and what they really want, because you can find out all sorts of things about *how* things are being used) and then to deliver it to them. You don't even need to be delivering bits. You could just be delivering glasses. Or healthcare. Or, christ, just about anything. The point is: we can do better. 

Some companies realise this. They tend to be younger ones because they can see it already and they're not dealing with 16 different kinds of inertia[6]  - remember, inertia is a property that accrues to things that are already moving. You don't have any when you're not moving. They tend to be the ones who can say: you know what, we're going to take advantage of all this digital stuff to make something that is better and then we're *also* going to take advantage of all this digital stuff to keep making the thing we made better. And then make it better again. And just keep making it better.

Because you know what? Part of the reason why software keeps eating the rest of the world is because in a lot of cases, the rest of the world is just a bit shit. Software wouldn't be eating the world if it didn't offer more choice or better choice. It would just be there. Borders would still be around and we'd still be helping them lose money by reading their books and drinking Starbucks coffee and then not paying for the books. 

Some companies are, though, trying hard to make better products. But the problem is even worse for them! Because if they're trying to make better or more innovative products and they don't also get digital basics right, they're going to have *their* lunch eaten by another company that can just copy their innovative product *and* get digital basics right! Look, here's Russell Davies again with a pretty innovative product from Sony[7] that came out a couple years ago (and I should know, because the product was part of a very swanky, expensive, award winning brand campaign that I creative directed) but where the innovative product is shot in the face by a complete failure of execution in the digital space. This type of thing kept coming up and was *obvious* to us when working on Sony but they still wanted to tell a great story that would help differentiate the brand and explain how Sony was totally different from Samsung (and I do believe they are, apart from how useless *both* of them are at software) instead of fix things like their website. 

Look, there's this quote at the end of the Marketing Week article that recommends that maybe, just maybe, "brands" should spend money on digital tech instead of digital advertising. It's from Alistair Macrow, the CMO of McDonald's UK and Northern Europe and he says:
“If we can find ways of using the technology that people carry with them to help enhance their McDonald’s experience then that’s exactly what we’ll do.”[1]
to which I would say: please stop sounding like someone who's out of touch, because no one wants their McDonald's experience *enhanced*, and it's not about just using the technology that people carry with them. It's about the opportunity that all of digital has to make everything that McDonald's does for the people who use their products and services *better*. 

In other words, the whole phrasing of Marketing Week's article ("Should brands be focusing on digital tech rather than digital advertising?") completely misses the point. The *opportunity* is for digital tech to help massively improve the quality of their products and services, not to focus on digital tech for digital tech's sake. This whole idea of switching from digital advertising to digital tech makes it super easy for a CMO to say: oh, we're doing digital tech now! and not use that technology in service of figuring out what their customers want and being really good at giving it to them. 

[0] UK adspend reaches record high in Q1 - Campaign
[1] Should brands be focusing on digital tech rather than digital advertising? - Marketing Week (registration wall, I'm afraid)
[2] Why the traditional ad agency is a dying breed - Mashable 
[3] US Digital Ad Spending Will Approach $60 Billion This Year, with Retailers Leading the Way - eMarketer
[4] A unit of delivery - Russell Davies
[5] The strategy is delivery - Transformation Beyond Technology / London Strategy Unit
[6] Bits or pieces?: A pet favourite - Inertia - Simon Wardley
[7] Death to innovation  - Russell Davies

--

It's 11:27pm and I've got a cab taking me to the airport in about six and a half hours, so I'm not going to write any more tonight. But, there is a thing that's still knocking around in my brain that I'll probably get around to tomorrow about how I'm slightly scared that it's more lucrative to just point out problems in software than it is to actually get that software fixed. Or, in a more apparently-attributed-to-Buckminster Fuller quote, "you never chance things by fighting the existing reality. To change something, build a new model that makes the old model obsolete". Which is just a fancy way of saying that writing a newsletter isn't going to change a damn thing, going out and actually building better stuff will. Which was part of why, toward the end of my time at Wieden, while I was looking at a whole bunch of close friends in different organisations - not just GDS, thank you - actually delivering and building *better* stuff, and I was busy making comms for things where I could see *stupendously obvious avenues for massive improvement but could do nothing about them*, I knew that things really weren't going to work out. 

Anyway. Send notes. Please. I really like it when I get them, even if they're just "hi".

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e10: Celestial Emporium; Algorithmic Copyright; Up And To The Right; More Empathy; Terms
Date: July 28, 2015 at 6:09:38 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-s4eh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

1.0 Celestial Emporium

of benevolent knowledge[0] of things to write about, or rather, the things that are in a Notes file on my phone that I jot down whenever I think I might have something to think about in one of these episodes. So, today:

2.0 Algorithmic Copyright

Based on a previous post about unclear copyright in deep dreamed images because artificial intelligences don't have personhood and a follow-up note from Casey Kolderup, as well as the also previously linked James Bridle thoughts on gopro cinema[1] where a) no, the neural net in the deepdream tools isn't "alive" and isn't something to which I think authorship or ownership in copyright attaches because right now it's still a directed tool. The case, though, of the monkeyselfie, *that* is the interesting bit. As in:
The human and the non-human meet technology (the triggered camera) and – crucially – the law, a whole other kind of technology, assembled over time, a macroscope or hyperobject which no one of us can quite grasp, but within which we are all inextricably embedded.[1]
so, you know. Let's have some more examples of technological artifacts that produce output interesting and valuable to humans (because that's why we end up having these discussions - because someone wants to get out of paying a photographer for a photograph that arguably a monkey took, not the human photographer) *with a human as far out of the loop as possible*. A sort of fire-and-forget creative act that can be initiated by something that has agency in the world, but where that agency isn't recognized through personhood in law. You know, like a monkey that can decide to grab a camera and press a button. Where a human - or something that does have recognized personhood or to which a property right like copyright can accrue, like a corporation (ha!) - hasn't *told* the monkey to press the button. 

3.0 Up And To The Right

Christopher Butler wrote a bit what we're using technology for, part of which is the continuing race to a) measure all current attention, b) all future attention, c) place a value on that attention instead of the Real Problems that are facing humanity collectively[2] which you can smush against Maciej Ceglowski's Web Design: The First 100 Years[3] and also Matt Yglesias' piece about The Automation Myth[4] where he essentially calls bullshit on all the stuff our computers and IT have done over the last few decades outside of a few small areas and asks: why aren't we having to work less, then? Why all the shitty jobs? Where's the giant increase in productivity? I think you can just about make it out, but part of the premise of Yglesias' piece - compared to, say, Mason's, is that we've yet to accrue the benefits that we maybe *should* be accruing from technology if we so chose. On the one hand, you want growth moving up-and-to-the-right, not just because we can pull more people out of the poverty well, but also because... why? We want to preserve our first-world way of life? In which we get more and better stuff but that stuff just doesn't work as well as it could do? Part of this whole Gross Domestic Produce and measuring productivity thing is in the tangible benefits that accrue out of the work being done - whoever and whatever is doing the work. You can then throw all of this stuff against someone like Scott Alexander's Meditations on Moloch[5] which essentially says that there's now no way for actors *inside* the system that we're in to bust out of it because we're in a race to the bottom in a gravity well that we can't power out of. As if there's some sort of capitalism/market-based singularity or lightcone outside of which you may not escape because as sure as e=mc^2, the change or energy required in a system required to escape a capitalist/market-based one that is trending downwards is an infinite amount. Or, in otherwords: external government intervention for the things that we do not want moving up and to the right, that would otherwise inextricably now, because of the environment, move up and to the right. 
 
[0] Celestial Emporium of Benevolent Knowledge - Wikipedia - yes, that list, the one with the fabulous ones
[1] Gopro Cinema | booktwo.org - James Bridle
[2] The Last Thing We Need - Christopher Butler
[3] Web Design: The First 100 Years - Maciej Ceglowski 
[4] The automation myth: Robots aren't taking your jobs— and that's the problem - Vox
[5] Meditations On Moloch | Slate Star Codex - Scott Alexander

4.0 More Empathy

Some (brief and continued) notes on empathy where I'm keeping alive the dream that at some point I'll just knuckle down and write the book I've been promising. I'm pretty sure this thread of thought was prompted by a conversation that veterans of online community and tone of voice that Heather Champ[0], Jessamyn West[1] and co had on Twitter. 

 * Slack's tone of voice is human and jokey but never patronising or condescending to the user
 * Flickr's (evolving) tone of voice by calling your photos "masterpieces"[2] has crossed a line over into a bit weird: are they being sarcastic? Are they being genuine? Not all my photographs are masterpieces! They're just photographs! 
 * Medium's frankly bizarre assertion that the recommendations your piece on their platform don't actually count in what West accurately calls a sort of negging-by-software that's actually trying to be familiar and your friend.  
 * At the same time, I'm continuing to look at examples of government technology RFPs that presuppose large organization-changing new software that rarely talks about the people who're going to be using that software. At all. 
 * Something about what iTunes has turned into. 

[0] Heather Champ (@hchamp) | Twitter
[1] jessamyn west (@jessamyn) | Twitter
[2] Paul Bausch on Twitter: "@jessamyn ugh, text like this sets expectations. Annoyed by Flickr "masterpiece" every upload--feels condescending. http://t.co/0951yqtzLw"
[3] jessamyn west on Twitter: "Even as @Medium congratulates me for having 50 recs they’re jokily implying I didn’t “earn” them. #neggedbysoftware http://t.co/GKdoQ1FA0r"

 * Something about what iTunes has turned into. 

5.0 Terms

I bumped into a recruiter who used to work at Wieden+Kennedy, the last (and only) ad agency that I worked at and we were talking about whether I'd ever go back to advertising, to which my answer was: probably not. I mean, really, really, really, probably not. I've talked about this before, but part of the problem is that at high enough level, advertising agencies make advertising (and advertising-the-thing-that-is-made still has a center of gravity that is _talking about things_ - even if that talking has progressed to _enabling a conversation about things_ (ugh) rather than _make a thing that is talked about_, instead of "actually solve business problems"). Nah, I'd go back to an ad agency if the terms were something like this: you've got a whole bunch of super creative people who are super creative in a few media and can come up with a bunch of ideas. There are a bunch of clients who have business problems and need those problems solving. There are super interesting ways of *solving* those problems that don't involve communications and don't involve talking about those things, or helping people have conversations about those things. In other words: there's way more shit products that want good advertising than good products that need good advertising. And I'm way more interested in the shit products - or even just the moderately good ones that have have that hint of glitter embedded in the proverbial turd - that can get better and break through and *then* are good enough for people to have a conversation about them.

So when there's something like HSBC's new Secure Key campaign[0], I'm fuck-all interested if some agency has got the campaign to *tell* people about how HSBC is going to be more secure. I'm way more interested in actually *making* HSBC more secure. 

And that's not most ad agencies. Not even most of the digital agencies, either. 

[0] Secure Key: two-factor authentication | HSBC UK

--

Sigh. Now I'm a bit angry all over again. I should just not ever think about the ad industry any more.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e09: The Puppyslugs; Car Phishing; 24th Century Procurement
Date: July 27, 2015 at 6:14:03 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-s325=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

I slept for like 13 hours yesterday. And my neck still aches. 

1.0 The Puppyslugs

Boris Anthony (ex-Nokia HERE, ex Dopplr) recently wrote a piece called Puppyslugs 'R Us: Part 0[1], a story about how he got a stupid (as in: not very clever) email from Xing, a European clone of LinkedIn and turning it into reminding us that a) algorithms aren't smart - they're just a set of instructions - and b) that if you're going to try to do something smart, or even more simplistically, if you're going to try to do something that might be perceived as smart, you should probably try to be at least as smart as a puppy[1, 2, 3]. *Especially* if there are other things out there that *are* at least as smart as a puppy - or recognisable as "smart" which would, in comparison, make your thing look stupid. 

If I'm reading Anthony right (and I'm waiting on tenterhooks for Part 1 of this continuing Puppyslugs universe), he's calling us to account for a) the dumb-as-sack-of-nails puppies that we're designing and unleashing into the world while at the same time recognizing - maybe? - the slugs that our deep dreaming convolutional/recurrent neural nets are busy producing for us. 

Anthony talks about three things: situational awareness, perfect memory and contextual relevance. My understanding of what Anthony's talking about is, depending on where you sit on those three axes, you really need to figure out what it is you want your algorithmic puppy to be doing, and whether that puppy is going to go out into the world and have a clearly discernable goal that others will be able to figure out from its behaviour, and then, that it won't be, well, dumb-as-a-sack-of-nails when or if it fails to achieve that goal. But actually, I don't know. Hopefully this will just make it more likely he'll have written the next piece of the Puppyslug Manifesto by the time you read this. 

(Meanwhile, I am reading about how to seed a recurrent neural network with my entire newsletter writing output so I can go off and live a life of leisure while my laptop writes for me[4].)

[0] Puppyslugs ‘R Us: Part 0 — Medium - Boris Anthony
[1] Gardens and Zoos – Blog – BERG - Matt Jones 
[2] B.A.S.A.A.P. – Blog – BERG - Still Jones
[3] Artificial Empathy – Blog – BERG - All Hail Jones
[4] The Unreasonable Effectiveness of Recurrent Neural Networks - Andrej Karpathy

2.0 Car Phishing

Tom Cross quipped on Twitter[0] that:
If you receive a USB key in the mail from your automaker, its totally legit. Plug it into your car right away. 
Which is the observation that now that software has invaded our cars to a sufficient degree, we now have a brand new way to social engineer people into plugging random USB sticks into things. OK, so for this one, you probably need a signed file on the USB stick from Fiat/Chrysler for the car to, er, execute it, but there's nothing from stopping someone from *in principle* figuring out a whole bunch of people who have use the applicable Chrysler cars and sending a keylogger or backdoor to them on a USB stick and asking them to plug it into their computer first. Because that's a thing that will just happen now.   

[0] Tom Cross on Twitter: "If you receive a USB key in the mail from your automaker, its totally legit. Plug it into your car right away. https://t.co/ytjfAOrIBg"

3.0 24th Century Procurement

Two things, one a bit silly and the second one a bit less silly. The first: I'm re-reading the Star Trek: Next Generation Technical Manual[0, 1], and there were a couple of things that jumped out at me:

a) the Galaxy-class NCC-1701 Enterprise-D was designed using a waterfall method (ie: someone at Star Fleet wrote down a bunch of requirements and transmitted them over subspace to Utopia Planitia or the Bureau of Space Ship Design) and it took YEARS for it/them to get built; 

b) Star Fleet Procurement - which DOES exist and IS a thing *because it's in the manual and I don't care what you say about canon* - made an initial order for 6 Galaxy Class wessels with an OPTION for 6 more and I don't even.

So: let's just stop pretending that TNG is some sort of post-money socialist utopia because it really, really isn't and there really is an Admiral somewhere over in Starfleet who's like: hm, how many ships should we order this year, can we afford that? 

The second thing: I continue to be thinking about how governments buy technology and the plan is to have something to show for it sometime soon. Needless to say that there are little bits and pieces that teams can do to improve how they use technology in general, but when you get people asking why the US Federal government can't build websites[2] (it demonstrably can, in places, and it is, in the words of the Pythons, "getting better"), but some of the big bits are that government needs to give a shit about it (ie: make digital by default a priority) and the rest of the points are fine but they don't really say what might be impolitic to say, which is that: people who know how to deliver technology should probably be put in charge of how technology is delivered and what it's used for. 

[0] Star Trek: The Next Generation Technical Manual - Wikipedia, the free encyclopedia
[1] Star Trek: The Next Generation Technical Manual - Amazon 
[2] Why can’t Washington build a website?

--

That's enough for today. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e07: Oh, I Don't Know, Just Everything; A Bit About Brand Advertising Again
Date: July 23, 2015 at 10:15:03 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ryvx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Sitrep  7:50pm and I'm at home and I'm angry because I've been reading about certain states of the United States and how they treat technology and literally at this point I just cannot even it's all I can do to  ¯\_(ツ)_/¯.   1.0 Oh, I Don't Know, Just Everything  Look, here's a bunch of things that have been doing the rounds: first, Hossein Derakhshan's The Web We Have to Save[0], and then Paul Ford's Fairly Random Thoughts on Ashley Madison & the Swiftly Moving Line[1], add a bit of a quote via Bret Victor[2] from Leslie Lamport about whether we want to go down a biological or provable, logical route with the (systems of) computer systems we're building[3] and then the one-two punch of Nick Grossman's thoughts[4, 5] on regulation 2.0 followed with a chaser of the UK Government's Treasury Spending Review[6].   And yes, I'm still thinking about Paul Mason's whole thing about What Comes Next After Capitalism Will Surprise You, er, I mean, Post Capitalism.  So. Where were we.    One thing, just one point, from Derakhshan's essay about the web is the bit about it becoming more like telly and being centralized. I realized that's two things, but I'm going to treat it like one thing because what he means by television is centralized in the first place. I'm not disagreeing about the central premise of those things. We've got big things, network-effects, and agglomerations of people who each have two eyeballs (well, most of them do), and all the attention that that brings.   This is the web we made because - and I can't remember where I saw this - we (the royal people-who-were-doing-stuff-with-the-web) were busy dicking about (sorry, that was pejorative and I mean it in the nicest possible way) about stuff like standards and accessibility and all that malarkey which meant that we'd ended up with a nice interoperable system where the race to the bottom has now been wholly (well, mostly) funded by advertising money based on not just *actual* attention but the promise of future, fictional, vaporous attention that might be monetized at some point in the future so hey, as Ford points out in *his* essay, there's no incentive to make your database translucent and sufficiently private with regard to users' information because you might be able to sell that stuff later. "Data," Cosmo from Sneakers didn't say, "is Real Money now and Imaginary Money in the Future."  Against all of *this* you've got governments flailing about because the other end of digital is coming to bite them not on the ass, but literally bite their face off and leave them bleeding in the snow because now Uber won in its fight against NYC Mayor Bill de Blasio and, for certain values of "got exactly what they wanted", got exactly what they wanted in terms of not being regulated and given a free-ish pass to keep doing whatever they feel like.   *That* leads to people like Nick Grossman legitimately pointing out that hey, perhaps governments have been getting this whole regulation thing the wrong way around thanks to how computers have changed the world and *if* we want innovation *and* we want that innovation to happen quickly *and* we want to be able to try new things because if we have to ask for permission for new things those new things will never happen (I'm not *entirely* sure that's a fair argument, but we'll take the point, I guess), then we need to stop the entire asking-for-permission-before-we-do-things (i.e. can I please have a license to compete against established transit companies) and then instead create the equivalent of regulatory special-economic-zones or free-regulation-zones where governments say: "hey, this thing [insert the most recent Valley innovation that applies a significantly less-friction market to something that was previously regulated using a mobile application that by the time you read this probably won't even be a mobile application, it'll just be a conversational interface in WeChat and have over two hundred and fifty million daily active users in China before you even wake up", this thing is awesome, we're going to *pre-emptively* allow you to do it in exchange for ALL THE DATA and then we reserve the right to impose regulation upon you, you new thing that we like, if at any point ALL THE DATA starts showing us things that we think we have to regulate".  To which: hm, okay. At a general level: yes, of course governments should be getting usage data to better figure out how to deliver the services that they provide and to ensure the safety of their citizens. Part of the whole deal with regulation of cabs in the first place (and part of the story that we're being repeatedly reminded of right now) was to help your average citizen not get raped or attacked or killed in a cab. Which is nice. But here's the thing: there's the minimum-level-of-service that in America is along the lines of the We Hold These Truths To Be Self Evident and some of those things are like: hey, you should probably not run a racist cab company because we happen to think that All Men/People Are Born Equal and that's a pretty important belief that we've decided to ground our country in, recent continuing evidence to the contrary.   So yes: cities - governments - should wise up and I don't understand why, if they're not, they're not already requiring these new types of services *as a condition of operation* to submit anonymized usage data so governments can figure out how to do one of their baseline jobs which is to *ensure the security, safety and wellbeing of their citizens*.   One amusing thing about the whole Portland thing was that it was *easy* for the new digital services to provide usage data on things in the public interest like wheelchair accessibility (number of requests, time to response etc) but that for the *traditional* cab companies: 
"The data provided by the cab companies about their wheelchair accessible rides appeared particularly problematic. Only three taxi companies submitted data. The city initially reported that the cabs provided 2,000 accessible rides, but that number included medical transport rides in error, and later dropped to 640."

they couldn't or didn't even do it! Way to look bad, traditional cab companies!   Drumroll, because it's coming: surprise! It comes back to figuring out what user needs are and satisfying them! New disruptive digital services are a great way to elicit more information about what citizens need! At the same time, if our governments are going to ask for that data, *we already know how to build translucent databases* that will let us, oh, I don't know, keep track of unique incidents in a way that lets us identify trends without identifying unique individuals! We know how to do this! 
But no. 

That would be too easy. It would be too easy to just make one requirement, one simple requirement, that new digital services in certain areas provide anonymized usage data. It's not like we've got an entire security apparatus that is actively hoovering up *all of that stuff anyway*. 

So this is the thing. If the UK government wants 40% budget cuts in spending (but also, presumably preserve the semblance of a fiction of delivering at least the same or better level of service) then in theory *yes* we can do that, but only if we know what to do and where to do it. And that means gathering a *shit-tonne* of data about us collectively. Which is where everything comes to a head, of course, and how it's awesome how governments and the private sector have been building up public trust in exactly that sort of thing because oh hell, they haven't at all. 

[0] The Web We Have to Save — Matter — Medium - by Hossein Derakhshan
[1] Fairly Random Thoughts on Ashley Madison & the Swiftly Moving Line — The Message — Medium - by the Internet's Paul Ford
[2] Bret Victor, always Bret Victor
[3] Leslie Lamport: The Future of Computing: Logic or Biology - via Bret Victor
[4] Here’s the solution to the Uber and Airbnb problems — and no one will like it - Nick Grossman
[5] Regulation, the Internet Way: A Data-First Model for Establishing Trust, Safety, and Security - Nick Grossman again 
[6] Spending Review 2015: A country that lives within its means - sorry, the main report is a PDF but basically 40% cuts and the opportunity to radically reinvent public services using digital delivery
[7] 3 Big Takeaways From Portland's Data On Uber And Taxis . News | OPB

2.0 A Bit About Brand Advertising Again

Two things. One: this Land Rover thing[0] and two, this F21 (sorry, Forever21) Thread thing[1], both of which are examples of Digital Advertising and both of which are examples of Things About The Thing That Don't Strictly Make The Thing Any Better But Hey At Least You Know About It Now And That's Good Enough For Me, The Chief Marketing Officer. 

This is one of the reasons why I can't work in advertising anymore, not if the clients want that stuff and not if agencies want to make that stuff (and are correspondingly rewarded for it). I mean, the F21 Thread Screen is *nice* and beautiful but I'm not exactly sure what it does for Forever 21. And Breakfast[2] are awesome and make beautiful things and the world is undoubtedly a little bit more beautiful thanks to what they made, but again, I'm not entirely sure it, uh, Solved A Problem for Forever 21. 


[0] How many saw Land Rover Adventuregram on Instagram? via Denise Wilton
[1] F21 Thread Screen — BREAKFAST 
[2] BREAKFAST
--

So I guess that was 1584 words in about twenty minutes. And I didn't even rant about government technology procurement. YOU'RE NEXT ON MY LIST, EXPENSIVE GOVERNMENT TECHNOLOGY PROCUREMENT. LOOK OUT.

Best,

Dan

PS. Send notes, I like to receive them, even if they're just "hi". 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: s2e05: Unblocking
Date: July 21, 2015 at 11:57:03 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-rvrx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Sitrep  9:39am on Tuesday July 21. There's a draft in here that was started on 6 July. Since then I managed to get hospitalised for viral meningitis (if you're going to get meningitis, get this kind - it's the kind that won't kill you within about 48 hours) thanks to, we think, my son explosively vomiting all over me at a July 4 party. Anyway. Today's another day, then, and another chance to get back to writing every day.   1.0 Unblocking  An assortment of things that have accumulated in my head over the past couple of months, in no particular order, that will probably provoke some sort of thought, opinion, reckon,  supposition, search engine optimisation keyword:    - Gopro Cinema | booktwo.org  - James Bridle on non-humans looking at other non-humans, where we're not even in part of the picture. Both literally and metaphorically speaking. I remember him mentioning this a while back, so it's good to see that he's written it down to explore it further.   - How to publish on GOV.UK - Guidance - GOV.UK - because I've been thinking quite a bit about websites. Long story. Not really a long story. Websites! They're kind of everywhere. How do you do good ones?!   - Possible Problems of Persona Politeness — Ben Hammersley - this is a really good one from Ben because it gets into a whole bunch of things I've been interested in over the past few years: non-human agents, personalities, robots, conversational user interfaces, empathy, little-d-or-big-d-Design and, of course, what you notice when you've got a baby in the house.   - The ticking time-bomb at the heart of our big banks' computer systems (From Herald Scotland) - another one for my law-of-mediocrity file, this one via Russell Davies who, I think, ended up quoting most of the article. It's a good article. "Legacy" bank mainframe systems are fucked, they've built up too much technical debt as a result of not knowing how to approach risk and keep iterating, instead hiding their heads in the sand. If you have to deal with governments that completely believe that they're unique in having fucked-up IT, then this is the perfect kind of example to use to say: no, you're not. Lots of organizations are.   - Television Is No Longer the Screen of Choice for Kids | Media - Advertising Age - this is not a surprise, but it will continue to surprise (some) people for at least the next 10-15 years until it does that cognitive flip into Being Really Obvious For Everyone.    - Is innovation faltering - or is GDP? | StatsLife - one for the "if we define the economy to exclude certain things then we won't measure them and then what we mean when we say economy might not mean what we need it to mean anymore" file   - 3 Big Takeaways From Portland's Data On Uber And Taxis . News | OPB - Portland let in Lyft and Uber and one of the conditions was that the city got access to data to make decisions about transport as a whole. I think.   -  A Thrive/Survive Theory Of The Political Spectrum | Slate Star Codex - I've been slowly working my way through a backlog of Scott Alexander's posts at Slate Star Codex, which is pretty much my deepest engagement yet with the whole rationalism/LessWrong/EthicalAltruism movement. I'm already pretty tentative about exposing myself to this stuff in least because it means I'm closer to the Eliezer Yudkowsky memeplex. BUT! This seems like a reasonable interpretation of the differences and possible reasons for left-leaning and right-leaning ideologies.    - The end of capitalism has begun | Books | The Guardian - Paul Mason's forthcoming treatise on what might come after capitalism. Compare and contrast with Tim O'Reilly's The WTF Economy and - from what I managed to get out of Mason's piece in the Guardian - you have people like Mason trying to figure out the implications of a networked, information society that's passed a certain phase-change/tipping point. And, um, maybe, how we get to a utopian Culture.   --   9:56am. Bit a of a linkdump, this one. Still, better than nothing, I think.   Right - to work.   Best,  Dan    
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e04: Everything
Date: June 12, 2015 at 11:13:42 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-qmcl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Tuesday, 9th June 2015. Mumble thousand feet, one-third of the way back from MSP to Portland, where Portland continues to be (relatively speaking) excruciatingly hot, gearing up to greet us with 87 degree f/31 degree c weather by the time we land. We're on our way back from a short family holiday in Madison, WI to fulfill filial duty in attending a family friend's wedding (and coincidentally see how the kids I used to play video games with in Birmingham, England, twenty five years ago have changed and moved all around the world) and then stopped off in River Forest, just outside Chicago, to visit some more close friends. 
 
1.0 Everything

I got the Warren Ellis Orbital Operations klaxon this morning; a collection of his talks[1] from the past few years have been collected into a Kindle book and they're a pretty quick read. I'm left with a sort of residual feeling of everything-connectedness, of the sort of future-making that looks to make sense of the present and create what's next. There's a part in Ellis' talks that takes the time to refute the idea of a manufactured normalcy field, something that I tried my hand at last year while newslettering, aggregating a whole bunch of optimistic-and-crazy-future-things that were happening right now, in 2014. It's not that the future is here not evenly distributed (if you're a certain kind of person in your mid-thirties, that phrase has been repeatedly drilled in to you by now), but to add a different kind of atemporeality to that future: the future is *still* happening, it's *still* new stuff (yeah, ignore all that jetpack shit, ignore all that smart car stuff and the idea that a lot of this stuff is easily graspable and imaginable now that we've arguably got more processing cycles than we know what to do with in most cases). In other words: new future is still happening. 

In a piece about pop music, Ellis talks a bit about weather. About complex, interconnected, networked systems and then later on about how we can't just think about the future of spaceplanes without, well, talking about the whole system that the spaceplane is embedded in. The politics, economics and environment of it. 

[An aside: last Thursday, when we'd arrived at ORD, I stayed up late in the hotel room reading abstracts and papers from the Santa Fe institute - look, here's the Pinboard/Instapaper trail of URLs. I had gotten there by reading an Atlantic article about Bettencourt and West finding invariant scaling laws at work in how cities work. West is a British ex-physicist[3] at the Santa Fe institute, and of course the Santa Fe institute is all about "the interdisciplinary study of complex systems"; so I have all this stuff swirling about in my brain and the thing that pops into my head about Ellis and giant weather systems is *of course* Ian Malcolm, the renowned mathematician at UT Austin specialising in chaos theory[4]  and then before you know it I'm off to the Kindle edition of Jurassic Park on my laptop and then cracking jokes about fanfic where the GOV.UK engineering/development/product/service/delivery team are hired by John Hammond to build a Jurassic Park that actually works[5, 6, 7]]

Anyway, that's where we are. Stupendously complicated, interconnected systems where the feedback loop has shrunk and increased its frequency.

Some other things: you've probably already seen this, but the fractional intelligence involved in the (human-designed) Russian billboard that attempts (and not particularly successfully, and doubly so due to the whole meta-effect of ad agencies wanting people to know about their campaigns so that their campaigns are known about because the story *about* the campaign is actually more of a hook than the actual campaign itself) to advertise contraband illicitly by using computer vision to, er, hide its wares whenever the police are nearby[8]. Which, you know, fair enough: children start lying when they're around two years old, the idea of having something or knowing something and concealing it from others is, er, pretty cool and it's great to see that advertisers have brought this skill to the medium of outdoor digital interactive advertising. I suppose. 

Anyway: another thought prompted by a throwaway Ellis tidbit[9] in relation to the news that some brands (in this case, Ballantines Whisky) after having escaped the early 2000s gravitational well of "build it and they will come", slingshotted their way past "build it where the people are" have now set a heading for "deploy fleeting structures of content on other peoples' networks" by commissioning a digital magazine for Instagram. I'll get to the point, though. Ellis says this: "Used to be that porn was the vanguard of any new comms technology shift. Now it's advertising. Has been for a while. Look at where the infomercial people are going" and he's not wrong. 

You take that and you throw it against the growing realisation that maybe advertising is more insular than ever[10] and is racing in a sort of zero-sum, doubling-down "for God's sake, just do something, anything, to get ATTENTION".

I am thinking of a stupid Twitter account that at nicely spaced random intervals just reminds you to stand, because that's what Matt Haughey's documenting[11].

It is Friday evening now, at the end of three days in San Francisco in the office. I have tried to write, kind of, most days since I started on Tuesday, and haven't quite gotten around to it. I'm not sure what kind of thread I had with the Everything collection of concepts that were floating around in my head. 

On Wednesday afternoon, work colleague Mike Migurski had invited Nicholas de Monchaux[12] in to the office to give a talk that was provocatively titled Spacesuits and Cities[13] which, if you've been following along for a while, is pretty much catnip for my already hyperactive brain. The spacesuit part was a quick overview of what de Monchaux talks about in this Bldblog interview[14], of which the things that stuck in my head were variously: the invention of systems design (and thus systems thinking) during the development of the first intercontinental ballistic missiles, what then turned into the space race and, like a sort of super-catnip, the idea that such technological systems-design systems break down, or, rather, their functionality kind of goes fuzzy the closer they get to the human body. The story woven from the reality of how the first spacesuits got made is one of patterns and sewing and hand-madeness, of what happens when a system that deals in black boxes and defined inputs and outputs instead deals with something that is grown and different but, roughly, more or less, within certain tolerances, is grown: the human body. 

So at this point there's a ding-ding-ding noise and the connections between Bettencourt and West's work in the physical laws behind cities - inherently grown things - and what de Manchaux is talking about in terms of what in systems design has hitherto been a tremendously successful way of humans to get tremendously complicated things done that they we wouldn't have been able to get done otherwise, like take a human being and not only put them just inside the envelope of an environment in which they *require* technology to survive, but then to push them out a bit further on to our most visible orbiting body.

Cities, then, feel like a sort of environment or structure that is excreted by a sufficiently dense group of human beings. Get enough of us in one place and then certain things just kind of start oozing out: they are grown, and not necessarily designed. Or, even, when we *think* we're designing them, how much have we been actually mathematically designing? We think we're being all so clever with our urban design and planning but at the same time, cities have been around for *ages*, and as de Monchaux points out, in the 1960s and 1970s, when we were awed by the power of systems design and wanted to apply it to the instant environments in which we lived, RAND and HUD's experiments with urban planning were, as he lightly put it, ranged from pretty much disasters to, I suppose, "mostly harmless". 

Which is all well and good, but there's a whole bunch of you in the advertising and strategy world who read this kind of stuff and are probably wondering when I'm going to get to the point or if, indeed, I'm going to be able to stick the landing[15]. 

So here's what's in my head. The weather. Giant, complex, interconnected systems where sometimes we just want to know if it's going to be hot or cold or even just if it's going to rain. Where we've been building models and collecting data and applying them to more computing power (that's now easier to access than ever to anyone and everyone) so that we can get higher and higher resolution predictions. Could you have built a system, a model, a *something* that could've looked at Tumblr and everything else and found healthgoth? Or normcore? Because, sure, there's a massive security-military-espionage-industrial-complex, but there's also a massive brand-advertising-complex, and at some point the people in the latter group are (might?) figure out the sorts of things that they *could* do with concepts like Total Information Awareness (that, ha, haven't gone away, they've, just... well, happened anyway) that would be potentially more useful than "better targeted ads" and instead: what's going to happen next? 

Who's going to be more accurate? A Machine that can look at everything and spontaneously start recognising cats in YouTube videos? Or a bunch of coolhunter trend identifiers? Or, more realistically, a combination of the two? Or, is this just a lot of wishful thinking and wanking about what is, essentially, just another educated middle-class guy re-hashing psychohistory, a science-fictional concept that is over seventy years old? I mean, on the other hand Google Photos just rolled out a *phenomenally useful* search engine for All Your Photos Ever that, even if it *doesn't* use something like that Automatic YouTube Cat Finder, uses something *like* it to look at, recognise and categorize the content all of your photographs. 

Anyway. Things that grow versus things that are designed versus things that are designed to grow. That's a thing. 

[1] CUNNING PLANS: Talks By Warren Ellis - Kindle edition by Warren Ellis, Ed Zitron, Roger Strunk. Literature & Fiction Kindle eBooks @ Amazon.com.
[2] Scientific Proof That Cities Are Like Nothing Else in Nature - CityLab
[3] Geoffrey West Finds the Physical Laws Embedded in Human Cities | DiscoverMagazine.com
[4] List of Jurassic Park characters - Wikipedia, the free encyclopedia
[5] Dan Hon is typing on Twitter: "Please back my kickstarter fanfic where the team behind GOV.UK are hired by John Hammond to build Jurassic Park."
[6] Dan Hon is typing on Twitter: "Making Dinosaurs So Good People Prefer To Use Them."
[7] Dan Hon is typing on Twitter: "Jurassic Park 4 is all about trying to make genetically engineered dinosaurs simpler, clearer and faster."
[8] Russian billboard advertising contraband hides when it recognises cops | Naked Security
[9] ORBITAL OPERATIONS
[10] What if Cannes Lions celebrates the worst, not the best of advertising? | Media Network | The Guardian
[11] Every Inappropriate Time My Apple Watch Told Me to Stand Up
[12] Nicholas de Monchaux
[13] Instagram - Spacesuits and Cities
[14] BLDGBLOG: Spacesuit: An Interview with Nicholas de Monchaux
[15] Emails are the new blogs. - Christopher Butler

--

9:11pm on Friday June 12, 2015, and about 1,900 words of splurging. I probably could've sent this sooner. Let's see how next week goes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: s2e01: Just Start Typing
Date: May 28, 2015 at 6:24:14 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-q2up=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Well, I'm back. For now.  In the basement, standing at the standing desk, listening to It's Not Unusual to Shake It Off from Best of Bootie 2014 ("What's a mashup?" "A mashup is when you take two songs and mash them together to make an even richer explosion of musical expression.") 
 
1.0 Just Start Typing
Okay, so here's what's in my head right now: 

 - what feels like an increasingly blunt instrument of streaks (implemented normally through badges/rewards) in behaviour modification apps (Did you move enough today? Stand? Walk? Drink enough water?) that feels like it subscribes to the Jerry Seinfeld "unbroken X" model of building a habit. To which: yes, but - it relies on sufficient mental capacity to bounce back from breaking the line of Xs, to break the streak. For some situations (e.g. managing my type 2 diabetes), just *doing the thing at all* is better than not doing it at all, and *the streak doesn't matter*. So, for specific goals where a required outcome is long-term management, asking: did you do this thing or not, rather than "you've done this thing so many times" might be better.

 - Still thinking about The Watch and what it could be other than gnomic comments like "the wrist is interesting" or "notifications are the new interface" and talking to people who range from indifferent verging on the abusive (yet continue to wear it) to those who love it. 

OK.

Let's see if I can write tomorrow.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Two Hundred and Nine: Sending Signals; So We Solved Publishing; 2015 (1)
Date: March 31, 2015 at 10:39:09 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-nyup=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

"Siri, play 'Captain America' from the album 'Captain America: The Winter Soldier' and put thirty minutes on the clock."
"I'm sorry, I can't show you your clock."
"Okay, fine. Siri, set a timer for thirty minutes."
 
1.0 Sending Signals
Lunch today with Ryan Gantz, with whom I've been internet-friend-circling for the past year or so. I'm happy to report back that Gantz is indeed quite tall and that we had a bunch of super-fun super-interesting things to talk about at lunch, of which one there's one thing in particular I want to write about tonight. 

Here's some background: Gantz and I are both geeks (I feel happy to speak for him in this regard) and we were talking about things like whether or not we could justify getting the Apple Watch. For me, I have to be perfectly honest and admit that at least 50% of the purchase would be to have the Cool New Thing, but I feel more and more comfortable with admitting that I'm genuinely curious about *How The New Thing Works* and that I want to have opinions about whether and how Dark Sky taps me on my wrist to tell me if it's going to rain. (Yes, you may make a "ha, when does it *not* rain in Portland" joke, for which I will simply point you in the direction of Seattle). In other words: the Watch and how it works - not whether or not it's useful, as such, or even whether or not it works as a quantified self bauble - is what feels interesting to me right now.

But then we both remembered the article in The Verge pointing out that (maybe, maybe not) the deal with the Apple Watch is that you won't need to look or use your phone as much[1]. On one level, this is a bit bullshit because the Apple Watch won't even *work* without an iPhone, so it's not like they're cannibalising sales in the short-term. Not until battery and radio technology advances to the state where you can get full-day LTE usage out of something that's watch-sized does that feel like it'll even make sense (and, arguably, Apple are planning for that day in the same way that they planned for the iPod to eventually be succeeded by something else that did more, better, than the iPod). All that's to say is that the continuum of computing fabric will become more expansive: for some people, a thing on your wrist may be the only thing they need, for some other people, they might need a phone-sized thing, for others, a Legacy Unmanaged Computing Device that runs full-on OS X. This isn't a big deal, as far as I'm concerned.

What we *did* talk about, though, was the whole idea of not having to *look* at your phone as much any more, and there were a few things that fell out of that. It's not like people didn't used to glance at watches to see what time it was - and that such glancing could be used as an explicit or implicit signal (and be received along the same continuum) as "this person is trying to hurry me along", for example. A pointed look at a watch that is just a watch can be quite rude. 

Of course, this presupposes that the thing you're looking at is a watch. My wife and I have a thing - and I suspect we're not alone in this, and it's something that Gantz and I talked about over lunch - which is the sheer opacity to a third-party observer as to what a person who is "computing" is doing. As Gantz put it, when he was growing up, he would see his father settle down at the weekend for most of the day with a newspaper and this was an implicit signal: his dad was paying attention to a newspaper (and the bundle of meaning and associations that come with what a 'newspaper' is). Ditto for settling down with a book, or talking on the phone with someone. These are reinforcing behaviours, showing young Gantz what's important: his father valued time reading a book, reading a newspaper and talking with relatives. 

A version that my wife and I have experienced is that when we're looking at our Black Mirrors or using our laptops, from a third party observer's point of view, without looking at the screen, you have *no idea* what the computer operator is doing. They could be paying bills. They could be booking a doctor's appointment. They could be on Reddit. 

The collapse of physical forms of media with signifiers as to activity down to media-agnostic electronic devices that can perform *any* media function means that we've encountered a massive loss of context. Gantz and I could be reading books - proper, literary books! - in the same way that our fathers did, but because we're doing it on our iPhone Black Mirrors, there's no signalling as to *what* we're doing. 

Sure, we've gained the ability to shield what we're doing, plus we've gained the ability to read books in places that we'd never take books. And we've gained the ability to carry with us a gazillion hours worth of video footage and enough books for lifetimes over and that's before you even get started with games or any of the other stuff that a general-purpose computing device with a high-resolution display and sound can do for you. But we've also lost the ability to show the world - and the people in it - what we're doing. 

This reminded me of the YotaPhone[2], an Android smartphone that is a regular phone on one side, and has an e-ink display where the back of the phone would normally be. As far as I can tell from reviews, the YotaPhone is a perfectly capable phone in the way that it should technically be hard to make a *bad* Android phone these days given reference designs from your common garden OEM, but the thing that a YotaPhone *could* do is give you the choice to signal what you're doing. 

A way to do this right now in relationships is to explicitly and verbally tell the other person what it is that you're doing. "Hey, I'm going to do this now", which is pretty much a good thing to do anyway because it's not like more communication is generally a bad thing for a relationship in the first place. 

But - and this is where I thought it was a bit funny - this type of signalling "hey, I'm listening to this thing now," or "Hey, I'm reading this book now" that help people decode context that might otherwise have been inferred without explicit or verbal communication sounds *awfully* like status messages from social networks of old, or even IM presence indicators. But of course, we don't really have IM presence indicators anymore. We just message each other. All. The. Time.

So what sort of messaging *did* physical media types do? They were local, for starters. More distance than NFC, less than a Bluetooth beacon. They were typically line-of-sight. And they were vulnerable to being hacked, but that kind of thing wasn't done by most people: sure, you could hide your copy of Playboy inside of The New Yorker, but not many people did that. And how people *love* to signal, sometimes! We might not do it all the time, but we're conscious of what other people think of us - sometimes too much - and sometimes make a choice as to what book we're seen to be reading or what music we're, er, heard, listening to. 

So, anyway. A phone or a laptop that lets me show people - if I choose to - what I'm doing. That would be interesting. Someone get on that.  

[1] Apple doesn't want to talk about the real use for the Apple Watch | The Verge
[2] The YotaPhone 2 has two faces, zero gimmicks | The Verge
 2.0 So We Solved Publishing
A brief thought, this: we "solved" publishing by making it easy for anyone, anywhere, to more or less publish anything they wanted on the internet, available for all n billion of the world. Facebook made it easy for around 1.5bn people to "publish" to 1.5bn other people.

So, great. We can publish now. One of the things we're working on at Code for America isn't to make publishing *easier* - it already is easy enough, in some ways, although certainly it can be more *usable* and more *accessible* - but one of the next potential questions is this: how do we make it easy to publish the *right thing*. 

A content management system is easy. It manages content.

But making sure only useful, relevant and actionable is published? Now that would be something. 
 
3.0 2015 (1)
There's a 100mbit line going straight into the basement, split into a gigabit ethernet switch. Piped into a 30in high-definition display with speakers and cameras to match, for a bunch of instantaneous video conferencing. And then, stuff a stupendous amount of computing power into an 11in form factor, with a battery that will last the better part of a day and wireless comms that can talk to the worldwide network at around 400 megabits a second. 

Then there's this: a fleet of cars parked all around the city, hooked up to the same data network, their positions updated realtime on a map accessible to anyone, anywhere, that can be hailed and reserved. Until there's a jitter in the network, this one around a 1.5 on the Webb scale - a system outage on the car management system that means all of the cars are unresponsive. They've dropped off the network, dumb nodes now, not talking to anything. Sure, they can read the local NFC card, but the auth request tries to get out and goes... nowhere. GPRS or UMTS or whatever's down, and falling back to the voice line - routed over IP to a call center somewhere that's commercially opportunistic, no doubt, definitely not located *near* to this particular city, at any rate - just results in a no-service tone. Maybe make that a 1.7 on the Webb scale. Definitely not a 2.0 yet, because it's just a single service. Sure, that entire single service has fallen over, but it hasn't spread. Not yet, at least. 

Ok. Cancel. Reroute. Find another car. Start walking. Follow the blue line. Look up, clouds look like they're getting dark, and there it is: a push notification that it's going to start raining soon and sure enough, fifteen seconds later, the drizzle starts. Keep walking. Ask the assistant to send a message home to say the car wasn't working, that you're walking to the next one. "Okay, send it." Keep walking. Another push notification, this time from a scripted personal coach. "You rarely walk for that long! Goooo Dan!" 

This is a long walk. Longer than normal. What would it take, you wonder, for those services to collude: the scripted personal coach to talk to the Diabetes research platform to talk to the car service and decide that a daily goal hasn't been hit yet and to engineer a longer walk. Not yet, you think. Maybe this time next year.

You get to the car, tap the card and wait. No idea if the service is back up. Check the chatter: other people are complaining about it, too. The car opens and you ask for directions home as well as how long it'll take. 

Drive.

It's 2015.

--

32 minutes, 50 seconds.

Send notes! I love to get notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Two Hundred and Six: Never Forget; OK, One Thing Google Apps Does; Weird Notes
Date: March 24, 2015 at 10:49:09 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-npmp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

"Siri, start the timer," - a new experiment where I sit down and write (well, mostly write - and some formatting in a browser, of which you might have seen some opinions lately) for thirty minutes. So: 8:32pm on a Tuesday night after a day out at the new desk at the new coworking space, just kitty-corner from the old office. 
 
1.0 Never Forget
Here's a thing computers should do. Lunch with a friend today and we were talking about needing Spotlight, but for Browser Tabs - that thing where you've seen something in a browser tab, but you can't quite remember which browser tab it might have been. Some of you might have this problem. There's another related problem - or, rather, issue - where there's just *so much stuff* that I see during the day in whatever streams, that I just can't remember where I've seen it. 

Some of the streams are dumb, and search is nigh-on impossible with them. I've written about the stuff I look at during the day before, and it includes everything from two Twitter streams (one, my public account, follows a good two and a half thousand people), an RSS feed reader account, Stellar and a whole bunch of other constantly updating, things. Sure, you can fav a thing in Twitter, but if you didn't fav it, it's not that easy to find. What was the thing, with the stuff? It feels a little worse with Facebook because you can see something in the feed there and feel like you know roughly how far down it is in scroll, but the problem is, *the damn thing won't stay in the same place in the feed* because, well, the Facebook feed is opaque and you could re-load the thing in three minutes time and *not get the same thing*. That, it feels to me, is a recipe for distress, if that kind of thing distressed you.

So: dumb idea. Or it was a dumb idea when we used to have oodles of local disk space, we don't now that we have SSDs. Or rather we either have oodles of slow local storage, or not very much fast storage. Anyway: version history for everything that happens on your screen. A scrubbable, searchable timeline for anything that your display driver and compositing windowing system throws up in front of you. Remembered. Forever. Hey, what was I looking at three minutes ago? OH RIGHT. I CAN JUST SEE IT.
 
2.0 OK, One Thing Google Apps Does
It was pointed out to me that one thing Google Apps - especially Docs - *does* do, is transparent, seamless sync and history. It's super useful. I just wish that it wouldn't also *pretend* to do some other stuff like formatting. I'd almost rather it didn't even bother doing formatting rather than do it badly. Which is just another variant of whether done is better than perfect, or if done badly is better than not done at all. In my opinionated state I'm in favour of not-done-at-all right now.
 
3.0 Weird Notes
I have "Bladerunner internet dirty" scribbled in a notes file somewhere and I'm not entirely sure what it means, but I do remember being quite happy with it at the time. I *think* it means something along the lines of wanting to see more dirty LA internet futures instead of shiny internet futures. There's a whole bunch of shiny internet futures we get these days like where knowledge workers, I don't know, work their knowledge, and swoosh things about, and it's not like I'm saying it'd be fantastic to have *dystopian* dirty internet futures, more like... what would a lived-in one look like? 

It's not like we don't already have people comparing the current internet to the street - and realising that we don't need to apply some sort of clunky 3D, virtual reality metaphor to the whole thing to*actually make it look like a street*, it turns out that things can have exhibit the same behaviours and elicit similar emotions *without actually being the same thing*, or visually looking like the same thing. The internet, right now, is busy. 

This is normally the part where someone tells me to go read a Warren Ellis comic and come back when I've educated myself.

--

8:47pm. My cat is trying to eat me. It's very distracting.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Two Hundred and Five: Use Google Docs, They Said; Digital Media; Force Touch; Product + Practice
Date: March 23, 2015 at 11:01:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-nod9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
Okay, so it's been a while since I last wrote. Nearly a whole week! But now I'm sitting down to write again. So there's that. 8:31pm on Monday, March 23, 2015, after having cleaned up after messy toddler dinner (the toddler was messy; we didn't eat him messily) and done some work homework in Google Slides *of which more later*.

And now my cat is eating me because he wants me to give him his dry food.
1.0 Use Google Docs, They Said

Those of you who follow me on Twitter might occasionally see my exclaim, in anger, about the various things that Google Docs does to me on a daily basis. Things like: use several gigabytes of RAM in a Safari tab and make my machine beachball. This machine is a Late 2013 13in Retina MacBook Pro with 8GB of RAM and I'm not going to say anything more than that because what we should be focussing on here is that in 2015, where we have software that can recognise cats, and where there are real people who have not been declared mentally unfit proclaiming about the imminent danger of machine intelligence wiping out the human race, we cannot edit documents on a computer and have the cursor keep up with our typing.  The reason why is because we have decided - rightly - that collaboration is good, and right now, one of the best (better?) ways to collaborate is to use the network of networks, the internet, to allow us to collaborate with people who might not be in the same room, building, city, state, country or even relativistic frame of reference[1].  Because the internet is the least bad way to collaborate and because the web is the least bad way to make information available on the internet to lots of people, the least bad way to collaborate - and by that, I mean work on the same document at the same time with multiple people like the way Hall and Oates did when they wrote one of their more classic songs[2] - is inside a web browser.   Which means that all the office productivity software we've spent the last few decades making as, er, least bad as possible[3], we now get to do *all over again* only this time in the browser, and this time with real-time collaboration built in.   Take all of this with the regular grain of anecdata, but in my head, as I'm using Google Docs and Google Slides and Google Drive and Google Forms, I'm thinking:   - I mean, it's great and all that I can edit text *in real time* and someone else can see those edits *in real time* but the bit that's less great is when I can't type *in real time* because, well, I don't know. It's not like Word *didn't do this as well* but like I said, we're in 2015 and computers can recognise cats now as well as people, and not just white people either.    - in the vein of "done is better than perfect", where does "copying formatted text in a Google Slide will paste as properly formatted text" fall. Because where I'm sitting, which is at 8:45pm on a Monday night, I really would like formatted text to paste as formatted text. For example, if I copy a bullet, well, the expectation - and I really hope I'm not stepping out of line here - is that the pasted text would, well, be formatted as a bullet.   Google Docs/Drive/For Work/Whatever It's Called This Week does *one thing* better than any other office productivity "app" out there, and that's the collaboration part. It feels like *most other parts* are parity at best, or introduce bugs or other unexpected behaviours at worst. In other words, Google For Work is still the best thing I and my team have found for "collaboratively drafting documents" but once you want to do something more than that, you may well be losing time.   And don't get me started on search.   Or how long it took them to update the "Incoming" tab to "Shared with Me" in Drive.   So, startup people of the world. You have an opportunity to build a better piece of collaboration software: you know, Like Slack, that actually does the job that people need it to do now.   (And yes, I am looking at Poetica[4]).  Related: there are no good content management systems anymore, given what we know about the world and how it works.  [1] Although I suspect you can use Google Docs whilst on the International Space Station, it is my uninformed opinion that the latency is probably quite bad and you wouldn't want to do it.  [2] Go Google: Hall and Oates - YouTube [3] I'm looking at you, New Consistent Ribbon Experience in Microsoft Office  [4] https://poetica.com
2.0 Digital Media 
I'm just going to take this Twitter conversation[1] and leave it over here and just say that "innovative digital advertising products" is something that makes me sad these days and let me tell you the stories that I really shouldn't tell you due to confidentiality agreements. But just imagine how bad things might be, and how hard it is to get things done. 

[1] https://twitter.com/rustyk5/status/580196468075708416
 3.0 Force Touch
Feels like - without having played with it in an Apple Store on one of those new Macbook/Retina Macbook Pros that has it - it might be for haptics/force-feedback what the initial multi-touch display on the iPhone was; ie: haptics done so they make sense for everyone. 

I'm less interested in the press-harder-to-x thing than how good the feedback algorithm is. Will it feel like one of those haptic setups you get in super-specialised industries[1]? The idea that you can get some sort of physical feedback when you're using Keynote, for example, and you have snap-to-alignment turned on, is pretty intriguing. And then if you have that, then how does it translate to something like an iPhone or iPad display? I mean, look at the size of the trackpad that's currently on your laptop and then look at your phone's display.  

[1] Force Dimension - home
 
4.0 Product + Practice
And leaving this here, too: you need the right product *as well as* the right practice to get organisational change and improvement. Technology sold us on thinking that just the product would get you there, but instead now we're thinking about technology that involves change-in-practice as part of usage. 

--

8:59pm. And just as Pat Benatar's Hit Me With Your Best Shot came on, too.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Two Hundred and Four: "Everybody"; The Webb Scale; Algorithms
Date: March 17, 2015 at 11:17:18 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-nh3t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
8:36pm on Tuesday, March 17, 2015 "St. Patty's Day" in America, which is the day all branded social media accounts turn green (and orange, I suppose) and make attempts to be culturally relevant. 
1.0 "Everybody"
Via a non-work-related Slack team (how many of you are doing that? Have a shoot-the-shit, non-work-related Slack team? I'm interested, so do drop me a note), news of Leap ("Your daily commute. Redesigned")[1]. 

Leap - from looking at their website - is the latest attempt of what I'll loosely call "the tech industry" or "startups" to "disrupt" the transportation industry. The job to be done that Leap is trying to disrupt, for lack of a better term, is "[taking] the hassle out of getting to work." 

Their offering is quite simple: one "express" route (which appears to be the same as a Muni route), a simple timetable (7-10am and 5-8pm on weekdays) and "$6 for a single ride ($5 if you buy in bulk)". Or, says their website, you can "use pre-tax commuter benefits and *ride for less than $4*" (their emphasis).

The bit that feels symptomatic of a general trend in how what's broadly seen as "the tech industry" - and more specifically, the bad, non-inclusive bits of "the tech industry" is specifically where Leap says:
EVERYBODY CAN RIDE  Use your iPhone or Android to board. Or if you don't have a smartphone, you can print a paper pass.

I just want to stop here and say a) technology, in general, can be and has been shown to be a democratising and empowering force. Yay for technology! But technology gets a bad reputation when it says "everybody" and doesn't actually mean everybody, *especially* in a place like the Bay Area, where there are already inflamed tensions about integrating into an existing community.   Because here's the thing: Leap isn't for everybody. It's for commuters. It's for "getting to work". It's not for going to the doctor or dropping your kids off at daycare or trying to get to the vet or picking up groceries or getting downtown to sign up for benefits or meeting a court date.   (Also: take a look at the imagery used on the Leap site. Look at the kind of people shown. Think about the kid of jobs that those people have. Leap isn't just for *all* commuters, it's implicitly for a specific *set* of commuters: the kind of people who aren't, say, service workers. You know: people like you and me who read this newsletter and work in Business Town[2].)  I had this same issue back in episode 119[3], where Bridj (whose website has since been updated), another startup in the "making [public?] transportation better" and if you don't want to read the actual long screed, you can just tl;dr it as "when you say everyone, you better fucking well mean *everyone*".   Otherwise - a phrase that I'm learning from the new job - the optics just don't look good.  The bigger issue, of course, and the one germane to San Francisco is that this is a bunch of capital going in to fix a specific problem for a small class of people, and that public transit in San Francisco is just generally not in a good state and that maybe the entire system needs to be invested in so that it works for *everyone* and so that not insignificant amounts of capital are wasted on short-term solutions for small groups of people.  In other words: Hey, if anyone from Leap is reading? I'm calling you out. If You Don't Mean Everyone, Don't Say Everyone.
[1] Leap - Your daily commute. Redesigned.
[2] BusinessTown
[3] Episode One Hundred and Nineteen: Bridj Laziness; Deciding In Public; Terrible Tools : Things That Have Caught My Attention
 2.0 The Webb Scale

Smart fellow Matt Webb wrote a few days back about a richter scale for system outages[1] - I had originally wrote "network outages" here, but systems is much better because "systems" is bigger and more descriptive than "networks", and systems comprise networks, but anyway. 

Webb's thoughts are around quantifying the effect of various interconnected (and frequently unanticipated connections) systems falling over in various ways. He suggests, for example:
 
Less than 2.0. Not distinguishable from normal network noise, like a call dropping, webpage not loading, or a computer crash.
and at the other end,
8.0. Major network freeze, can be recovered with time or reboot; major human impact. Examples include the 2008 credit crunch where bank lending gridlock precipitated the global financial crisis; power network outage major enough to require black start; the Icelandic volcano that grounded European flights for 6.5 days.
which, mmm, is such a crunchy set of ideas it just makes you want to eat his brains. But anyway, this stuck in my head because a few days later (ie: today) I tweeted that Google Apps Is Down is the new Dog Ate My Homework.   And, related: this *is* happening more and more, and there will be more black swans. I feel a bit weird and doom-saying honestly, but over there in that not-work-Slack-team, we're busy talking about Yet Another Vulnerability in OpenSSL, another critical but unloved part of internet infrastructure, and on the drive home from the pub, the EyeSight system in our car (that is the stereoscopic camera system that does lane detection and automatic, rubber-band cruise-control and emergency stopping) turned itself off *for no reason*, and then turned itself back on *for no reason*, but at the same time as it turned back on, the Automatic[2] dongle did its happy beep which means that the connection between the car's OBD-II port and one of our iPhones over BTLE was active, and that just screams *there is a bit of software in this car that has a bug in it and something just restarted and fuck knows what it is and I bet it can't be fixed by taking the car into service* and god I don't know what to do anymore.    At least my toaster doesn't do this. Yet.
[1] A Richter scale for outages (12 Mar., 2015, at Interconnected)
[2] Automatic: An Auto Accessory to Make You a Smarter Driver
 3.0 Algorithms

A photo taken by Paul Mison of a Charles Schwab bus shelter ad that read:
Say hello to your personal investing algorithm. Introducing Schwab Intelligent Portfolios. intelligent.schwab.com [1]
This means: algorithms are something that computers do, not a series of instructions that can be carried out by any information processing platform, including humans. Algorithms are now something that people want, because hey, those high frequency trading guys make money, and they use algorithms, so I want some of that. It is not clear, from cursory reading of the intelligent.schwab.com service, what such Intelligent Portfolios are doing (but it is a nifty responsively designed site with those little circle button things that fill in whilst you scroll down the page, so, yay?)
[1] Paul Mison on Instagram: “algorithm”
--  9:10pm. And tomorrow, I think I'll write about shoes that talk too much.  Best,  Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Two Hundred And Three: Compiling Consciousness.dat; No Apple TV; Negging, but for A.I.s
Date: March 16, 2015 at 11:23:22 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-nfhl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:38pm on Thursday, 12th March 2015 on a flight back to Portland after having spent the first part of this week in the Code for America office in San Francisco. I'm tired, my wrists hurt in that somewhat irresponsible way of "I'm thirty-five and have been typing for probably the last twenty-years (really), what did you expect was going to happen if you weren't pro-active about this you idiot?" and this year's installment of seasonal allergies combined with an Exciting New Medication (with this new prescription I really do feel like a New Yorker article - there are those of you who might be able to make an educated guess as to what that might be) mean that a) I appear to have extra mucous (the allergies) and b) the nosebleeds are back (the Exciting New Medication).
Anyway.
1.0 Compiling Consciousness.dat
So let's get this out of the way first: if you're ranking (recent) movies about artificial intelligence and, say, uploading, then:  - Her[1] is "quite good and obviously SFnal whilst not really dealing with, say, the worldbuilding aspect of what happens when the equivalent of everyone-with-an-iPhone gets an artificial general intelligence";  - Transcendence[2] is *literally* silly, I am not sure where the script came from but if one result of the singularity is that we don't produce movies like Transcendence any more and see Johnny Depp ascend into a data center, then I think as a species, we can deal with that. Transcendence will make you stupider, so if you're afraid about that as a species we're getting smarter and increasing the probability (in general, and in the short term) of creating a singularity, then Transcendence is a good thing, because everyone who saw it got stupider.  - CHAPPiE[3] *is* a re-telling of Short Circuit combined with Robocop combined with, um, District 9 (it will be interesting to see what Neil Blomkamp does with a film - the purported Alien/Xenomorph-universe Fox deal - that has nothing to do with the Tetra Vaal universe that we've seen in District 9, Elysium *and* CHAPPiE now). There are genuinely silly bits in it, where Dev Chapel (who puts in a good performance of an idealistic young hacker who thinks he's created life but doesn't seem to realise what that implies and hasn't really had to deal with "the real world"), says to himself that he has terabytes of code to write and needs more red bull, and yes, there's a bit where he tries to compile consciousness.dat and, well, it doesn't work for a bit (probably because he forgot to insert a semicolon somewhere - we've all been there, especially when it's 3am), until it does and then you have consciousness.dat on a USB stick and it's an epochal moment in the history of mankind and the mundanity of the damn thing is that a) the/a next step in evolution is a single file on a USB stick, and b) it's called "consciousness.dat", and c) the only way it could be *more realistic* would be if such file was named "consciousness.dat-v2-use-this-one-final-DO-NOT-ERASE.dat". And then there are the bits that work because you put something that acts like a human baby (moves like one, talks like one) in something that isn't a human baby, it totally lights up all the structures in (most of) our brains that goes AWWWWWWW, and they're very well done indeed, and there are the bits that are just really emotional manipulation ("Please don't hurt Johnny Five!"), and then the end of the film where it actually feels like the beginning of a trilogy that would deal with real-world implications of people being able to upload. Which, you know: interesting.  - Lucy[4] is funny if only because Lucy ends up looking like some kind of IBM z-series mainframe but also downloads herself onto a USB stick, presumably also titled LUCY.DAT  All of this is essentially a segue to say that Greg Borenstein wrote a very long reply to when I wrote about hard takeoffs and my reaction to some very elementary reading around the IEEE Spectrum Yann LeCun interview. Borenstein's first point was to remind me that the most likely thing to happen in terms of a hard take-off is that, well, there won't be. LeCunn's response to the idea of a liftoff was:
"As Neil Gershenfeld has noted, the first part of asigmoid looks a lot like an exponential. It’s another way of saying that what currently looks like exponential progress is very likely to hit some limit—physical, economical, societal—then go through an inflection point, and then saturate. I’m an optimist, but I’m also a realist."
In other words (potentially inaccurate ones, but hey), part of the whole deal with the idea of a liftoff/takeoff is that progress is accelerating (it might be, but it certainly isn't doing so linearly) and that it instead goes through fits and starts. Sure if you zoom out a bit, for the last few decades we've been able to notice a sort of trend in terms of the number of transistors we can pack in a certain area, but that's all it is: it's certainly not a *law*. The idea of the takeoff relies on *assuming* that things continue as they are, and that *nothing will change*.  The second bit Borenstein wrote me about involved some more background on the Google DeepMind work. This work, if you recall, is super exciting because a thing is "learning" how to get better at certain late 70s/early 80s computer games without us having to tell it how to play them. Borenstein explains that the DeepMind work uses a technique called reinforcement learning, where you define a simple reward function ("say, how far towards the top of the screen the triangle [should] move, or how long you [should] stay alive without dying, or how many Tetris lines you make"). The algorithm then "explores the space, starting off by making random moves, but all of the time recording at each point the best reward score it earned for taking each action."   You can see how this makes sense for super early computer games - they're in a dimensionally simple universe (e.g. pong) and it's fairly simple to define the reward function (make this number bigger). Borenstein says: 
"as more and more of the space is explored and greater and greater rewards are earned it establishes a gradient through possibility space that leads to the highest possible reward."
This sentence gets points from me because it includes the phrase "possibility space" but also because it helped me remember and realise that these algorithms are (potentially?) subject to getting stuck in local maxima: ie - they can potentially continue down a path of reward that gets stuck (the usual example here is climbing up a mountain) and then get stuck at the top of that mountain without realising that there's like a way higher mountain just two clicks over.   Borenstein says that this approach - reinforcement learning - is pretty similar to genetic algorithms. The thing here is that "the process [of reinforcement learning] bears little resemblance to real world processes of learning from reward". For starters, "humans and animals learn from very few examples, whereas reinforcement learning needs an endless supply".   "Second," says Borenstein (and this is where I feel happy for understanding something), "there's a reason why this stuff gets used on videogames, particularly simple 2D ones." It turns out that this technique only works where a "dead simple, totally unambiguous reward function can be defined" that will have a direct connection to the correct actions needed to achieve it. You can't have any levels of indirection or higher-level planning here, not like what's contemplated in terms of Starcraft playing: the reason why this works in stuff like Pong and then Mario and so on is because the feedback loop is so short and so simple: push right and Mario moves right, push him too far and he dies. Once you understand this, you look at a game like, say, Portal, or any sort of 3D first-person perspective game that requires some semblance of planning or internal model representation and it feels like the approach starts to fall down.   This gets to the last point of Borenstein's epic reply to me about the state of the art in artificial cognition. The big debate, he says, is the question of symbolic vs non-symbolic learning. A long time ago, if I have my history right, back in the SHRDLU days and when Minsky ruled the world with an iron symbolic representation, concepts were encoded symbolically. That worked for a while - but only so far. Then we had an AI winter because nothing happened and we never made those plastic pals who were fun to be with. Now the pendulum has swung the other way to non-symbolic learning: "neural nets and reinforcement learning and the entire cohort that's currently ascendant are strongly on the non-symbolic side". They, as LeCun says, represent knowledge by vectors: the strength of connections in various networks, for example. These vector-based systems "have no language- or mathematical-like internal representation of the world pre-programmed into them, just simple generic units that get shaped into a new form through experience of the world."  All of which is just a long way of saying that it's probably a while before a) our Toaster decides to pick a name for itself, and b) pleads for its life if ever someone threatens it with an angle-grinder.  [1] Her (film) - Wikipedia, the free encyclopedia [2] Transcendence (2014 film) - Wikipedia, the free encyclopedia [3] Chappie (film) - Wikipedia, the free encyclopedia [4] Lucy (2014 film) - Wikipedia, the free encyclopedia
2.0 No Apple TV
Look, it's been so long since I've written a newsletter episode that not only have Apple shown off their watch and subsequently been responsible for the generation of a whole bunch of thinkpieces, but they've *also* completely not disrupted the TV world by a) not announcing an update to the Apple TV, and b) maybe but not quite disrupted the TV world by being the exclusive launch partner for HBO NOW which is a new way of getting HBO content totally different from other ways of getting HBO content (for free, via BitTorrent, for free via someone else's HBO Go password, or for money via either bits delivered over the internet, or bits stamped onto shiny discs).   I don't think there's going to be a new Apple TV for a while. Or, at least, I don't think it's worth Apple's while to do anything with the hardware - other than the price drop that they announced - mainly because the only thing that will make the Apple TV significantly better at TV is, well, doing the job it's supposed to do, which is mainly a TV job, and when it comes down to it, mainly a content play. Apple is in a radically different position that it was when it negotiated the iTunes Music Store content deals: it can't just say to everyone - hey, your stuff should be on the Apple TV. Eddie Cue's evidently got to have a different negotiating tactic, and until and unless an Apple TV can do "watching video content on my TV" better than the current mess of over-the-air, cable subscription and over-the-top subscriptions, it's too messy. Apple's all about simplification, and there isn't necessarily a simple way through the thicket of rights that we have right now.   The alternative, of course, is to just wait a few more years (trust me, the TV industry will still be there, in some form) until a whole bunch of people *don't want or need* over-the-air. Which we're starting to see already: Unbreakable Kimmy Schmidt is a thing that couldn't get a network deal, but was just fine on Netflix. We'll see more and more of that, and pretty soon the people who *want* Network TV will be in the minority.   [1] Apple’s HBO Now Deal Has Been in the Works for a Year | Re/code   
3.0 Negging, But For AIs
Via Paul Mison, two bits of 'viral' ARGish marketing to come out of current marketing festival SxSW: the first that's most likely for Terminator: Genisys[1] (presumably there is a crap-tonne of Hyundai sponsorship in this movie), and the second for Ex Machina[2], both of them movies about artificial intelligences. The Ex Machina one is interesting if only because it preys on single dudes (mostly) who want to hook up with an attractive young woman, who - twist! shock horror! - turns out to be an A.I. who isn't interested in them, which naturally leads *my* brain to the space of future pick-up artists teaching bros techniques to successfully neg A.I.s., to which my brain *then* goes to the space of such A.I.s still turning down the advances of men who've created them specifically as robo-girlfriends who'll fawn over their every action, and that's why all those dudes completely freak out.  [1] Yep, That Anti-Robot Protest At SXSW Was A Marketing Stunt [UPDATED] [2] Tinder Users at SXSW Are Falling for This Woman, but She's Not What She Appears | Adweek  --  9:20pm on Monday, March 16th, 2015. When I write it like that it sounds like the announcer to the Daily Show, which isn't a good thing because the Daily Show is funny and has a whole team of people writing on it and a good presenter and a point to it, whereas I have this newsletter and I write to it occasionally, when I get around to it. Suffice to say that I still think Newsletters Are A Thing and I've just renewed the internetofnewsletters.com domain for another two years, so I must be able to wring a little bit more out of this.  Best,  Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Two Hundred and One: The System Of The World; Hard Takeoff
Date: March 3, 2015 at 11:40:59 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mzdh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:14pm on Tuesday, March 3, 2015. The new process/practice/habit/general writing thing is in the evening: after family dinner with the toddler, after we've put him to bed, after I've cleaned up the dining room and the kitchen and put everything away. And then, some time to write.
I said before that I didn't want to write in the evenings - it took time away from my family - but it turns out that this isn't so bad, and is, like most things in life, a compromise. It's also a little bit time-constrained: it means that in practice, I only really have around forty-five minutes to an hour to write, which also isn't that bad. I get to splurge stuff out, but am kind-of prevented from just writing and writing and writing.
1.0 The System Of The World
Ha, fake-out. This is not a bit about the Neal Stephenson book that I never started, never mind got through: whilst I enjoyed Cryptonomicon, I never could get into the whole Quicksilver thing and instead did what any other reasonable person would do and just bought a proper doorstop instead.
ANYWAY, via Margaret Robertson[1], news of the game Amnesia[2] (no, not the one with pigs), which was a) a text adventure; b) that came out in 1986 and c) "[simulated] every block and street corner south of 110th Street [of Manhattan]".   A few things here. Thing the first: text interfaces are back, but they're not command lines, they're conversational interfaces. I spent lunch today catching up with Matt Haughey and besides geeking over his futuristic robot electric car, we talked lots about, well, writing and talking to things through text and what that feels like. So there's what feels like a massive body of knowledge in terms of writing not just parsers, but *interactive text*, for interactive systems, that might just be on its way back. There was a while when we thought Google was the command line for the internet, and now it's kind-of the command-line for the internet, but Apps are turning out to be a thing, because it turns out that a command line is pretty good when you've got a keyboard and sometimes you don't have a keyboard. You have a tiny thing in your hand. Or a phablet. But you know what I mean.   The second thing is this: the people who went through 1986 or at least have a passing remembrance of it are, I hope, going to have a bit of an edge because they'll have seen what worked and didn't work back then. I like this theory because I am someone who was alive in 1986 and this is a thing that is different about me than all the young people who are alive these days, who weren't alive in 1986 and this is still something that my therapist and I are working on finding new and interesting ways for me to accept.   The third thing is: we clearly had a bunch of ideas back in the 1980s (and before!) that were hard to realise to the degree that we wanted to with the technology that we had available. One easy reference point for this is stuff like Elite, which Kickstarter remake, Elite: Dangerous is more of a "the same fundamental idea and game, but gussied up with better production values" and rendered in something a little bit more - well, not *realistic* but, *high-fidelity* what with even our mobile phones having more graphics-FLOPs than we know what to do with when they're not rendering things that look like paper or casting shadows on other things that are not real. One of the reasons why I pick a thing like Elite is that it, like Amnesia, attempted to be a high-fidelity, detailed simulation on, from our current-day perspective, pretty crippled hardware. I read something like the Wikipedia writeup for Amnesia and think to myself: what would this game look like now, if we tried to remake it, but the focus wasn't on graphics and the presentation layer, but on the fidelity of the simulation? The text interface may well be something that doesn't scale, but nineteen billion dollars and however many DAUs and MAUs for Whatsapps and their assorted brethren put paid to that notion, I think. Text *is* an interface, and it's still something that's usable by lots of people, no matter how fucked up our education systems all over the world may be, and no matter how much gifs are coming to *accompany* and not supplant, our main methods of communication.   The fourth thing is what I think is the big one, and that I kind of alluded to in yesterday's episode about textual interfaces and all the copy that's going to need to be generated. There's the Strong-AI version of doing this which is: somehow, build a system that can construct the text that it needs itself, that makes sense and can be used by humans as an interface. In other words, make a thing that is smart enough to express itself in words that can be conversed with. The much more opportunistic and doable version of this in the short-to-medium term is: we already have things that are really good at parsing text and also have things that are really good (for certain values of "really good") at writing text, too: humans. So what does it look like when the architecture of the interface of an application is reams and reams of text such that, in the same way that most of our utterances are unique and never-before-said in the entire history of the universe just because of the combinatorial way our grammars work, what does it look like when we start constructing applications that we converse with - however we converse with them, whether by free text entry or smart, conversational-ish interfaces, like the kind you might use on Lark these days?
[1] https://twitter.com/ranarama/status/572841491552448512 [2] Amnesia (video game)  
2.0 Hard Takeoff
I've been doing more reading around the state of the art in artificial cognition (note: not intelligence, cognition, and not "computing" either). One of the best introductions that I read recently came to me via Greg Borenstein, a condensed and edited interview with Yan LeCun, Facebook's new-ish director of AI, in IEEE Spectrum[1].

It's good because it's a readable explanation of what convolutional neural networks are, when the idea came into being and why we're finally able to do things. It's also the thing that made me wonder if one of the reasons why the US still uses checks/cheques is because they built a stupendous neural network that *reads cheques* and processes them, whereas the Brits instead built a stupendous interbank electronic clearing system for about thirty million people. Anyway, the cheque bit is a side-issue. One of the interesting points that LeCun explains about current work with neural networks is that because they're inspired by the human visual cortex, the kind of things we've gotten them to do so far is mainly around recognising things, and not necessarily *predicting* things. The easy way, LeCun points out, to do this is to show the neural net a thing and not to train it on whether it has seen a cat or a dog, but instead to ask it what it "thinks" the scene will look like in one second's time, and then compare that with the still frame from the video of, well, what happened a second later. I think what LeCun is saying is that this is an approach that may well help with unsupervised learning: grab a bunch of video and see what a convolutional neural net can learn about the properties of the world without us having to tell it things like "hey, did you know gravity exists?"

This approach is, in a way, similar to what's described in Artificial Intelligence Goes To The Arcade[2] by Nicola Twilley in the New Yorker. The main rival to LeCun's group at NY and Facebook is the DeepMind group, formerly independent and now a part of Google. DeepMind is in the news because they have, well, "built" a neural net that has learned how to play 1980s videogames really well. Demis Hassabis' goal with DeepMind is to get to something that can play late 90s videogames - you know, StarCraft and the ilk - and not just play them in the way that our "AI" opponents play them when we don't have human players, but learn how to play them and infer the rules and essentially discover and make-up their own strategies. 

There's the argument here - that I can kind of agree with - that developing artificial cognition that can cope with the environment of a videogame is simply learning how to do the same with artificial cognition that can cope with the real world, but trying to not kill yourself with a very difficult task and starting with something a bit more achievable. Videogames are abstractions that have grown, more or less, only more detailed over the last few decades. Games now have 3D engines, model physics (and sometimes altered physics that means us humans have to learn new rules about how the world works, like: fast thing goes in portal, fast thing comes out of portal) and acoustic models, to name but a few. What better environment than the real world to try to make something that can make sense of that world? The rest, as some engineers might say, is "trivial" and just a scaling problem once you've figured out the former. 

To have come across these two articles and at the same time discover the new novel Acadia[3] by James Erwin[4]. James Erwin is an interesting fellow because he's the one who answered a Reddit question about what might happen if a modern US Marine battalion found itself transported back to the the time of the Roman Empire being ruled by Augustus Caesar[5] and ended up with a film deal. 

Anyway: suffice to say that Erwin's new novel is one that even though I haven't finished it yet, feels like it comfortably fits into the Egan/Ted Chiang subgenre of super-interesting writing about sentient software and humans having to do things. For starters, one of the character's full names is “4-Charlie osNASA 0z4ooh65 dm: 3-Azimuth.” Look, just take it as read that if you like hard science fiction with space and von-neumann probes and intrigue and what feels like a Neuromancer-esque tale of AIs flitting around the network, drones, drone warfare, and all that other stuff, just go read this book so I can talk to you about it. You know who you are.

[1] Facebook AI Director Yann LeCun on His Quest to Unleash Deep Learning and Make Machines Smarter - IEEE Spectrum
[2] What Google DeepMind Means for A.I. - The New Yorker
[3] Acadia: James Erwin: 9780978501686: Amazon.com: Books
[4] Official website for James Erwin | Dad, husband, author, screenwriter[
 Rome, Sweet Rome - Wikipedia, the free encyclopedia

--

9:38pm, because I had to go away because *someone* was too excited to go to sleep.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Two Hundred: Stock; Two Thoughts
Date: March 2, 2015 at 10:28:13 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mxr1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:54pm on Monday, 2 March 2015 and back in Portland, Oregon after having driven down from Vancouver, BC today, and episode 200. Another milestone!
1.0 Stock
I have to admit, it took me a bit longer than I wanted to hit episode two hundred. I hit my first hundred[1] newsletters on June 11, 2014 after having started on January 23. There are a whole bunch of things that I wanted to have done: for starters, my long-term archives are up on newsletter.danhon.com[2], which requires me pretty much manually copy-and-pasting from Tinyletter archives into Wordpress and then adding tags, setting the date and publishing. There is, of course, a better way of doing this - I just haven't had the time to get around to doing it yet, nor am I quite happy with, say, getting myself a TaskRabbit or setting up an MTurk "process" to do it for me. You know, like a person, or an intern. Whoever heard of newsletters having interns, anyway?
All this is to say that my long-term archive is _thirty-seven_ episodes behind now, which means that it's more difficult than usual for me to do a usual roundup (ie: the clip show) of the bits that I've most liked since episode one hundred. But I'll try anyway. Here are some of my favourite bits so far from episodes one hundred, to one hundred and ninety-nine:  
	•	Episode One Hundred and Two: Structure; The Thing About People - this one was about a piece of working I was doing - one of the first pieces of consulting work I did post-Wieden, really, and what it felt like not being part of a big human organisation anymore, or at least, not having that infrastructure around. And also, some thinking about what it means to represent people in databases.
	•	Episode One Hundred and Six: Meat Puppets; The Circuit : Things That Have Caught My Attention - lots of ranting about what would presently be called "jobs under the API curve" and yet another mention of Bruce Sterling's Maneki Neko short story.
	•	Episode One Hundred and Eight: Clarity; The Customer : Things That Have Caught My Attention - you would not believe how much I'm feeling guilty about not having figured out the Clarity Problem for Code for America yet, despite lots of staring at blank Keynote documents and text files until my forehead does the equivalent of bleeding. This is, I suspect, one of those things that will just inexplicably pop into existence one day, but still not be as good as "simpler, clearer, faster", I bet. Oh, and lots more thinking about User Needs and who your customer actually is.
	•	 Episode One Hundred and Twenty: Mundane Blue Ant; Press Square To Hack : Things That Have Caught My Attention - I started reading Pattern Recognition again (and right now, haven't really started reading Gibson's latest, yet) but there was something nice about going through and reading about Blue Ant having been inside, well, Blue Ant. 
	•	Episode One Hundred and Twenty Three: A Continued Error; Nadella; Hypermedia : Things That Have Caught My Attention - mainly, thinking about what television companies are up to these days. Those of you in the UK and still tangentially involved in or interested in what the BBC is doing, or thinks it should be doing, probably continue to have Strong Opinions. 
	•	Episode One Hundred and Thirty Two: Only 10%; This Hasn’t Benefitted Ordinary Lives As Such : Things That Have Caught My Attention - otherwise known as the General Contact Unit Productivity Gains Are Assumed
	•	Episode One Hundred and Thirty Eight: The Exoskeleton of the Internet; The Web Created the Modern Camera; Data Has Replaced God : Things That Have Caught My Attention - so the bad news is that Michael Mann's _blackhat_ was ridiculously dull and boring for something that could've been way more interesting, but the good news is that he did say "we live in the exoskeleton of the internet", which is exactly the kind of phrase that makes someone like me go all tingly. 
	•	Episode One Hundred and Fifty Eight: WATCH; BERG : Things That Have Caught My Attention - a wake for BERG.
	•	Episode One Hundred and Eighty Four: Our Crap Connected Future; Oh My God More Advertising; Echo 
	•	Episode One Hundred and Eighty Nine: Ops, Not Apps; The Internet (Of Things); Reviewing Reviewing A Year In Review - mainly for "Ops, Not Apps" which seems to be sticking around the office a bi
	•	Episode One Hundred and Ninety Four: The Internet Of Your Economic System Of Choice; Little Red Spot; Stuck - for the phrase "and then I have to *go downstairs into the basement* because *that's where my mouse pointer is* and I have to physically retrieve it so I can get on with doing whatever I was doing on the couch."
Those are some of them. There's a collection of 2014 sections that I did that I want to collect, mainly because it felt like at times it was easy to get a bit jaded (ie: do that Louis CK thing about how "everything is amazing" which is of course difficult because things are more complicated than that and things can entirely justifiably be amazing, mundane *and* shit at the same time), so an attempt to describe the world in the terms of: look, there's some seriously weird and wonderful stuff going on right now. That is, those pockets of future? They continue to out-break.
 
2.0 Two Thoughts
Just two more thoughts for tonight. 

(1) I feel like Jonathon Libov's brief survey of conversational interfaces makes interesting reading[1], and on the basis of which I've started playing around with Lark, the pseudo coach-buddy-thing-that-reads Healthkit data and then tells you about it. Lark is like a really dumb text adventure, or like a sort of Flappy-Birdish text adventure: you don't so much as have a conversation as have multiple choices (and frequently, only one choice), but the end result *feels* like a conversation, mainly because it's presented as such *and* the writing is good enough to support it. At least from my point of view. It feels like there will be some space - if not a huge one - for people who can help computers talk and write microcopy on the order of, well, lots because if interfaces like Lark catch on (and there are the suggestions that Messaging is the Next Big Thing), then there's a lot of copy that's going to need getting written. 

(2) Charlie Stross' latest on politics *and* capitalism *and* democracy in the early 21st century[2] was notable for including the observation in footnotes that capital can move more freely than labour can: so capital moves. In other words, it's not that those dirty foreigners over there are coming here and taking our jobs, it's more that our dirty money in our pension and retirement funds is a) stopping paying for our jobs, b) going on a bit of a holiday, c) employing a bunch of dirty foreigners and d) paying them to make cheap consumer electronics for us so we can pretend that our standard of living is going up. Which feels, I don't know. There is a thing here.

(3) I lied about there being just two thoughts, I saw this one on the way down. Neven Mrgan's latest Tumblr post on not-perfect-but-trying software[3] feels like another weak signal: software that doesn't try to be super smart and always correct, but software that tries to be good enough and that fails gracefully. The example he gives, I feel, is perfect: software being more able to tell you: well, I think it's option (a). But if it's not, it could be (b) or (c) and just getting out of your way, rather than the traditonal (a) or quit in some useless modal dialog that makes you want to hurl your computer out of the window and scream at Miles Dyson for inventing the neural net processor. 

[1] Futures of text | Whoops by Jonathan Libov
[2] A different cluetrain - Charlie's Diary
[3] Try - Neven Mrgan's tumbl

--

8:26pm. Back to work tomorrow. Big kisses, send notes, love you all.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Nine: Just No; Don't Do That, Either; Seeing Like The Internet
Date: February 27, 2015 at 11:27:11 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mu8l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
I started writing this on Thursday, 26 February, 2015.
1.0 Just No
There are friends of mine who remind me that a) I don't work in advertising any more, b) I don't have to think about advertising any more and c) the problems of advertising, and that advertising agencies have, are nothing that I'm being paid to think about any more.

An easier, better way of saying this if you're British is to imagine someone telling me to LEAVE IT SHARON, HE'S NOT WORTH IT, where Sharon is me, and he is the entire advertising industry. But, as those much smarter than me have observed, he wouldn't let it lie.

An even even easier, better way of saying this is simply: trigger warning - digital advertising.

And so, via a promoted tweet from The One Club[1], an august institution of advertising excellence, I excitedly click over to Entrepreneur.com to see The Four Digital Advertising Trends That Are Reshaping Advertising[2] which if you've been reading for a while you won't be surprised to hear completely did not fail in any way to disappoint my already lofty preconceptions of exactly how digital advertising and, specifically, four of its trends, were reshaping the business of advertising. 

The first, and I genuinely shit you not, was that mobile video advertising is a Big Deal. If you're to believe the author (and in this case, I don't see any reason not to), mobile video consumption has increased by 400% in the last two years, which seems fair enough. 

I'm just going to excerpt these two little bits. First is the opening sentence:
Mobile video consumption is growing rapidly and providing advertisers with a way to reach consumers when they are paying attention.
And then: 
 
Mobile video viewers are what you might call a "captive" audience. When TV commercials begin, people look down at their phones. On the bus or subway, people focus on their digital screens instead of the ads passing by in the cityscape. When radio ads begin, people change the station. However, when people are already looking at their smartphone, nothing is going to distract them. Use mobile video ads to take advantage of this undivided attention.
to which - and I may be projecting here - my assumption is that our author actually means that mobile video consumption now offers a suite of shitty products where you can *interrupt* consumers and hopefully guarantee better attention. This is pretty much reinforced in the second excerpt, where the author describes mobile video viewers as a "captive" audience, in a sign that the ad industry - in this case, and by extension, views endorsed by The One Club - isn't really interested in moving away from an interruptive model and instead is thankful that finally someone is able to deliver back to them the literally captive audience they had in the golden days of only n broadcast channels and literally fuck-else to do than watch bad tv and the ads in between them. 

You know what's fucking annoying? The fact that autoplaying videos are coming back on mobile sites. Mobile video ads aren't a way to take advantage of undivided attention, especially if they're being used as gates. They're a way to seriously piss me off. 

The second trend is essentially "hey, have you heard of Buzzfeed and Vice", ie "native advertising" to which one of my experiences at Wieden when trying to work with Buzzfeed was that they, well, weren't necessarily *excited* at the prospect of working to create native content around a certain FMCG. But, to be honest, how many of us are. The third trend is basically making up for a whole bunch of fraud and appears to say: hey, so digital advertising was making numbers up and defrauding clients to the tune of potentially $11b but hey, it's all better now, so, um, please do more? 

If there is one partial truth it's that the last trend - behavioural data - in theory should make ads that are more relevant and more effective, but again, those aren't the brand ads. This was something I spent a lot of time thinking about when I was working at Wieden: sure, the targeting is better, but when you're trying to motivate a whole bunch of people who've spent most of their lives wanting to make really great TV ads, the creative opportunity of a well-placed but relevant Facebook ad just doesn't cut it if Nike is asking for a 2 minute brand anthem spot because they want to remind everyone during the Olympics that they're number one. 

In other words, bullshit, The One Club, and bullshit Entrepreneur.com.

[1] https://twitter.com/oneshow/status/570800477409046529
[2] http://www.entrepreneur.com/article/242393 - The Four Digital Advertising Trends That Are Reshaping Advertising
2.0 Don't Do That, Either
So Code for America is in the middle of hiring for a User Researcher (hey! Are you a user researcher? Are you based in America? Do you know a user researcher who is? Do you want to help us fix government so it works better? Why not apply!) and it turns out that we use TheResumator[1], a piece of software-as-a-service that helps make the process of recruiting easier by, I dunno, helping you collaborate on job descriptions, post them, and then collect candidate information as they apply through some sort of candidate-relationship-management system, and then presumably make sure that everyone who's supposed to provides feedback from interviews and all that stuff. 

So I'm busy looking at how many views our listing has received and how many people have applied when I realise that the candidate names aren't blinded: as in, I can see the names of the people who're applying. At Code for America we take diversity seriously - I like to think that we're one of the counter-examples of Ivy-League Educated White Male Dude Tech-Related Business that's based in the Bay Area, and was reminded of, frankly, depressing stories about what happens when you blind orchestra conductor and player auditions (women actually get in), and also, more recently the news that when teachers blind-marked young boys and girls maths papers, boys outperformed girls when teachers knew pupil names, and vice versa when teachers didn't[2, 3], suggesting that teachers may have overestimated boys' abilities and underestimated girls' abilities. 

So. Simple question: Tweet at TheResumator and ask them if they have the ability to blind candidate names because that (hopefully) simple change would have a real impact on our ability to select the best candidate for a job, and work against any innate biases we might have. I have to admit here that my assumption was that Twitter would be pretty effective as a customer support and feedback channel (you know, pretty young SAAS startup, all that jazz) but only now, when I look at what they're actually using Twitter for[4], it looks like, well #brand #engagement of the detestable kind mainly because, like exclamation marks were an indicator for mental instability in Terry Pratchett's world, the overuse of #hashtags is similarly so in the world of, uh, whatever it is that entry is in Business Town. 

Anyway, here's what happened:
Me: @theresumator hey, is it possible to configure your product to blind candidate names? Would really help when trying to be non-discriminatory  theresumator: @hondanhon No, we don't have the ability to "hide" candidate info.  Me: @theresumator Any plans to?  theresumator: @hondanhon Not at this time. But you are welcome to submit feedback and suggest a feature request.

This is, of course, for those of you old enough to remember training sessions delivered on VHS tape in the mid late 90s, where as the instructor I would pause the tape and ask the audience if they had spotted the mistake that TheResumator had made. Because, my next tweet:
Me: @theresumator But I just gave you feedback and submitted a feature request.[5]
makes that pretty clear!   Look, it's not like I subscribe to some sort of weird customer entitlement thing, and it's also not clear if TheResumator knew that I was an existing customer (or that the organisation I work for is a customer), and I definitely don't want to get sidetracked into some weird black hole of talking about stupendously out-of-proportion customer entitlement issues. But. The thing that I'm getting my head around here is that literally the simplest thing to do would've been to log this as a piece of feedback and a feature request internally, say, "hey, thanks for that! We'll let our developers know" and hey, I don't have anything to write about for a newsletter episode. But instead, we get this!
Theresumator: @hondanhon @hondanhon [sic] Hi Don [sic], please submit your feedback and feature request here: success.theresumator.com/s/  Me: @TheResumator is there a reason why I have to give you feedback twice? Do you understand you're making a customer do more work? [6]
I mean, a) steady on, no need to use my Twitter handle twice there, just the once will make sure that it gets to me, and b) I'm not Don (an aside: this happens to me a lot in America and even happens when people have *typed in my email address and domain name* so I literally have no idea what's going on there) c) as a Brit, I find it hard to deal on an emotional level with URLs that contain the word "success". because honestly, so eager, and d) let's just go into this.

I have just provided feedback and a feature request, and I'm being asked to do so again, through a different form. 

Anyway, the whole exchange ended like this:
Theresumator: I will have a customer service rep submit this. For the future, this is where you can submit feedback: success.theresumator.com/s/ [7]
So, I suppose if I can try and wrap this whole sorry tweet exchange up on a positive or actionable note, it's that: (user story hat on) as-a-user, I wanted to provide feedback to the provider of a service I was using so that I could potentially see that service improve. As-a-user, I didn't give two shits about what communication platform I used to provide that feedback, and used the one that was closest to hand. The mistake on Theresumator's part appears to be - again, looking at the evidence as to how they describe and both use their Twitter account - is that it's pretty much an outbound broadcast marketing channel, and only rarely a conversational one, and in the light of the interaction I had with them, one where whoever was running "social" had nothing to do with "customer service" to which, well, hello silos. 

So. Don't do that.

[1] https://www.theresumator.com
[2] http://www.nber.org/papers/w20909 via
[3] Young children must be protected from ingrained gender stereotypes - Laura Bates, The Guardian
[4] https://twitter.com/TheResumator
[5] https://twitter.com/hondanhon/status/566285918752219138
[6] https://twitter.com/hondanhon/status/566311201299116033
[7] https://twitter.com/TheResumator/status/566313651162710016
3.0 Seeing Like The Internet
This is all I'm going to say about _that dress_: that it feels like, at least for the Western, English-speaking parts of the internet (a network with *multiple, partitioned collective intelligences being spawned, partitioned by language and character sets!) yesterday was potentially the moment when a layer of neurons got together and decided to think about white balance for a bit and come up with (at least some sort of) random firing that resulted in one of two answers as to what colours made up a certain dress. 

You can tell that I've been reading about convolutional neural networks and that I've been going back and brushing up on my elementary understanding of the visual cortex: a network of people arranged just so, all being fed the same input, all being asked: is this one thing or is this another, a web of connections between each of those nodes, with some connections being stronger than others, and then: certain connections becoming reinforced whenever Buzzfeed or Wired or Vox or whomever decides to write an Explainer about what it means to see what you think you're seeing. 

As a relatively recent parent and someone who's never actually *done* any cognitive psychology, it's interesting to see a group of people doing what a baby does. I wonder what some part of the internet is going to do next. 

--

... and I finished writing this at 9:25pm on Friday, 27 February 2015. I'm in Vancouver, BC after having spent the better part of the day driving up I-5 at various speeds between zero miles per hour and over a hundred kilometers an hour and then only at the last minute last night remembering that I'd actually need a) my passport, and b) maybe my Green Card. Anyway, I'm in Canada now. And everyone seems nice so far.

Have a good weekend,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Six: Noticings; Insecure; No Jobs But What We Make
Date: February 23, 2015 at 11:17:50 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mo2h=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Monday 23 February 2015, 8:15pm. I had two wisdom teeth out on Friday morning: general anaesthetic, not even counting back from ten and the next thing I remember is waking up in the same dentist's chair with a whole bunch of gauze in my mouth before being slowly bundled into a car and collapsing into bed at home. That meant pretty much the entire weekend lost to both getting over the anaesthetic and dealing with the Percocet, plus drinking lots of smoothies.   I did not get my CD with my CT data, so I have no animated gif of my jaw. This is disappointing, and only a little less irritating than having to deal with the consequences of two teeth being extracted from my mouth for the next five weeks or so. 
1.0 Noticings
No, not those noticin.gs[1], but instead some things that I've noticed lately. Denise Wilton popped up in my timeline with an observation about the way Twitter was letting users know about some of its new features[2] ("Wonder how many 'no's you need to give Twitter before it stops asking if you like a feature. Guess it's trying to wear me down.") which prompted me to have a think about it's not just *how* you say something, but also *when* and how often you say something, too. You can have as friendly or approachable a tone of voice as you want (and lately, it seems that pretty much the only tone of voice you're going to get in this new age of designer-driven products and services *is* an overly familiar matey one), but it doesn't really matter if the product in question is, well, a bit psychotically insistent at reminding you about what it wants to tell you.

Another person in one of my streams commented about what ad retargeting feels like, and yet another about the practice of increasing sales conversion. These are the practices that, when enacted by a person, would seem downright creepy, but we seem to tolerate in some sense when we're interacting with machines and systems. It is one thing, for example, for a salesperson at Target to greet you on your way into the store, yet another thing for another salesperson to ask a "guest" if they have been able to find everything they've been looking for so far, but I bet that none of those salespeople would follow you out through to the parking lot, follow your car, wait outside your house, and then whilst you were sat down to dinner, tap on the window and hold up a packet of crisps that you'd temporarily but in your shopping cart, but then left, and ask if you wanted to change your mind and buy them now.

The argument, of course, is that there's probably a whole bunch of data supporting the notion that reminding people about abandoned items in shopping carts result in a certain percentage increase in purchase conversion, and that, well, that's probably worth doing. Because, of course, you don't really get to quantify any potential loss of goodwill involved in repeatedly getting in touch with a customer and asking if they want to buy that thing or not.  

I don't know if my go-to example of Zappos does this. It would seem at first glance to go against their customer-service-at-all-costs attitude, but then I also similarly wouldn't be surprised - given their acquisition by Amazon - if they *did* do such a thing. As with everything, it feels a bit like nuance, but also that the environment is a little like a zero-sum game. It doesn't matter if your particular service is more respectful of peoples' time and bunches up said notifications if the environment in general is toxic. Your basket reminder may well be the straw that breaks the camel's back. 

[1] http://noticin.gs
[2] https://twitter.com/denisewilton/status/568638472455659521
2.0 Insecure
I wrote, a while back in episode 188[1], that given the Target hack and the Sony hack, what we should be afraid of is a principle of mediocrity and that we would depressingly find out that such breaches were the norm, and not in fact the exception. So the recent news that Anthem, a health insurer based in the United States, had been subject to a breach that potentially dated back to April 2014[2], isn't really surprising, just, well, more of the same. And then, the news that Lenovo had - in the name of "customer experience" - pre-installed malware on certain of its computer products that effectively (and by effectively, I actually mean: pretty damn effectively, for those who chose to take advantage) allowed bad actors to man-in-the-middle any attempted secure communication involving those machines.

I suppose what I'm getting at here is this: what are we supposed to do, or expect, when a *computer manufacturer* makes a decision in its business interests that is so clearly aligned *against its customers interests* - ie: it gets to make money off the installed malware - and is also clearly incapable of judging the risks of installing said malware? Was it purely that the profit motive was too big? Was there genuinely (and I find this hard to believe) no-one at Lenovo who could have been capable of assessing whether the malware was fit for purpose? Of course there probably was: one can only assume that they just weren't involved in the decision making to pre-install the malware in the first place. 

So not only do we have to worry about practically infinitely-resourced state-sponsored actors like the NSA and GCHQ, who at this point you have to admit: yes, I suppose it was their job to break into Gemalto and get the private keys behind as many 3 and 4G SIMs as possible, but we also have to worry about *stupendously incompetent* computer hardware manufacturers. You could look at this and say: well, IBM probably wouldn't have done that so a good fifteen years ago you still would have been safe buying a ThinkPad, but I guess another way of saying it is this: the business managers in charge of selling computer products don't understand the software systems that they're selling, and are clearly in no position to effectively audit them. You'd be forgiven for thinking that we're now stuck between the wall of an internet effectively riddled with holes, and a variety of rocks where commercial interests are presumably so strong that it's difficult to distinguish between pure incompetence and malice. 

Normally I think my position would be to not worry about this kind of stuff - that the kind of advanced persistent threat isn't really something that applies to the everyday individual, but it's clear now that, in principle, all it would take is for you to be identified as someone who's merely collateral damage. Look, if I wanted to, say, find out what Nike's product line for next year was going to be, it wouldn't be so hard to spear-phish a whole bunch of people who not only a) worked at Nike, but b) worked at their known agencies, and c) might have access to commercially sensitive information. Throw a couple of Windows exploits through emails to account managers, sit back, and Bob's pretty much your corporate intelligence officer based in China. 

[1] http://tinyletter.com/danhon/letters/episode-one-hundred-and-eighty-eight-the-new-normal
[2] Anthem Breach May Have Started in April 2014 - Krebs on Security
3.0 No Jobs But What We Make
Is Sarah Connor's election slogan where she campaigns upon a platform of a robust social safety net as well as ambitious education and re-training for a) a workforce that's going to be skilled-and-automated-out as well as a workforce that is wondering what to do with its liberal arts degrees. (Surprise: those liberal arts degrees should keep going until they find themselves at the intersection with Technology Avenue whereupon they might find some jobs on Main Street). 

Anyway, via Metafilter[1], the good news that we don't have to worry *as much as we were worrying* about robots taking away our jobs[2], due to the reason that: well, duh, the jobs should have gone away already. That said, there is a comment in the original article pointing out that Summers is stuck in 1980s land where a bunch of disintermediation hasn't taken place yet. Summers argues that whilst an end goal of automation might be a whole bunch of self-checkout lanes (it turns out that we don't really want that, but anyway) he thinks that to get from here to there, we'd need "a million people" running around migrating from one checkout system to the other, neatly avoiding the whole self-serve/software-as-a-service/"dark-IT" patch that has been growing increasingly relevant to those who thought they were in charge of corporate IT. Sure, this isn't as much a problem in places like Target, where you don't get to turn up one day to work as a cashier with your iPad in one hand and your Square reader in the other and proclaim that you've got a much cooler way of checking people out, but instead it happens *everywhere else* and instead happens to Target last. This isn't necessarily the loss of a bunch of jobs at Target as it is *not as many jobs being needed* for a whole new area of growth to happen. National Cash Register[3] - who I'm only aware of because for some reason NCR made one of the early computers (a 386DX running at 16 MHz, thanks very much) that my dad borrowed and took home from work - still pretty much sells "cash registers", in the expanded term of "point of sale systems", but as of 2014 still employees about 29,000 people. Square, on the other hand, might employee up to 1,000 people, and a cursory Googling revealed that Paypal might employ around 13,000 employees. 

Conversely, the International Business Times (yeah, I know) reckons that Blockbuster had a peak of 60,000 employees worldwide in 2004[4], whereas Netflix might employ around 2,000[5]. This isn't necessarily "automation" or "robots" getting rid of jobs, but it certainly is the impact of the machine age. And, even, there's the wonderful example of Netflix disrupting itself by inexorably moving away from its original DVD-by-mail business (arguably a hack whilst it waited for connectivity to catch up with its founder's vision) to digital delivery of video. I'm not arguing that those 60,000 jobs that Blockbuster provided employment for should come back: just pointing out that 60,000 jobs did disappear, and jobs like that will probably keep disappearing. Those 60,000 retail jobs first went to centralised distribution centers, and then slowly faded away as it turned out that you didn't need to stuff a disc in the mail, you could just have servers stuff bits down a pipe instead. 

(An idle thought: is the availability of YouTube instrumental tutorials a net good thing or bad thing for music teacher jobs? One of the examples of high-speed internet links was always the remote teaching thing, but I can easily make the argument in my head that for a lot of people, non-interactive recorded video is good enough for learning an instrument and that it might, instead, widen participation - for musical instruments where access is cheap and available enough - to result in more demand for music teachers. Anyway)

I don't really see how this is going to go away. Part of the argument with all of this replace-humans-with-automation/APIs is that we'll end up with more leisure time, but I don't strictly see that happening. It feels like it's quite easy for the available work to take as much time as it needs to; that work will expand to fill the available time. I saw this at my time with Wieden - there were certain clients who would quite happily noodle away on a brief for, say, a stupendously large sporting event, and only approve script until the very last minute whereas other clients would be happy to have something shot and in the can up to 18 months prior. 

[1] Everyone should take it easy on the robot stuff for a while - ennui.bz, Metafilter
[2] The One Where Larry Summers Demolished the Robots and Skills Arguments - Mike Konczal
[3] NCR - Wikipedia
[4] The Sad End Of Blockbuster Video: The Onetime $5 Billion Company Is Being Liquidated As Competition From Online Giants Netflix And Hulu Prove All Too Much For The Iconic Brand
 - IB Times, and what a ridiculously long headline
[5] Netflix - Wikipedia

--

9:16pm. More of a petering out there than a satisfying conclusion, I feel.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Five:
Date: February 19, 2015 at 9:56:02 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mjph=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
7:06pm, in the basement in the work cave, stood in front of the giant Thunderbolt display on a weeknight after a decidedly "meh" day at work. The kind of day where you kind of get things done but there isn't just any oomph and lots of things just *happen* to your work diary. Side note: Americans snigger in confusion at the British use of "diary" in a work context (as in: can you find some time to schedule that in my feelings journal?)

Anyway. Unlike some other days, I don't have a text file full of things that are interesting or that are on my mind at the moment. To paraphrase Tony Curtis, I'm just a boy, standing in front of a keyboard, hitting it hoping something intelligible comes out. To that end:
1.0 The Process
This is what the Process is like: it's looking at a numbered text file (in this case, 195.txt) in a newsletters folder that's synced in Dropbox and having a look at it in TextWrangler. Scratch that, that's what the process is normally, this time around, I'm writing straight into Tinyletter's compose interface, something that I'm not entirely happy with because the formatting never comes out right. The last few newsletter episodes I've been writing in Textwrangler directly - HTML tags and all - and then pasting into the compose interface. 

But anyway, perhaps that's too much detail. Sometimes I just paste links or thoughts into those numbered text documents - and there's only ever the most recent one, not any in the future. Any links or thoughts that don't get used, just get punted to the next one. A sort of running order, if you will, and I get to move things around. And then I do stuff like look at stellar.io[1], Jason Kottke's pseudo-social network based around the things people fav as a way to discover, oh, I don't know. Weak signals. I mean, you can look at the people I follow[2] on Stellar to see the kind of people whose brains I think are interesting - what are the things that these people have faved, and that kind of thing. They're like another layer of my exobrain, some sort of social tinglyness detector, a sort of spidey-sense for making sense of the world. 

And then I might do what I normally do each day, which is look through all of the RSS feeds that I still subscribe to via Newsblur[3]. I guess it's interesting that so far, both of those tools are things that I pay for. I'm a relatively well compensated person and I can afford to pay for stuff that's useful to me, so I don't mind paying for an RSS reader (thanks, Google) and I certainly don't mind supporting someone like Kottke, who's made something like Stellar that I visit multiple times a day (and also appears on my iPhone's home screen as a web app icon). Newsblur reckons that I subscribe to 271 RSS feeds, which strikes me as not very many, certainly not as many as I used to subscribe to back in the heady heights of RSS, back in the days of NetNewsWire and reading Scripting.com and reading about The Thing Dave Winer Had Said That Had Offended People This Time. I don't treat my RSS feeds as a sort of must-read list - more something that I dip into and dip out of. Newsblur also reckons that there are 3,749 somethings and 21 somethings, and I have no idea what that means. I'm pretty resigned (and blasé, I reckon) about the fact that things happen in the stream or river of news and then they might just pass me by. Stellar is actually a good way of picking that up - if my friends - or the people I follow - find something interesting, then there's a good chance that I might, too. 

A guilty secret that I have is that I kind of obsessively hate-read Hacker News[4], if only to find out what's currently occupying the group mind of *that* particular community, but also because it does surface interesting links now and then. And it's the links that are always interesting (unless, of course, you go and read the comments in which case it's pretty much a crapshoot). Sorry, Hacker News community, but you've kind of built a stereotype for yourselves. I guess I feel like there's been a *bit* of an improvement in terms of how inclusive that community has been over the last 12-18 months (mainly because of the slow but inexorable progress that I think the tech community *has* been making over the last 12-18 months), but certainly nothing to write home about. 

I don't think stuff on Facebook ever really triggers thoughts that I end up writing about in here. Sorry, Facebook. But you're not that kind of network, and you don't offer that kind of utility to me. 

Sometimes - sometimes! - if I'm desperate I'll take a look through my Pinboard[5], which at the moment is mostly full of things that I've faved on Twitter and things I've instapapered (which is sort of becoming a substitute for bookmarking/pinning on Pinboard itself because I'm happy to say out loud that I don't actually *ever* get around to reading most of the stuff I Instapaper, it's mainly so that I have an archive of it somewhere). The reason for looking in my Pinboard feed is that honestly I have no idea what I've found interesting over the past 24 hours or so and feel like, in general, I have an attention span that's down at the planck scale. Demonstrably, it isn't, otherwise I wouldn't be writing this, so perhaps it's more that I just can't remember things. No matter: I outsource all that to Maciej Ceglowski. If I don't find anything interesting that jogs my memory in Pinboard, then I'll turn to my Pinboard network which, like my Stellar flow, is a collection of Pinboard bookmarks from people I find interesting. But to be perfectly honest, I just looked at that page right now to see if I could link you to it, and I can't, and I also can't even remember the last time I looked at that page. So I guess I don't do that very often.

Oh, and Twitter, I suppose. 

I have two Twitter accounts. One for friends - that holds quite steady at the Dunbar number - and a "public". Friends have said that they're sometimes surprised at where I draw the line between "public" and private, that I may sometimes seem a little reckless with what I feel able to say publicly. Perhaps that's a reflection of whatever privilege I might enjoy - I've never been in trouble for anything I've tweeted. I've certainly *turned myself in* about something I've tweeted, and was then told that it wasn't a problem. I am, I've realised, the kind of person who is able to get away with saying things - at least, so far - and it seems to rebound (so far, again) in a positive fashion. I know it's not like that for most people. 

I might see something on Twitter - probably via my public account, which is the noisy stream one where I accept I won't see everything and apparently follows 2,358 people. That's a silly number of people to follow. I went through a process a few months ago when I tried really hard to be more diverse in the people I follow, and I'm still trying to do that. It's still mainly white dudes, unfortunately, but I think I'm making progress. Anyway, occasionally there'll be something that I see in the stream that grabs my attention and before you know it I've stuck something in a text file or, even better, I've just started writing.  

I've gotten in trouble - or at least, gotten valid criticism - about the actual writing process. Some of you have probably noticed that the way I write this newsletter is more like speech than prose writing - that it's not like I'm sitting down and constructing an argument, instead, that I'm pretty much typing as I'm thinking out loud. I'm just not audibly saying the words. People have said to me that you can follow an argument or position being developed just by following the writing, and that it's pretty interesting to see that happen almost as if I'm talking. It also appears to be the way that I figure stuff out - only by "saying" things do I seem to get that feedback loop, which probably means that I need to go back and read up on why Sapir-Whorf is wrong again. 

Anyway. The writing is quick and stream of consciousness and not edited. And that means mistakes. And it also means that I've had that valid criticism about how the stream of consciousness - by design - reflects innate biases that I have, whether I like those biases or not, and definitely whether or not I see those biases as being positive parts of my character. It has meant that over the last few months, I've tried to slow down a bit. There's a tension between writing this for me: which I maintain that I have always done, and recognising that I have nearly 2,000 subscribers to this newsletter which, if we're being completely honest, is pretty impressive for something where I just spew out bits of my brain into a text field. (And, if you've seen the subscriber list to this newsletter, which hopefully you haven't, because it means that Tinyletter have a pretty major security breach, then you'd be surprised - as I am - at exactly who *is* subscribed to this list). 

But, ultimately, that's what the process is. I don't make claims to write about anything other than what's on my mind at the moment, so that's why I can be ranting and raving about the 'californian ideology' for a few episodes and then go off on one about digital transformation before having a go at a terribly executed ad campaign to just getting Annoyed At Something. 

These are all just reckons, and I think something important to do is to take them all with a hefty block of salt. I try to remind you all that they're just what I *think* and that in some cases whilst there might be evidence on paper that I'm "smart" somewhere, I actually don't really know that much about what I'm talking about. I might be good at *writing* about what I'm talking about, but being persuasive or being interesting doesn't necessarily mean that you're right. 

Anyway, again. That's what happens. I just come up with something to write. I have no idea how many bits-per-second of stimulus the human brain gets, and when you include all the internal stimulus it can generate through just recalling stuff, never mind relevant stuff, I suppose all I'm doing when I write this is just reacting to stimulus. Which is in a way, a terribly reductionist and depressing way to look at things.

[1] stellar.io - you can't sign up at the moment, I think you have to be invited. Tell you what, email me and I'll use up *one* of my previous invitations. 
[2] http://stellar.io/danhon/following
[3] https://newsblur.com
[4] https://news.ycombinator.com
[5] https://pinboard.in/u:danhon
2.0 A Watch For Your Car For The Mind
There are several things floating around in my head. One is that it's getting impossible (not really, but you know what I mean) to avoid hearing about the imminent launch of the Apple WATCH. The second is a tweet from giant mind on planet Earth Ian Bogost, who said "The iPad is technology + design. It doesn't become "liberal arts" on account of somebody can read a book on it."[1] which, well, yes. The third is this weird rumour that Apple is thinking about making a car, which prompted me to make an overly labored joke about how one should skate to where transport is going, not where transport has been[2], which is trying to say, but in 140 characters: a) are cars really so bad that Apple needs to show us how to make a car? (Answer: no, not as bad as they were in 2007, when there was no iPhone, because Tesla exists), b) does Apple think that it can beat Tesla? (Maybe, who knows? They certainly know how to make lots of complicated things, and appear to have the whole supply-chain thing down pat) and c) what is it with cars anyway? In the same way that AI always seems to be about 50 years away, are we *really* 50 years away from driverless cars this time?

And the whole WATCH thing. I am persuaded that there is an end-game here, in that people "want" (in the way that people can be said to want these things) the sort of science-fictional magic "terminal" devices that you get in settings like Iain M. Banks' culture novels where essentially you have a piece of jewelry that's a network connected node to a stupendously powerful set of computing resources and Minds. One of the things that I'm profoundly disappointed about in terms of the WATCH is that it falls into this whole area of:

a) things;
b) wearables;
c) things that sense;
d) things with screens; and
e) that are connected.

Other people have said it better than me, but "wearables" is what you get as a term when you have an industry that has never really made anything wearable and has mainly started in making room-sized things, and then desk sized things, and then luggable sized things, and then balance-on-your-lap sized things, and then, put-in-your pocket things, and has suddenly realised that thanks to a "law" which is more of an observation and lately even more of a prayer, the things that they are making are now small enough not just to be *carried* by people every day, but actually to be part of something far more intimate and closer to our person. 

What's confusing is that one of the things that's super interesting is: things that sense that can talk. Never mind the whole thing about things that can sense and that tattle and tell tales on you - yes, we've talked about that and we can keep coming back to it because things will always tattle on you unless you made them yourself - there's no reason right now for them *not* to tattle on you. To me, that's what's interest in smartness: what happens when a thing that was dumb becomes smart. What does that mean? In that infuriating Matt Jones/Tom Coates/Matt Webb way, what happens when these things become 'as smart as a puppy'? In other words, when was the last time you looked at a smart thing and you thought: oh, that's interesting. They're using smartness *as a material* and you get a visceral, innate sense of the smartness of the thing? You can look at a thing now and say: oh yes, it's got the *steel* qualia or, let's be perfectly honest here, if you're reading this newsletter there's a fair chance that you have something relatively close to hand that you can say has the *made of milled aircraft grade aluminium* qualia. Do you know of anything made, anything designed by humans, that absolutely has the *made of smart* qualia? What might that thing look like?

But what's frustrating for me is a preoccupation in the "wearable" area of things that most things need to have a screen. Smartness doesn't mean having to have a screen. If we had Smart Dogs right now, they'd have screens instead of ears, and they wouldn't be able to bark in a somewhat indecipherable but yet still full of meaning way, they'd just have a whole bunch of notification icons that would come out of their butt and would all be red circles with numbers in them. In this way, one of the most interesting things to me about the Apple WATCH isn't the screen - boring - and isn't even the Digital Crown - also boring from my point of view until I've used it - but instead the amusingly named Taptic Engine - the thing that essentially sounds like a finely tuned vibration motor that will creepily feel like someone tapping on your wrist BUT THE TWIST IS THE TAPPING IS COMING FROM INSIDE THE WATCH.

Screens, as I think I've said before, are lazy. Imagine a world where every animal didn't have a face and instead had a screen with icons on it and text that you had to read. Apart from being a logically inconsistent and impossible world (I mean really, how would such animals evolve?), what a *tiresome* world it would be, too. You'd have to *read* all the time. I would love, for example, just to see, just to see someone fucking dare to do it, a smart watch where all it did was display different animated gifs. Of course, in *this* world, we're not allowed to have such a thing because Jesus Christ can you imagine how much that would cost in copyright clearance. But seriously, Tumblr, get on that right now. 

This is why I like GERTY from Duncan Jones' Moon: that non uncanny valley of hacking at the backdoor vulnerability of us reading emotion and intent and agency into anything that even *looks* like it has a face, as opposed to having to *read* shit, made that movie mean so much more, even if it was voiced by the power-hungry Kevin Spacy. 

[1] https://twitter.com/ibogost/status/568205725832511488
[2] https://twitter.com/hondanhon/status/568497187480604673

--

Okay. 7:55pm. I just kind of stopped. 2,942 words tonight. See you all tomorrow.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Four: The Internet Of Your Economic System Of Choice; Little Red Spot; Stuck
Date: February 18, 2015 at 10:01:09 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-migx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:13pm on Wednesday, 18 February 2015. The funnest thing today (for certain values of fun) was getting a CT scan of my head (more specifically, my jaw) as a result of my American dentist being a) surprised that I only had two wisdom teeth - which was a suprise to me because I thought I had none, and b) further being surprised and somewhat alarmed that one of my wisdom teeth had effectively gone rogue and was proceeding to move, albeit practically imperceptibly, towards one of my molars resulting in a sort of slow-motion dental car crash. Only made out of enamel instead of steel and aluminium and probably without the benefit of crumple zones.
I digress. The good thing about getting the CT scan of my head/jaw is that I'm going to get rid of two wisdom teeth (I think that's good?), but the *even better* thing is that after I've paid whatever my dental/medical insurance deems I need to pay for the consult and procedure, I get a CD with my CT data. Which means I can make an animated gif of my jaw bone structure rotating. How cool is that?! I mean, probably not three hundred and fifty dollars worth of cool. Or maybe. It's hard to tell these days.
In other words, protip: any time you get a scan of anything, ask for a copy. You may well end up being charged up the wazoo thanks to the opacity of the charging structure of your relevant local healthcare regime, but you might also end up with a nifty animated gif that no-one else has. Think of it as a family keepsake.
1.0 The Internet Of Your Economic System of Choice
The collision of two separate replies to yesterday's newsletter and the Internet of Capitalism, rather than the Internet of Things being the thing that we might want to be fearful of.
The first, from the Internet's Tom Hume[1], pointed out that two things: a) that the Internet of Things is a tool that we're using at the moment - or, rather, that the trend of increasing connectivity to tend toward the omnipresent is the lens through which we're reflecting other current fears. Replace capitalism with $dominant_economic_system, or whatever then, as Hume says, "it's the story, not the fears to blame"; and b) reminding us of the age-old vision of micropayments all over the information superhighway and being literally nickel-and-dimed for every single transaction that we conduct, including all of the ones conduct on our behalf down in the API plumbing layers that enable the modern web as we know it. Hume pointed out to me that despite this vision being at least decades old, it still hasn't come to pass.
Okay, I agree with the former: Ubik was a story that Dick could use to tell a cautionary tale about the extension of capitalism and contract-based transactions into every facet of life, however small and detailed. A sort of "what if capitalism and contracts, but too much"[2] style Mallory Ortberg retort of Black Mirror, I suppose. And Black Mirror *does* - well, I think it does, because I haven't seen the Christmas Special yet - cover that "what if things were connected to the internet, but too much" story. The truth, as reasonable human beings are supposed to consider, will always lie (or hopefully lie) somewhere in between.
I suppose the point is this: does Bitcoin actually make that doomsday clock of micropayments everywhere, for everything, move closer to midnight, stay still, or move away? Are we closer to a wonderful libertarian ideal of being able to assess the value of something on an instantaneous basis, to have markets everywhere and have intelligent agents negotiate on our behalf for fractions of a BTC? History indicates no, but then history has a funny ability of being half-wrong about things, and half-right about others.
The second reply came from Paul Mison, who pointed me in the direction of two quotes. First, here's Kim Stanley Robinson who of late is apparently turning out to be some sort of surrogate father figure for "get your ass to Mars" Elon Musk, talking about utopias in the era of climate change:
"a non-capitalist co-operative society in which people band together in small collectives, and then, instead of buying and selling things like a company, they fill out lots of requisition forms, somewhat in the style of a Chinese work unit or even a soviet"
"Possibly it would not be a very appealing utopia to live in, but we don’t know; and in any case it’s fully worked out, an alternative system that with modern supercomputers could very possibly work. Maybe the computers could even fill out the forms. An algorithmic artificial intelligence economy; it’s worth considering.
"The problem, however, with this and all other utopian alternatives, is that we can’t imagine how we might get there. We can’t imagine the bridge over the Great Trench, given the world we’re in, and the massively entrenched power of the institutions that shape our lives — and the guns that are still there under the table. Indeed right on the table."[3]
My anecdata-based thoroughly unresearched reckon about how we get from here (globalised capitalism in a highly un-distributed pre-post-scarcity semi-networked economy) to there (post-scarcity utopias a la the Federation in the 24th Century) (perhaps the even more instructive and applicable sequel to Steven Johnson's current How We Got To Now[4])) is that invariably there's a sort of slate-cleansing and great levelling. Almost as if JJ Abrams would come over and reboot our world economy and social systems and then when we wake up, sure, they cost about $25 to get in and you need to wear swanky 3D glasses all the time, but everything is super glossy and gosh the lens flare really starts to wear on you after a while.
How *do* we get there from here? Is there really such a thing as an end-state? And part of the amusing thing about KSR's non-capitalist co-operative society that requisitions things is, of course, a) who fulfils the requisition requests (presumably TaskRabbits) and b) no, you don't need modern supercomputers to fill out the forms because everyone who's anyone knows that sufficiently advanced user experience is indistinguishable from a) magic, b) a post-scarcity utopian economy, c) hell, if you're on the other end and d) "delivery".
Mr. Mison then hits me over the head with this quote from Ursula K Le Guin (who recently delivered this barn-storming speech[5] upon receipt of the National Book Foundation Medal for Distinguished Letters)
"Now the future is a kind of attenuating peninsula; as we move out on it, one side drops off to catastrophe; the other side, nowhere near as steep, moves down into various kinds of utopian futures. In other words, we have come to a moment of utopia or catastrophe; there is no middle ground, mediocrity will no longer succeed."
"Capitalism’s grow-or-die imperative stands radically at odds with ecology’s imperative of interdependence and limit. The two imperatives can no longer coexist with each other; nor can any society founded on the myth that they can be reconciled hope to survive. Either we will establish an ecological society or society will go under for everyone, irrespective of his or her status."[5]
Le Guin's speaks about how we live in an age of capitalism, and how its power seems inescapable, like the divine right of kings. But even that age changed and now seems alien to us, in the same way that there are social changes that have happened even in the last fifty years that would seem alien or shocking to those who preceded us hundreds of years ago. Granted, it may mean that there isn't much potential for massive change in the space of a lifetime - but that isn't to say that we can't also experience a punctuated equilibrium at the same time.
There is something of the inevitable about the grow-or-die way that capitalism, as a system, eats the world. Does it eat the world in the same way that software eats the world, and how inexorably is software tied in to that? There is, it feels like, the possibility that we end up with mundane utopia: not a shining bright future, but not a dystopia either. But a normal workaday future where we still work, where there are still daily lives, and, well, perhaps things aren't that much better. Perhaps not a world so starkly divided as one in Blomkamp's District 9/Elysium, but one in which more people have more connectivity, where there are more basic services, but that things just aren't... perfect.
[1] Tom Hume [2] Next on "Black Mirror" - Mallory Ortberg, The Toast [3] Remarks on Utopia in the Age of Climate Change - Kim Stanley Robinson [4] How We Got To Now - Wikipedia [5] The Future of the Left - Ursula K. Le Guin, which speech also appeared in Debbie Chachra's newsletter a week or two ago
2.0 Little Red Spot
I opened up Spotify today because I felt like listening to some more Robyn (I don't care if I'm supposed to have listened to it already, and I don't care about telling you - remember this typing is for me, not for you) and, well I had a notification for eight... things. I took a screenshot and tweeted about it, saying:
Help my music player has 8 notifications what is it notifying me about is this a young people thing am I old now[1]
I do not know what it is that my music player has to notify me about. I do not know why there might be eight things. I am aware that music can be social, but given that I'm the kind of person who still is much more likely to buy music than to stream it (in fact, I pretty much always buy music, and don't stopped paying for a Spotify Premium account a couple years ago), that makes me an Old Person and thus the kind of person who doesn't Consume Music in the way that Young People consume it, which given the way we appear to be using the verb 'consume', must be orally.
Anyway. Nothing more than: notifications? Really? What for? What could be *so* important that I can't figure out a way to dismiss them? That they have to be yet another little red spot with a number in them resting in my dock?
[1] https://twitter.com/hondanhon/status/568158366427529218
3.0 Stuck
I use a piece of software called Teleport to, er, teleport my mouse and keyboard from one computer to another when I have my work laptop sat next to my personal laptop and the Big Monitor. It works great until I grab one of the laptops and wander off - because that is rather the point of a laptop - and forget to turn off Teleport and then my mouse pointer falls off the edge of the screen and then I have to *go downstairs into the basement* because *that's where my mouse pointer is* and I have to physically retrieve it so I can get on with doing whatever I was doing on the couch.
I will just say the word "computers" and you can insert your own sigh.
[1] Teleport
--
7:56pm. I'm done. Send me notes, I love reading them and then feeling super guilty about not replying to them. Also - is there anything you'd like me to write about? I won't promise that I'll write about anything you send me, only that it might trigger something else in my head. So no expectations of performing to reader requests, okay?
Best,
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Three: Internet of Capitalism; Internet of Things Winter; Transmogrify
Date: February 17, 2015 at 10:30:22 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mh2d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:53pm on Tuesday February 17th, the day after President's Day, so the first day back at work after a long weekend. Sprint planning meetings on two big projects, and lots of admin work: all the stuff to do with keeping a team moving along and headed in the right direction. *waves to team*.
I'm not sure what I'm going to write about today. I sometimes keep a text file open and drop links into it during the day that I think I'll have thoughts on, or opinions about. I know there's one thing that I want to cover, but beyond that, not quite so sure...
1.0 Internet of Capitalism
In Joe Chip's problem was never his door[1], Tom Armitage deftly takes the room that's required to deconstruct the particular Philip K. Dick passage from Ubik that's been doing the rounds, pointing out that this isn't so much the Internet of Things sucking, but that it's the Internet of Things sucking under Capitalism.
As Armitage points out, the thing that Dick was able to extrapolate wasn't that the future could and would be connected, with a variety of interesting and mundane devices talking to each other, but that we would inevitably force that network of devices to operate under the auspices of capitalism. That we would have, instead of an Internet of Things, an Internet of Contracts.
This has already been contemplated. Go to any Bitcoin conference, and there's probably good odds that there'll be someone there talking about how the blockchain enables all of these connected devices - doors, doorframes, doorbells, floor mats and so on, to enforce a directed-graph of obligations and charges to each other, all enabled by not just the cryptocurrency of the day, but the distributed and validatable ledger that holds it all together.
Fast Company covers this - in a sense - in their article The Gig Economy Won't Last Because It's Being Sued To Death[2], that I'm not entirely sure about because they (Fast Company) appear to be coming down on the side of the "gig economy" and a headline that seems to lament the possible passing of the Gig Economy. The Gig Economy, of course, being one of the outcomes that Dick would anticipate:
But the gig economy can also be interpreted as a loophole for avoiding labor laws—more of a familiar nightmare than a new dream. Robert Reich, a political economist and the former secretary of labor, compares it to the piecework system of the late 19th century, the very same system that led to trade unions and labor protections in the first place. "There is no economic security, there is no predictability, and there is no power among workers to get a fair share of the profits," he says. "You and I and everybody else, if the present trends continue, will be selling what we do to the highest bidder."
Ah, the highest bidder. The Fiverr and TaskRabbit of the invisible hand, guiding slowly and inexorably toward creative directors, chief operating officers and human resource directors, all the usual occupants of the B ark, all of them subject to becoming, at some point, either parties in a marketplace, where all we're really looking for is something like centralised, automatic, Project Cybersyn-style[3] efficient allocation of resource.
For what it's worth, it's unclear whether we'll ever get to a utopian, Star Trek-ian post scarcity economy, or whether we'll find a way to auto-extinct ourselves before we get there. Right now, it feels like instead of inventing a future of freedom, we're quite happy inventing a future where we just keep a) destroying jobs, b) inventing jobs and c) moving bits of capital around, but mainly in one direction, toward smaller and smaller groups.
All of the above, of course, is just your regular Tuesday night reckon.
Where are the futures where some things really are free? Stephenson's Diamond Age had a sort-of basic income implemented through compilers/3D printers: each individual had a baseline amount of feedstock, or at least a flow-volume of feedstock that could be used to make things like food, or, in Nell's case, mattresses. That future is so, so far away - and it's not like it was ever really desirable in the first place.
[1] Joe Chip's problem was never his door - Tom Armitage [2] The Gig Economy Won't last Because It's Being Sued To Death - Sarah Kessler, Fast Company [3] Project Cybersyb - Wikipedia
2.0 Internet Of Things Winter
The danger (thanks, Kim Pallister) of the current wave of Internet of Things products is that they kind-of work in a not-quite-working kind of way. Sitting with Tom Coates and having him show me things, there's a lot of shoddy stuff out there. It feels like there's a bunch of factors in play here: that everyone is egging everyone else on in some gigantic game of chicken that will actually result in "winners" some day, but perhaps not quite soon - Internet of Things is going to be massive, because the Internet before it was massive, but maybe thinking about the Internet of Things right now is more like thinking about the Information Superhighway. We're at the 90s era of Tom Selleck telling us about all the things that we'll be doing, like reading bedtime stories over videophone to our kids from a payphone kiosk, rather than essentially missing the point of ubiquitous wireless connectivity. Oh, and the culture of shipping.
I think it's fair to say that startups are starting to get that hardware is hard - you only need to look at a whole bunch of broken Kickstarter dreams to quickly get up to speed with the notion that unless you really know what you're doing, what can on the outside look quite easy to do, actually requires a lot of time and effort and that this appears to scale in a sort of log fashion: the easier something looks, the more time and effort has gone into it. Here's a quote from the recent New Yorker piece on Jony Ive:
The company’s process, which is enabled by almost limitless funds, and by sometimes merciless pressure on suppliers and manufacturers, also provides a layer of commercial armor plating: an Apple object is “manufactured in a way that makes it harder to copy,” Paola Antonelli said. “That’s the genius. It’s not only the formal effect.” When, in 2007, Robert Brunner first saw a MacBook’s “unibody” housing—made, unprecedentedly, out of a milled block of aluminum—it was a “mind-blowing epiphany,” he said. Apple “had decided that this was the experience they wanted, so they went out and bought ten thousand C.N.C. milling machines.” (Apple didn’t confirm that figure, but Brunner was not being hyperbolic.) Soon after the iPhone débuted, Brunner said, Ammunition was approached by “a very large Korean company” to create a touchscreen competitor: “They wanted us to do it in six weeks.” He laughed. “We were, like, ‘You don’t realize, this was years. This was years of a lot of very good people.’ ”[1]
Something that looks so simple, with all that friction-stir welding that had all us Apple geeks googling during the product Keynote, and all those jokes about aircraft grade milled aluminium (with an extra I, thank you very much), took years to pull off.
So internet switches should switch. Nest smoke alarms should, you know, detect smoke, and then be easy to turn off if they've gone all false-positive on you. Things should work. We give computers a whole bunch of latitude, quite why I don't know, because we've been trained into some sort of Stockholm syndrome type thing where we don't expect any better (and Apple users aren't any better - we still want the Fucking Finder to be Fixed). Consumer electronics, for better or worse, have felt like they've had this pass in terms of "oh, well, they're super complicated and sometimes they just don't work and have you tried turning it off and on again?"
No, if I were being a doom and gloom naysayer, I'd say that unless someone gets really good at *executing* the internet of things, and internet-connected-things and so on, then you're just going to end up with the same bunch of people who're looking forlornly at their wrists, wondering what Fuel is, and how many steps they should be taking.
"It just works" means so much more when there's hardware *and* software involved. Are there only so many things as an industry that we can concentrate on? Whilst Sony's PS4 is an unqualified improvement over its predecessor, the OS is still an unmitigated piece of Sony crap. Because, you see, even if you are slightly better crap than your previous version, you're still crap.
[1] The Shape of Things to Come - Ian Parker, the New Yorker
3.0 Transmogrify
I am still thinking about digital transformation, to the extent that I've gone in some very dark places on the internet and read things like reports[1] where there are shocking things like a) the percentage of CEOs "supporting and championing digital change within your company" (42%) and the percentage of CMOs doing the same (54%) which leads me to the inevitable conclusion, basically, that we're fucked: it is going to be easier to start new businesses that are digital first than it is to transform legacy pre-digital businesses. Mainly because such a change ultimately comes down to culture, and if you don't have a leader at the front with the executive authority and trust to start changing that culture, then I don't know what YouTube is, I'll ask my fourteen year old neighbour and maybe she can tell me what Minecraft is at the same time, I think it's a new Lego game.
I don't know, apathetic bloody planet, I've no sympathy at all.
[1] The 2014 State of Digital Transformation - Altimeter
--
8:28pm. That'll do nicely.
Best,
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety Two: Bureaucracy Is An Algorithm; Vapourware; No New Ideas
Date: February 16, 2015 at 10:27:07 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mfnl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:57pm on a school night - although not a particularly schoolish one for me seeing as the office is shut today on account of it being President's Day here in the US. Instead, pancakes for breakfast, visiting grandparents and The Day After The Second Birthday Party, so lots of wondering why we can't just eat cupcakes all the time (him, not me).
1.0 Bureaucracy Is An Algorithm
With a hat tip to Christopher Kent[1], the re-stating of the obvious that bureaucracy is an algorithm - means to get done that which needs to get done with what you have to hand - in this case, being, well, a pre-networked society. In other less laboured words: bureaucracy - the administrative procedure, not the bit of government, but we for whom we have to thank for the linking of the two concepts *I'm looking at you, British Government* - is just another system for dealing with the world and the stuff we have to do in it.
Two other things here: the first, the re-linking recently of a Forbes piece by Anthony Wing Kosner about Jobs Below The API[2], and the second being Sam Altman's blog post on the Software Revolution[3], another attempt at stating what exactly it is that's happening in the world right now in terms of the intersection between globalisation, capitalism, IP networks, Moore's Law and wireless connectivity.
I'm not the only one who thinks that the 21st century organisation - that thing where people have to slot into boxes and HR needs a certain kind of job description before you can hire anyone, and where the concept of cross-functional/multi-disciplinary/end-to-end teams is a bit nebulous if not, well, unheard of - is outdated, but at the same time it's not clear to me that there are necessarily any great front-runners in terms of its replacement (not least of which because the organisation, the company, the Weyland-Yutani building better worlds to sell things in, is a product of its environment. If, way back in episode forty-seven[4], I was right (or at least aiming in a vaguely interesting direction) by thinking of our info-tech conglomerates busy terraforming the developing world for capitalism (such developing world already quite ready thanks very much and not quite needing the narrative of well-meaning white guys in suits coming in to fix it again), then perhaps something else in the same direction is interesting: what is connectivity terraforming for? There's one view of the future which is a kind of Charlie Strossian/Cory Doctorian early 2000s extremist view where everyone's got whuffie (bitcoin) out of their wazoo and is a self-facilitating media node endlessly forming, breaking up and re-forming fluid overlays of collaboration and getting paid by aforementioned micro-cryptocurrencies, but then there's the other one, which is a bit like this: what does the non-silo'd organisation look like? Do any of you work at one? Pixar isn't it. There are arguments that Valve, with their wheel-anywhere desks is it, but at the same time Valve doesn't always sound like the video game development utopia that it projects through cunningly released employee handbooks. Are startups and Facebooks and Googles that inevitable take on the trappings of bureaucracy (inevitably once they start hiring adult supervision) really the best example that we've got?
I guess what's scary is this: what happens when we really can do more, with less? Or rather, what happens when *some* people can do more, with less? When it only takes twenty people to build and maintain something that half a billion other people can use - and find enough utility to use daily, but not necessarily pay anything for - but those twenty people happened to have the right starting conditions, the right environment? It's one thing for some of those people to say "well, the prevailing belief on Hacker News is that we should tax the rich and guarantee some sort of basic income" but it's not as if I see there being a big campaign for the basic income. From either Hacker News or A16Z (of whom, if memory serves, Marc Andreessen also happens to believe that the safety net is due some proper sort of execution. As it were).
Because people are obviously doing more with less. And that "under the API" curve is just another way of saying that Jobs Get Swallowed and really, there's no point in fighting it - and sometimes jobs can get swallowed faster and sometimes you can fight it a little bit, but really: if fewer people - ie those who can afford the right starting conditions, which increasingly include things like 'college' or 'connectivity and equipment', end up making more of the gains, then, well, draw your own hockey stick.
Basic income, basic connectivity, and basic compute resource.
[1] https://twitter.com/cekent/status/566252202139074560 [2] Google Cabs And Uber Bots Will Challenge Jobs 'Below The API' - Anthony Wing Kosner [3] The Software Revolution - Sam Altman [4] Episode Forty Seven – Building Better Worlds; Mobile; More video
2.0 Vapourware
White papers are the vapourware of government.
That's it. Nothing more than that, really. Just the observation that if a prototype is worth however many meetings, then a prototype is worth however many white papers. Sure, I'll allow that white papers if properly applied in the right place at the right time with the right amount of pressure might be effective to do things like "start a debate" or "open an Overton window", but wouldn't you rather ship something than write something down?
3.0 No New Ideas
So Warren Ellis has a new column in Esqure and in his latest, this is the bit that caught my eye:
Things don't "just work" the way they were claimed to, online services are getting bloated and broken, network interoperability has been ruined by carriage disputes over eyeballs and naked grabs for user information, and apparently the important thing is that we buy a three-hundred-quid watch that connects to our phones and does absolutely nothing that our phones don't do. It's a desperate move from a field that's run out of ideas.[1]
This feels a bit awkward, because it's kind of like pointing a stick at Mr. Ellis and saying 'now see here, Mr. Ellis' but I feel like picking out the beginning of that paragraph and the end of it: namely that we do have a complete lack of things 'just working' the way they were claimed to (and have always claimed to, to be fair), and I wonder how much of 'just working' is a prerequisite for new ideas in the first place. In other words: right now, I would probably take ten more things just-working than one more new idea. Perhaps that might just give us the space to come up with some new stuff, rather than endlessly trying to re-invent and re-execute the same tired old ones from 1978, just in slightly shinier form factors than the last (ie: your wrist, not your pocket, not your lap, not your desk, not a room, not an entire factory floor) and hoping for a magical market breakthrough. Not that I'm blaming "the market" or anything, but if we're to believe the invisible hand that by all accounts has exceedingly bad impulse control, what we really need right now is a television that 'just works'.
[1] It's Still 1978 Somewhere: The New Digital Watches - Warren Ellis
--
8:25, and still on a school night. Maybe, just maybe, I'll see you tomorrow.
Best,
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety One: When Things Listen; An Unproductive Argument; Process; Until It Turns Into Writing
Date: February 13, 2015 at 7:04:42 AM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-mb9t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

On the way back to Portland from Louisville (Lou-uh-ville), Kentucky after having spoken on a panel on "syndicating innovation across jurisdictions in government". My first conference in the government space (I'm not counting attending the Code for America summit last year, that was more of a throwing in at the deep end before the new job). From my point of view, there were some reasonably interesting parts (and certainly interesting people to meet and have met) but quite a lot of the talk was, well, talk. For example, a lot of talk of the potential role for the US Federal Government in setting standards when my own inclination is not to wait for someone else to do it for you (nor to wait and try to do it 'perfectly') but to start bottom up and iterate as you gon. In other words: just start.
1.0 When Things Listen
The latest realisation that threatened to bubble over into everyday life was the realisation - through the implementation of a ham-fisted privacy policy - that Samsung's Smart TVs that feature voice recognition features, well, listen to you.
Amber Case has written well on this subject[1], explaining that Samsung relies upon a third party provider - Nuance - for voice (and more accurately, speech) recognition capability (and if memory serves me correctly, Nuance also powers the speech recognition portion of Siri's architecture for Apple) to provide the interpreted data it needs to run commands when you use the voice recognition feature. Which makes sense, and is how a lot of these technologies work unless you own a lot of the stack, in the case of a company like Google.
To me, part of this comes back to a failure on Samsung's part to recognise their users' literacy of the systems that go into the operation of the products they sell. It used to be that when you bought a thing from someone, that someone was responsible for all of the things that were in it - and that whilst physical components might come from multiple suppliers, those components didn't go off and tattle-tale. Or, rather, that the product was bounded in terms of connectivity: I can see the edges, and nothing, goes outside of those edges. Smart TVs and smart/connected anything else started to upend that model of understanding, but only to the extent that it makes sense for certain user-focussed features. It makes sense that for a Smart TV to be in communication with a third party like Hulu because, well, you're watching a TV show or a film *from* Hulu. What is unclear - precisely because it isn't shown in a visual manner, for example - is what is being sent *back* to Hulu. Televisions (and especially the formerly single-purpose items of consumer electronics used to receive signals over the air, through cable or satellite) have for most people only ever acted as *receivers* and not transmitters.
I'd suggest that another reason why this revelation that to perform commands by voice Samsung's TVs necessarily need to transmit information to a third party is that, again, these are televisions. As others have pointed out, no-one seems to be particularly surprised that devices like smartphones can (and in some cases do) passively listen at lal times, waiting to be activated by a keyword. And how else could that keyword activation work, if not by passive listening at all times?
But again, we're not used to having such objects in the world. The way they work is not explained to us. And I was thinking the other day, we're taught in schools - at least, I and my classmates were, a good twenty years ago - about biological systems and cycles, but certainly not information systems and cycles. It's not as if we're not capable of understanding flows. But when some of us talk about understanding the world in the form of systems and infrastructure and how those systems interact, the surprise at TVs talking to other things is just yet another example of mental models not having caught up to the pace at which the modern world is being delivered and experienced.
So there's the challenge: in devices formerly known as dumb, where there had been no expectation of *transmission* of information from the device, how do you show, unambiguously, that such transmission has occurred and is occurring?
[1] Samsung TVs and Privacy Policy Gone Wrong - Amber Case
2.0 An Unproductive Argument
If I were a mean writer looking for an unproductive argument and one that would attempt to troll to generate pageviews and an influx of People Expressing Opinions On The Internet, I'd probably start an unproductive argument like Which Company Do You Think Has Less Empathy: Google Or Samsung, And No, You Can't Choose Facebook.
The latest salvo in "do a dumb thing that you can't reasonably expect would be well-received by users who paid for your product, so the only reasonable expectation is that in fact you do not give a damn how your users are treated" is a Samsung entry: the news that they might be inserting ads when you use third party apps on their Smart TVs[1].
At this point, I don't really feel like I need to bang the empathy drum but to say: in what world does a manufacturer think it's a good idea to *surprise* people with extra advertising in a product that they *own* and again, have a reasonable expectation as to how it might function. To paraphrase the great scientist Dr. Ian Malcolm again, I can't help but imagine that the product managers at Samsung behind this particular "feature" - and I must say, as a consumer I am always looking for ways to encounter advertising that is relevant to my interests - were too busy congratulating themselves about having found a way to increase revenue and, well, to deliver advertising relevant to my interests, that they didn't stop to think about whether they *should*.
Score: Samsung 1, Straw-Man Google, 0.
[1] Samsung smart TVs inserting ads into third-party apps - Ars Technica
3.0 Process
That Russell Davies has, in his inimitable and economical way, merely by *quoting someone else* demonstrated that he is yet again a ridiculously smart individual. This time, a quote from Charlie Stross Bond/Spy/Cthulu mashup The Rhesus Chart, from the Laundry Files series:
"A bureaucracy is all about standardization, so that necessary tasks can be accomplished regardless of the abilities of the human resources assigned to it."
When I took my team to visit GDS at the end of last year, one of the things we came away with was being beaten over the head with the concept that if you're looking to see if transformation is going to take hold in an organisation, the two things you want to check for are: research (ie: measurement) and iteration. That's all. Those two things should in theory allow you to fix all other things, given time.
But this quote about bureacracy and standardisation has hit that home again as I've been thinking with our team about how we help transform and prepare governments in America to properly operate in the 21st century which, as weird and complicated as it is, is only going to get weirder and more complicated, and at an increasing rate at that.
Part of this is the increasing belief after having had the opportunity to meet with and listen to people like Sir Ken Robinson[2] - you know, the TED talk about schools killing creativity - is that the majority of people in our workforce have been churned out in a more or less industrialised fashion with skills and training pretty much still fit for an assembly line. Again, I completely acknowledge that I'm spouting off with my *reckons* and that the last time I really had direct experience with k-through-12 education was, well, when I was *in* it, and the occasional chat with teachers every now and then, but the anecdata is that we wouldn't still be talking about a purported "skills gap" if there wasn't, well, a purported skills gap.
To bring this back: government is great at bureacracy and arguably it was the British government that hit upon it as a great idea (that may well have been a perfectly reasonable operational response at the time). But as the world is coming to realise, we just don't live in a world where a bureacracy with standardisation - and the silos that come with it - is fit for purpose.
So with that in mind, or in the back of my mind at least, we've been talking more at work about the end-to-end service delivery team, which isn't as snappy as a Multi-Disciplinary Team, but is at least more understandable to American audiences and makes more sense to them outside the domain of the delivery of digital services. What we've found when we've been talking to governments has been that when we mention end-to-end service delivery teams as an explicit unit we're interest in increasing the capability of, their eyes light up in a way that indicate that they'd really like to invite us in and help demolish some organisational silos. Which is always a nice thing to see, because who doesn't like to wake up in the morning to the smell of demolishing silos?
In other words, this is a recognition that the necessary tasks in the delivery of a service are specialised and require unique roles within a team that works together. Which if I were Russell, I'd have found a better way of saying. In other words, the unit of delivery is the team.
[1]blog all kindle highlights: The Rhesus Chart - Russell Davies [2] Ken Robinson: How schools kill creativity
4.0 Until It Turns Into Writing
Two last things. First, Matt Webb in the latest of his blog posts wrote:
But let's be clear... this is all about me: What I get out of this is that somehow, by typing, four unrelated things that have caught my eye sometimes show signs of coherence. I get glimpses of the gestalt. So that's why I type.[1]
which is pretty why *I've* been writing this newsletter, write back in the beginning. This is a way for me to get my thoughts out and to see what they are. I've found that I do a lot of my thinking out loud, or verbally, or at least in sentences and that it's only when I'm writing or talking to ideas start to take shape. I'm not a doodler or a sketcher in the way that some of my friends are (which I'm trying to take not necessarily as a deficiency, but just in a way that I'm different; regardless, it's always been on my list to learn how to draw better) but I do know that when I write - and readers of this newsletter who've followed my progress over the past year will have noticed this - you can pretty much see my thoughts and arguments developing over the course of paragraphs if not even the very sentence that is running on.
And, of course: the death of David Carr, whose writing I've always admired, and for expressing the other reason why I started the practice of writing every day. I wanted to keep typing until it turned into writing.
[1] Filtered for Muybridge and Moorcock - Matt Webb
--
OK, that's it. Friday, 7:58am Eastern and I'm signing off until the next time. This was fun. Let's do it again. And if you're new, say hi (and check out the archives), and if you're old, say hi too, I'm sorry I haven't been around as much. Perhaps it's given you a chance to catch up on what I hear is in a number of cases a large folder of unread newsletters. And in any event, send me notes. I love receiving them.
Best,
Dan.
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ninety: Translation; Drift; The Thing About Things
Date: January 30, 2015 at 11:18:35 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-lss1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:03pm on my flight back to Portland after having spent the week at work in San Francisco. It may well be that my newsletters essentially become things that I do on planes at this point. BUT! Still thoughts in the back of my head about *that* New York Times Farhad Manjoo piece about the new work economy[1] (namely: I bloody hope not, that's not the world I want my son to grow up into).   Anyway. On with the show.   [1] Uber’s Business Model Could Change Your Work 
1.0 Translation
We've been struggling with how to take the GDS concept of "multi-disciplinary team" and translate it, rotate it, smush it, into something that makes sense in the context of American local government. Perhaps the valuable thing here is that to the extent that GDS have talked about what a multi-disciplinary team is, they've meant in the specific context *of* what GDS is doing both itself, and is trying to get the UK's government departments and agencies to do. "Multi-disciplinary team" in the GDS context means a certain configuration of 1 or more user researchers, service managers, designers, content designers, developers, delivery managers and so on. This makes sense in the specific context of digital delivery of services. Or, rather it makes sense in terms of *what GDS is trying to do*.   The thing is, of course, that what GDS is trying to do isn't what Code for America is trying to do and isn't what your organisation is trying to do either. GDS has a narrow remit compared to Code for America - and it also has authority deriving from a different source than the organisation that I work for. GDS might speak softly (at times) and carry the big stick of Sir Francis Maude, Code for America must work through persuasion, but is uniquely able to use its position as being a non-governmental, apolitical third party.   No, what we're trying to do at CfA is, more or less, *transform government*. That's a pretty big goal. We explicitly include in our mission citizen participation and rebuilding trust in government. America has - in a very distinct way that the UK does not - a history of community organising that is very much a part of CfA's mission.   And, crucially: because we've decided to work with *all* local governments, all cities and so on, we're dealing with a large range of potential partners. Some of those cities may well be able to deploy significant internal development resource. Some less so. And some others even less so again.   But when we're able to pull back and say: hang on, we're about organisational transformation against a backdrop of a digital world, then there's a way we *can* be specific, but also have a big enough umbrella to cover what we need to cover.  To attempt to un-bury the lede, we think that our sticky equivalent of multi-disciplinary team is the end-to-end service delivery team. It doesn't say anything about "digital". But it does - importantly, to my mind - make explicit that we're concerned with *everyone* who is involved in the delivery of a particular service, no matter where they may fall on an org chart or which silo they might be in. And the people in an end:end delivery team probably already work with each other, but at least on an informal basis.  In a way, this is a re-working or re-derivation of Russell's "the unit of delivery is the team". But also a way to define *what* that team is. We can say: "it's anyone who's involved in the delivery of this service". It raises super interesting questions like what you do when there is an abstract sharp organisational delineation (ie: where the organisation of city government ends) that is ignored in practice by the delivery team, like what happens when cities partner with food banks for delivery. Or what might happen in the future when cities proactively work with entities like Bridj or Uber in the design and provision of transit facilities for residents.   Or, to put it another way: the unit of delivery is the team that delivers. 
2.0 Drift
First, I want to acknowledge the smart Kim Plowright and this tweet[1] as a response to the BBC's announcement of a raft of new programming for iPlayer, their online video-on-demand service[2].
BBC iPlayer presents a huge creative opportunity to push the boundaries of storytelling" (by making more telly) - Kim Plowright
And a segue straight into another Russell thing: his piece that is yet another nail in the undead coffin of What To Do About The BBC[3].  Part of the frustration that many people have with the BBC is that it really can't make up its mind and behaves like the kind of person who's telling you that they really want to change without, um, ever really changing. This is because there are some people at the BBC who are excited about new kinds of media and some who just want to make television and have wanted to make television all their lives.   So if I may paraphrase, the Reithian vision to satisfy the user needs to be informed, educated and entertained is a very compelling one.   (I have to admit, there's a part of me that wants to go full on about Russell's aside about Wieden's thinking that they've solved brand advertising by cutting it up and putting videos on the web (to which: nigh), and I'm going to do my best to try and ignore it.)  Davies' comparison of what the BBC *does* and what it says it is *supposed to do* is the idea of drift. If you're the kind of organization that does have a medium-agnostic/delivery-agnostic charter or vision, then you really do need to try and remember exactly what it is you *say* you're supposed to be doing against what you're actually delivering. One would be forgiven for thinking that the BBC's charter is *actually* to deliver some of the best television and radio programming in the world. If it turns out that that's what the BBC *actually* wants to do, then no big deal. But, amongst friends' discussion of this point, one only needs to ask the question: what garners more traffic to the BBC - News, or all of iPlayer?  What gets the people who love the BBC and its chartered ideals as opposed to the delivered ones is that there are wonderfully new and exciting and - crucially, *more effective* ways of satisfying the user needs it thinks it's delivering than the ones it's currently using.   Perhaps it's just because we don't live long enough. But there is a massive blind spot which it still feels like the leadership of the BBC doesn't understand, which is this: if it relies, as it is doing, upon television and radio, it runs the risk of being unable to satisfy its users' needs of information, education and entertainment *as effectively as television does right now* in relatively short order. And at that point, no amount of costume drama will be able to justify its price tag.   [1] https://twitter.com/mildlydiverting/status/558926193211482112 [2] BBC iPlayer announces raft of new exclusive programming  [3] Principle Drift - Russell Davies
3.0 The Thing About Things
Matt Webb responded[1] to the last newsletter episode, which is very nice because Matt is a person with a quite intimidating brain, and it's good to see how his brain works and where it's at.   The bit that stands out to me is Webb's calling out of *that line* from The Graduate; "plastics". The rallying cry here is a sort of thing-that-there-isn't-a-word-for-yet which in part of my head matters, and in another part of my head doesn't matter. Webb's examples of what you get from "plastics" (Pacemakers! Wind Turbines! Happy Meals! and so on) is, I think, the space that we're grasping at.  So, a few things:   - labelling a space makes it easier to point at it. I think what's interesting - and difficult - about nailing down the attributes of the Internet of Things space is coming to a general understanding of what those attributes might be.     - this is kind of what we mean when we talk about treating things like materials. Materials have labels - wood - that are nice encapsulations of a whole bunch of other characteristics. But we can relate to these physical materials because, well, we learn about them like sponges from the day we're born and we are either hardwired with some understanding of them, or we develop them to the extent that they're innate. It's why metamaterials are so gosh-darn interesting, for example.   (I fully realise that at this point I am just splurging out what's in my head. There are those among my readership who are *actually* materials scientists and know what they're talking about. So take all of what I am writing here as just, I don't know, wild and probably inaccurate conjecture backed up by nothing as substantial as, I don't know, *actual knowledge of the field*)   - there is a material, or a space, or whatever metaphor that you want to use that describes the class of "thing" possible that you get where software (which to fully get you have to understand is more-or-less infinitely malleable in the Church of Turing) plus connectivity (and in particular, a certain kind of networked, open/open-ish connectivity), plus physical, instantiated presences in the world.     - two out of these three things (persistent connectivity to a network and software) are fundamentally new things to our sphere of understanding as a species, so it's kind of exciting to be teetering on the brink. We've seen (ish! We're just at the beginning) what those pieces do *individually* and we've just started mixing *both* of them in terms of getting the mobile internet and I think it's not an understatement to say that *that* combination has been nothing short of, well, disruptive.     - the last thing, the physical thing, the bits that exist in the world, we're *also* learning about because in terms of being a species that's been around the block and built up a body of knowledge, you can kind of zoom out and say that we might be at the inflection point of "building stuff". Sure, it's super crude in that we don't have self-assembly or nanotech or any of the other Church of the One True Rapture stuff, but what we do have China, or more accurately, what we do have is one point five billion pairs of hands (roughly) that are (roughly) hand-making and assembling all this *stuff* in a supply chain that is just getting tighter and tighter and more responsive and, well, networked. In fact, just the act of software and connectivity, just applied to the making of *dumb* physical things is super exciting!   I do think Matt's right about local connectivity being a different thing from backhaul in his post. There's a case for your house network not necessarily needing to be connected to the superset of networks. I'll agree with him on that one.  Something else came up in conversation when I was talking with Tom Coates about this which was that - in the branding sense at least - I remembered that I consider myself to be in the descriptivist camp rather than the prescriptivist one. So whilst there may be in my head the *correct* definition of the Internet of Things (such as there is one that competes for taking up space in the most number of brains in the world and thus influences the kinds of things that gets made), the Internet of Things will end up being called whatever it ends up being called. But then I just fall back to the whole concept of having a map and needing to know what to call that space over there...  [1] http://interconnected.org/home/2015/01/27/comment
--  I have to say, I'm super proud of the team I've got at Code for America. I pretty much put them through the wringer this week in terms of stuff they hadn't done before and what I'm asking them to do over the next year, but it feels like a good sign that when I left they looked both energized *and* exhausted.   Anyway. Notes. I bet there'll be reckons off the back of this one. Next time I'm on a plane again is in about 10 days' time, so I won't necessarily promise anything until then...  Best,  Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Eight: The New Normal
Date: December 16, 2014 at 2:06:00 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-kgox=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
11:25am on Tuesday 16 December, sitting in Kenny & Zuke's with something of a splitting headache, ploughing through the email that's collected over the last few days of being sick with the manflu. I don't have a fever anymore, but I do have a head that feels like its awareness isn't quite in sync - almost as if moving my head around has some bizarre lag. 

In this episode: a thoroughly unsubstantiated reckon and bag of feelings at a bunch of things that have been going on with corporate information security. 
 
1.0 The New Normal
So, the Sony hacks. You probably know all about those. About the abysmal state of corporate security that Sony Pictures Global had that, thanks to the mediocrity principle[1] (and, you know, our collective experience), we can assume to be more-or-less *normal*. About the way that the hackers have been operating: by uploading material to public servers and then sending journalists links to the material, rather than sending the material to journalists directly, thus getting around any sort of regional equivalent to a D-NOTICE because once the stuff's out there, well: you gotta report on it, right? Can't issue a takedown on stuff that's *everywhere*, and being torrented around. That's how the internet works, right?

And it's not like the documents haven't thrown light on things that *are* in the public interest, like fairly egregious and hard-to-justify pay gender pay disparity. And, of course, things that aren't *really* in the public interest and just illuminate exactly how certain executives do business. (I mean, have you ever sent an email to someone you're negotiating with that says "why r u punishing me?")

Anyway. Via Kevin Slavin, the news that *months* prior to the Sony Pictures hack, an equivalent, possibly state-sanctioned hack of American company Las Vegas Sands Corp[3] at Businessweek (who have done excellent reporting on corporate hacks, like their investigation into the abysmal Target credit card breach[4]).

There are moments - with the recent (hard to verify, to be honest) threat that those who go and watch The Interview in cinemas will be punished in some way, and that Sony Pictures executives must satisfy the hackers' (unclear) demands - where what's happening feels just a little bit like the National Anthem opening episode of Charlie Brooker's Black Mirror, which by this point if you're American you're probably sick of hearing about from British people, and if you're British, you're silently sniggering at how behind the Americans are in their depressing, deflating and nihilistic depictions of a near-to-present dystopias. 

At this point, given what little we know about what's happening and why with Sony Pictures - is it North Korea? Is just a bunch of hackers in it for the lolz? Who can tell? Does it matter? - does it feel like Amy Pascal or Michael Linton are going to be asked to do something fundamentally difficult to understand or unreasonable, just to make a statement? Because, you know, why not? If you're going to thoroughly destroy a company, well, why not? 

But then you zoom out a bit and you ask: how good is *your* employer's security? Is it good enough to fend off a sustained attack from an unreasonably motivated and skilled attacker? Is your internal email encrypted? Nobody, no-one and nothing looks good in the cold light of day and without context. 

So this is one possible future out of all the ones that lie ahead of us: continual, persistent attacks on that *other* infrastructure that is under-invested in because it's not well understood. Sure, there's the cyber-infrastructure (sigh, that phrase) that controls the *physical* stuff. 

And here's the bit where people who've been reading me for a while will recognise in that today's episode has been slowly approaching a quote from Sneaker: it's just like Cosmo said in 1992: "The world isn't run by weapons anymore, or energy, or money. It's run by little ones and zeroes, little bits of data. It's all just electrons."

(I know you'd rather me quote that than Sandra Bullock vehicle The Net)

We've known what Cosmo has said for a while. But something has changed in the 22(!) years since Sneakers came out where now it's *undeniable* that the world is run by little bits of data. Sure, the weapons and energy and money still *also* run the world. Megalomaniacs always get preoccupied with zero-sum positions. 

Given the extent of the breach at Target, all it takes is a politically motivated actor instead of an economically motivated actor. It was *profitable* to steal 40mm credit card details from Target. But what happens when you have actors who only want to make a statement? Who don't care about the money? Who can still find their way in through a stupidly unsecure HVAC system running on the same physical network as the EPOS systems? 

So this is where we are. Your health insurer. Your bank(s). Your car loans. Your insurance. Weirdly, most of the information that's held about you that is from *non-traditional companies* - ones that are pre-internet, might even be most at risk. Google gives a shit about your security, even from a principled point of view. Microsoft too. Even Yahoo. These are all technology companies. 

But Gap? McDonalds? The different bits of GE? And hey, it doesn't help when there's evidence that companies are already being targeted by western intelligence agencies for... well, who knows. But Regin[5] came from somewhere (and it's hilarious that US-CERT has to issue an alert for it).

The thing about phrases like "info-terrorists" or "cyber-terrorists" is that, from background informed by advertising, at least, they sound like silly, made-up juvenile threats from a dated era. They bring about thoughts of mirrorshades and not, you know, hugely competent state-sponsored teams in some cases with specific agendas in mind. 

You can't see this stuff, but it's out there. It might be the new normal.

Instead of "NO FATE BUT WHAT WE MAKE" etched into a picnic table, we might just end up with "INFOSEC TAYLOR SWIFT WAS RIGHT" etched into a stone tablet. 

[1] http://en.wikipedia.org/wiki/Mediocrity_principle
[2] http://en.wikipedia.org/wiki/DA-Notice
[3] Now at the Sands Casino: An Iranian Hacker in Every Server - Businessweek
[4] Missed Alarms and 40 Million Stolen Credit Card Numbers: How Target Blew It - Businessweek 
[5] Regin Malware - US-CERT

-- 

Best,

Dan

 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Seven: Snow Crashing (10); How The Web Works Now
Date: December 10, 2014 at 6:45:43 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-kasx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

4:18pm, Central Standard Time on 29 November on the way to London Heathrow, from Kansas City via Mineapolis St-Paul, leading a Code for America expedition to the UK's Government Digital Service. I'll be meeting up in London with five of my colleagues trying not so much to find out what makes GDS tick as to see how we can translate what they do into something that makes sense in the mirror-world. 
 
1.0 Snow Crashing (10)
It's been a while since I've done one of these. (Snow Crashing (9) was in episode 127, back on 23 July[1]).

We're at chapter eight of our trip through Neal Stephenson's Snow Crash - we've just had infodump on Juanita, and now things are about to kick off. 

Whilst in the metaverse - more specifically, the Black Sun - Hiro's forgotten to tend to his physical body and his tongue stings: he's forgotten to swallow his beer in one of the first (and only?) signs we see of someone neglecting their real-world body in favour of the one that they inhabit in the metaverse. 

Juanita, we're reminded, was the one who figured out how to make "avatars show something close to real emotion", so it's ironic that she's turned up in a black-and-white, low-resolution, low-fidelity avatar. Or, you know, it could be A Sign. In any event, this is an opportunity for us to learn more about Juanita and Hiro's relationship: from his point of view, at least, she did most of her work when they were together, and "whenever an avatar looks surprised or angry or passionate" in the metaverse, he sees an echo of their former selves. Which, it has to be said, raises a question as to exactly what Juanita did when she was bringing emotion and facial expressions to avatars: if they're all modeled on a base-set that she rigged based on her and Hiro, or if every so often they strapped on the mo-cap suits and ping-pong balls and had an argument with each other. 

Whatever: Hiro can't escape Juanita, because she's wherever he looks in the metaverse. He can't even hide in virtual reality. 

The Black Sun turns out to be your typical software success, and there's a curious phrase in here about "marketing the spinoffs" which at least for me sounds distinctly 80s and 90s: spinning-off, not franchising, not licensing, but suggesting instead something like a successful entertainment property that spun off into Black Sun: The Next Generation and Black Sun: Voyager and Black Sun Into Darkness. Stephenson takes this history of the Black Sun to remind us that it wasn't the collision-avoidance algorithms that made the "place" a success (which makes more sense if you read "collision-avoidance algorithms" instead as "physics middleware" and remember that Havok got bought by Intel a while back[2]) or the bouncer daemons (which makes even less sense) but instead the frighteningly realistic, non-uncanny-valley effectiveness of "Juanita's faces". See, the Nipponese businessmen do business here in the Black Sun: paying attention to facial expressions and body language and there's that phrase again: condensing fact from the vapour of nuance, synthesist style.

There's two camps here: the one that believes that you can quantise and digitize everything and literally condense fact form the vapour of nuance, and there's the one that believes that you can't, that "something ineffable" is going on, something that you can't explain with words. And, most likely, something that you can't reproduce with a convolutional neural network running on Google's data centers. Juanita's in the latter camp, an "irrational mystic", who ends up quitting the Valley (well, it's *implied* it's the Valley, if you ask me), taking a job with a Nipponese company (Stephenson taking the view here that even if you write stupendously popular and successful software, you still don't get to retire for life) and reinforces her stance that the metaverse introduces distortion in relationships, never mind the fact that she's (apparently) the one who made the experience real-enough for most people. 

And then here's a thing: whilst Hiro scans the room with Bigboard, Da5id notices him and "indicates with a flick of his eyes that this is not a good time." We're told that normally such subtle gestures are lost in the noise, but not this time: not only does Da5id have a "very good personal computer", but Juanita also helped design his avatar, so his message is received "like a shot fired into the ceiling". 

How does this work? Does a Very Good Personal Computer mean something that's got a high-rez, high-fps 3D LIDAR-type scanner that can detect Da5ids real-world facial microexpressions? That part is easier to buy: high fidelity scanning equipment and a prodigious pipe through which to send the information, but the part about Juanita designing his avatar to make it *even clearer*? Does it mean that Juanita's a combined modeler/rigger in the Pixar tradition, someone who can both put together a high-polygon avatar for Da5id, but also rig it to such an extent that what in the real world would be a microexpression but somehow in the metaverse, in the Black Sun, comes across even more clearly? 

Anyway. There's a boring bit where Stephenson makes fun of Hollywood and gets to show how Hiro makes a living (trading gossip and tips on the writer and director involved in a movie in development in a somewhat naive way because it's actually much more useful industrial intelligence for a rival studio to know that a director is basely interested in bazooka-blowing-things-up scripts than it is for screenwriters to know to include a bazooka in their submissions).

When Stephenson describes the Movie Star quadrant, he says that actors "love to come here because in The Black Sun, they always look as good as they do in the movies. They can strut their stuff and visit with their friends without any exposure to kidnappers, paparazzi" and so on. Which, with hindsight, kind of misses (at least some of) the success of things like Reddit AMAs and Twitter: that it's closeness-in-general, not physical closeness that is valued. Sure, now we have people lining up for selfies with One Direction. But the appetite for contact is insatiable whatever the medium. 

And then we have our first introduction to L. Bob Rife who at the time of Snow Crash is a cable-television monopolist and these days would invariably not be someone like Rupert Murdoch or Disney but instead a different information monopolist and it's really, really hard to come up with a viable suggestion other than someone who's running Google. 

Then we learn three things in a conversation between Juanita and Hiro. 

One: Hiro's sword-fighting reflexes (seeing something coming and instinctively deflecting it) are Important and are going to be valuable. 

Two: Juanita warns Hiro off Snow Crash, and Hiro points out: of course, it's catnip to him. 

Three: Juanita has a Thing for Hiro, and at the very least, they share a Special Connection. 

Four: Hiro is sufficiently stereotypically male and egocentric to think that the reason why Juanita is guarded is because she *does* have a Thing for him, and that she's got to be Careful around him. 

Five: The VR system in Snow Crash - specifically for undetermined and potentially impractical reasons *only* in The Black Sun - is so good that Juanita can *literally* read *every* expression on Hiro's face. 

And then, and *then*, we get to hypercard bit. More on that next chapter. 

(That said, I can't resist: Stephenson is obviously a fan of skeuomorphism. The BABEL (Infopocalypse) hypercard turns into a "realistic, cream-colored, finely textured piece of stationary". 

[1] Episode One Hundred and Twenty Seven: Belong; Snow Crashing (9); Humans 
[2] Havok (Software)
 
2.0 How The Web Works Now
This is a story of how the web works now.

On 26 November, I got an email from "Vodafone Outreach", a Gmail address (vodafoneoutreach@gmail.com) purporting to come from the MEC Outreach Team at MEC Global, a media agency owned by WPP. The email was as follows:
Hi,

I am contacting you on behalf of my client Vodafone.co.uk. I am trying to remove some links pointing to their website. While I understand that you have linked to them in good faith, I would really appreciate your help in the removal of the link(s) highlighted on the page(s) below to enable them to comply with Google’s Webmaster Guidelines. This is at the request of the marketing team at Vodafone.co.uk.

danhon.com/ec/v3-archive-feb2001.html

Can I ask that you remove as stated above? 

Thanks in advance!

I hope to hear from you soon,

Best wishes,
MEC Outreach Team
vodafoneoutreach@gmail.com
 
1 Paris Garden, London, SE1 8NU, United Kingdom
http://www.mecglobal.com
A GroupM Company

I get link removal emails like this every so often. I don't think I've ever replied to them. So I ignored this one. The only thing that was different about this one, that I noted at the time, was that it came from an agency that I'd met with before: in my Six to Start days, I'd had meeting with MEC at their Paris Garden office in London. I filed that away.

5 days later, I got another email. It didn't say much more, but did offer "formal documentation". This one said:
Hi,        

I am just following up my previous email. Have you had a chance to look at the request to remove the links to Vodafone.co.uk from your site? We are carrying out ongoing removal work and would very much appreciate your help on this.

Please get in touch if you need any further assistance or require formal documentation from my client if this is preventing you from removing the link.

Best wishes and speak soon,

MEC Outreach Team
vodafoneoutreach@gmail.com
 
1 Paris Garden, London, SE1 8NU, United Kingdom
http://www.mecglobal.com
A GroupM Company

This one was also just something I'd normally ignore. So I ignored it.

4 days later, I got another email. This one said:
Hi there,

I hope this email finds you well.  I’ve contacted you twice previously to request the remove of links from your website to Vodafone.co.uk . I know you may have missed our earlier emails or may have been busy and unable to reply.

However I’d be very grateful if you could help me by removing the links. If not, we may need to include your website in a disavow request to Google. I’d like to avoid this as it could affect your website’s standing with Google and result in a reduction in its authority.

Below are the pages on your site which contain links to Vodafone.co.uk:

 danhon.com/ec/v3-archive-feb2001.html

Your help on this would be greatly appreciated and I hope to hear from you soon!

Best wishes,

MEC Outreach Team
vodafoneoutreach@gmail.com
 
Bass Warehouse4 Castle St, Castlefield, Manchester, United Kingdom
http://www.mecglobal.com
A GroupM Company

This one, I paid attention to. See, the thing is, it's a bit embarrassing. The link I'm being asked about is the February 2001 archive from my blog. 2001 me (who comes across as a thoroughly arrogant, naive and precocious individual) is being quite impressed by the Nokia 8210 candybar phone and is writing about switching from Vodafone, his current but contract-expired network, to Orange, where most of his friends were. This was a time without cross-network minutes, and I think at that time, I switched to Orange Everyday 50. Anyway, being the good web citizen that I was, the words "Orange" and "Vodafone" were linked to their respective homepages. 

There was no other link to vodafone.co.uk on that archive page. Could this really be what Vodafone (and their agency) were objecting to? And could they really be implying -- threatening me, really - that they would use a Google tool to "disavow"[1] that page, my domain that might result "in a reduction in its authority"?

At this point, I start to get a bit snotty. This isn't how the web works: you link to thinks! This is, as the Vodafone/MEC Outreach Team said in the first email, a "good faith" link. 

But this is where we are now. A commercial web. Pagerank. Linkfarms. And after getting increasingly outraged on Twitter and sending two somewhat politely irate replies (asking first for the particular part of the Google Webmaster Guidelines that MEC, on behalf of Vodafone, were attempting to "comply" with and secondly pointing out that I'd be quite happy to get in touch with Google if the MEC Vodafone Outreach Team were doing anything dodgy), I decided that, well, it might be "fun" to call up the front desk at MEC Global and ask to speak to an account manager working on the Vodafone account.

Like a lot of companies these days, MEC Global have a full name policy on their front desk. This feels like the kind of rule that Russell Davies describes as -- and I can't find the blog post -- the kind that was called forth into being because a particular event happened that must Never Happen Again. You know: you see a sign and you think yourself: this sign is only here because someone did that thing before and now we should not do those things anymore. But the person I spoke to on the front desk - whilst pointing out the rule - was pretty helpful and in the end tried to put me in touch with someone, and gave me their name in case I had any trouble. There's no reason to say who I was put through to, suffice to say that I left a voicemail. 

My wife - and friends of mine who've heard it whenever they've seen me in a work context - make fun of something I have that's a bit like my Professional Telephone Voice. It only gets turned on when I need to turn it on and when I want something to happen, and is most likely the kind of thing that results in a whole bunch of different factors: like growing up in a middle class family, going to a selective grammar school, going to Oxbridge, reading law and training as a lawyer. It is, bluntly, a Do You Know Who I Am voice, and in writing, it's the tone of voice that understands the escalating use of the phrase "with respect" and "with due respect" and "with the utmost respect", and comes about entirely from a whole bunch of intersecting privileges - and something that in parts was certainly learned, if not taught. What I'm saying is: it's easy for me to call up the front desk of an international media agency and to sound like I know what I want and that someone should give it to me. I understand it's not easy for everyone and furthermore, that it doesn't result in, well, results, for everyone. 

Anyway. I emailed, left a voicemail and was, as people are these days, Irate On Twitter. 

In the meantime, there was a bit of back and forth between myself and my friends on Twitter because one thing that was just *weird* or unexplainable was the fact that all of this correspondence was being done through a Gmail email address, which is an instant signal that something fishy is up, when combined with the inclusion of overly bloated corporatese signatures. Why would a WPP-owned global media agency be sending official emails from Gmail? Was this a phishing attempt? All of the links - such as there were any - checked out, so probably not. Was this email from a sub-sapient artificial intelligence running on EC2, evolved out of a sophisticated online marketing management suite, desperately trying to make contact with the outside world? (Unlikely) Or, as someone pointed out: was this because what MEC Global were doing was dodgy - requesting the removal of valid, good-faith links that were undesirable to the client, threatening the downgrade of the linking site's pagerank - and they wanted some sense of (ineffective) plausible deniability? Or - even further down the rabbithole - was this an attack by some other sub-sapient online marketing agency to discredit MEC Global or to make their client, Vodafone, look stupendously ham-fisted?

Who knows?! It's marketing and advertising! Or, you know, the occam's razor explanation: it *was* from MEC Global and it was just shit software and they didn't know any better. 

And then I got this email, from the Director of Organic Performance at MEC:
Hello Dan
 
I have been made aware of communication to you regarding link removal. I apologise if there has been any confusion on this and would you be free for a call to talk it through? If so please let me know the best number to call you on.
 
Thank you
 
Richard George
MEC
Director Organic Performance
 
Richard.George@mecglobal.com
Office : +44 161 930 9000
Fax: +44 161 930 9030
4 Bass Warehouse, Castlefield, Manchester M3 4LZ, United Kingdom
http://www.mecglobal.com
 
Description: Description: Description: MEC logo
A GroupM Company
Follow us on Facebook 
Follow us on Twitter
Description: Description: Description: http://images.insidemedia.net/DigitalSignature/mec/rp4signature1.jpg
IPA CPD Gold accredited agency
 
Privileged/Confidential Information may be contained in this message. If you
are not the addressee indicated in this message (or responsible for delivery
of the message to such person), you may not copy or deliver this message to
anyone. In such case, you should destroy this message and kindly notify the
sender by reply email. Please advise immediately if you or your employer
does not consent to email for messages of this kind. Opinions, conclusions
and other information in this message that do not relate to the official
business of WPP 2012 Ltd. shall be understood as neither given nor endorsed by it.
For more information on our business ethical standards and Corporate Responsibility 
policies please refer to our website at http://www.wpp.com/WPP/About/
You know this is an Official Email because the signature is longer than the actual content of the email.

And I let Richard George have my phone number and we had a short call on the phone.

George was incredibly apologetic, apologising for mainly two things: confusion and distress. He had reviewed the link in question and had admitted that it was easy - and quick - for him to determine that it was a valid link and should not have triggered the removal request. So I asked him exactly what the process was that resulted in the request being issued, given that it was so clear to him that the link didn't qualify.

It turns out that there's a bad-link-identifying software-as-a-service that MEC Global (and doubtless other organic and SEO optimisation agencies) use. You can kind of tell this from the headers because the emails originate from EC2, Amazon's cloud web service. 

This software crawls the web and I can only imagine if they're trying to do their job well, some sort of semantic analysis and web-of-trust algorithms, produces candidate "bad links". Pretty much the same kind of thing as the various automated DRM takedown systems like Content-ID used on networks like YouTube that - as we know - consistently result in false positives.

Unlike those Content-ID systems, there's (ostensibly) a human used in MEC Global's link removal request process. I was told that in all cases, a (junior) employee is required to eyeball the link before sending out the correspondence. So we were going to pin it on a junior employee, then. I asked exactly what the state of their training must be when an employee was not able to identify a good-faith link seeing as this was something the person I was speaking to could do it pretty quickly. I was told that this would be "passed on to the team", and it was repeated that I could of course imagine a situation where a (junior, inexperienced) employee would be approving such link removal requests. 

Which pretty much means: this is a numbers game. There is money to be made employing people to look (or not look, as the case may be) at links proffered up by an identification system, to initiate a manual request for removal process, that if not, can be escalated to the usage of Google's Disavow Tool.

As an aside: one of my friends got in touch with someone at Google who was pretty adamant that if the Disavow Tool was used on a page with good pagerank - or where presumably it was being used to disavow a link that "shouldn't" be disavowed, the requestors pagerank would instead be affected. So, you know. Karma.

Too long, didn't read: I subscribe to the principle of mediocrity. If something's happening to me, it's not because I'm a special and unique snowflake. If MEC Global and Vodafone have the time and inclination to run a programme that identifies archived good-faith blog links from February 2001, then imagine what else they're finding. And imagine how many times they're using the Disavow Tool. 

Well, bullshit. 

This is another example of people getting caught in a shitty crossfire thanks to the direction we've collectively (intentionally or not) pushed the internet in for the last fifteen years. Where it's so important, and presumably offers enough return on investment that it's OK to go after what made the web one of the most important inventions of the last hundred years. The fact that *anyone* can publish to it. The fact that good things on the web can come from anywhere - Vodafone *or* a precocious 21 year old blogger at the beginning of the century. But one where the traditional power asymmetry is attempting to reassert itself. Vodafone - and through them, their agency - are bigger and more resourced than I am.

Congratulations, Vodafone Marketing and MEC Global. You've made yourselves look stupid.

[1] https://www.google.com/webmasters/tools/disavow-links-main

--

11:04 GMT, Monday December 8 on VS19 on the way back to San Francisco - only 320 miles away, at an air speed of 510 miles an hour, an altitude of 40,000 feet and probably the first time I've been in a 747 in a long, long time. I'm headed straight to the Code for America office after the London/GDS field trip: a very full week of work and a weekend of catching up with friends I haven't seen in a long, long time. 

And now, 4:43pm PST, Wednesday December 10, waiting for a flight back to Portland. Waiting to go back home.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Six: Videogame Tourism; Principles for 21st Century Government
Date: November 19, 2014 at 10:02:47 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-jp7t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
 
8:42am at a Starbucks in suburbia, getting the suburbia Giant Car fixed because the magic eye that lets us see out the back of the car gets fogged up and moisture clogged resulting in a fog-of-war type rendering effect whenever we look through the magic mirror that lets us see out the back of the car. An aside: there's a Starbucks in Portland that's made out of a SHIPPING CONTAINER which I keep wanting to visit because there are certain people I know who get either very excited or very interested in shipping containers but I wouldn't go so far as to say that some of their best friends are shipping containers. Anyway, here's a picture of the Shipping Container Starbucks in Streetview[1] and Satellite[2].
 
[1] Starbucks Shipping Container: Streetview
[2] Starbucks Shipping Container: Satellite
 
1.0 Videogame Tourism
 
Okay, follow my train of thought: the latest installment in Ubisoft's series of historical fiction meets conspiracy theory meets alien encouragement of human evolution  (oops, largely unsurprising spoiler) meets free-running meets getting stuck in the ground meets assassining[sic] people meets tourism (previous episodes included visiting Jerusalem, Acre, Damascus, Venice, Florence, Rome, Constantinople, Boston and New York) videogames[1] is set during the French Revolution. 
 
One of the things about the Assassin's Creed series has been Ubisoft's somewhat fanatical if not painstaking-ish devotion to more-or-less recreating (I realise the qualifications are somewhat working against the description here) the locations in which they're set, to the extent that the second in the series, Assassin's Creed II: Italian Holiday Edition, included a reasonable accurate and *evocative* representation of Venice and Florence. (I haven't played Assassin's Creed: Let's Visit The Pope, but I'm going to assume - ethics in video games journalism concerns aside - that the reproduction of Rome is reasonable atmospheric there, too). 
 
All of this leads somewhat inevitably to the accusation that Assassin's Creed Unity: An Assassin In Paris is historically inaccurate[2], which recalls the Jon Stewart response "I'm a comedian, this is a comedy show" to the fact that he is one of the more interesting journalists and news programmes on television. (John Oliver makes a similar point whilst meeting the New York Times' David Carr[3]).
 
The point being that, as one of the developers said, Assassin's Creed Unity: Les Grandes Vacances, is a "consumer video game, not a "history lesson", which is fair enough, but did make me remember how nice it was to just *wander around* and the model for idle entertainment. The Assassin's Creed games, when they're released, are normally priced at around $50-60 - the top pricing tier for that generation of gaming console/gaming PC, which is pretty expensive for a videogame, but nowhere near as much as flying over to Paris to wander around for a bit.
 
Of course, not that playing a videogame and ignoring the prompts to sneak up on people to steal from them or kill them, or complete side-quests is anything like a holiday (or, at least, the kind of holiday that the vast majority of people take), but it certainly is *nice* using the free-running system to explore and stand, Hollywood Hero style, on top of a very tall building and spin the camera around you. 
 
In other words: videogames as tourism. Sure, the idea of videogames-as-tourism, or escapism, isn't necessarily a new one. But in Ubisoft at least we do have a multinational company (headquartered in France!) that makes videogames "developed by a multicultural team[s] of various faiths and beliefs"[4] that is spending gazillions of dollars (trust me, I checked, or at the very least, a Person I Trust Told Me So) on asset creation is mainly making games where you can run around and watch some tedious exposition about conspiracy theories and a memory-exploration device (such exposition is vaguely interesting in that - OMG - Ubisoft is the corporation that's allowing you to explore the unreliable collective memory of a people and visit the past!), but really, my anecdata points to a bunch of people who just like wandering around other cities and climbing on top of things.
 
So what's the market for an explore-and-climb-on-things-in-a-real-city game? Well, maybe not enough to spend gazillions of dollars on, but the nice thing about videogames and data and computers is the close-to-zero-marginal-cost when you've already done a lot of the legwork. Sure, you'd need to strip out all the quests and stuff, but maybe you'd need lots of people milling around (hopefully they're people who are of differing heights[5]), but you'd have a Different Thing. It might not be a Triple-A sales-expectation game, but then, you'd be not selling to "gamers" - you'd be selling to people interested in visiting Paris and wandering around a bit. Which as we've seen from Google Maps and streetview - at the opposite end of the entertainment/utility spectrum, is *totally* a thing. 
 
But what if Assassin's Creed *were* a history lesson and not a consumer video game? For one, it probably wouldn't look as good because the production budgets are totally different, but if there's one thing that videogames *could* be good at, it's the idea of unreliable narrators and presenting differing (and contradictory?) points of view[6].
 
What I'm getting at, I think, is this: there's a stupendous amount of value locked up in the high-res mostly-accurate models, textures and geometry involved in the production of contemporary Triple-A videogames. With organisations like the BBC and their will-they-won't-they Creative Archive[7], I can kind-of imagine a company like Ubisoft offering some of their assets up on a CC-alike no-commercial use licence for educational or non-profit products. Imagine what could be created with access to those kinds of assets. Imagine what The Fullbright Company[8], the studio behind Gone Home, could do with such assets. 
 
[1] Assassin's Creed - Wikipedia
[2] The new “Assassin’s Creed” game is reviving an ancient debate over the French Revolution - Quartz
[3] John Oliver’s Complicated Fun Connects for HBO - NY Times
[4] Assassin’s Creed, Multiculturalism, and How to Talk About Things - Magical Wasteland
[5] https://twitter.com/ultrabrilliant/status/534332698383638528
[6] Hat tip to long-time reader Paul Rissen: https://twitter.com/r4isstatic/status/534385638842593280 
[7] BBC Creative Archive
[8] http://fullbright.company
 
2.0 Principles for 21st Century Government
 
I haven't written much, specifically, about the new day job. One of the things we've been working on over the past (counts) six-and-a-half weeks since I've started is trying to define how we think government should work, and the result is this: Principles for 21st Century Government[1]. Let me see if I can write some background here. 
 
[and we're back, at 9:35pm and in the sky on the way to the family farmhouse in Missouri]
 
Code for America has an interesting position: they're a 501(c)(3) - a non-profit - whose goal (I'm paraphrasing here, and producing my own explanation, which is part of the issue) is to improve the quality of government using technology and process. Part of the clue is in the name, but the name is also a bit of a misnomer: before I really started talking to them I was under the apprehension that they were a bit like Teach for America[2], which is a different kind of thing. They're also not a government program, unlike organisations like 18F[3] or the US Digital Service[4], both of which are modeled, in some ways, on the success that the UK's Government Digital Service has had. (You can see the practically seminal effect that GDS has had through 18F's current website subhead, "*Delivery* is the strategy", an inversion of one of GDS' taglines, "The Strategy is Delivery".
 
Anyway, I digress. Part of what I'm trying to do at CfA is help with a sort of organisational clarity. I think it's fair to say that at the very least *I'm* not very happy with one of CfA's current slogans, "We believe that government for the people, by the people, can work in the 21st century" because it doesn't really say what we do. And we're (the royal organisation we) are at that stage, getting to nearly 50 staff, where we're approaching a phase-change that most organisations go through. 
 
For example, the principles are a tightening-up of what were previously known as "capabilities". We talked about things that governments ought to be able to do, abilities that they should have, in order for them to deliver services that people would prefer to use. But the shift that I wanted to make was that a capability without implementation is, from a practical point of view, not a capability at all. Ability without use is just unrealised potential. 
 
So it's one thing to parrot "The strategy is delivery" but I feel that, the vagaries of human communication being what they are, it's a very simple phrase to grok on one level, but you need to really understand what *delivery* means. In GDS' case, they have a unique situation: a top-down mandate, both political and apolitical for change in the way that the civil service does things. They also have, in Mr. Bracken, someone with what can only be a formidable political superpower in terms of shielding those doing the work from day-to-day political machinations. 
 
No, if you're serious about taking on "the strategy is delivery" you need to know what it means, and you need to make sure that *everyone* knows what it means. This is an interesting challenge for CfA because we don't have a mandate at all. We have to go out and persuade local governments, who are frequently at the sharp-end of delivery in the Federal United States, that "delivery" is the way to go. 
 
In other words, we have to sell delivery. 
 
And the thing about "the strategy is delivery" is that it's recursive: the reason why your strategy is delivery - of making things, of incrementally improving services, of focusing on, as the jargon goes, outputs and outcomes, on the things that residents and citizens actually use and are entitled to use, is because results - instrumented and measured results, are hard to argue with. 
 
The strategy is delivery because when done right - and there's the point, see - delivery works. 
 
The strategy is delivery because delivery means improving the end-user experience and capturing the documentation that the end-user experience has improved. That wait-times have decreased. That support costs and enquiries have gone down. That usage has gone up, or gone down. That policy is actually being delivered. 
 
This is hard. It isn't easy. You can't "buy" delivery. You can't just come in externally and train a capability or an ability to do user research and then not actually enact it. So right now, we're having an internal discussion about what it means when local governments ask for training. How do we make sure that we're actually achieving our aim of better government, delivered, rather than providing training for an ability that might not actually get used? 
 
And, bluntly: how do we help those who don't know what help they need?
 
Personally the principles were an interesting thing because they were written from the point of view of "things that you should be able to do" rather than "look, you have to agree with these things". Because if you don't - if you don't agree with those things, then you're never going to do the other stuff. If you don't, in effect, drink the kool-aid, and agree to work this way and do things this way, then you're not going to, essentially, do things this way. 
 
So then you have to prove them: why these principles? Why "Design for people"? Does it actually work? Well yes, it does. So the next step is the case-studies and examples that prove and shore-up that work. We don't have the benefit that GDS does in terms of a top-down mandate to tell people that this is the way things are going to happen. We don't get to dictate standards. We have to win converts, one local government at a time. 
 
And for that, the strategy is better government, delivered. 
 
[1] http://www.codeforamerica.org/governments/principles/
[2] http://www.teachforamerica.org
[3] https://18f.gsa.gov
[4] https://playbook.cio.gov
 
--
 
9:59pm on a Wednesday evening.
 
Send me comments, as ever. I love to eat them.
 
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Five: The Ritual of Dying; The Mission
Date: November 14, 2014 at 9:10:32 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-jkhh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
6:46pm on a Friday night, over a week after my last episode. I think it's pretty fair to say at this point that it's become difficult to write every day. Probably not impossible - at least, not for the kind of person who looks at Ben Franklin's daily schedule[1]. But in any event: less writing. Probably because there's significantly more writing and more thinking going on elsewhere. Draw from that your own conclusions. 

I'll tell you one thing that's still difficult, though: coming to terms with the fact that the "work" that I do, the "stuff" that I make isn't product-making but more sense-making. It shows up in lots of other things. But even when there's this shift to Makers (and with all due deference to Getting Excited and Making Things), even when "making things" includes intangibles now like shipped-code, there's still this stigma that feels like it attaches to those-who-don't-make. Well, bullshit. I make stuff.  

[1] Benjamin Franklin's Daily Schedule - Swissmiss  
1.0 The Ritual of Dying
Philae died ("went to sleep") today[1], and as things are these days, she went to sleep publicly[2], through her Twitter account. 

We're good at this, us humans, putting mind and agency into places where there isn't any. We anthropomorphise lots of things. It started with the space probes with, I think, the Phoenix Mars Lander[3] back in 2008 and, well, it just kept going. One of the more poignant (if not distressing) recent examples was that of the Chinese Space Agency's Jade Rabbit posting "Goodnight, Earth, goodnight, humanity"[4] as a mechanical failure caused it to power-down. And when CSIRO's Mars orbiter arrived, Curiosity greeted it, too[4].

There's a thing here. I said tonight that there's a "ritual of anthropomorphised robotic space probes dying in public on social media."[5]

The idea that as a species we have a practice now - I mean, America's doing it, Europe's doing it, China's doing it, India's doing it: we give our robot probes voices and they're our emissaries. This is citizen science engagement in a way that we haven't really done before, not because we didn't want to, but because we couldn't. But also because there's a gap in what you get from a textual status update: we fill in the voice and the emotion ourselves, and we humans, we're great at looking for patterns and agency when there isn't any. So we'll happily take a vessel like a comet probe and fill it with our own emotions and yearnings. 

Also, don't forget: there's every chance that these accounts are being written and "crewed" by people who know what they're doing. We are undoubtedly being manipulated - at least in as much as we're manipulated any time someone tries to communicate with us. There's a mental state that someone or something is trying to transfer. 

So this is the ritual: we offer up a scientific endeavour and give it a voice. And then we have to kill that voice and feel terrible for it. I mean, can you imagine? The idea of reality tv show funded space exploration for *humans* is pretty old hat - but right now we have reality shows of robot probes doing exploration. Arthur C Clarke wouldn't have imagined there being a job for someone to take what a probe was doing and translate it into the first person, and for that first-person account to *hook* millions of people around the world. What a bizarre thing to do. But now, with hindsight, it seems all so obvious. 

Look, I can do it too. We take these robots. They're not human. They're frequently written to be lonely, separated from us by distances that no human has ever really been able to comprehend, and may not be able to comprehend for tens or hundreds of years. They're written to embody the hopes and dreams of hundreds or thousands of people who have worked and dedicated their lives to a single scientific endeavour. We know space is cold, dangerous, inhospitable. And they're so *alone*. 

It's almost as if we can send humanity as a proxy, through these little robots and then cut them loose. All without risking any lives. 

[1] Rosetta mission: Philae goes to sleep on comet as batteries run out - The Guardian
[2] https://twitter.com/philae2014/status/533423541413502976
[3] Wired Science Scores Exclusive Twitter Interview with the Phoenix Mars Lander
[3] China's imperiled Jade Rabbit moon rover: 'Goodnight, humanity' - CNN
[4] https://twitter.com/marscuriosity/status/514611142178516993
[5] https://twitter.com/hondanhon/status/533446792637984768
2.0 The Mission
At work, doing a thing. The thing mainly being: what is it that we do, and why? Never mind the how. But then also working out how to explain to them *exactly* what "the strategy is delivery" means. Because you can deliver lots of things. How do you know you're delivering the right thing? What does iterate mean anyway? And then, once we agree on those things, how do we move forward? Deliver understanding. Deliver the ability to copy. Deliver training? Can you even deliver training if it's not being applied? Is training that is delivered, but not applied, even effective in the first place? If the goal is to deliver *better government*, then does what's being proposed actually deliver that, or actually have a chance of delivering that? 

So yeah, the mission. What do we do, and why? 

--

7:09pm. Shorter, more frequently. Let's try that as an experiment. 

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Four: Our Crap Connected Future; Oh My God More Advertising; Echo
Date: November 7, 2014 at 1:28:08 AM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-jcfx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

6:59pm in Las Vegas. There are at least 16 slot machines in my line of sight. A day trip this time, to see how things are going, and they're, well, going. 

To be honest, it feels weird to have written a bunch of reckons about the Samaritans stuff and digital and advertising and all of that. I got a great bunch of notes back, and I'll be writing back to you individually over the next few days (or even weeks). 
1.0 Our Crap Connected Future

When I was a teenager and in the midsts of my first relationships, buying jewelry for my girlfriend was totally a Thing. Jewelry's one of those things that back then was a whole bucket of neuroses - am I buying the right thing, does it mean the right thing, is it "pretty", will she wear it, will she like it, all of that kind of stuff. All of that self-analysis to try and make the right kind of gesture. 

Back then - you know, the 90s - things were made out of dumb matter and nothing had a radio in it never mind a TCP/IP connection and they certainly didn't light up or sense things. I think about the kind of jewelry that my son might buy for someone and what it might do. 

Alexandra Deschamps-Sonsino[1] pointed at Artemis, an indiegogo campaign for a piece of personal safety smart jewelry[2] on Twitter, describing it as a "Nice, pendant that doubles as a geolocation safety service"[3]. Which appeared to light a touch paper of sorts: relationships already have to now negotiate a sort of public graph and visible interactions on networks like Facebook and Twitter, *never mind* what will happen when the objects that we use to show affection become (inevitably?) smarter and just more nodes on the network. 

So: 

"When we broke up, I promised to never forget him; he gave me a locket to wear forever. 

Turns out it's leaking my GPS location."[4]

"A List of Exes Who Remember Me Every Day They Use My HBO Account"[5]

"After He Cheated On Me, I Changed The Passwords On All Our Jewelry"[6]

I think it's the last one I like the most. The idea that in our crap connected future - the one where you can buy GBP 24.99 jewelry from the equivalent of a catalogue retailer like Argos in the UK. Or, you know, $25 jewelry from the case at Walmart that's churned out in the millions-of-units range. Or hundreds of thousands, I don't know. But that each and every single bit might well come with a radio and an IP address and an account and some sort of smarts - or dumbs - that require yet another layer of management because hey, it turns out we still don't really have good patterns for building the software that mediates that relationship yet. 

And then, and then!

After all of that, the idea that those objects start to permeate our culture. I grew up with Bridget Jones's Diary, but in ten years, it might be Bridget Jones's Wearable[7]. Or a Film About A Divorced Man Who Falls In Love With His New Amazon Shopping Appliance[8].

There was a nice piece in Genevieve Bell's talk at Web Directions last week - about how her research has shown that people are egocentric - not a value judgment, just a fact: that when we're told our objects can talk or communicate with one-another, we assume that they're talking *about us*. That they are talking behind our backs. That, for example, your connected devices might tell tales on you. That Facebook might talk to that new app you signed up to and tell it that you're lying about what your mother's maiden name was. That if you're in a relationship, you might find out that your partner's really in love with you because his heart rate increases whenever he's around you, or that last Wednesday he ran to meet you. 

And, of course, if you *trusted me*, if you *loved me*, then of course you'd let me access your data. Of course you'd pair your Withings scale with me. Or that by the time you decide to move in together, you get a shared Withings account. Or can you have a Withings account in a shared house? What's shared smart home infrastructure look like? 


[1] Alexandra D-S at Designswarm 
[2] Artemis: Smart Jewelry for Personal Safety
[3] https://twitter.com/iotwatch/status/530535180797497344
[4] https://twitter.com/hondanhon/status/530548021738500098
[5] https://twitter.com/hondanhon/status/530548834472960000
[6] https://twitter.com/hondanhon/status/530549595710189569
[7] https://twitter.com/hondanhon/status/530552131175329792
[8] https://twitter.com/hondanhon/status/530550510676635650
2.0 Oh My God More Advertising
Okay, so. More advertising. I haven't watched the Amazon Echo ad yet, but suffice to say there's commentary from people whose opinion I respect, like Ellen Chisa[1] that indicates that it's about par for the course for tech advertising that isn't Apple's stuff, or maybe Google's more recent stuff: ie, pretty terrible. Amazon doesn't have the excuse that Samsung has, for example, of being culturally out of touch with what's acceptable in a Western audience (or, indeed, everywhere) so it's not like it sounds like it's *ridiculously* sexist like last year's Samsung SSD "ad"[2].

But anyway. As Gus from Drop the Dead Donkey[3] was prone to say, I'm just stopping by with some ingredients I'd like to pop into your thought-wok and for you to give a stir around:

 - the idea that before, you built a brand not just by doing but by advertising, and advertising was the one way you could (and still can) quickly and efficiently reach a lot of people with a single, consistent message (if you're doing it right)
 
 - the idea that it was easier to exemplify a brand through just saying what it was than by *doing it*. And easier is/was also cheaper: the argument that I've seen running through the replies to some of my previous episodes has been along the lines that it will *always* be cheaper (if not effective) to advertise your way out of a problem than to actually "do better". Or, you know, deliver.
 
 - the weird idea that, as some people seem to think[4], television advertising is figured out because we know how to make "good" ads. The truth being that the web *does* need to learn, but it hasn't quite figured it out yet, and it *feels* like the trend is for the brand-advertising that works on the web is more like brand-advertising that works on TV. Basically: video.
 
  - but then, the thing that I get hung up on which is: what is the web best at? It is certainly *better* at a lot of things, and that's probably enough. It's *better* at letting people see what they want, when they want to. It means push-brand-advertising rather than pull-brand-advertising. TV is still pretty good at reliably delivering large audiences in one go - not as big as the ones it used to - so that when you've got the cash to burn and you absolutely want people to see your thing, then hey, maybe you can put it in front of those eyeballs. The web doesn't quite work that way (thank god), and some of the stuff Facebook have been saying about how their forthcoming video ad units might work is, well... interesting. 
  
 - no, the web is best at the link: first linked pages, now linked data, and all the link implies. But you don't need to be best to just be better, and the web is better than television at delivering things that people want when people want it. You know, like that ad they saw on tv that they liked. But "branded experiences" from the heyday of things like The Wilderness Downtown (which is OVER FIVE YEARS OLD NOW[5]) and required that you actually download a browser to experience it feel like they're over. They're big and they rely on, like some of my readers suggested, some idea of "engagement" that was super immersive as opposed to the lightweight engagement that seems to be optimised for these days. 
 
 - the thing instead that brands are built these days by doing, not by telling. Nike was also built by doing, but its doing was constrained to atoms - it had to make shoes and sell them out the back of cars, waffle-irons and all, but it was the advertising-that-wasn't-advertising from the taste of Phil Knight and the partnership with my ex-employer Wieden+Kennedy that used Nike and advertising and communications to be the *idea* of a thing, rather than the *delivery* of a thing. When a client like Facebook or Airbnb comes to a traditional brand advertising agency, the kind that doesn't want to do product advertising, the doing is already there. All that's left is the massaging of the messaging. A "provocative relationship" is already being formed in a way that's not been possible thanks to a new digital medium. 
 
 - the more-or-less-lie being told by *advertising agencies* to their creative teams - especially the younger ones who are coming into the business in that they don't actually get opportunities - or will rarely get opportunities to *solve business problems creatively*. Ultimately, what they have to do is advertising. The creativity part, at least in advertising, serves as part of the "how do we get attention in an increasingly noisy environment". Part of this is the really weird thing where ad schools are teaching ad school students how to come up with "apps" when, really, I can't even do this. I'm sorry, I can't. It's just such a bad idea. 


[1] https://twitter.com/ellenchisa/status/530541892153655297
[2] Stupendously Sexist Samsung Evo SSD Ad ("Have you ever played with little toy bricks before?") 
[3] Drop the Dead Donkey
[4] https://twitter.com/cdixon/status/530157819454971905
[5] http://www.b-reel.com/projects/digital/case/57/the-wilderness-downtown/
3.0 Echo

OK. I've watched the Amazon Echo ad[1] now. You don't need me to tell you it's terrible. Not only is it, like Chisa above says, stupendously sexist, it's also just a *bad ad* and smacks of what Dustin Curtis talks about when he says they just plain have no *taste*[2].   Leaving aside the "what problem does this solve" thing other than an incremental (but, I suppose useful) benefit, for when you a) can't be bothered getting your phone out of your pocket, b) can't be bothered *lifting your wrist to your hand that has an Apple WATCH on it I guess you could c) strategically position a NUMBER of Amazon Echoes around your house (the video has the Echo creepily following our weird Stepford Advertising Family around their house - we see it in the living room, then someone's moved it to the kitchen, and most amusingly, Dad (I presume, seeing as he's the one to blame for this entire mess) appears to have taken it up to the parental bedroom at nighttime so he can wake up next to both it/Alexa and his wife).    Also, I *guess* and I don't know if this is a good thing or not, but I suppose at least Amazon Echo is a thing, and Alexa is a separate thing, and the thing is not Alexa in the same way that Theodore's OS upgrade was an OS upgrade and was also Samantha but seriously the whole thing is just *weird*. From Tech Dad's Mansplaining (at least Playing Dumb Wife had the decency to mock him behind his back when he wasn't looking) and strange dialogue: "It's Amazon Echo", as if he's been handed a brand guidelines book with the package (which he obviously has, because this smacks of the kind of ad or infomercial that happens when there's no one with a bit of sense to smack the client around the head and say JESUS CHRIST GET OVER YOURSELVES, YOU'RE GOING TO LOOK STUPID).   And to those people asking: how can something like this still exist, still be made in a post-Snowden world? Have you not looked at the post-Snowden world? It's pretty much the same as the pre-Snowden world, only now, we're a lot more terrified. Sure, a bunch of opsec people at Google are super pissed and bits of the internet are becoming more encrypted, but hey, this is AMAZON we're talking about here. They have a SPECIAL VERSION OF AWS that they built JUST FOR THE GOVERNMENT. What did you expect?   But yeah: Alexa is not a thing in her own right, just a feminine slave to be commanded by the family and fought over by the children, and she's also "named" Alexa by the family, apparently? ("She only hears you when we say the wake word we chose") to which there are going to be a bunch of families who, if they ever buy this and have children, will inevitably have to figure out why Alexa no longer responds to Alexa but instead responds to "pooface".   I just. Can't. Even. I mean, "ALEXA, GIVE ME MY FLASH NEWS BRIEFING" - is that something that Tech dad programmed into Alexa so he could be all GIVE ME MY FLASH NEWS BRIEFING? I mean, I suppose it can be *fun* and pretending that you're having fun, but there's no *pretending that you're having fun* in that horrible ad, he's *actually being serious*. Like, serious serious. And if that phrase *isn't* something that's user-defined and is instead a standard Alexa activation phrase: seriously, Amazon?   And then again, the fact that you have to be *invited* to buy this thing and that Prime Members will get $100 off which again: how much is this thing going to cost? What's Amazon's plan here? Is it to just embarrass themselves?  [1] http://www.amazon.com/oc/echo [2] http://dcurt.is/amazon-has-no-taste  --  Alexa, post this newsletter episode for me and set an alarm for 7am.  Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Three: The Thing About Brand Advertising
Date: November 3, 2014 at 10:29:01 PM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-j8ih=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:50pm on a Monday night after having arrived home from Sydney yesterday. I've realised I have two habits: one is always going to a farm within 30 days of arriving in Australia, which requires me to be really paranoid and tick a box (first, staying on the in-laws farm before going to Perth, this time, visiting a pumpkin patch for Halloween before Sydney), the second of which is travelling whenever the clocks change. It's easier (ish) to travel when the clocks change in Spring - just make sure you go to a conference like SXSW and you'll mostly get screwed by the time change. This time around, the clocks going back for autumn is just lost in the noise of jetlag.
1.0 Brand Advertising
If you've been following the last two episodes, you'll have been watching my flashback to my not-so-long-ago advertising days after having seen the Samaritans Radar "campaign" / "app". 

Obviously this whole thing is still on my mind. There's a bunch of things going on here:
Thing The First:
No one really knew what "digital" was going to be. It's an achilles heel of advertising that part of the job is to get attention, and part of the deal with getting attention is to do New Things that have Never Been Done Before. In fact, they're so much part of the deal of getting attention that such phrases become part of the landscape and used in briefs. Creative teams literally get asked to do something that's Never Been Done Before. 

The deal with capital-D digital is that it was a whole *bunch* of things that had never been done before. That's the beauty of a two-way medium that is made of software - it's pretty much infinitely malleable. There's a reason why part of what excites people about digital is the idea of *inventing* new forms of media, and not just populating existing media. 

With digital, there are new ways of doing things.
Thing The Second:
I used to think this was a problem, and now I'm not so sure anymore. In fact, I'm not even sure *where* the problem is anymore. I used to get excited when I'd pull on the thread of a brief with my teams and we'd get to the Root Problem and we'd come up with a Creative Way To Solve It. Sometimes, this would involve doing or making a new thing, and that's invariably where the wheels would come off, especially at a place like Wieden. You see, the think about Wieden is that for the last thirty-odd years, it's been an ad agency, and the thing that ad agencies do is, well, they make advertising. Their clients want to buy advertising. And by the time a client selects Wieden as an agency, it's pretty much a foregone conclusion that the *answer to the business problem* involves advertising.

This is what eventually irritated me and led me to ask the Ultimate Question: are we solving clients' business problems *full stop* or are we solving clients' business problems *within the confines of advertising*. You can pretty much guess what the answer was.

The thing is - what would you expect an advertising agency to actually do? Not Advertising? Sure, they might *want* to do that, but why would a client want to do that? And sure, you might have a bunch of smart people in that building who can Think Shit Up, but by the time you get to a Creative Answer To A Business Problem that's Not Advertising, suddenly you've run out of people you have a relationship with whom to sell it to. How can a CMO buy a non-advertising solution to a problem? That's not within their remit. The typical situation is that a CMO is going to be in as silo'd an organisation as the agency trying to sell a solution. It's not going to work. Not without a whole lot of work. 
Thing The Third
Once you figure out that an advertising agency's job is to make advertising - and to not *actually* solve the client's problem, but to solve the client's problem *through advertising*, things get a bit simpler. You can get rid of all the digital people who want to solve business problems with a large brush: they're just going to get frustrated. Instead, you're left with... something else? You're left with things like Chrome Experiments, the Arcade Fire Thing, Streetview Stuff and, well, mostly films[1] as pointed out by Faris Yakob. 

[1] What Happened To Interactive Digital Advertising? - Faris Yakob
Thing The Fourth
And then, you get to one of the big questions. What does "digital brand advertising" mean? Or, what does "digital branding" mean? On the one hand it's entirely appropriate to say that something like Nike's FuelBand *is* digital branding. It was - however successful or not it turned out to be - an attempt to marry what Nike meant into something that - kind of - served a user need. Shoes serve a user need. Just Do It is a way of, I guess, talking about that need. A FuelBand is a way of serving a user need - ish, if it's been researched and demonstrated to exist! - to be active all the time. So yeah, I guess that product-and-service kind of makes sense. 

Russell Davies has written a lot about this, and this is the nth time I've linked to his The Strategy Is Delivery[1, 2] piece now, and I guess I'm going to keep linking to it until everyone finally understands what he means.

I have no idea what digital brand advertising is. It's weird. It feels like - given what we've seen is winning awards, it's just regular brand films on the internet. You know. Volvo splits type stuff. Which means this is all well and good until...

[1] The Unit of Delivery 
[2] The Strategy Is Delivery - London Strategy Unit
The Wheels Fall Off
Ben Thompson is a stupendously smart person who amongst other things has written about the idea of Peak Google[1], which is what happens when Google realises that it's not very good at - tada - brand advertising. Ben says this is what brand advertising is:
"The idea behind brand advertising is to build “affinity” among potential customers. For example, a company like Unilever will spend a lot of money to promote Axe or Dove, but the intent is not to make you order deodorant via e-commerce. Rather, when you’re rushing through the supermarket and just need to grab something, the idea is that you’ll gravitate to the brand you have developed an affinity for. And once a customer has picked a brand, they’re loyal for years. That adds up to a lot of lifetime value, which is why consumer-packaged goods companies, telecom companies, car companies, etc. are among the biggest brand advertisers."
This sort of thinking is pretty much in opposition to what the LSU and GDS folks are espousing (and the smart people will quickly be able to work out what the link is between the two). On the one hand, Google's going to slowly and quickly (as things are wont to happen) fade away because it's not going to get a bite out of the brand advertising pie. On the other hand *brand advertising itself* is getting a hard smacking because it turns out that (horrors) it might not actually be any good. Or, instead, that the real arms race isn't in more-and-better brand advertising for FMCG-type companies, it's in making better products. 

What happens if or when a Unilever or a P&G adopts a strategy-is-delivery approach to its FMCG products? Will their rival be able to brand-advertise their way out, our will we suddenly be in a red queen race that leads to, well, better and better products, rather than more and better targeted advertising? 

But then, this is the thing. Do you think a Unilever will be able to rework its product offering to make sense in a fully digital world? I mean, take a really boring thing like shampoo. You'd say that there wasn't much more to be done with it, but that hasn't stopped "innovation" happening in the shaving area (I literally can't believe I just typed that) where you can now get shaving products on-demand? And sure, some of that stuff might be *really dumb* right now, but we're talking about making lives easier and better. 

To take GDS' words and use them elsewhere: what does a toothpaste so good that people *prefer* to use it look like? Is it the kind that invests in packaging technology so it knows - internet fridge/bathroom or no - when it's near to running out and puts an easy-to-cancel order in that ties into your existing subscription shopping Is it the kind that works so well with a toothbrush that it's able to help you with preventative care? Is that all it needs to do? Are there other things it *could* do? Or, you know. You could just do something stupid and hook it up to a social network so you can see how many of your friends are dentists who also use it, *because that's useful*. (I was being sarcastic). 

A product so good that you prefer to use it, because it's hooked into a digital ecosystem, because that's what the world is, and what the world's moving to. Where it's *easier* and *better* to use this product, and you choose it for those reasons, not for brand affinity. What do things start looking like then?

[1] Peak Google 

--

8:27pm. Send me notes. Especially all you advertising lot. I know you're out there.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty Two: The Starship Enterprise; How Do You Solve A Problem Like Digital?
Date: November 2, 2014 at 10:43:54 AM CST
To: <dan@danhon.com>
Reply-To: danhon <reply-j6m9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

A ground speed of 608 miles an hour. 31,000 feet or 9,448 meters high. 162 degrees, 9 minutes, 35 seconds east, 26 degrees 47 minutes 48 seconds south. Either 2:45pm from my departure location or 8:45pm the previous day at my destination.
 
1.0 The Starship Enterprise
I was having dinner the other night with Tom Armitage and we figured out what my next talk was going to be. We've been friends for a very long time - at the same time as crossing paths at university, we were both bloggers in the late 90s early 2000s in the UK. Tom knows that I have, if not a soft spot, then a sort of obsession with the world of Star Trek: The Next Generation - not necessarily in terms of the characters and stories, but more in terms of what the world of the Federation actually means. How hard you can push it and how much of it just ends up being silly, or falling apart at the seams. 

I've written about this kind of stuff before - way back in episode 12[1] I was writing about the computing infrastructure of the world of the Next Generation, I mean, does *everything* in the Federation run LCARS? And, you know, somewhat tongue-in-cheek, who runs devops at Starfleet? Is LCARS open source? Can any civilian submit a pull request? 

But no, this is the idea, and like most things, I can't remember how we got here. I think it was because Tom saw that I'd somewhat facetiously tweeted if LCARS supported animated gifs. Or maybe it was because I'd been thinking out loud and told him that I wondered how the Enterprise-D's Main Computer disambiguated names when routing communications requests. There aren't that many times (I haven't looked) where someone does the equivalent of *tap combadge* "Picard to Smith" and Computer says "there are seventeen currently Smiths on board, which Smith did you mean?" and Picard has to say "John" and Computer says "there are three currently John Smiths on board" and Picard has to say "John Smith, no bloody A, B, C or D". 

(Of course, I realised as I wrote that last sentence that that's a pretty good example of  Computer requiring disambiguation, and a pretty good episode to boot[2]). 

The reason why the Enterprise-D is so big, the reason why it has hundreds of crew, the reason why it needs to haul around all of that *stuff* is that the Enterprise-D is chock-full of knowledge workers. "Enterprise" isn't just the name of the ship, it's a description. It's a tiny little city state - with everything that that city state needs - and it doesn't do it through magic hand-wavey unobtanium technology, it does it, horrifyingly, in *exactly the same way* we do things right now. With computer-augmented humans. 

(Yes, I have a copy of the TNG Technical Manual. I know that's not how the Enterprise-D *really* works. Computer has over 47 kiloquads of processing power! No, this is taking what we have now, sticking it in the Next Generation universe as a way of thinking about what we have right now. Thank you for holding fire, Star Trek pedants.)

There's what, 10-15 bridge crew on the 'D. They haul an immense support infrastructure around with them. Here's what happens when Riker taps his combadge to be put through to Dr. Crusher:

Riker taps his badge and as it chirps, someone down there on Deck 47 sitting at an LCARS terminal, *just like a call center worker*, sees Riker's profile pop up on the screen in front of them. Computer is listening everywhere, always, just like Echelon and the NSA are - there are mics and cameras all over the place. Knowledge Worker (Ensign Grade) Barclay sees a transcript of pretty much everything that Riker's been talking about over the past few seconds, minutes and hours. There's a graph layout of everyone Riker talks to and how often. And Knowledge Worker (Ensign Grade) Barclay taps on the pre-selected, auto-completed icon of Dr. Crusher and routes the call. Because there's a *switchboard*. 

Every single one of those LCARS terminals has a support ratio. At least 5% of the D's crew are desktop support staff, either replacing burnt out LCARs terminals or refreshing them. Some of the items are self-service, like the vending machines on the Facebook campus. But it turns out that a lot of the time, you just have to see someone down in IT. 

Every time Data looks something up there's at least ten people behind him, several layers deep, preparing reports and checking on computer-augmented intelligence. It's kind of depressing, really: the entire infrastruture is set up so around 10-15 bridge crew can swan around and do away missions. The only genuinely piece of *absolutely amazing tech* that can work itself is the transporter. 

The worst part, the absolute worst part, is the holodeck. Whilst 5% of the D's crew are desktop support staff, there are at least twice as many texture artists slaving away making sure that when Riker wants to program in Riker Risa Scenario Forty Seven Alpha, he's got the right Blender models to choose from in the library and the right textures to decorate everything. Assassin's Creed: Unity, the latest in the Ubisoft I'm-a-pretend-assassin-travelogue set in Paris, probably has up to 10 teams working around the world, say up to a thousand people recreating Paris for us to play in 1080p on next-generation consoles like the PS4 and the Xbox One. The future of the Enterprise isn't magically waving a wand and creating a new Holonovel like a sort of interstellar-holonovel-writing-month all on our own, it's more of a production line. Have you ever sat through the end-credit sequence of a Lord of the Rings Extended Edition Movie? Yeah, that. Now look at the Enterprise and every single one of those glinting portholes. That's a 3d modeller, rigger or animator, texture artist or whoever, slaving away so that Picard can pretend to be Dixon Hill again. That's the mission: to explore new worlds, to boldly go where no one has gone before and to create disruptive innovations in the VFX workflow/pipeline. 

Oh, oh, and you want to know why the Enterprise is so big, *on top* of all of the staff? At least sixty of the decks (oh, I don't know how many decks there are) are just made of CLOUD. Do you have any idea how much iron it takes to bring a small bit of cloud with you? There's a scene that both Tom Armitage and I love from Danny Boyle's movie Sunshine where you see that the ship's computer is overclocked - it's submerged in liquid nitrogen or something so that its processors can run at a gajillion gigahertz because otherwise it turns out you'd need a billion of those processors to provide the voice interface. We see this when one of the characters has to plunge their hands into the liquid bath keeping the compute infrastructure cool. 

The TNG Technical Manual has a little bit about how the Enterprise has a main computer core, it runs vertically, I think, through a few decks but: come on. We've seen datacenters. Look at all that back-end infrastructure you need! Most of it, again, is just racks and racks of nVidia/AMD GPU nodes so that Geordi can have a semi-plausible visual simulation of Dr. Leah Brahms (which is creepy enough in itself). At least you're in space so you don't have many problems cooling all of that stuff. Just open an airlock every now and then. 

Think of the Enterprise as a regional office: 1,200 people, with ten or so Director/VP-level appointments at the top. Everyone else is just hanging around, clocking in and clocking out. This is what an Enterprise means: taking a little bit of culture, taking a little bit of infrastructure, taking a neighbourhood and making it self-similar so it can fly around in a metal bubble filled with air. 

It's not a post-scarcity society. There are still jobs in Starfleet. They just all happen to be knowledge-worker jobs. Tobias Revell's closing keynote had a reference to a particularly dystopic recording of a call centre marketing call where the human recipient accuses the caller of being a robot and the robot - or, at least, you think she's a robot, you can see the rules and the branching trees performing the VoiceXML analysis and routing, picking up on keywords and protesting that she is not a robot, she's human. But the twist is this: not only was the call *coming from inside the house*, but it was operated by a human using the equivalent of a call centre sound board - a human listening to another human, but having no mouth and not being able to scream, communicating only through pre-recorded snippets that *cater for the fact that she will be accused of not being a human*. Mechanical Turks, all the way down.

The Enterprise's computer is the kind of computing system we all use right now: one where computers do things that computers are good at, and where humans kick in doing the things humans are good at, or even better, are *cheap* at doing, even cheaper than computers. Red Dwarf took this to the British satirical extreme, where a miles-long mining ship employs hundreds of *vending machine repairers and cleaners* because it's easier to get humans to do it than it is to get robots to do it. We use Protein Folding games right now to get humans to pattern match - to work in symbiosis (of a sort) with computers to examine things and click things just so. That's what's happening behind the scenes on the Enterprise. You wake up. You get breakfast from the Replicator, which menu today has been laboriously manually programmed by Chavez, two bunks down, you sit in front of your LCARS terminal and then you look at things and tap on them. For the rest of your life. But hey, space travel! I mean sure, we get episodes like Below Decks and get introduced to Ensign Laren and her friends every now and then, but that's really not what Star Trek: Call Center is like. Or Star Trek: Amazon Fulfilment Warehouse. Or Star Trek: Knowledge Worker. 

(An aside: Tom and I were also talking about how stupidly surprisingly awesome Tom Cruise's Oblivion is because of the Big Dumb Object that hearkens back to classic Science Fiction, or at least a certain genre of it, and the idea that somewhere in Starfleet there's a Warehouse 13, or a Special Circumstances, or just the team that goes out and discovers the Genuinely Weird, Unexplainable, Really Fucking Terrifying Outside Context Problem stuff. Like the Whale Probe. I mean, that's super alien! But no, we have to have little episodes about relocating indigenous people so we can steal their youth-providing radiogenic field or whatever.)

There's of course the joke that Star Trek: The Next Generation is the way it is because it's the quintessential 1990s show - all curved edges, fake wood trim and Marriot In Space, but the other idea is that pretty much everyone else on the ship apart from our bridge crew are Uber-style "independent contractors" - and maybe even the bridge crew, maybe even Captain Kirk is an Uber-style independent-contractor-not-an-employee so the next time his sexually assaults a first contact species or accidentally destroys a civilisation, Starfleet Corporate can go "well, he's not *technically* an employee" and disavow his actions. 

Yeah, the horrifying future of space travel is a super exciting thing for around 10-15 people and cube-farm hell for the other thousand-or-so travelling. Mundane, manufactured normalcy. Your job in space is *just the same* as your job on Earth. 


[1] Episode 12 - Attention, Star Trek and Cars
[2] Relics at Memory Alpha
 
2.0 How Do You Solve A Problem Like Digital
I'm still mildly simmering after having hammered out the previous episode about the Samaritans Radar mess. And let's be clear: there's a lot of mess to pass around, and it's fair to say that there was at least *an* interesting insight in that people are saying things and how, well, can we be more empathic to those who're in our feed and sensitive to what they're saying. Which at some point after pulling on the thread for a while you come to: ah, well that feels a bit like a societal problem, how do we, as you say, "move the needle" and create a more kind environment for everyone so *everyone* can deal with mental illness better.

But this isn't about that. This is about the piss-poor situation regarding "digital" and making things that work, that make things better, rather than making half-assed stuff that just opens a can of worms of problems and now you have Two Problems but I suppose you have an advertising award, so you can just fuck right off. 

I can post-rationalise and tell a reconstructed story of how something like Radar might have happened. For those of you who are (relatively) new to this newsletter, my "creds", as such as they are are that I spent the last four-and-a-quarter years doing "digital" stuff in agency land, first as as senior creative at W+K London, and then as a Creative Director at W+K Portland. I've seen briefs glittering in the dark off the gate to the planning department, I have. I've seen creative teams fly out to New Zealand to build a website. 

And I've seen what happens when agencies tell themselves that they're there to Solve Business Problems. 

There are so, so many things at play here. You have your main two players: the Client, Samaritans, who, given the lack of any evidence to the contrary, appear to be somewhat naive in the "digital" space. You have their agency, Jam, part of the Engine holding company, self-billed as "a social media marketing agency, and part of Engine. We create award-winning social media communication strategies for brands."

And behind all of that, I am assuming that there's pressure both at Samaritans and at Jam to "get" digital. Because "digital" is a thing that is happening, and it's changing everything or some things or maybe even no things and you'd better damn well have a strategy for it. It's doing that everywhere, whether you're a car service or laundering clothes or selling clothes or treating people for diseases or "reading the news" or watching a tv show or any of those things.

It is doing those things because "digital" is a transformative technology just like the way electricity was. 

There will have been someone at Samaritans who wanted to Do Something. Probably, I'm guessing, because Twitter is a thing and young people are vulnerable and at-risk, and it's generally good advice that's been passed around for the last ten years or so in the digital space that you "go where the people are" and that you shouldn't be Kevin Costner and build things hoping people will just turn up. And it turns out that the young people that you, as an organisation wanting to help people with mental health issues, want to make sure that you're doing the best at serving younger people.

So you go find a group of people, an organisation, who can "help you reach younger people" and you find an agency like Jam, because hey, younger people "use the internet" and they definitely "do social" and what you definitely want to do is "communicate" with young people so they know about Samaritans and how Samaritans can be there for them when they need someone. 

All good so far.

Problem: you're worried about young people knowing about Samaritans. 

Solution: young people use the internet and social media, so figure out a way to "create awareness" so that young people know about Samaritans and how they can help. 

This is, especially if you hook on to the "awareness" word, a communications brief. It's a "hey, we do a thing, and we want people to know that we do this thing". It leads, inexorably, to a campaign. With advertising, say. 

And then everything goes to shit. 

Because the way things are in agencies at the moment, most of them - if not all of them, really - are *shitting* themselves trying to figure out what "digital" means to them and what it means to what they do. 

A very quick answer to the problem of "awareness" for the Samaritans would be to do a bog standard social media campaign and get people to talk about them. You know the kind, throw in a few hashtags. Because that's the problem, right? Get people to know that the Samaritans exist? 

But agencies look at the new economy and the way the internet works and they get a bit unsure of themselves (sometimes quite rightly) because it turns out that actually, in a world where it's easier to create connections between demand and supply, there are different ways of satisfying or creating user needs. John V Willshire puts this succinctly as "make things people want" versus "make people want things". Advertising and the whole deal about "brands" has all been about making people want things. Digital doesn't *mean* making things people want, it means that there are new *ways* to make things people want, that people are able to discover and use on their own. The two approaches aren't contradictory - they work together a lot of the time. 

It's terrifying for agencies to look at fast growing businesses that are able to, well, grow fastly *without* "traditional" advertising. The reason why those businesses grow quickly in the first place? They rely on new communications infrastructure and they serve latent need that hasn't been served. Sometimes those latent needs are *so great* - in the case of products like social networks through the ages - and they come with new behaviours that you don't really need advertising, as we've known it. 

So then there comes this talk of expanding what it is an advertising agency does - they don't just, well, advertise, but they *solve business problems*. Most of the time that's OK: the business problem they're being asked to solve is something like "make sure people buy our stuff" or "hey, it turns out people think American cars aren't very good, but they actually are now, how can we get people to pay attention to us". 

The problem is when you start expanding that definition. The reason why that's a problem is that - now, bear with me here - the kind of people who've been working in advertising agencies are the kind of people who a) have been making advertising and b) want to make advertising. There's a smaller subset of people who, over the last few years I think have actually been lied to a bit, and want to actually "solve problems creatively" and sometimes advertising is a way to do that, and sometimes not. 

Let me put it this way: there's different types of creativity going on in the advertising process. When a client comes along to an agency and says "we appear to have sponsored the Olympics" and the agency says "well that's an interesting thing to do, you don't appear to have anything to do with athletic performance at all", it's an issue of creative problems solving to figure out exactly how and what a fast-moving-consumer-goods company *does* have to do with the Olympics. If you've been following at home, the resulting (genius, in my opinion) brief that goes to the creative teams is "Every athlete has a mother." And *then* you have the creative idea of telling that story and getting that story across, so that suddenly the act of being a mother to an Olympian is something that hopefully will connect with you on an emotional level. Two different kinds of creative problem solving, there. 

Where it gets a bit more grey is where the brief can be interpreted as a business problem that can be solved not by communications, but by something else. Traditionally, this hasn't been in the remit of advertising or communications agencies because, well, clients come to them for advertising and communications and not, for example, brand new product ideas. And even if agencies do respond with product ideas, it's frequently an uphill struggle because of the client/agency environment: clients come to agencies for advertising (why else, right?) and the relationship is mediated, in the end, by the CMO and CEO, and *normally* it's OK for the CMO to buy an advertising or communications solution to a business problem because hey, that's in their remit, but if they want to buy a product or service solution to a *marketing* problem, that requires the sort of inter-silo collaboration that is apparently nigh-on impossible in this day and age, and a symptom in my opinion of rather disappointing executive leadership. 

But, digital! Digital is a way of doing new things! Digital, because it means *everything* and because it commonly means *innovation* is a chance to do New Things, and advertisers and creative people love New Things because New Things get attention, and New Things plus Attention equals awards, and awards equal a promotion or a new job. Because that's the way the advertising job industry works. So you always want to do a new thing. And if you can do a new digital thing, well, all the better, because those Cannes Cyber Lions aren't going to award themselves. 

So, let me draw a line. Digital advertising is not products and services. It isn't. Stop trying to behave like it is. You can't do both. You certainly shouldn't be trying to do both if you've never done the latter before. And if you're going to try to do the latter, try to build a product or a service having never done it before, but you're stupidly cocksure of yourself because you're "creative" you'll learn that no, the idea isn't everything, it's the execution, stupid, just like the way you spend 3 weeks in an edit suite, only this time it isn't 3 weeks, it's potentially *the rest of your life*. 

I tried doing this. I tried doing this at a stupendously successful and well-regarded agency, one that has a well-deserved reputation for a) great insight and b) wonderful execution in terms of creative and emotional storytelling. I wanted to be able to use that attention to detail and craft and creative and emotional storytelling to make products and services that hadn't ever been made before, could never be made before, precisely *because* they had that advertising-level of craft and emotional resonance.  And at the end, it came to asking them: "Look, I buy that you want to create provocative relationships between good companies and their customers. I also want to solve business problems. But is there also a giant unspoken asterisk there that says: *Only using advertising?" And, fair play to them, they've decided they're an advertising agency. Which means making advertising. Which is *one specific way* of creating provocative relationships and solving business problems. 

But, it turns out that those things that *I* wanted to make wouldn't be ads. They wouldn't be communications. They might solve *exactly the same problem* as an ad brief, but they wouldn't be advertising. 

And I felt good about doing that, *because I'd done that before*, and because I know how to do that. And because I know the people and team I'd need to put together to do something like that, and it looks hardly anything like the team that creates a 60 second tv spot. 

The pressure in a lot of agencies is still do a New Digital Thing. It doesn't help that products like the Nike FuelBand win big at Cannes: it makes other agencies think that they need to do things too, and it's certainly true that the FuelBand "solves" a problem and "does branding" for Nike in a way that "traditional" comms can't or won't. But it's a fundamentally different thing. 

Having the idea for something and being able to deliver it are very, very different skills and to quote the apocryphal, fictitious Sorkin/Fincher Mark Zuckerberg, "if you'd invented Facebook, you'd have invented Facebook" - which includes not just coming up with the idea but actually turning up every day and delivering it until it has over a billion monthly active users and still not stopping. There are hardly any people in agencies anywhere - agencies like R/GA and AKQA somewhat excluded - where there are a mass of people with that kind of non-campaign experience. 

So, we're at Jam. A brief comes in: get young people to understand that Samaritans exists and use "social" in some way, because that's how young people express themselves these days.

The sexy idea, the alluring idea, the one that you're supposed to have if you're a creative team these days is a digital one. One that solves the problem. Not a service - you can see how Radar is talked about publicly - Radar is an App. An App that does X! That would certainly solve the problem. 

Those of you who have actually built apps know what it's like. You know how much is involved. Guess what: making tv ads is really hard, too! It turns out though, that the skills involved in making a standout award winning tv ad are *not necessarily transferrable* to making a stupendously *good* and successful application. Because why would they be? Sure, there are skills that are applicable anywhere: knowing how to make decisions, having the right taste, editing, and so on. But they're fundamentally different things! 

It's easier in the making-a-tv-ad world, because all of that expertise is abstracted away behind a production system roughly a hundred years in the making. There are *hundreds* of people involved in tv shoots. Right from the gaffer all the way to the edit assistant to the editor to sound design through wardrobe and location and production accounting and client management and rights clearance and so on. All those things! And, at the same time, a whole bunch of experience in the form of the creative team having *practised how to make ads a lot*. 

That practice just isn't there most of the time when it comes to creative teams at advertising agencies. It just isn't.

But, this is the environment. A swaggering one that solves problems. That wants to win awards and make new things and get attention. One where four creatives, a creative technologist and a project manager can make an App. No matter what kind of app it is!

Where the idea is alluring, where the idea gets presented to executive creative directors who decide: Yes! This is a thing! This is a good idea! Go and make it! And literally hardly *anyone* in the building has done anything like it before. And why does this thing have to be done, why does it have to be made? Out of some sort of fear of irrelevancy? 

Let me turn it around: it's easy to make fun of startups that pick up a Canon 5D MK III and shoot an ad. It kind of works. It's not great, but it kind of does the job. But, advertising creatives say, it's not done *properly*. It could be done so much *better*. They don't know what they're doing. 

Yeah, well shit goes both ways. 

I'd say this: if you're at an agency and you want to make "apps" and *most of your experience* in the industry has so far been things like tv spots or microsites, and if your app idea is something marginally more complicated than a soundboard or an Instagram clone (or, *even* an Instragam clone) or you're having delusions of grandeur and think you can sell through an Uber for X, then not only do you have an uphill struggle, but your job makes you practically unqualified for the task without a whole bunch of teamwork and, honestly, stepping back and being less involved. In other words, having the idea and then handing over to someone else who's had practice in doing that thing. Sure, this might sound like the business as usual of handing over to a production agency, but here's the thing: that situation might not be any better either, because a lot (certainly not all) of those production agencies will just make what you tell them to make, especially in an agency/production shop relationship. I don't envy you. You're being told by your colleagues and by the industry, and all the awards around you, that you'd better be shit hot at Making Stuff now, and Making Stuff includes a whole bunch of digital stuff more than culture-on-digital-platforms. 

And the thing is, agencies are - more or less - *good* at making culture-on-digital-platforms. Because it turns out: that's advertising! But making apps and services is pretty much the equivalent of thinking that if you've done a few 60 second spots, you can knock out a - to a certain extent - a 4 hour blockbuster trilogy of Peter Jackson proportions. You can't. And frankly, *no one should expect you to*, because it's not like you've done that before. It's an unrealistic expectation that will lead to terrible work all around, *apart* from the fact that the ad industry will see on-the-surface successful work - just like the hardly-alpha of Samaritans Radar and start giving it awards. Give me a fucking break. Why does this thing smell like a marketing campaign? Because it was made by people who make marketing campaigns. 

That's just the agency side. The other side is the from-the-outsides somewhat-shambles of Samaritans rolling this thing out in the first place and not understand what a big deal it is and what it means. This is, of course, Samaritans behaving like they need an Electricity Strategy and going out and finding Electricity Experts (who have quickly rebranded themselves such after having spent a lot of time being instead Horsepower Experts because what they're really about is Power when really a Very Different Thing is happening). Because this is the hard work: this is the idea that Samaritans, *like every organisation and company out there in the world* needs to figure, in some way, how it's going to react to electrification. But all it has to do is to not fuck up. 

We've had the internet for a while now. There are certain things that we know about. The work (I'm sorry, but it's pretty much inevitable I'm going to make this reference at this point) that GDS are doing isn't New and it isn't Shiny. Not in the way that the context around Radar stinks. No, Radar stinks because it's a Samaritans problem and it isn't an outside-Samaritans problem. *Samaritans* should've done the work behind Radar, and it should've been Jam's job to *tell* people about Radar, if people even needed telling. I buy that there are academics involved to make sure the right questions are asked. But the whole thing stinks of someone at Samaritans not knowing what electricity is and throwing something out there without knowing the context in which it will be used. 

In other words, no equivalent or visible "chief technology officer" or "chief product officer" - not that those are necessarily good roles to have because more often than not they result in siloisation, but bluntly, this: where's the service manager who runs this? How does this not feel like a campaign? Is this something Samaritans are going to run for months? 

I got taken to task - or at least, it felt that way - by James Aylett for putting the Samaritans in a difficult position. If they don't know about digital, then how are they supposed to know about digital? Well, guess what: if you're on the exec or leadership team of a company or on their board then it's your *job* to figure it out. It's your *job* to hire someone who knows what they're doing. It's your job to be sure that they *know* what they're doing and that they're not some fucking huckster who're going to sell you on a hashtag strategy. And believe it or not, *good* digital people exist, because like I said, we've had the internet for quite a while now. In fact - just like GDS - sometimes those people even already exist *inside* an organisation, they just haven't been given the room to do the smart thing. 

For crying out loud, this is the way that the world *is* right now. If you're in charge of a company - say, a bank - and for whatever reason *no-one* is able to figure out whose job it is to publish a page with Routing Number information *despite* it being the number one organic search query, then you're not doing your job. You're a *bank*. You provide *banking services*. You don't care *how* those services are provided, you just make sure you do it in the best way.

If you're the Samaritans and you provide assistance to at-risk populations with mental health issues, then you damn well figure out how to do that across *everything*. That's your job. 

You don't let "digital" be a black box that someone else gets to deal with. That's not trying. Not trying is a signal. That means you're not bothered about *what the point of your organisation is* and you're more worried about the existing ways you deliver whatever it is that you do. Digital is the *one* thing that changes how you can being doing business and how you can be serving people. Not having understanding of it internally and relying on someone else for it is one of the stupidest things you can be doing and you should just go and fire yourself. 

-- 

2:25am, Monday 3 November at time of origin. 7:25am Sunday 2 November at time of destination. Ground speed of 603 mph, an altitude of 35,080 feet, and 165 miles to destination. 121 degrees 13 minutes 30 seconds west, 34 degrees 7 minutes 54 seconds north, heading east with a runny nose thanks to cabin air. 

Only a few hours until I get to see my son again after I connect through LAX.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: [PREVIEW] Episode One Hundred and Eighty Two: The Starship Enterprise; How Do You Solve A Problem Like Digital?
Date: November 2, 2014 at 10:43:03 AM CST
To: danhon <dan@danhon.com>


0.0 Sitrep

A ground speed of 608 miles an hour. 31,000 feet or 9,448 meters high. 162 degrees, 9 minutes, 35 seconds east, 26 degrees 47 minutes 48 seconds south. Either 2:45pm from my departure location or 8:45pm the previous day at my destination.
 
1.0 The Starship Enterprise
I was having dinner the other night with Tom Armitage and we figured out what my next talk was going to be. We've been friends for a very long time - at the same time as crossing paths at university, we were both bloggers in the late 90s early 2000s in the UK. Tom knows that I have, if not a soft spot, then a sort of obsession with the world of Star Trek: The Next Generation - not necessarily in terms of the characters and stories, but more in terms of what the world of the Federation actually means. How hard you can push it and how much of it just ends up being silly, or falling apart at the seams. 

I've written about this kind of stuff before - way back in episode 12[1] I was writing about the computing infrastructure of the world of the Next Generation, I mean, does *everything* in the Federation run LCARS? And, you know, somewhat tongue-in-cheek, who runs devops at Starfleet? Is LCARS open source? Can any civilian submit a pull request? 

But no, this is the idea, and like most things, I can't remember how we got here. I think it was because Tom saw that I'd somewhat facetiously tweeted if LCARS supported animated gifs. Or maybe it was because I'd been thinking out loud and told him that I wondered how the Enterprise-D's Main Computer disambiguated names when routing communications requests. There aren't that many times (I haven't looked) where someone does the equivalent of *tap combadge* "Picard to Smith" and Computer says "there are seventeen currently Smiths on board, which Smith did you mean?" and Picard has to say "John" and Computer says "there are three currently John Smiths on board" and Picard has to say "John Smith, no bloody A, B, C or D". 

(Of course, I realised as I wrote that last sentence that that's a pretty good example of  Computer requiring disambiguation, and a pretty good episode to boot[2]). 

The reason why the Enterprise-D is so big, the reason why it has hundreds of crew, the reason why it needs to haul around all of that *stuff* is that the Enterprise-D is chock-full of knowledge workers. "Enterprise" isn't just the name of the ship, it's a description. It's a tiny little city state - with everything that that city state needs - and it doesn't do it through magic hand-wavey unobtanium technology, it does it, horrifyingly, in *exactly the same way* we do things right now. With computer-augmented humans. 

(Yes, I have a copy of the TNG Technical Manual. I know that's not how the Enterprise-D *really* works. Computer has over 47 kiloquads of processing power! No, this is taking what we have now, sticking it in the Next Generation universe as a way of thinking about what we have right now. Thank you for holding fire, Star Trek pedants.)

There's what, 10-15 bridge crew on the 'D. They haul an immense support infrastructure around with them. Here's what happens when Riker taps his combadge to be put through to Dr. Crusher:

Riker taps his badge and as it chirps, someone down there on Deck 47 sitting at an LCARS terminal, *just like a call center worker*, sees Riker's profile pop up on the screen in front of them. Computer is listening everywhere, always, just like Echelon and the NSA are - there are mics and cameras all over the place. Knowledge Worker (Ensign Grade) Barclay sees a transcript of pretty much everything that Riker's been talking about over the past few seconds, minutes and hours. There's a graph layout of everyone Riker talks to and how often. And Knowledge Worker (Ensign Grade) Barclay taps on the pre-selected, auto-completed icon of Dr. Crusher and routes the call. Because there's a *switchboard*. 

Every single one of those LCARS terminals has a support ratio. At least 5% of the D's crew are desktop support staff, either replacing burnt out LCARs terminals or refreshing them. Some of the items are self-service, like the vending machines on the Facebook campus. But it turns out that a lot of the time, you just have to see someone down in IT. 

Every time Data looks something up there's at least ten people behind him, several layers deep, preparing reports and checking on computer-augmented intelligence. It's kind of depressing, really: the entire infrastruture is set up so around 10-15 bridge crew can swan around and do away missions. The only genuinely piece of *absolutely amazing tech* that can work itself is the transporter. 

The worst part, the absolute worst part, is the holodeck. Whilst 5% of the D's crew are desktop support staff, there are at least twice as many texture artists slaving away making sure that when Riker wants to program in Riker Risa Scenario Forty Seven Alpha, he's got the right Blender models to choose from in the library and the right textures to decorate everything. Assassin's Creed: Unity, the latest in the Ubisoft I'm-a-pretend-assassin-travelogue set in Paris, probably has up to 10 teams working around the world, say up to a thousand people recreating Paris for us to play in 1080p on next-generation consoles like the PS4 and the Xbox One. The future of the Enterprise isn't magically waving a wand and creating a new Holonovel like a sort of interstellar-holonovel-writing-month all on our own, it's more of a production line. Have you ever sat through the end-credit sequence of a Lord of the Rings Extended Edition Movie? Yeah, that. Now look at the Enterprise and every single one of those glinting portholes. That's a 3d modeller, rigger or animator, texture artist or whoever, slaving away so that Picard can pretend to be Dixon Hill again. That's the mission: to explore new worlds, to boldly go where no one has gone before and to create disruptive innovations in the VFX workflow/pipeline. 

Oh, oh, and you want to know why the Enterprise is so big, *on top* of all of the staff? At least sixty of the decks (oh, I don't know how many decks there are) are just made of CLOUD. Do you have any idea how much iron it takes to bring a small bit of cloud with you? There's a scene that both Tom Armitage and I love from Danny Boyle's movie Sunshine where you see that the ship's computer is overclocked - it's submerged in liquid nitrogen or something so that its processors can run at a gajillion gigahertz because otherwise it turns out you'd need a billion of those processors to provide the voice interface. We see this when one of the characters has to plunge their hands into the liquid bath keeping the compute infrastructure cool. 

The TNG Technical Manual has a little bit about how the Enterprise has a main computer core, it runs vertically, I think, through a few decks but: come on. We've seen datacenters. Look at all that back-end infrastructure you need! Most of it, again, is just racks and racks of nVidia/AMD GPU nodes so that Geordi can have a semi-plausible visual simulation of Dr. Leah Brahms (which is creepy enough in itself). At least you're in space so you don't have many problems cooling all of that stuff. Just open an airlock every now and then. 

Think of the Enterprise as a regional office: 1,200 people, with ten or so Director/VP-level appointments at the top. Everyone else is just hanging around, clocking in and clocking out. This is what an Enterprise means: taking a little bit of culture, taking a little bit of infrastructure, taking a neighbourhood and making it self-similar so it can fly around in a metal bubble filled with air. 

It's not a post-scarcity society. There are still jobs in Starfleet. They just all happen to be knowledge-worker jobs. Tobias Revell's closing keynote had a reference to a particularly dystopic recording of a call centre marketing call where the human recipient accuses the caller of being a robot and the robot - or, at least, you think she's a robot, you can see the rules and the branching trees performing the VoiceXML analysis and routing, picking up on keywords and protesting that she is not a robot, she's human. But the twist is this: not only was the call *coming from inside the house*, but it was operated by a human using the equivalent of a call centre sound board - a human listening to another human, but having no mouth and not being able to scream, communicating only through pre-recorded snippets that *cater for the fact that she will be accused of not being a human*. Mechanical Turks, all the way down.

The Enterprise's computer is the kind of computing system we all use right now: one where computers do things that computers are good at, and where humans kick in doing the things humans are good at, or even better, are *cheap* at doing, even cheaper than computers. Red Dwarf took this to the British satirical extreme, where a miles-long mining ship employs hundreds of *vending machine repairers and cleaners* because it's easier to get humans to do it than it is to get robots to do it. We use Protein Folding games right now to get humans to pattern match - to work in symbiosis (of a sort) with computers to examine things and click things just so. That's what's happening behind the scenes on the Enterprise. You wake up. You get breakfast from the Replicator, which menu today has been laboriously manually programmed by Chavez, two bunks down, you sit in front of your LCARS terminal and then you look at things and tap on them. For the rest of your life. But hey, space travel! I mean sure, we get episodes like Below Decks and get introduced to Ensign Laren and her friends every now and then, but that's really not what Star Trek: Call Center is like. Or Star Trek: Amazon Fulfilment Warehouse. Or Star Trek: Knowledge Worker. 

(An aside: Tom and I were also talking about how stupidly surprisingly awesome Tom Cruise's Oblivion is because of the Big Dumb Object that hearkens back to classic Science Fiction, or at least a certain genre of it, and the idea that somewhere in Starfleet there's a Warehouse 13, or a Special Circumstances, or just the team that goes out and discovers the Genuinely Weird, Unexplainable, Really Fucking Terrifying Outside Context Problem stuff. Like the Whale Probe. I mean, that's super alien! But no, we have to have little episodes about relocating indigenous people so we can steal their youth-providing radiogenic field or whatever.)

There's of course the joke that Star Trek: The Next Generation is the way it is because it's the quintessential 1990s show - all curved edges, fake wood trim and Marriot In Space, but the other idea is that pretty much everyone else on the ship apart from our bridge crew are Uber-style "independent contractors" - and maybe even the bridge crew, maybe even Captain Kirk is an Uber-style independent-contractor-not-an-employee so the next time his sexually assaults a first contact species or accidentally destroys a civilisation, Starfleet Corporate can go "well, he's not *technically* an employee" and disavow his actions. 

Yeah, the horrifying future of space travel is a super exciting thing for around 10-15 people and cube-farm hell for the other thousand-or-so travelling. Mundane, manufactured normalcy. Your job in space is *just the same* as your job on Earth. 


[1] Episode 12 - Attention, Star Trek and Cars
[2] Relics at Memory Alpha
 
2.0 How Do You Solve A Problem Like Digital
I'm still mildly simmering after having hammered out the previous episode about the Samaritans Radar mess. And let's be clear: there's a lot of mess to pass around, and it's fair to say that there was at least *an* interesting insight in that people are saying things and how, well, can we be more empathic to those who're in our feed and sensitive to what they're saying. Which at some point after pulling on the thread for a while you come to: ah, well that feels a bit like a societal problem, how do we, as you say, "move the needle" and create a more kind environment for everyone so *everyone* can deal with mental illness better.

But this isn't about that. This is about the piss-poor situation regarding "digital" and making things that work, that make things better, rather than making half-assed stuff that just opens a can of worms of problems and now you have Two Problems but I suppose you have an advertising award, so you can just fuck right off. 

I can post-rationalise and tell a reconstructed story of how something like Radar might have happened. For those of you who are (relatively) new to this newsletter, my "creds", as such as they are are that I spent the last four-and-a-quarter years doing "digital" stuff in agency land, first as as senior creative at W+K London, and then as a Creative Director at W+K Portland. I've seen briefs glittering in the dark off the gate to the planning department, I have. I've seen creative teams fly out to New Zealand to build a website. 

And I've seen what happens when agencies tell themselves that they're there to Solve Business Problems. 

There are so, so many things at play here. You have your main two players: the Client, Samaritans, who, given the lack of any evidence to the contrary, appear to be somewhat naive in the "digital" space. You have their agency, Jam, part of the Engine holding company, self-billed as "a social media marketing agency, and part of Engine. We create award-winning social media communication strategies for brands."

And behind all of that, I am assuming that there's pressure both at Samaritans and at Jam to "get" digital. Because "digital" is a thing that is happening, and it's changing everything or some things or maybe even no things and you'd better damn well have a strategy for it. It's doing that everywhere, whether you're a car service or laundering clothes or selling clothes or treating people for diseases or "reading the news" or watching a tv show or any of those things.

It is doing those things because "digital" is a transformative technology just like the way electricity was. 

There will have been someone at Samaritans who wanted to Do Something. Probably, I'm guessing, because Twitter is a thing and young people are vulnerable and at-risk, and it's generally good advice that's been passed around for the last ten years or so in the digital space that you "go where the people are" and that you shouldn't be Kevin Costner and build things hoping people will just turn up. And it turns out that the young people that you, as an organisation wanting to help people with mental health issues, want to make sure that you're doing the best at serving younger people.

So you go find a group of people, an organisation, who can "help you reach younger people" and you find an agency like Jam, because hey, younger people "use the internet" and they definitely "do social" and what you definitely want to do is "communicate" with young people so they know about Samaritans and how Samaritans can be there for them when they need someone. 

All good so far.

Problem: you're worried about young people knowing about Samaritans. 

Solution: young people use the internet and social media, so figure out a way to "create awareness" so that young people know about Samaritans and how they can help. 

This is, especially if you hook on to the "awareness" word, a communications brief. It's a "hey, we do a thing, and we want people to know that we do this thing". It leads, inexorably, to a campaign. With advertising, say. 

And then everything goes to shit. 

Because the way things are in agencies at the moment, most of them - if not all of them, really - are *shitting* themselves trying to figure out what "digital" means to them and what it means to what they do. 

A very quick answer to the problem of "awareness" for the Samaritans would be to do a bog standard social media campaign and get people to talk about them. You know the kind, throw in a few hashtags. Because that's the problem, right? Get people to know that the Samaritans exist? 

But agencies look at the new economy and the way the internet works and they get a bit unsure of themselves (sometimes quite rightly) because it turns out that actually, in a world where it's easier to create connections between demand and supply, there are different ways of satisfying or creating user needs. John V Willshire puts this succinctly as "make things people want" versus "make people want things". Advertising and the whole deal about "brands" has all been about making people want things. Digital doesn't *mean* making things people want, it means that there are new *ways* to make things people want, that people are able to discover and use on their own. The two approaches aren't contradictory - they work together a lot of the time. 

It's terrifying for agencies to look at fast growing businesses that are able to, well, grow fastly *without* "traditional" advertising. The reason why those businesses grow quickly in the first place? They rely on new communications infrastructure and they serve latent need that hasn't been served. Sometimes those latent needs are *so great* - in the case of products like social networks through the ages - and they come with new behaviours that you don't really need advertising, as we've known it. 

So then there comes this talk of expanding what it is an advertising agency does - they don't just, well, advertise, but they *solve business problems*. Most of the time that's OK: the business problem they're being asked to solve is something like "make sure people buy our stuff" or "hey, it turns out people think American cars aren't very good, but they actually are now, how can we get people to pay attention to us". 

The problem is when you start expanding that definition. The reason why that's a problem is that - now, bear with me here - the kind of people who've been working in advertising agencies are the kind of people who a) have been making advertising and b) want to make advertising. There's a smaller subset of people who, over the last few years I think have actually been lied to a bit, and want to actually "solve problems creatively" and sometimes advertising is a way to do that, and sometimes not. 

Let me put it this way: there's different types of creativity going on in the advertising process. When a client comes along to an agency and says "we appear to have sponsored the Olympics" and the agency says "well that's an interesting thing to do, you don't appear to have anything to do with athletic performance at all", it's an issue of creative problems solving to figure out exactly how and what a fast-moving-consumer-goods company *does* have to do with the Olympics. If you've been following at home, the resulting (genius, in my opinion) brief that goes to the creative teams is "Every athlete has a mother." And *then* you have the creative idea of telling that story and getting that story across, so that suddenly the act of being a mother to an Olympian is something that hopefully will connect with you on an emotional level. Two different kinds of creative problem solving, there. 

Where it gets a bit more grey is where the brief can be interpreted as a business problem that can be solved not by communications, but by something else. Traditionally, this hasn't been in the remit of advertising or communications agencies because, well, clients come to them for advertising and communications and not, for example, brand new product ideas. And even if agencies do respond with product ideas, it's frequently an uphill struggle because of the client/agency environment: clients come to agencies for advertising (why else, right?) and the relationship is mediated, in the end, by the CMO and CEO, and *normally* it's OK for the CMO to buy an advertising or communications solution to a business problem because hey, that's in their remit, but if they want to buy a product or service solution to a *marketing* problem, that requires the sort of inter-silo collaboration that is apparently nigh-on impossible in this day and age, and a symptom in my opinion of rather disappointing executive leadership. 

But, digital! Digital is a way of doing new things! Digital, because it means *everything* and because it commonly means *innovation* is a chance to do New Things, and advertisers and creative people love New Things because New Things get attention, and New Things plus Attention equals awards, and awards equal a promotion or a new job. Because that's the way the advertising job industry works. So you always want to do a new thing. And if you can do a new digital thing, well, all the better, because those Cannes Cyber Lions aren't going to award themselves. 

So, let me draw a line. Digital advertising is not products and services. It isn't. Stop trying to behave like it is. You can't do both. You certainly shouldn't be trying to do both if you've never done the latter before. And if you're going to try to do the latter, try to build a product or a service having never done it before, but you're stupidly cocksure of yourself because you're "creative" you'll learn that no, the idea isn't everything, it's the execution, stupid, just like the way you spend 3 weeks in an edit suite, only this time it isn't 3 weeks, it's potentially *the rest of your life*. 

I tried doing this. I tried doing this at a stupendously successful and well-regarded agency, one that has a well-deserved reputation for a) great insight and b) wonderful execution in terms of creative and emotional storytelling. I wanted to be able to use that attention to detail and craft and creative and emotional storytelling to make products and services that hadn't ever been made before, could never be made before, precisely *because* they had that advertising-level of craft and emotional resonance.  And at the end, it came to asking them: "Look, I buy that you want to create provocative relationships between good companies and their customers. I also want to solve business problems. But is there also a giant unspoken asterisk there that says: *Only using advertising?" And, fair play to them, they've decided they're an advertising agency. Which means making advertising. Which is *one specific way* of creating provocative relationships and solving business problems. 

But, it turns out that those things that *I* wanted to make wouldn't be ads. They wouldn't be communications. They might solve *exactly the same problem* as an ad brief, but they wouldn't be advertising. 

And I felt good about doing that, *because I'd done that before*, and because I know how to do that. And because I know the people and team I'd need to put together to do something like that, and it looks hardly anything like the team that creates a 60 second tv spot. 

The pressure in a lot of agencies is still do a New Digital Thing. It doesn't help that products like the Nike FuelBand win big at Cannes: it makes other agencies think that they need to do things too, and it's certainly true that the FuelBand "solves" a problem and "does branding" for Nike in a way that "traditional" comms can't or won't. But it's a fundamentally different thing. 

Having the idea for something and being able to deliver it are very, very different skills and to quote the apocryphal, fictitious Sorkin/Fincher Mark Zuckerberg, "if you'd invented Facebook, you'd have invented Facebook" - which includes not just coming up with the idea but actually turning up every day and delivering it until it has over a billion monthly active users and still not stopping. There are hardly any people in agencies anywhere - agencies like R/GA and AKQA somewhat excluded - where there are a mass of people with that kind of non-campaign experience. 

So, we're at Jam. A brief comes in: get young people to understand that Samaritans exists and use "social" in some way, because that's how young people express themselves these days.

The sexy idea, the alluring idea, the one that you're supposed to have if you're a creative team these days is a digital one. One that solves the problem. Not a service - you can see how Radar is talked about publicly - Radar is an App. An App that does X! That would certainly solve the problem. 

Those of you who have actually built apps know what it's like. You know how much is involved. Guess what: making tv ads is really hard, too! It turns out though, that the skills involved in making a standout award winning tv ad are *not necessarily transferrable* to making a stupendously *good* and successful application. Because why would they be? Sure, there are skills that are applicable anywhere: knowing how to make decisions, having the right taste, editing, and so on. But they're fundamentally different things! 

It's easier in the making-a-tv-ad world, because all of that expertise is abstracted away behind a production system roughly a hundred years in the making. There are *hundreds* of people involved in tv shoots. Right from the gaffer all the way to the edit assistant to the editor to sound design through wardrobe and location and production accounting and client management and rights clearance and so on. All those things! And, at the same time, a whole bunch of experience in the form of the creative team having *practised how to make ads a lot*. 

That practice just isn't there most of the time when it comes to creative teams at advertising agencies. It just isn't.

But, this is the environment. A swaggering one that solves problems. That wants to win awards and make new things and get attention. One where four creatives, a creative technologist and a project manager can make an App. No matter what kind of app it is!

Where the idea is alluring, where the idea gets presented to executive creative directors who decide: Yes! This is a thing! This is a good idea! Go and make it! And literally hardly *anyone* in the building has done anything like it before. And why does this thing have to be done, why does it have to be made? Out of some sort of fear of irrelevancy? 

Let me turn it around: it's easy to make fun of startups that pick up a Canon 5D MK III and shoot an ad. It kind of works. It's not great, but it kind of does the job. But, advertising creatives say, it's not done *properly*. It could be done so much *better*. They don't know what they're doing. 

Yeah, well shit goes both ways. 

I'd say this: if you're at an agency and you want to make "apps" and *most of your experience* in the industry has so far been things like tv spots or microsites, and if your app idea is something marginally more complicated than a soundboard or an Instagram clone (or, *even* an Instragam clone) or you're having delusions of grandeur and think you can sell through an Uber for X, then not only do you have an uphill struggle, but your job makes you practically unqualified for the task without a whole bunch of teamwork and, honestly, stepping back and being less involved. In other words, having the idea and then handing over to someone else who's had practice in doing that thing. Sure, this might sound like the business as usual of handing over to a production agency, but here's the thing: that situation might not be any better either, because a lot (certainly not all) of those production agencies will just make what you tell them to make, especially in an agency/production shop relationship. I don't envy you. You're being told by your colleagues and by the industry, and all the awards around you, that you'd better be shit hot at Making Stuff now, and Making Stuff includes a whole bunch of digital stuff more than culture-on-digital-platforms. 

And the thing is, agencies are - more or less - *good* at making culture-on-digital-platforms. Because it turns out: that's advertising! But making apps and services is pretty much the equivalent of thinking that if you've done a few 60 second spots, you can knock out a - to a certain extent - a 4 hour blockbuster trilogy of Peter Jackson proportions. You can't. And frankly, *no one should expect you to*, because it's not like you've done that before. It's an unrealistic expectation that will lead to terrible work all around, *apart* from the fact that the ad industry will see on-the-surface successful work - just like the hardly-alpha of Samaritans Radar and start giving it awards. Give me a fucking break. Why does this thing smell like a marketing campaign? Because it was made by people who make marketing campaigns. 

That's just the agency side. The other side is the from-the-outsides somewhat-shambles of Samaritans rolling this thing out in the first place and not understand what a big deal it is and what it means. This is, of course, Samaritans behaving like they need an Electricity Strategy and going out and finding Electricity Experts (who have quickly rebranded themselves such after having spent a lot of time being instead Horsepower Experts because what they're really about is Power when really a Very Different Thing is happening). Because this is the hard work: this is the idea that Samaritans, *like every organisation and company out there in the world* needs to figure, in some way, how it's going to react to electrification. But all it has to do is to not fuck up. 

We've had the internet for a while now. There are certain things that we know about. The work (I'm sorry, but it's pretty much inevitable I'm going to make this reference at this point) that GDS are doing isn't New and it isn't Shiny. Not in the way that the context around Radar stinks. No, Radar stinks because it's a Samaritans problem and it isn't an outside-Samaritans problem. *Samaritans* should've done the work behind Radar, and it should've been Jam's job to *tell* people about Radar, if people even needed telling. I buy that there are academics involved to make sure the right questions are asked. But the whole thing stinks of someone at Samaritans not knowing what electricity is and throwing something out there without knowing the context in which it will be used. 

In other words, no equivalent or visible "chief technology officer" or "chief product officer" - not that those are necessarily good roles to have because more often than not they result in siloisation, but bluntly, this: where's the service manager who runs this? How does this not feel like a campaign? Is this something Samaritans are going to run for months? 

I got taken to task - or at least, it felt that way - by James Aylett for putting the Samaritans in a difficult position. If they don't know about digital, then how are they supposed to know about digital? Well, guess what: if you're on the exec or leadership team of a company or on their board then it's your *job* to figure it out. It's your *job* to hire someone who knows what they're doing. It's your job to be sure that they *know* what they're doing and that they're not some fucking huckster who're going to sell you on a hashtag strategy. And believe it or not, *good* digital people exist, because like I said, we've had the internet for quite a while now. In fact - just like GDS - sometimes those people even already exist *inside* an organisation, they just haven't been given the room to do the smart thing. 

For crying out loud, this is the way that the world *is* right now. If you're in charge of a company - say, a bank - and for whatever reason *no-one* is able to figure out whose job it is to publish a page with Routing Number information *despite* it being the number one organic search query, then you're not doing your job. You're a *bank*. You provide *banking services*. You don't care *how* those services are provided, you just make sure you do it in the best way.

If you're the Samaritans and you provide assistance to at-risk populations with mental health issues, then you damn well figure out how to do that across *everything*. That's your job. 

You don't let "digital" be a black box that someone else gets to deal with. That's not trying. Not trying is a signal. That means you're not bothered about *what the point of your organisation is* and you're more worried about the existing ways you deliver whatever it is that you do. Digital is the *one* thing that changes how you can being doing business and how you can be serving people. Not having understanding of it internally and relying on someone else for it is one of the stupidest things you can be doing and you should just go and fire yourself. 

-- 

2:25am, Monday 3 November at time of origin. 7:25am Sunday 2 November at time of destination. Ground speed of 603 mph, an altitude of 35,080 feet, and 165 miles to destination. 121 degrees 13 minutes 30 seconds west, 34 degrees 7 minutes 54 seconds north, heading east with a runny nose thanks to cabin air. 

Only a few hours until I get to see my son again after I connect through LAX.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty One: It's Too Hot; Monitor This
Date: November 1, 2014 at 6:52:18 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-j5vx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

10:19pm in Sydney, Australia on the hottest day of the year so far, a sort of 93 degrees fahrenheit hot. And then a surprise (pop-up? flash mob?) thunderstorm in the afternoon after I'd popped down to Circular Quay to do some Guilty Dad Shopping and the requisite photo of Sydney Opera House (it looks quite nice). 
1.0 It's Too Hot

On the it's-too-hot-ness, learning from Mark Pesce at the closing party for Web Directions that when it hit above 43 degrees celsius in Sydney, weird things started happening. And by weird, I mean that bats. Just. Die. They can't regulate their heat anymore. They just fall down and die. Loads of them. Birds stop singing, because it's too hot to sing. 

The world just goes quiet.

And there's me, standing there, thinking: well, more people need to know about this. There's the abstract effect of climate change, but there's that back of the neck chill, that absolute atavistic *fear* that something has gone terribly, terribly wrong when *the birds don't sing anymore*.

That's what climate change is. Yes, yes, sea levels rising, increased instability due to food security and everything else.

But it's going to get too hot for the birds to sing.

That should scare the fuck out of you. 
2.0 Monitor This

OK, so read this first: Adrian Short's blog posts about Samaritans Radar, a "Twitter App" that does potentially naive keyword monitoring to alert you to potentially at-risk Twitter accounts you follow in your stream so you can help them. Read: 

- Samaritans Radar: Paved With Good Intentions
- Unethical Twitter 
- Samaritans Radar Must Close

And it's good to hear what Samaritans have to say for themselves, too:

- Samaritans Radar Press 
- Samaritans Radar Update 

Okay, so. There are a number of trigger phrases in what I've read about Radar, least of which is something like "created by digital agency x" and then I'm all, *oh really*, created by a digital agency, let's see about that, then. 

Let's be clear. Samaritans Radar is a campaign. Here's the writeup in Campaign Live[1]:

Samaritans, the charity that supports anyone in distress, is launching a Twitter app to help people spot the signs that a friend is struggling to cope. Jam created the app, which uses Twitter’s application programme interface to pick out key words and phrases from Tweets that indicate a person is contemplating suicide. Samaritans then offers the user advice on how to help. Twitter is supporting the Radar app as part of its Twitter Ads For Good, which offers charities free Promoted Tweets. The campaign was created by James Greening, Joel Lim and Liam Chapman.

I know a thing or two about campaigns. I've been briefed on them and I've CD'd them. And they are not, absolutely not, products or services. But the briefs that come in for them, well. We know about the pressure for advertising creatives to come up with something new. About how sexy it is to "make something". About how advertising is actually about solving problems, not just communications. 

But then Jam is described on Google as "a social media marketing agency, and part of Engine. We create award-winning social media communication strategies for brands." 

I've been in meetings like this. 

I don't know what the brief would've been. But given that it went to Jam in the first place, I'm sure it was something to do with "let's do something on social or mobile". And it's exciting to think, as a creative team, that you've come up with an "app" that can "solve a problem". 

Well, part of the fucking problem is this: those creative teams have most commonly *never shipped* an "app" or a "service" before. And the skills required in actually making a good application or service are vastly different from those involved in creating compelling creative communications. Because, you know, one of these things is used and the other one isn't. That's not to say that good apps and services *can't* be informed by the kind of taste and direction that informs well-performing advertising creative communications work. But the two things are different! 

This is why, for example, good producers try to find people who've actually done something in the relevant area before, so you're not playing a fucking crap shoot. 

There is a *world of difference* between coming up with the idea for an app - "hey, let's use Twitter to see if we can help find people who might be at risk so their friends can help!" and actually making it and figuring out if that's a good idea or not. 

Being a good copywriter or art director or knowing how to ship a microsite that has pretty good parallax scrolling is incidental to doing a good job. 

And the blame here doesn't just lie on the agency - who, I have to admit, I think are pretty reprehensible here for on the surface displaying hardly any competency to do the thing that they did properly for a fucking social charity involved in *mental health* - but also on the part of the client, who at this point look like they have *no idea what they're doing* and is just another example of the whole trainwreck of leadership and management *not getting it either* and someone either being asleep at the wheel or looking at the thing in front of them and *not even knowing it was a wheel in the first place*. 

There are *tonnes* of better agencies in London that could've and would've done even a marginally better job at this. There are tonnes of ways that this "campaign" could've been better communicated. 

If it's not clear, this is one of the reasons why I'm disgusted with the advertising industry.

This stupendous pressure to be "good at digital" at an agency is being foisted upon people who range from having no idea of what they're doing to being genuinely terrible at what they're doing to trying to do the best in a pretty hostile environment, where most other people have no idea what they're doing. Oh, and try and make money and sell the fucking work, please. And where the leadership as well have no idea what they're doing, and can just hear "Well, that sounds like a good idea! Go and make that!" 

I mean, woo hoo. You've made some microsites and some viral campaigns and maybe even shot some ads and hey, on a good day you get to do some compelling banners. This is *different stuff*. Where's the fucking service manager? Where's the research? Oh, you don't need that, you just need a planner, a creative technologist, *FOUR CREATIVES* and a project manager. Fuck that shit. There's a reason when I was at Wieden that when I wanted to do stuff like this the first thing I did was pick up the phone and call an agency or production company that had actually done it before. And, in fairness, why Wieden itself would never have gotten to do that work in the first place. 

This is what you get when "digital" is just a black box that doesn't need to be understood, that can be foisted off on someone else. I'm angry at Jam for pretending they could execute and puffing themselves up, and I'm angry at Samaritans for not having their shit together. 

This is what happens when we don't have digital transformation. We get crap like this all over the place. 

But hey! Digital Campaign of the Week in the Third Sector![2] Great job everyone! Pat yourselves on the back, stick that on your LinkedIn and go home with the knowledge that you killed it and made a Great Campaign!

[1] http://www.campaignlive.co.uk/thework/1319601/
[2] http://www.thirdsector.co.uk/samaritans/communications/article/1319884
--

10:45pm and I'm angry. I'm going to bed.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighty: Web Directions South; A Thousand Songs In Your Pocket; Odds
Date: October 30, 2014 at 7:55:10 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-j4l1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

9:02am, Friday 31 October in the Seymour Centre, Sydney, Australia. I arrived in Sydney on Wednesday morning local time - having misplaced Tuesday carelessly at a speed of roughly 600 miles an hour - and now I'm sat ready for Genevieve Bell to give the second and final day's keynote. 
 
1.0 Web Directions South[1]
I sat in the Product Track yesterday. A Keynote from Matt Webb who pretty much opened on slide number two or so with a wonderful image from the Usborne Book of the Future which it seems is emerging as a Significant Cultural Touch Point for People Of A Certain Background And Age: which was amusing and frustrating only in that the third slide of *my* talk had an image from the same book, just a couple pages later. 

I've been giving talks now for about ten years - the first time I really did it was when I joined Mind Candy full time and at the invitation of gave a talk at a BBC conference. I felt sick the day before. Sick the night before. Sick the morning of. I remember feeling the same way that I felt when I was probably around seven years old being driven to a piano recital competition, some Associated Board of Music thing in Birmingham and desperately not wanting to do it, being terrified of making a mistake in public in front of all of those people. 

I still feel sick. Maybe not quite as bad, but pretty much all of yesterday up until the moment I was on stage and opened my mouth and the words started coming out was a sort of dread pit in the stomach, and it was only until around 3pm in the afternoon, about an hour and a half before I was supposed to start, that the nausea and nervousness gave way to a physical collapse of tiredness, an exhaustion of adrenalin. 

And then of course, the talk starts and everything is awesome and you're looking out into the audience and you can make them laugh and cry and stop and pause and you really care about what you're talking about and it just feels right. And then the new, different adrenaline comedown.

But that was just one thing. 

There was a bunch of stuff from yesterday, the kind of "things that have caught my attention". When Webb talked about the design of the early operating systems and the way that computers see the world, that in the Unix philosophy (specifically, the Unix philosophy) *everything is a device* (and everything is a file) and thinking about what that means for the world we're creating right now. And it feels like this is why we talk - when we talk in negative ways - about services like Uber and the rhetoric of the sharing economy and things like Meat Puppets and the moving of things around and algorithms extending their tendrils more (they were always into he world of course) into the world. The idea from Webb of the Web being egalitarian - that it felt Australian in its promise of a fair go for everyone - int hat it was a new way of *allowing* people a fair go, but that we would have to work at it to ensure that things stayed that way.

Hearing from Younghee Jun about what user research looks like in the field and feeling that conflict of all that *good work* that Nokia did in terms of attempting to understand their audiences and their users and, well, the *people* out there and then attempting to square that with What Happened Next, which was the steamrollering they received from Apple when the iPhone came out that felt like it might be inevitable but certainly not *this* inevitable, but slowly and quickly solidified over time. But Apple didn't do user research apart from Steve who was the user and then you remember, well, of course, Steve was a human, a person, too and whilst he wasn't and no one is the Universal Human, he certianly had an opinion and knew what he wanted and the resulting products worked for people who passed some threshold of similarity to Certain Values of Steve. 

And then, this killer realisation from Erin Moore that *of course* we don't experience time in the same way that science experiences time, that the second is an abstraction and a measurement but isn't the same thing because we know (and have experiments!) that show relative conscious experience of time is smushy, is elastic. And how do you square that with an engineering culture that works with clock ticks, that works with measurable things and doesn't quite know sometimes how to deal with how something *feels*? 

Webb has talked for a while now about the idea of fractional intelligence - a way of looking at how the network will change us in the way that electricity introduced fractional horsepower. All of those things that could happen once our environments became electrified and fractional movement, fractional power was a thing that could become not an inherent property of the natural environment but something we could augment it with. And then that idea of panpsychism that just by dint of existing things process information. Maybe not very much, maybe not very quickly, but just maybe everything does. Of course the other way of looking at it is that in the early 21st century we look at everything through a lens of processing information, we can't help but see information processing anywhere. We may or may not be right. 

But then this idea of a stupendously complicated world, the idea approached from different perspectives by both Webb and Tom Armitage that ease of use has obscured things from us and that we need to work out ways to help us increase, well, maybe not our *understanding* but that at the very least our theory of mind is perhaps broken when it comes to the potential embedding of fractional intelligence in everything. We already anthropomorphise things. Genevieve Bell this morning talked about how in her work people are *convinced* that connected objects are talking, gossiping even, about them. The fridge knows things about you and it's going to tell all its friends. The screens know what you watch and will tell your car. Part of this, I think, is because on top of the fact that it sounds like we *expect* objects to act this way, or for actors with intent to act this way, is that that's also the way we're telling stories about these objects. They *are* things that know about us and we *do* talk about them *telling* things other things. We shouldn't make fun of people who see The Cloud as a Thing even though the whole point of the network diagram icon was to show a Not Thing, even when it was an abstration in the first place. What do you expect from a bunch of barely-evolved hunter gatherers who still think one sex is superior to the other in the first place? They will *tell tales* on us. Of course they will. 

So who do we trust to tell us about what's going on? Should a fridge be able to explain to you? Should its seams indeed be visible so we can see in a potentially new way, what goes in comes out here? Armitage makes a compelling case for yes, but the slightly-less optimistic me looks at the world and recoils a bit: gosh, there sure are a lot of seams that need exposing.

[1] Web Directions South
 
2.0 A Thousand Songs In Your Pocket
I saw that the "LG G Watch R"[1] (I will just point, in these brackets, to that product name and not even bother saying anything) has been announced/launched and after taking a brief look through the (terrible) website that shows breakthrough features like being able check your stocks "as easily as you check the time" (which, let's be honest, for a large number of people these days, "checking the time" is also known as "pulling out your phone and checking the time). 

This feels like the A Thousand Songs In Your Pocket problem - the "what does it do, and what is it for", the simple communication of what this new Thing does for you and why you might be interested in it. This isn't anything new, what I'm saying about wrist-watch-wearables is certainly not a new insight, it's just that, well, we know what the potential might be. It's just a compelling answer for why. A Thousand Songs In Your Pocket could exist because the reason for the original iPod was clear, and part of that earlier, simple time back in the early 2000s was because we didn't have quite as many MIPS lying around as we do right now. The iPod wasn't (but could have been) a general purpose computer in the same way that our current touted wrist-saviours are. That's why I *like* the Withings Activite - because it's simple and it does a thing and it doesn't have a screen. I still believe that screens are the tricky thing because they're infinitely configurable, especially once they're on the end of a TCP/IP connection. 

Tell me: what does the magic screen do?

Well, it's magic. It can do anything. Good luck with that copywriting.

And when we take a look at the Gizmodo review[3] for the LG G Watch R, sure, it's a nice piece of hardware, but it seems like no-one's sure what problem Android Wear is solving other than "wearables are a place where we need to show up, so show up we will". There's certainly that belief that "sometime in the future, this will be worth it" but again, no one's quite sure. Or, if they are, they're not saying yet.

[1] LG G Watch R
[2] Withings Activite
[3] Gizmodo Review - LG G Watch R 
3.0 Odds

Phrases that are temporarily stuck in my head:  I continue to feel happy about the way I've been describing my team's work at Code for America: make building digital government *easy to understand* and *easy to copy*. The copy thing is key, I think. The understand bit is the expected bit. The easy to copy bit is the bit that makes me tingly.   I said yesterday after I showed an ad we made for Facebook that this particular genre was weaponised empathy. Created with a purpose. Edited and soundtracked to an inch of its life. The same thing as ever, just a different name.   Getting ready for my talk yesterday, showing Tom Armitage the recently released Google Fit and railing at its dashboard of charts, getting a little righteously indignant and having him respond to me that, well, *of course*, this was just the first step, this was just the "equivalent of pasting Google Analytics javascript to your foot".   A conversation with Dan Williams in the morning before getting to the venue about Surprise and Delight and him coming up with the wonderful phrase that "delight" shouldn't be "something unexpected that a corporation does to you."  --  11:18am. Finishing a breakfast of bacon and scrambled eggs, sat in Toby's Estate with a flat white.  Send me notes. I love them.  Best,  Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Nine: It's The Money
Date: October 28, 2014 at 8:39:54 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-j2i9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
Monday October 27, 8:23pm at the Delta Sky Lounge at LAX before a 15 hour flight to Sydney for Web Directions South[1]. I'm speaking at the end of the first day after what'll probably be a mind-bending opening keynote by Matt Webb and just after an intriguingly titled talk from Tom Armitage. 

Again, it's been a week since I've written anything. I was going to say: "I'm not sure how I feel about that", but I don't think that's true. I do know how I feel about that - and it's not great. Every day has been another day not writing, and I've kind of been okay with it whilst at the same time not being okay with it. The only thing - the big thing - that's changed is that I've made a decision to stop writing in the evening. Before, if I hadn't managed to write during the day, then I'd write after dinner - but now, something's flipped in my head and the evening is family time. It might have something to do with my son growing up - he's stringing words together now, knows his own name and is racing around like a crazy thing during the day, shrieking "PUDDLE!" at puddles and then splashing through them with unrestrained delight. 

And, of course, the new job. I am sponging - absorbing, translating, rotating, rephrasing, trying to distill what we mean from the things that we say. Trying to work out what we *really* mean and then working out the best way to say it. And where. And how. And all of that, a whole new bunch of working relationships with new people. 

[1] Web Directions South 
 
1.0 It's The Money
Nothing other than the simple observation - that others have made already - that the ostensible difference between Apple Pay[1] and the MCX's[2] CurrentC and the kerfuffle that's happening in the US is that Apple Pay is trying to make things easier (for certain values of easy) for people, and that CurrentC isn't - it's trying to make things easier for "merchants".

I mean, here's the copy that's on MCX's website:
"Merchant Customer Exchange is the only merchant-owned mobile commerce network built to streamline the customer shopping experience across all major retail verticals."

Here's the thing: the story that's being told right now is that MCX isn't even an attempted end-run round the credit card operators (whose ~2% cut of transactions in fees is significant when you're a retailer like Walmart) but that it's just an attempt to make Visa and their ilk *hurt*[3]. From that last footnote: 
At last year’s BAI Retail Delivery conference, I hosted a meeting of CMOs from large FIs, which featured Lee Scott, the former CEO of Walmart (who is a member of MCX). I asked Mr. Scott why, in the face of so many failed consortia before it, would MCX succeed?
 
He said: “I don’t know that it will, and I don’t care. As long as Visa suffers.”
I mean, this is the setting up and rolling out of technology and payment as a *negotiating tactic*. 

So yes: empathy for users, solving user needs (I can see that you probably need to dig a bit to see the user need for Apple Pay, but you need to dig a bit further, and potentially break into a mains water line to see the need for CurrentC) - all of that stuff. It still keeps happening. It will keep happening. It has always been happening. 

[1] Apple Pay
[2] MCX / CurrentC 
[3] Failed CurrentC

--  Now it's 12:30pm on Wednesday October 29 in Sydney. A 15 hour flight from LAX to SYD and, in the words of a friend, I'm not entirely sure if I've been incepted. In any event, a reasonable amount of sleep.  This isn't as long as I wanted. But: open beats closed, so I'm hitting send. I'm going to try and get back into the groove.  Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Eight: Who's Afraid Of Infrastructure; White Hats; Utopias; Chinese Room Mobs
Date: October 20, 2014 at 3:25:36 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-iuc5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

5:27pm and perched at a table at the Code for America office. I didn't write last night, and I think I'm okay with that: I have things that I'm happy writing about today. 
 
1.0 Who's Afraid of Infrastructure?

I quipped the other day that it's not that I'm afraid of ebola, I'm afraid of an under-invested healthcare infrastructure in America. I think I would be less scared of ebola in the UK, where it feels like there's been a historically stronger tradition of delivering public health as opposed to healthcare-for-people. 

So it wasn't that there was a US citizen in Texas who had contracted and died of ebola, it was that there was a nurse who had now contracted it who had been involved in treating him. It was that the existing systems of notification had failed: the hospital initially said that the information about their patients travel had been captured but not communicated to the doctor, and then that lapse was blamed, in a way, on the electronic healthcare record software used by the hospital. But we know that software is built to reflect need and working practices. 

Instead, it feels like another one of those vulnerabilities in how the human mind works and processes risk: I can read articles about how checklists work and how their adoption in hospitals is doing wonders for patient safety. About how sharpies being used to mark *this leg*, not that leg, are helping to reduce the (rare!) occurrences of wrong-limb-surgery. And, you know, I can read about how MRSA was totally a thing that required changing working practices and a reminder that it might be a good idea to keep hospitals clean-clean, as opposed to cheaply-clean. 
 
 
2.0 White Hats

The idea to white-hat your product isn't a new one, but this is a nice read[1] around the same principle. At Six to Start when we were building stuff for big broadcasters like the BBC and Channel 4, we learned about the Time To Cock rule - the (minimal) amount of time it would take for someone to subvert your call for user-generated content and turn it into, essentially, just a dumping ground for someone typing "cock" a lot. 

[1] Your next project needs a white-hat jerk - Ross Floate
 
3.0 Utopias
Deb Chachra let me know that Paul Raven had responded[1] to my thoughts last episode on his original post about technological utopias and Kevin Kelly[3]. 

I'd say that my intent was not necessarily to shift the *blame* on to marketing and advertising, just that I got super excited about what Raven had said, and was looking for other factors as well. 

Raven's key point here, I think, is this: 
Facetime solves the problem of being able to say goodnight to your kids when travelling on business, but it doesn’t solve the problem of a business culture that expects you to spend shit-loads of time away from your young family — which is a systemic problem with many other side-effects besides keeping you away from home, and one that technology tends to exacerbate at the molar scale, even (if not especially) when it seems to ameliorate it at the molecular scale. Or, to put it crudely: in order for an iPhone to make your life easier, a number of Chinese workers must make their lives rather more difficult. The benefits of technology are not at all evenly distributed, and neither are the downsides.
I'm not sure if I completely buy this. Or, rather: I buy this, but I think an interesting thing happened when, as Raven says, technology met B-School and the American Protestant Work Ethic and the dominant message became one of productivity and optimisation. There's a sketch from the UK 90s comedy show Fist of Fun[4] with a character called Simon Quinlank, who's the self-proclaimed King of All Hobbies. Certainly the way that hobbies are spoken of in the US - from what I've experienced - is that people are very *serious* about them here and you end up with people like Martha Stewart and her associated empire. I'm not necessarily being fair here, but it feels like back in the 17th Century, the British were busy with hobbies that ended up with the Royal Society[5] instead.

I wonder if the proposition that Raven is putting forward is, or has to be true: that for an iPhone to make my life easier, a number of Chinese workers must may their lives more difficult. Someone like Marc Andreessen might say that the same Chinese workers are more or less lining up to have their lives made rather more difficult, but that those difficult lives are easier (or maybe just differently difficult) than the rural lives that they might have had before and progress, of a sort, is being made. Or that the example of the manufacture of the Neo Lucida[6] from Golan Levin and Pablo Garcia in their XOXO talk when they went to China to meet the people making it - by hand - who were very proud of the work that they were doing. And that's without even considering the fact that Chinese workers might not have had to make the iPhone in the first place, but that's the price we're willing to pay. As Levin and Garcia remind us, pretty much *everything* we buy now, is hand-made and touched by human hands. The idea that robots assemble things for us is more or less a fallacy. 

Raven's call is for a flattening and a more vigorous, honest definition of the problem rather than a vague waving at a sort-of-everything. So what if it's difficult for us to keep the whole thing in our heads? Make new things to make it easier to keep the thing in our heads. Try to understand that which we need understanding. Build those giant data-viz rooms as Bret Victor appears to be calling for so that we can use our pattern-matching to tease apart relationships in ways that our brain architecture might be better suited to understanding. 

[1] (DIS)ASSEMBLING #STACKTIVISM; POKING HOLES IN UTOPIA - Paul Raven
[2] Episode One Hundred and Seventy Seven: We Will Sell it To You Wholesale (TinyLetter archive link, because I am so far behind on the archives at newsletter.danhon.com)
[3] Make technological utopia easier with this one weird trick - Paul Raven
[4] Fist of Fun - Wikipedia
[5] History of the Royal Society - The Royal Society
[6] Neo Lucida
4.0 Chinese Room Mobs
Imagine you are a GamerGater. You are angry at the world and you want to do something about a perceived attack on your hobby, on something that is near and dear to you, and you want to lash back at what you see or feel is systematic oppression. What's one thing you can do? 

From Elementary Penguin on Metafilter[1]:
So GamerGaters prowl Twitter for any negative mention of GamerGate, find appropriate copypasta from their secret stash that used to be on Girhub, and spam replies, right? I just realized that this is exactly Searle's Chinese Room. So does any part of the system actually understand what it's doing?
Of which, a tweet[2] and a very long conversation with Sarah Jeong[3] and later persuasive counterpoint from Eleanor Saitta[4].

So, here's the gist: a mob evolves or discovers the behaviour that to communicate, propagate and distribute its message whilst its members perceive that it's under attack, it uses an elementary form of pattern matching. When it sees the enemy saying a certain thing, match against that pattern, look up a response that's been pre-written and simply post that response. 

The gist of Searle's Chinese Room argument, one that Searle used against those who believed that human consciousness could be replicated as a series of simple-to-understand processes, was that you get a bunch of people, lock them in a room and give them a set of easy to understand instructions like, if you see this symbol, show this other symbol. No one person in the room *understands* Chinese, but if you get the rules right (and enough people) you can feed the room Chinese and out comes English and it kind of works. Searle says: this is a system, and it's not conscious. 

The argument about AI and consciousness isn't really the point of this particular observation, more that once you have people who are treating a medium as broadcast and aren't involved in understanding or conversation, they appear to be acting like a bot, a thought that Fred Scharmen is pretty sure that he's had since *at least* 2009[5] in the form of social media encouraging bots (also: brands) to act like humans and humans to act like bots. 

Saitta's point from her tweets - that not all communications mediums are about communications, that there are channels that people use for broadcasting and explicitly not listening, and that we've seen this before in speech divided by class where there are private channels for listening.

But, I still think there's a thing here, which is this: when individual components of a mob start *acting* like a Chinese Room in a certain medium (ie: they aren't just Chinese Room components everywhere, just in a certain space) conversation disappears from that medium. In a way, this presents itself as a the "these people are impossible to have a conversation with" problem because the conversation isn't one: it's a conscious choice of the other party deciding to not understand what's being said by the responding party, and to instead resort to pattern-matching and talking points and then...

And then when we talk about talking-points and staying on message, isn't that something that we learned from PR management of politicians? Find a keyword in your interviewer's spiel, match it to a talking-point and then spew out that talking point. There's no wonder people like Jeremy Paxman get annoyed and ask the same question and Ian Katz, the former editor of BBC's Newsnight has written about this death of the political interview when one side has been reduced to performing like automatons[6]

Because: how do you argue with something that isn't conscious, or, in other words, is *choosing* to not be conscious?

Saitta's suggestion - that you go to where you can be assured that you'll be listened to and *understood* - in respect of Gamergate is what you get when Jesse Singal goes back to Reddit to counter accusations of his article on the same being poorly researched[7]. Singal eviscerates and engages with members of the movement on their own turf, which, for what it's worth, doesn't *appear* to degenerate into name-calling. 

So part of the question is this: why does this happen on Twitter? Is this something that only happens on Twitter, or on all broadcast networks? Is this behaviour - copy-paste-Chinese-Room-ish behaviour an emergent behaviour of limited-content networks that have a high susceptibility to virality and pass-along and where certain types of content like hashtags are rewarded when they get repeated with high frequency? 

[1] Insomnia Thoughts
[2] https://twitter.com/hondanhon/status/523922780631617537
[3] https://twitter.com/sarahjeong/status/523923453275930624
[4] https://twitter.com/dymaxion/status/523992887025864704
[5] https://twitter.com/sevensixfive/status/524054829849919488
[6] The death of the political interview - Ian Katz, The Financial Times
[7] Another poorly-researched hit-piece, from the Boston Globe - singal commenting on Reddit

--

3:21pm, Central Time, somewhere on the way to Salt Lake City after having given the opening keynote at the HOW Interactive Design Conference in Chicago yesterday. Opening keynotes are pretty scary - you don't have anything to refer back to and it's kind of up to you to kickstart things and make them happen. There's nothing to react to yet. And then the stereotypical hiding in the hotel room afterwards for the post-talk comedown. 

I hadn't written for a while and it was becoming a Thing in my head, and I was worried that I just wouldn't anymore. Or that people would accuse me of not writing anymore because the writing had "done its job" and I'd, well, gotten a job, neither of which are strictly 100% true - well, I *do* have a job, but it's not like the writing has lost all value to me. And it's true that the writing did help me get the job, but I'd like to think a whole bunch of other things helped me get the job, too. But, honestly, more a matter of my brain being overloaded with essentially being jacked-into-the-matrix of the new job, learning a whole bunch of new relationships and concepts and teasing them all back and forth until I get some sort of clarity. 

So. An endeavour for more writing.

Dan 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Seven: We Will Sell it To You Wholesale
Date: October 12, 2014 at 10:04:19 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-imgd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

7:07pm on a Sunday, about 10,000 feet above Oregon on the way down to San Francisco again for a few days in the office. I didn't write on Friday - something that I'm aware of but trying not to beat myself up about. There's a flaw in my mental machinery that I've noticed where success seems to be balanced on a knife-point. If the Seinfeldian unbroken line of Xs in the diary against each day is broken, then that's a failure: it means resetting and starting from zero again. It's not a kind attitude to take, certainly not one that rationally understands that sometimes in the universe, Shit Happens that means that you miss one day every now and again, whether it's for something like exercising or writing every day. What I can understand rationally as mattering is the journey and the practice, not the numbers: fall off the horse, get back on the horse. Don't just stare at the mud and wail and wallow about how you've fallen off the horse: just get back on it. It doesn't matter. So: on a Sunday night, writing today, instead of Friday. 
 
1.0 We Will Sell It To You Wholesale
Via Deb Chachra[1], Paul Raven's blog post about a non-technologically focussed utopia[2]. There were a couple things about Raven's post that stuck in my head: first, that "hardly anyone's buying utopias these days" and connected later on in the post that "we'e had enough historical and personal experience with previous technologies failing to deliver upon their utopian promises that we are no longer willing to take them on face value."

There are other points of Raven's - the central piece of his post as I understand it is to try to remind people that progress is as often societal (ie, in that it's a result of people changing, not merely the introduction of new technologies, and a reminder that technologies are as much processes as they are anything to do with binary and processing on silicon substrates, as is the current vogue). 

So, a few things that I wonder: the idea that as a culture or society we've wised up to the *marketing* and promises of technology: that most people alive right now have had time to remember the difference between what's been promised and what we actually ended up with. There are certain things that technology has promised that haven't come about either because they're about technology solving *human* problems that, if you will, have an inadequate understanding of user need or user research in terms of whether they'd actually work in the real world: for every promise of office automation and a paperless office, we end up with more email in more places. 

On the other hand, we get things like the broadly-true-in-principle-but-not-execution of AT&T's You Will[3, 4] advertising campaign of the late 90s. In the midst of euphoria about the information superhighway we get the put-your-kids-to-sleep-over-the-videophone idea, but AT&T thought we'd be doing it over fixed lines (no doubt ISDN, because it's not like anyone was going to install fiber anywhere, right?) or ordering concert tickets from an ATM or sending a fax from a laptop on a beach - all of these things we do now, because they were solved by networks and infrastructure, and they didn't necessarily require us *changing the way we do things*. Well, not really, right? I mean, it's like we still *want* to buy concert tickets wherever we want, and we still *want* to say goodnight to our kids over Facetime or whatever.

An aside: Facetime works because it works like a *phone call* and it is unlike Skype. It doesn't require signing in to a presence server. You just "call someone up" using Facetime and it interrupts what they're doing. They can choose to ignore the call. Every other video chat service requires you to be *signed in to the video service* in that there's also a state where you're also *not signed in to the video service*. I mean, imagine if you had to actually have an *app running, that you signed in to* on your phone for you to receive phone calls? (Yes, I know some of you would choose to never sign in to it and to delete it). I digress.

I was going to say something about the inherently short lifespans of human beings and that for us to like technology we need to see appreciable change within out lifetimes, and hey, it turns that in the last century, we *have* seen appreciable change within a cohort's lifetime. But my gut reckon is that there's been such a lag between the promise of the thing and the actual realisation and delivery of the thing. In AT&T's case, it was 20 years after the ad campaign ran in the mid-90s before an appreciable proportion of the population had access to the services and products promised. 

So I wonder if part of this is about simply *delivery*. Part of Raven's piece is about how so many things that are part of a utopia are actually deliverable *now*, if we want them to be. e-government that works and is usable by the whole population is something that the UK's Government Digital Service is trying to do (and there's me hitting my quota of GDS-mentions-per-newsletter-episode again). Facetime is, I think, a better attempt at making video-calls-that-work, work, and you can easily imagine a pseudo-irrational Steve Jobs saying that it should literally be "as easy as calling someone" and then someone saying "but Skype does that" and him saying: "that's not as easy as calling someone". 

Perhaps part of the deal is that the geeks who build the things we have in the world, the ones inspired by science fiction are the ones who're also inspired by the potential of things, and not necessarily the solid realisation of things. In a science-fictional outlook of the world, there's always a tomorrow, always a better technology, always a Moore's law and a manufacturing process advance that means that we don't *really* have to work harder at making software easier, we can just throw more clock cycles or more transistors or cores at the problem and hope it goes away. 

As a science fictional geek, I am, I think, seduced by the potential of things to be amazing, and it's a different thing to try to make those things right now. That, I imagine, is a difference between utopian product design and actual hands-dirty engineering. 

And this is why the marketers and advertisers get a bad rap. They lie: it is so easy to sell us the promise of a thing and not the actual thing. The marketing of technology has been a marketing of possibilities, and who would blame us for being tired of possibilities when instead we want delivery?

My ex-employer launched Windows 95, but I'm not sure if they came up with the "Where do you want to go today?" tagline that Microsoft used. I presume that they did. Steve Jobs famously described the computer as the bicycle for the mind. But somewhere along the way, the promise of technology ran away from us. That's why, I think, we don't trust it anymore. Because the story it's been telling to us has been disingenuous. 

[1] https://twitter.com/debcha/status/521440551393329153 - Deb Chachra
[2] Make technological utopia easier with this one weird trick - Paul Raven 
[3] You Will - Wikipedia
[4] You Will - YouTube

--

8:02pm. See you tomorrow. As ever - send me notes.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Six: Not Missing Out
Date: October 9, 2014 at 7:29:06 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ik65=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

5:17pm after having sat through what's felt like a whole day of Google Hangouts. 
 
1.0 Not Missing Out
One way of looking at social networks: ways of telling people things and ways of finding things out. Perhaps an artificial distinction, but maybe an interesting one as a thought experiment at least. Here's the lazy version: a post-rationalisation of Facebook as the creation of someone who didn't fit in at college who wanted to know more about people without actually having to talk to people. Interaction without anxiety and a much greater chance to gather information from and about people without having to talk to them. At its inception, then, a tool to find out about other people - one that didn't have any privacy safeguards or considerations built in from the beginning, because *that wasn't the point*. 

The other way of looking at social networks - say, things like IRC or Twitter that are less identity based and more about *telling people things*, not finding out things about people. Sure, Facebook wasn't necessarily about finding-out-about-people when the original product launched - Timeline didn't exist, for starters, but it was a bunch of profile pages. 

Ello as maybe a way of telling, and less about finding out. Or maybe the other way around. Tilde.club as a way of huddling close, a way of preserving that small Dunbar number, even in a large group of a thousand. 

So, perhaps two user needs: wanting to tell, and wanting to know. A whole continuum between the two extremes, and potentially different business models between the two. And then how much of that just figures into psychology and how our social minds work, how we want to interact with the rest of a group? I would joke about Graph Search being pitched as a way to find out what to buy your "friends" for Christmas without actually having to ask them, a sort of SQLish query interface to the interior states of those you call close to you. But then that's what this technology is doing, right? Taking squishy human beings that aren't easily Normal-Formed into relational databases (ha, the irony) and abstracting them away and providing interfaces to them that are necessarily *less* high fidelity than the original interfaces in the first place. 

We also used to talk about social *software* and not social *networks* and now it's hard to think of the former without them automatically being the latter - where everything must scale and hockey stick all the way up to hundreds of thousands or millions or billions of users for it to be judged as "successful". Social software is now defaulted to a networked graph, where users are nodes and we try to replicate relationship connections every single time without necessarily improving upon or greatly increasing the vocabulary of what that edge between one node and another might *mean* other than "following" or "friend" or even just "noise". Let a thousand edges bloom and let them all mean different things. 

So what sort of social software would a well-adjusted person create? The type of software created by young people, anxious about fitting in, anxious about defining and creating and trying out identity, about wanting to know more about people and not really being sure about how to navigate messy, analogue, wet-biological *stuff* - what would people with the benefit of hindsight build?

--

5:28pm. Time to head home. 

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Five: Housekeeping; Private In Public; It's The Basics
Date: October 9, 2014 at 12:18:40 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ij6p=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:20pm in a coffee house next to a Chevron in Oregon City having dropped off my father-in-law to a square dancing night to which I now know far more than I ever really wanted to know about the lives of seniors and retirees. This is the bit where if I'm narrating the TV show of my life I say something like "And here's how I knew I was growing up: driving my father-in-law to a dance, and chaperoning him, telling him no, I wasn't going to let him get a ride back home that night and that I was going to wait up for him instead, that there were things I wanted to do and instead we both knew that I wanted to keep an eye on him. So here I was, nursing a coffee at 8:22pm in the evening, wondering who he was dancing with, who he was meeting, and what he was doing out late at night."
 
1.0 Housekeeping

A short one, this, but a change in policy: I now presume that all replies to this newsletter are private correspondence. I'll ask you before I quote anything you say when you email me a note. 

Part of the reason for this is a private exchange I've had with one of my readers that exposed a bunch of stuff that I've done that I don't feel very comfortable with and doesn't reflect the kind of person that I want to be. Another part is Justin Hall's talk at this year's XOXO - that isn't online yet, but I'll link to it when it is. The main thing being an issue of consent and (mis)representing other people. Hall saw this in his early years because he presumed that because he lived his life online that meant he had blanket consent from the people in his life that *just by knowing him* they would be OK with the intersection of their life and his being online too. And we know now, after having both grown up on the internet and growing up in general, that things are a lot more complicated than that. That the act of publishing on the internet, that free speech on the internet necessarily conflicts with others' autonomy. 

There's a decision that I have to make about *how* I write this in the easy way (unedited, stream of consciousness) and the good and bad things about that method. I've said before that one of my concerns is what that stream of consciousness shows me about the delta between how I act and how I say I act, or how I act and how I *want* to act. So, first step: all correspondence is private, and I will ask for explicit consent before I talk about you, or something you've sent me. 
 
2.0 Private In Public

I've been thinking quite a bit about tilde.club[1], Paul Ford's performance reminiscing of what it was like to have a shell account in the early years of the 'net. If you were a student in the 90s, you probably got a Unix shell account and had a public website address at http://some.college.edu/~username/ or if you had a Demon or Pipex dial-up SLIP/PPP account in the UK you probably had something like http://your.isp.here.net/~songtwo/. At University, my first account was at http://www-stu.cai.cam.ac.uk/~dyh21/ and there are friends I have now whose usernames still carry over from the ones against those shell accounts.

There's something about tilde.club, though that has been preying on my mind. There's the exhortation that it isn't a social network, but I think that's only true in the sense that it's not a 2014-era social network. It's not something where you Follow people or Like things: Ford's right in that it's just a common-garden Unix box running as a micro ec2 instance, that just comes with the regular collaboration software that's been accreting as part of a standard Unix distro (talk, wall, public web directories and now an IRC server). The thing that tilde.club is *really*, and the thing that I see that people like Ford think is beautiful about it is that it's a community space. And that's what the earliest social networks were designed to be, until they became the perverted commercial spaces that are now a part of existing on the internet. 

In that sense, what tilde.club feels like, for those into their net.lore is the founding of communities like The Well, or the original dial-up ISPs that were run by what we'd now call neckbeards but actually were just run by People Who Wanted To Talk To Other People And Use This New Thing Called The Internet. Part of the thing is that the claim that "anyone can start up another tilde.club" is part true and part false: part of what's valuable about tilde.club is the people, not the infrastructure. Yes, the optimism is fantastic but the optimism in the early tilde.club users is more about people who get where Ford is coming from and where he wants to go with it - it came with the people, not the fact that this is a tiny little Unix instance running in an abstracted Cloud using the same tools and interfaces through which a bunch of now-successful people cut their teeth on in the 90s. 

This has always happened though: it's part of what the internet does in terms of making things that are usually private public, or at least more visible. It is harder, now that we have the internet, to have a closed, private group of friends and not expose that grouping to the public. It's the kind of thing that happens when people hear about O'Reilly's FOO Camp and it sounds like a sinister cabal when in reality, it's a bunch of like-minded people getting together in private, but in public. 

Perhaps what contributes to the slight feeling of unease is this techno-utopian fallacy that because Information Wants To Be Free (because how else would that infinitely long Turing tape work, right?) everything should be public and why would people want to have closed groups anyway? Everyone should be friends with everyone, and keeping secrets means bad things are happening. This means people can't talk behind closed doors anymore, this means that the egalitarian anyone-can-join-in nature of the what the internet sometimes feels like (and the way in which the open-source movement is predicated upon anyone being able to contribute) conflicts with what humans *actually* turn out to be in practice, which is a bunch of cliques and groups through no real desire to want to do Bad Things. 

Of course, if I did want to do bad things (and I'm well aware of the rhetorical device I'm using here), I would say something like: well, what's the gender balance of tilde.club accounts like? Is it implicitly just supporting existing power structures? And is there anything wrong with a bunch of like-minded people getting together? Does Ford, for example, have some sort of higher duty to be inclusive?

Another way of looking at this is simply that the internet lets more of us have private in-jokes in public. That there are references that some people will get and others won't get and now we have to think even more than ever before as to whether that's OK. 

If you take a look at the people who're in tilde.club, they read like a kind of who's who of early web culture. There are people there who have done wonderful, amazing things for the web and the internet and bringing people together, so there's a part of me that absolutely doesn't want to sound like I'm shitting on them from a great height. There's also, if I'm being perfectly honest, part of me that's looking at the club - because it's got the word club in it! - and feeling excluded and not part of the in crowd, which probably says as much about me and my sense of self-esteem as it does anything else, because by all accounts if I'd actually bothered to apply for an account when I first saw Ford tweet about it, I'd probably be excitedly telling you about my new ~dyh21/ account right now. 

A thing that I wanted to do was to go and register a domain and start another tilde.club instance: because Ford's point is true: this is a good thing, and fostering this kind of community *is* a good thing. He's written about it, for crying out loud, quite eloquently[2] and I'd like to see more of these things. 

I suppose one thing is this: people having fun on the internet is indistinguishable from seriousness. It's hard enough to infer internal motive and we're terrible at working out peoples' motivations for things and are always comparing our insides to their outsides. Having fun in public is the kind of thing that, by necessity and due to its nature will attract attention. I don't quite know where that goes. 

Another thing is that it feels like there's a bunch of nostalgia for a smaller, simpler web - and that in a way this is literal nostalgia for the types of accounts that people had when you did Monty Python miner skits about how you hand-rolled HTML in a text editor on a server and you had to FTP stuff uphill both ways and most stuff was done in Perl and yadda yadda yadda. That deal with tilde.club is *optimism* and a green-fieldness, that maybe by pretending everything and everyone is on a tiny Unix instance we can roll back to the 90s and not have this corporate dominated net and some of the free-for-all that some people - but certainly not the millions who've come onto the internet since then, have appreciated. This was a net without DMCA takedowns, without automated copyright infringement bots, without terms of service violations, without dubious claims as to copyright over user-submitted content. A net where you could do things and you didn't have to be worried about *everyone* seeing it, where you could carve out a little space all over again and explore who you were. Does that still exist for other people? Is that why Tumblr's a big deal? I quipped that there was something that *felt* wonderfully indie about tilde.club, without actually being Capital I Indie Web Indie. 

Too long, didn't read: just read Danny O'Brien's piece from 2003[3], which let me emphasise is OVER TEN YEARS OLD and realise that nothing is new and that we just keep doing the same things, over and over again and also that Danny is one of the smartest people I know and I miss NTK[4] so much.

[1] tilde.club
[2] tilde.club/~ford/
[3] The Register - Danny O'Brien / Oblomovka
[4] Need to Know

 
3.0 It's The Basics

Whirlpool emailed me today - a sentence that requires explaining in the first place ("What do you mean a company emailed you?") to tell me that as a "as a loyal member of the Whirlpool brand family, we want to share a first look at our new campaign, launching to the public on National TV the week of October 6. Be the first to watch our new video below."

In my new guise as Content Director, I feel like I get to have more of an opinion about this stuff than before, when I was "just" a Creative Director in advertising. For starters: what makes me a loyal member of the Whirlpool brand family? Who even talks like that, other than out-of-touch brand managers? For all this talk of tone of voice and brand voice, what makes a regular person, a *user*, a point-at-this-person-in-the-street a *loyal* member? 

Do I go to Whirlpool user groups? Do I sit around and flick through albums of my favourite Whirlpool appliances through the ages? I mean, I have no doubt that there *are* people who are doing that, who have encyclopaedic knowledge of Whirlpool and its lore. But I think what *probably* happened is that I signed up my gmail address at some point sometime - presumably when Whirlpool announced that they were integrating with Nest[1] and finding out more about that sounded interesting - but that doesn't make me *loyal*. That makes me *vaguely interested* to receive information that I can throw in the trash with a simple gesture. 

There is no, as I pointed out on Twitter, shrine-to-Whirlpool in my basement that I've been accreting over the last ten years. I am not one of Whirlpool's Thousand True Fans. 

And really, a Whirlpool Brand Family? *Really*?

But then, let's take a look at their new brand campaign, Everday, Care[2]. Now, you should take this with the grain of salt that goes along with someone who's been in brand advertising for the last few years and is on the one hand acutely aware of how well it can work, but also is acutely aware of *what it doesn't do*.

The brand campaign looks like it's designed to forge an emotional connection with, I don't know, the person or people who are going to buy new Whirlpool appliances. It's not a play for technical specifications or purchasing-by-feature-list, instead it's a play straight for the irrational part of the brain that will have you think: Whirlpool *gets* me and wants good things for my family. It is a play for the bottom-third of Maslow's pyramid: Whirlpool wants the best for your family, wants you to feel safe, wants you to understand that *they* understand that the chores that you're doing every day aren't just chores, they're *important*, damnit.

Look, here's the brand ad[3] script I've just transcribed:
Every day:
we cook,
we clean,
we wash.
But these simple acts are more than chores.
While seemingly insignificant or annoying,
these daily tasks are actually something far greater.
Each act of care
each gesture of kindness,
reprograms our brains.
Forming bonds of attachment and love,
weaving the very fabric of our society more tightly,
making our world smarter,
    SUPER: Conversation at dinner can impact a child's vocabulary more than reading to them
stronger,
    SUPER: Not having clean clothes to wear is a leading contributor to truancy rates
and a better place to live.
    SUPER: Household chores help kids become self-sufficient adults.
That's why whirlpool is introducing the every day, care project.
To show the power of these simple acts.
To help families and communities thrive.
To prove the value of care in ways that are bigger than us all.
Because when we all care,
every day,
we can change the world.

Super: The Every day, care project
Card: Whirlpool / Designed to Simplify
This is where we're at right now in terms of western society: a multi-million dollar brand campaign around household appliances and how they will change the world and fix a broken society. And not, you know, about appliances that *actually work* when you need them to work, or are more reliable, or save you time. 

[1] Whirlpool: Works With Nest
[2] Whirlpool: Every day, care
[3] Whirlpool: Every day, care Brand Spot / :93 cut

--

Annoyed at advertising. Send me notes.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Four: Depth, Not Breadth
Date: October 7, 2014 at 10:48:59 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ii05=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:08pm on a Tuesday night and it's still warm in Portland. There's a giant moon outside. Thinking about Alien: Isolation and Shadow of Mordor, two "next generation" videogames that whilst not necessarily *looking* much better (traditionally the main benefit of a generational shift in videogame technology) nonetheless appear to be *playing* differently in terms of experience. Neither of these games feels like it's doing anything particularly special with all of that new-fangled x86 architecture processing power and gobs of GPU compute being thrown about, but Shadow of Mordor at least has a game design that makes the gameplay feel significantly more personal - at least, that's what the reviews are saying. 

My son's vocabulary has now expanded to two-word phrases. Tonight's was "big moon" and "daddy working". Not quite sure how I feel about that.
 
1.0 Depth, Not Breadth

Dan Saffer smartly tweeted the other day that "Going in-house does not usually make for variety. Instead, it means depth, not breadth. If you like variety, work for an agency."[1], presumably in response to the news that superstar design agency Adaptive Path (responsible for, well, the AJAX in AJAX) has been acquired by Capital One, the financial services company[2].

So, a couple things here, other than a vigorous head-nodding and vague irritation and professional jealousy, admiration and so on at Mr. Saffer for being quite so astute in the medium of 140 characters. 

This is part of the reason as to why organisations like GDS decide to implement internal design and build capability, because some things are strategic to the success of the organisation. It's why, for example, I was confused that a company like Nike might have something that on the face of it is so strategic to its future success (digital products like Nike+ Running) in the hands of an external agency when we all know that yes, *in theory* you own the code, but in *practice* it's being run by an outside company. It's the kind of thing that leads to weird situations like Target deciding to outsource its website to Amazon[3], a decision that they made back in 2001 and if it didn't look stupid then, looks exceedingly stupid now.

So there's the short-term view, which is that right now, there's not enough talent in organisations that need to have good digital capabilities and skills - which is why you get exceedingly good agencies like Siberia[4] and Teehan+Lax[5]. But it's also why in conversations with the people who're running those well-admired agencies, they know that their role in certain businesses is just at the beginning, and they need to be able to hand over well-designed services to their clients.

It feels like this is a good thing to think about in terms of what makes you happy: do you like being exposed to lots of different things? Or do you like working in one area, but only one area, and focussing on it? That's the trade-off that I could start to see at a place like Wieden+Kennedy - and admittedly, it's a very different place than a digitally focussed agency like Adaptive Path or Siberia or Teehan+Lax. But there was certainly the *variety* there as opposed to the depth. The depth for some people was a refreshing change, and potentially the thing that delineated more-digital people from less-digital people - in that digital, as ill-defined as it is in the advertising world, can mean so many things that you can, if you want, take it to mean *solving a problem* instead of *talking about a problem*. 

I don't want to make out that this is a binary situation - few things in life are. Merely that there's a continuum, and on some ends it might be easier to get more breadth - in agency land, for example, when you're the hired gun coming in - and on others you might get the opportunity to spend more time on solving a particular domain. Whether any of those are easy to *execute* is a different story. 

What does feel like a sign is this, though: if this is the kind of acquisition that works (and hopefully it is), then it's potentially the better kind than a superstar CEO who's going to come in and fix your problems. The kind of CEO who can say that service design is a pretty big deal for a financial services company is probably the same kind of CEO who has a chance of allowing that design team the room to actually make usable products. 

There's a wonderful irony here in which last week I was trying to sign up to my new employer's healthcare benefits (which, for some archaic American reason are not administered by the 501(c)(3) I work for, but a different company, and well... it's complicated, but apparently also completely normal) and errored out with a Hibernate ORM error complaining about something funky in an Oracle database, whereupon I'm on the phone with a customer assistance agent and they say that the application on *really* works on Firefox, nevermind Safari or Chrome, and that *really* Windows is probably better, and once the issue has been escalated to IT, hopefully it'll have a resolution within three business days. 

And here I am at an organisation that's trying to help governments make their services not just better, but usable in the first place. Mr. Customer Service agent, when he hears that that's what Code for America is doing, says that he's right there with me. I don't know if he appreciates that his employer is part of the problem, too. 

Already, though, what I've seen in the depth-not-breadth part of the equation having jumped over to the equivalent of client-side (when you've been working at an agency, anywhere that isn't an agency is practically client side unless you're in production), I've been struck by how much time and effort I can spend just thinking about what things *mean*. 

And of course, whilst I'm doing all of that, Russell Davies puts up another barnstormer of a blog post about clarity as a business model[6] and it's in some ways all I can do to not just give up and tell everyone to read his blog all the time, and then I spend a good few minutes trying to work out if the word we want to use is "residents" or "people" before plumping for the latter. 

I've been in the new job for just over a week now, and you can probably count about a week's worth of immersion prior that and I'm still trying to clarify - make clear, distill, describe, explain, communicate - some very complicated things into some easy to understand things. This clarity works both ways: it's not just an external clarity, but an internal clarity, a sort of fractal, self-similar description where the act of figuring out what it is that you're doing for other people helps you figure out what you're doing *for yourself*. 

It felt like I had a similar moment when I was chatting with a friend over XOXO and trying to get him to explain to me what the big deal about the blockchain - the specific mathematical/technological innovation behind the current crop of cryptocurrencies - that's gotten everyone quite so excited, and it took a while for me to grok the concept of the public, self-consistent ledger. But I'm still not sure how you get from that all the way to Bitcoin Native Apps[7] that allow for automatic compute resource markets - is it just because the current financial system is too crufty? There's too much friction? It feels like some of the deal with Bitcoin is that it's just blowing away a whole bunch of legacy systems that are impeding innovation, but it's not clear that you *need* to blow away a whole bunch of legacy systems or instead you just need to have payment providers that aren't being dicks about the whole thing and actually try to invent new things.  

[1] https://twitter.com/odannyboy/status/518432011036270592
[2] Adaptive Path and the Death Rattle of the Web 2.0 Era - Mat Honan, Wired
[3] Why Target Ditched Amazon - Rachel King, Wall Street Journal
[4] Siberia.io
[5] Teehan+Lax
[6] Clarity as a Business Model - Russell Davies
[7] Some ideas for native bitcoin apps - Chris Dixon 

--

8:47pm. I wanted to find a red crayon and daub an X on our front door. This is a sick house, there is a sickness here. I have successfully passed on the cold I had to my wife and son.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Three: Names; The Condition
Date: October 6, 2014 at 11:10:45 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-igr9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

8:29pm on a Monday night, and it's inexplicably 77 degrees fahrenheit, 24 degrees celsius nearly two hours since the sun went down. I'm writing this on the new work laptop, newly named Insurrection - yes, I name my computers - which I had wanted to call Narcissus (it's an 11in Macbook Air, the escape pod companion to my otherwise workhouse 13in Retina Macbook Pro called... Nostromo). I might still change the name. It's not like you can't change the names of things. 
 
1.0 Names
I'm getting the hang of this working-remotely thing, slowly carving out a space downstairs in the basement (American houses!), working out how to do Hangouts (and wondering why, exactly, it is that this Comcast internet connection doesn't seem to be performing, and looking for an answer other than "because it's a Comcast internet connection"), doing things like assembling standing desks (standing is weird after sitting for so long) and staring at spreadsheets and skeletal Keynote presentations. 

One thing was this: spending what was probably two hours today thinking about *one* word, trying to figure out what a better word might be. To try and understand the shape around everything that the first word represented and where it was going to be used and the context it was used in and all the different people who might hear it and what they might think it means, and to try and come up with something that's at least a little bit more clear, a little bit more understandable. 

And then, trying to hold all of that in my head and to construct some sort of structure that can explain all of those *other things*, that's going to make sense, and all the words that are going to be used for those things.
 
2.0 The Condition
This bit is just a list of stuff that is literally just on my mind. Nothing more than that, just things that are lodged somewhere in an unfathomable neural network:
	•	How Ebola Spread Out Of Control - The Washington Post
	•	Failing the GDS Service Assessment - "The team is planning to achieve [a simple and intuitive enough system that users succeed first-time, unaided] by replicating an existing system and fixing defects and making minor improvements, so that further training for users will not be required"
	•	Titan installs Bluetooth "beacons" in NYC phone booths under the guise of media
	•	Reddit apparently acts as a command-and-control network for an OS X worm 
	•	The jetstream changes
	•	VR is at the stage of the Gartner Hype Cycle where people are just doing stupid things
Other things that are in my head: that there was something different between Diaspora and Ello, not just the function of time (Facebook has done so many more things in the time that's passed between Diaspora attempting to be an alternative and Ello attempting to be an alternative), the idea that people didn't want an *indie* web that meant that they had literal control over the data they were feeding into the maw of the network, because that would mean work and until running your own web server is an "app" that you just one-click fire-and-forget, then perhaps that wasn't going to work.

But that said: the p2p music servers and era of Gnutella and Napster and Torrenting seem to work, at least they seem to work in the sense that people will fire up a server *to do a thing* and then they might not leave it up all the time because, thank you very much telcos, you fucked us over very nicely when you invented asymmetrical network services you bastards, just make it feel like TV won't you - but anyway, maybe that's something for sometime else - the idea of the ephemeral network service, that distributes content and hosting and that you can run a server for a little bit but not permanently. 

Anyway, the idea of Ello, just the *idea* of a network that might treat you more equitably, even if a lot of the promises are hand wavy right now, even if the implementation leaves a lot to be desired - some sort of an example of a minimum viable *idea*, not even a minimum viable product, one that taps into a different kind of user need. The user need here? Not to communicate, but a need to *not be on Facebook*, or a need to show unhappiness. A protest vote, but the kind of protest vote that can attract other protest votes and then suddenly snowball in its own way.

Of course, the pessimist in me takes a look at all the content being put into Ello right now and wonders: when it all falls down, is Jason Scott and the Archive going to have to rush into the burning server farm and rescue our photographs and rants and raves and, well, pornography-that-is-allowed? 

But anyway, this is 2014, and networks are everywhere and we still don't know what most of them look like, we still erect them all over the place, and they just beget one another. On the one hand, social media is a fantastic weapon in fighting the spread of ebola, on the other, frontline staff didn't have enough surgical gloves and high-level video conferences didn't help anyone. Lots of talking and hardly any doing. 

--

Figuring out how to write this newsletter again. 

Dan



 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy Two: Week One; Universal Basic; Karen
Date: October 4, 2014 at 1:36:00 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ieep=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

11:08pm on a Friday night and after an unplanned hiatus due to, amongst other things, illness. I have to admit: I tried starting this episode a whole bunch of times this week, and it's acutely preying on me that this - on a Friday night - is the first episode that I've written this week. In the past hundred and seventy-odd episodes, I haven't had a four-day break before. And a lot of shit's gone down. 

But, here I am. This is me trying to remember that the point of this was to *just write*, and whilst there might be a tonne of stuff going on, I'm still going to try and *just write* anyway. 
 
1.0 Week One

I started the new job "for real" this week - Content Director at Code for America, putting my typing-for-coins where my fingers and my mouth are and re-emerging through some sort of capitalist chrysalis through the other side into a 501(c)(3) non-profit.

There was a weird feeling as I started on Monday morning - the flight into SFO delayed as usual thanks to Karl the Fog, and bumping into a bunch of ex-colleagues from Wieden+Kennedy, doing the same day trip that I used to do to present to clients at Facebook. Plus ça change, I suppose. But Monday, Tuesday and Wednesday (and the preceding weekend) were taken with the usual man-lurgy, the kind that women know about because when it comes down to it, it's just a cold or not even the flu but still the kind of thing that lays most men useless and snivelling. 

There's not *that many* people at Code for America. There's probably around thirty-odd staff, but the building is shared at any time with Fellows and startups that are being incubated. Senior staff aren't that big a number, and it's not like I didn't already know a bunch of people I now find myself working with having bumped into them, on and off, during the summit the previous week. 

It was a different feeling though: when I started at Wieden in Portland, I had kind of been doing the job as an Advertising Person at their office in London, and had even come out a couple times, once on a Coke brief and the other time on What Crazy Thing Should We Do Next On Old Spice brief. But I knew, kind of, what I was supposed to be doing because there was all this extant structure. In the case of the Portland office, it was around thirty years of institutional advertising that had accreted, not only in terms of the walls of the building and the physical layout but also The Way Things Are Done. And part of the fun bit of the job was demolishing that, but knowing that part of the job was being able to come in and ask stupid questions. 

This time, there are kind-of stupid questions in a "why are we doing things this way" but the answers aren't quite as institutional because the organisation is only a few years old, and what it's going through is more of your standard maturation phase as a startup (or, as most other people would call it, a young organisation) starts to grow up both in terms of age and number. 

But here's the thing about this particular job. I'm defining it in terms of how easy it is for people to understand and to copy what the organisation does. What my team will produce is *understanding* and *copying*. Not lines of code. Sometimes it will involve things like locking people in a room and thinking really hard and then coming out two weeks later with *three words*. And they'll be *really good words*, and they'll be words that totally help with the understanding and the copying. But the words on their own won't be a product or a service or marketing, they'll still need to exist somewhere out there in the world. 

And, funnily enough, a (in retrospect) stupid conversation with my wife about how everyone was kind of looking at me to Make Decisions and Be In Charge, and that I'd felt that I'd never actually done that before when - as she pointed out - didn't I co-found a startup? Wasn't I the COO who made sure things were moving in the background at another? Didn't I Creative Direct teams and get a whole shit-tonne of stuff done?

Well, yeah. 

So: week one. Meetings and greetings and coffees and listening and sponging and absorbing and translating and settling and writing and scribbling and drawing and sketching and setting up laptops, wrangling Dropboxes, getting Yet Another Google Apps^WFor Work account, flexing github muscles that haven't been touched in *years*, peering at a new work laptop (the 11in Macbook Air isn't as small or as light as it feels it should be, next to a 13in Retina Macbook Pro), waiting for 1Password to sync all the things that I've outsourced to an outboard enciphered brain. 

And then: the room with the stickies. The one where four people deconstruct the entire organisation on 3M-manufactured bits of paper and then move them around until they make some sort of sense, and then the New Labels and New Descriptions of things, the This Is What We Do Now, the heading back to Portland and the remote Hangings Out and one-on-ones and the inexorable feeling of building up momentum, of the kind where you want it described as an appreciably portion of c where if you want to stop or slow down you're going to have to flip around, do a one eighty and then *burn hard*. 

Right. Moving now.

Making more understanding. 
 
2.0 Universal Basic
Universal basic income, smartphone and data. The question that if you were going to throw a whole bunch of money at developing infrastructure for a new country or trying to make sure that you stayed ahead of the game, that if you were going to tear everything down or at least start to build a new layer on top of the old, what might that be? The feeling that more and more people are starting to say that perhaps we're really going to need those social safety nets, perhaps universal basic income is one of the ways to do things, and then what?

And then universal basic data? Universal basic ways of navigating the world? What tools does a government give a citizen to navigate a world with? It's not like we've moved past the time where people no longer scoff at saying that "internet access is a human right" - especially when it's said by the new conglomerates that we're increasingly feeling uneasy about - but then we think about all the things that are accomplished via internet access, the way that access to the world is mediated by the digital and then what? 

In what now feels like a certain heyday of the UK there was the Great Analogue Switchoff - the event where analogue terrestrial broadcasts were finally stopped to make way for another Great Spectrum Auction, the new one-time, one-shot way in which governments tentatively stepping into the digital age might make some money, by freeing up all that wasteful analogue stuff and switching over to the shiny new digital distribution network - so much more efficient, so much tighter, so much more capacity. And it was a big deal and it was done slowly and it meant that your TV might not work anymore or you needed a box and television, well, that was a thing that most people had, that was an important thing. 

Free bus passes for seniors. Free smartphones. Free data. 
 
3.0 Karen

Karen[1] is not Samantha[2], but Blast Theory are. You should probably keep an eye on this. 

[1] Karen from Blast Theory
[2] Are these feelings real?

--

Friday. See you on Monday.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy One: Empathy, Continued
Date: September 26, 2014 at 10:48:55 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i7cp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
2:15pm, at least 10,000 feet in the air, and flying blind if by "blind" I can mean "without internet connectivity". It's not like I need internet connectivity to do stuff, apart from *all the stuff I have to do that needs internet connectivity*. 
 
1.0 Empathy, Continued
"You're hyperventilating. Look into my eyes. Breathe through your nose," - the emergency dentist who was fitting my new crown, the one I got after I fell off my back porch and concussed myself. 

The last few days have felt, at times, like standing barefoot on a ledge, toes gripping the side and trying desperately to not look down despite knowing that you're very, very high up. I would joke that the good thing about joining Code for America is that there are lots of problems to fix, and the question is more about choosing where to start rather than finding the right one. At some point, all problems are problems and just making progress is progress. 

The summit was a little bit being pushed off that ledge at times. Some of the better case studies were exercises in what you might call an aggressive humanisation process. It's not a mistake that some of the most successful factual TV shows in the UK like Back to the  Floor and Secret Millionaire involve taking people who are typically insulated from people on the front line and essentially forcing them to spend contact hours. Almost like a sort of an inverse training process that one might go through when preparing for war: when instead of going through a psychological process of dehumanizing the enemy so that soldiers are able to do terrible things, you go through a process of meeting people and undergoing a procedure of catastrophic empathy re-integration. 

The general impression I've had is that when you take a bunch of smart policy wonks and make them part of multidisciplinary teams focussed on delivering service, they actually quite like it. And then you stick everyone - not just some people - through a regular, no-holds-barred, mandatory process of user contact. And then you repeat it. Again, and again, and again. 

This is, what I think, is powerful about some of the Code for America rhetoric of the For the People, By the People stuff. It does two things:

 - reminds people working in government where their mandate comes from; and
 - acts as a sort of ring-zero, unassailable reason to do user research

The irony of this being delivered by a British citizen is not lost on me. 

A lot of the examples given over the last few days were where the users of government services were disrespected and the interactions themselves at their worst stripped people of their dignity. These are *indifferent* services - the kinds that are abstracted away and where the idea of a service is delivered without the understanding that the service is to be delivered to a living breathing person. I would hesitate to call the examples that came up again and again - mainly, waiting and standing in line - cliches because at this stage there are far too common and they're all real. 

--

8:48pm, with one of those days that is just fragmented with travel and airports and cars and email. Nothing in my brain. 

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventy: Small Pieces, Loosely Joined; The New Slang
Date: September 26, 2014 at 1:09:06 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i6et=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

4:17pm in the green room at the Yerba Buena Center for the Arts, watching the feed of the main stage in a place where I can listen and but also talk, catch up and slowly have my brain process the stuff that it's been absorbing over the past forty-eight-odd hours. 
 
1.0 Small Pieces, Loosely Joined
My interpretation of the "small pieces, loosely joined" is that it's an explanation of the design philosophy first of Unix, and then the internet. That there's value in small, well-defined tools that do one thing well, but that can be connected to each other to form larger, more complex chains and networks of features. 

It turns out that the world that we're building in 2014 is one that, in some cases, is intentionally brittle and inflexible. Via the not-always-depressing new aesthetic tumblr[1] is this story of new business models enabled by telecommunications, the end-result of small pieces, loosely joined, but in effect, strictly, inflexibly and abusively deployed[2]:
The thermometer showed a 103.5-degree fever, and her 10-year-old’s asthma was flaring up. Mary Bolender, who lives in Las Vegas, needed to get her daughter to an emergency room, but her 2005 Chrysler van would not start.  The cause was not a mechanical problem — it was her lender.  Ms. Bolender was three days behind on her monthly car payment. Her lender, C.A.G. Acceptance of Mesa, Ariz., remotely activated a device in her car’s dashboard that prevented her car from starting. Before she could get back on the road, she had to pay more than $389, money she did not have that morning in March. - Miss a Payment? Good Luck Moving That Car - New York Times Dealbook

Just in case that doesn't make you angry enough, if you go and read the full NYT article, regulations typically only allow for repossession when borrowers are in default - which is around 30 days after payments become due. In none of the four cases in which Bolender's car was remotely disabled was her account in default.   Sometimes, though, this isn't even a case of blaming things on an inflexible algorithm. The NYT article makes clear that most of these deactivations are done by people. They can be done from smartphones, and one lender at a credit union boasts of remotely deactivating a car from a Walmart.   This isn't empathetic. This, I imagine people would say, is *business*. This, I imagine people would say, is a *clear contractual relationship* with penalties that are spelt out, and furthermore, I'd imagine that they say that what they're doing is a Net Good, because it's given More People Access To More Credit.  Well, bullshit.   You want a consequence of an internet of things? This is one of them. Absolutely and unequivocally. And one of the consequences of a world in which you can reach and touch and affect people at scale, from anywhere is that you lose empathy and that you lose understanding of those with whom you're dealing.  The shellshocked Bash shell exploit[3] turns out to be a small piece, somewhat loosely joined, but now a piece of infrastructure. Are they still small, loose pieces or are they instead the equivalent of hundreds of thousands or millions or billions of screws, holding a precarious structure together? The rumoured rolling-outages at Amazon point to a cloud where infrastructural complexity has been abstracted away, and you don't have to worry about patching a gazillion bits of real hardware with real Bash exploits in it, until your cloud infrastructure goes down.   But this is what software is. It can do amazing things, and it's also everywhere but still invisible, until it breaks. Concrete doesn't break. Well, sometimes it does. Screws aren't supposed to break. Roads aren't supposed to break. Infrastructure is thought of as being made of physical things, something you can actually rest a coffee cup on. But this new layer of infrastructure is ephemeral. And it's not just "the internet" - it's *all software*. It's anything the network touches, and most software is on a network now. It is this bizarre situation where you are as likely to have your credit card information compromised if you use it at a big-box US retailer as you are if you use it online. Because: software. 
[1] The New Aesthetic - entry permalink
[2] Miss a Payment? Good Luck Moving That Car - New York Times Dealbook
[3] CVE-2014-6271: remote code execution through bash
 
2.0 The New Slang
So I'm playing around with ello.co[1], the startup that's taken $435k in funding[2] to build a non-advertising-funded "you are not the product" social network. 

It's really hard to use, and apparently I'm not the only one who finds it that way. It's opaque and cool and I'm not entirely sure that this is a conscious design choice: in that I'm not convinced that it's been intentionally designed this way to keep the olds out. 

There's a lot to be skeptical about with ello. After having spent three years in manifesto-land, ello's manifesto[3] sets off alarm bells for me because there are a bunch of things that they're saying that either aren't true, or feel like overreaching. Certainly there are things in there that resonate with people ("You are not a product"), but the way that they're acting in communications ("In the meantime, please help us spread the word") doesn't address the fact that there's labour to be profited from. And again, the now conversion-and-engagement-driven pattern of not including content in notification emails to increase click-through for site retention means that those emails saying someone has replied to your post don't actually include the reply to your post: requiring you to go back to the site. 

Completely separate to whether ello is going to work or not is the idea above that it's intentionally designed in a difficult to use way purely to define it as a separate space, much like the way that teens like to invent new language so that they can erect some sort of language boundary. The idea that there's an evolution from language to products/services with which to create safer/more private spaces is super interesting and feels like something that we're potentially seeing more of, if not just in name with things like archiveofourown.  

[1] ello.co 
[2] Andy Baio on ello
[3] ello.co - Manifesto

--

OK. Brain fried. Back to Portland tomorrow. 11:08pm. 

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Nine: Thinking In Public; Writing In Public
Date: September 25, 2014 at 1:33:53 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i5i5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
10:03am just after the beginning of Frances Berriman's talk about the Government Digital Service Design Principles at the Code for America Summit, thinking about what makes sense to be used in a different country, but trying to achieve the same end-user aims.
 
1.0 Thinking in Public

A bunch of people outside the screen and inside it have asked me what, exactly, I'll be doing as a Content Director at Code for America. So in an effort to start doing my job before I actually start on Monday, here's me trying to do the hard work to describe it simply. 

This is what Code for America believes: we believe that good government in the 21st century is inseparable from digital services. That we can not only save money in providing government services to citizens, but also provide better services. That this transition to digital services is an opportunity to rebuild trust in government, too. 

America, though, is really big. So every time we succeed in building better government (working through fellowships, directly with government or with companies), designing and launching new services, we need to make those services, and the processes involved in designing and launching those services, repeatable. 

That doesn't just mean making the code available on github. 

It means documenting the process. It means, just like the way the Patent Office requires you to submit a filing so that when your monopoly runs out, anyone can implement your invention, we must do the same thing. 

So, this is the working, internal description of my job that I have: making everything that Code for America learns, across everything that it does, as accessible, understandable, and as easy to repeat, as possible. 

That's how I and my team will be helping to show that government can work for the people, by the people, in the 21st century. 
 
2.0 Writing in Public
When I started writing this newsletter, I didn't really have any aims for it other than to try to start a habit or a practice of writing every day. I think I like writing. That's not to say that some days it feels like a chore, but more often than not, I feel better after having done it. 169 episodes in, this is a rough list of what I've gotten out of it:

 - It's both a practice and practice. Sometimes the writing doesn't take very long. Sometimes it takes a while. But I like having the discipline. It's taken me a good thirty-four odd years (and the first ten or so of those didn't really count) to realise that I do most of my thinking verbally. Writing is a substitute to just sitting in silence, trying to think.  
 
 - It's a way for figuring out what I'm interested in and what I might want to do. I started the year knowing that I was unhappy at Wieden and that things weren't quite working out. And in all the times that I had tried to interrogate "what it is that I want to do", I hadn't had much success. So perhaps I needed to come at it from another direction, and almost surprise it. Writing about what I found interesting seemed to work, and now I have a body of one hundred and sixty nine stream-of-consciousness type artifacts that allow me to interrogate my own thinking. It almost, I suppose, like flying and learning how to miss hitting the ground. 
 
 - It's a way for people to understand me, and how my brain works. This isn't an attribute of newsletters, more of an attribute of how I choose to write mine. Most of the productive conversations and interviews that I've had since the Great Laying Off have been purely as a result of this newsletter. I'll try and explain it this way: because I'm doing this unedited, it's a way for people to find out how my brain works and how I think through concepts and ideas. It's a pretty good way of getting to know me, without actually having to spend time with me (unless, of course, you count spending the time of reading a thousand-odd words every day as time spent getting to know me). But, unless I'm lying (and I don't think I am), the stuff that I'm writing here is pretty much the truth. Or *a* truth, at least. This is how I think. If you're interested in how I think, or if you think how I think might be applicable to what you do, then it's much easier to reach out. It is not a coincidence that I found myself on the receiving end of an email from Code for America because of what I had written about GDS. 

That said, I've also learned, painfully, about the downsides. I used to take it as a strength - or at least, assumed that it was *good* that I wrote this unvarnished and unedited. But it so happens that writing that way also exposes hidden biases and ways in which I view and deal with the world that don't reflect how I *consciously* want to view and deal with the world. And, like Justin Hall explained at XOXO a week or so ago, I've had to re-examine the rather naive idea that anyone who interacts with me is fair game for this newsletter. That, I've learned, was a manifest lesson in consent, power and privilege, and not one that was pleasant to learn. 

Net, net, though, I still think this has been a good thing. It's helped me become more aware of myself, and it's helped expose me to a whole bunch of interesting people. It has, in the best way that the internet has always done, connected me with people. This isn't an inherent benefit of the medium: it's a result of the way I've chosen to use it, I believe. 

And even still, now, I don't think I'd go back to blogging. This works for me. 

--

11:31pm. I shied away from Code for America Summit Ignite Talks tonight, my brain stuffed full, like some sort of super-saturated solution or sponge that's at carrying capacity, and any extra stimulation just wouldn't help all the background processing that needs to get done. Still a little bit of simmering rage and resentment at having to spend more than zero time today on basic sysadmin to fix my phone after the botched iOS 8.01 over-the-air upgrade. And whilst forgetting to go to a friend's leaving party, accidentally ending up at the same leaving party, and being able to see a whole bunch of other super close friends. 

And I got scared. And then less scared. And had some really great tacos. And it's not even Taco Tuesday. 

Send notes, as ever.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Eight: Continued Careening
Date: September 24, 2014 at 2:33:30 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i4h1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

Sat next to Frances Berriman at the Code for America Summit ("Wow, I'm seeing the magic happen!") on opening day, and already feeling pretty good about the next section. An early morning: a 4:30am wakeup for a 7:25am flight (you can tell I'm paranoid about arriving in time at the airport) that ended up being delayed until 8:25am, because I know you're totally into the logistics involved in transporting my meat/water hybrid body a few hundred miles south a bit. 
 
1.0 Continued Careening
I briefly alluded to this a few episodes ago, but it looks like the cat is out of the bag now, at least it is if you're the kind of person who's, I don't know, some sort of completist and enjoys stalking me on multiple platforms. I'm making no assumptions, so here's the bit where I write about career number four.  

Since the Great Laying Off in May, I've been doing a bunch of freelance consulting that's been very interesting, but it's been the kind of lucrative interesting as opposed to intrinsically interesting. At the same time, it's been increasingly clear to me as I've looked at what I've written about that there are some things I care quite a lot about now: I obviously incredibly admire the work that friends and strangers have done, and continue to do at the UK's Government Digital Service. And I've written about a peculiar sense of public duty, and about missing the particular phase of the UK's web history that resulted in going through the BBC as a sort of rite of passage. There were definitely two things that stood out to me as a result of all of this forced daily habitual introspection: healthcare and government. And not even, necessarily, "Government", just the fact that things can and should be better. That if someone tells me that something like a quarter of residents enrolled in food stamps in San Francisco get de-enrolled due to administrative overhead, that this happens to people who have specifically been identified through voter-enabled legislation and deemed to have been deserving of assistance - this is a Bad Thing that should be fixed. And the chance to do so with technology and people and cultural change to build a better world, and to leave it in a better place than I found it, is super compelling.  

I would be lying if I said I wasn't terrified as well as excited. At dinner tonight with some of my new colleagues and partners, I did kind of introduce myself as being the (willing) victim of a particularly well-executed conspiracy. 

So: what does a Content Director do for Code for America? The discussions that I've been having around the role involve as much strategy as they do actual curation and development of content. I think the organisation has a window right now to be very specific, and to act as a standard bearer in terms of what we believe should be the *minimum standard* of government in the 21st century. That we (we!) can be an exemplar of what government can be like when it uses the best tools for the job it's responsible for doing and when it focusses on serving those from whom its power derives. 

And boy does Code for America have a big job. After living here for three and a half years, I'm still amazed by how *big* America is. Jen Pahlka, my new executive director, was recounting an anecdote about how America has on the order of around sixty *thousand* independent, distinct police jurisdictions, compared to the around sixty thousand total police *officers* that Canada has. America, as Douglas Adams would say, is *big*. And unique in that it believes in - and carries out - ideological devolution of power to the lowest local level. The job of bringing up *all* of America's local governance up to a standard worthy of existence in the 21st century is a giant one, and they currently do this work through three different areas: by working with companies through an incubator/accelerator program, by working with governments through fellowship programs, and by working with citizens through volunteer brigades. But it's a mammoth job, and we're impatient people. So part of my remit as Content Director is to make what the organisation does replicable. When a government or partnership creates a better way of enrolling children into K12 education or develops a better, more humane way to deliver food stamp assistance, how do we help that knowledge spread as far and wide as possible and in a replicable, repeatable way? 

Such meaty problems with such delicious ingredients. People. Organisational change. Communication. Being in the gaps. Bridging technologists with strategists and policy specialists. Spreading the knowledge of how to do proper user-centered research. Learning how to communicate in more humane, accessible and understandable ways. 

And at the same time, even though I'm British, a deep-seated belief that America wants to be good. During my interview process I'd talk about being taken by my then-girlfriend and now wife and mother to our son to the Jefferson memorial in Washington, DC where she was living at the time when we first started our trans-atlantic relationship. America got a shit-tonne of stuff *right*. And they're really, really good at the propaganda and branding. Believing that all people are equal? Check. That power derives from the people? Check. Sure, there's a whole lot that might have gotten wrong along the way. But I believe that the founding principles of this country were sound and admirable. And I want to help them be good, not least of which because my son's an American until I get around to filling in the paperwork for his British citizenship. 

And I'm scared, not least of which because I look at people like Tom Loosemore and Ben Terrett and Russell Davies and Roo Reynolds and Leisa Reichelt and numerous others at GDS who I haven't even met and they're all *so good* at what they do. People who've done, as they say, the hard work of making things simple. 

But then I remember that the team at Code for America is great, too. That I'm not on my own, and that I'm going to be working with a bunch of smart, passionate people who believe in what they do and have the tenacity to pull it off, too. And that whilst Code for America doesn't have the unique primordial soup starting conditions as GDS did, it does have a bottom up mandate it's claimed for itself in government for the people, by the people. 

So: terrified. Excited. Energised. 

--

12:31am. And it's an 8am start tomorrow. As ever, send notes: I appreciate and read them all, and try to reply to as many as I can. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Seven: How Are You?; Built It And They Will...; In The Gaps
Date: September 22, 2014 at 11:56:12 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i39l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

10:12am on a Monday after what was frankly one of the weirdest things yesterday at the Oregon Renaissance Festival, that distinctly American tradition of dressing up and pretending that you haven't died of the lurgy yet. But anyway: right now, a cool, cloudy morning, sat in Ristretto Roasters nursing an irresponsibly large mocha. 
 
1.0 How Are You?
A new thing that many people in 2014 are experiencing, I think: the idea of knowing someone from afar without ever having heard their voice, without having seen them in the flesh, without breathing the same air as them or awkwardly laughing at the same ice-breaking joke. I wrote about this last in episode one hundred and sixty one, that feeling of a new negotiated dance where you're not quite sure that there are missteps, but there are certainly faux pas. Or maybe not? 

It's pretty easy to think that you know me. I have a personality that is sliced and presented across multiple media, and there are some things that I elect not to control in terms of privacy. I have a public Twitter account, a public Instagram account and I can't remember if my Foursquare, er, Swarm account is public or not. Sometimes my posts on Facebook are public. My profile on LinkedIn is public so as to, as the saying goes, "increase my surface area", to make it easy as possible for you to figure out who it is that I am. And, of course, I write in this newsletter. 

So the dance is this: it's the social interaction and the give and take and the ums and the ahs and the micro facial expressions and the probing and the slinking back to establish some shared sort of understanding without actually come-on-out-with-it. It's the: do I reference the fact that I know what you just said on Twitter? Do we both acknowledge that we know, kind of, that we stalked each other, if stalking is a thing? Do you say that you know that I fell off my porch and broke a tooth and suggest that perhaps we go somewhere that has nice soup today? Do I say that I'm sorry that your partner is sick? 

Or, maybe now, a slightly more tentative form of: well, I'll just expect that you know this now, and you'll expect that I know too - at least, maybe not everything, then maybe most things, and if not, then we can negotiate around that instead. 

Because how do you say "So, how are you?" when you have in your pocket a minicomputer that can access - for the right person - a stream of the minutiae of their thoughts, or at least, the ones that they wish to fire off into the ether? And how do you deal with it if you're *good at remembering*, because that's indistinguishable from *being super creepy*, right? The difference between having an ambient knowledge of someone so you can get to know them and say "So, what did you think of The Winter Soldier?" because you know they saw it a few days ago and liked it? Is that creepy? Or is that helping? Is that better than saying: "Seen any good movies lately?" because you want them to say "Why yes, just the other day I saw The Winter Soldier".

It's a dance, and there's new music. 
 
2.0 Build It And They Will...
Tom Loosemore was looking for things to talk about at the Code for America summit this week[1], and one of the inspired and quippy replies was the notion that if you build user-centrically, they will come[2].

We (I say we, I mean the general grouping of people-who-make-things-on-the-internet) kind of knew this for a while in that the general refrain to the other kind of people who wanted to make stuff on the internet was that they failed to realise *how* people would get to those things that were made. And so it was that we replied, invariably, with "build things where the people are", which on reflection was only marginally better than "build things where the people aren't," which had been the default position. 

The thing about building user-centrically is that to build centrically in the first place, you need to understand the user enough to know the centric bit. You don't get to have a dream about building a baseball field in the middle of nowhere and hoping that some sportsball team will turn up. Instead, you have to, I don't know, perform a whole bunch of user research to work out that there's a genuine user need for baseball amenities in Iowa. 

I mean sure, we end the film seeing that there's enough user demand for at least ONE game of baseball in a field in Iowa, but hey, Iowa's pretty big and did you do research on the population density lately? And they all drove there by car! That's not sustainable!

Anyway: there's a couple things going on here. One of them is nicely summed up in a pithy phrase coined by the wonderful John V Willshire[3], who says "Make Things People Want > Make People Want Things"[4], which is the kind of insightful thing that someone says after having spent a good amount of time in advertising and media. We end up with *better things* when we make things that people want, rather than spending time on making people want things that already happen to exist. It's not that making people want things is necessarily bad (well, maybe it is after I just typed that out), but more that for a certain group of people who *used* to have to work in advertising and communications, the problem of making things that people want is more interesting than making people want things. 

There's probably a whole bunch of uncomfortable people thinking that if you throw away the whole Field of Dreams thing then we'll never get any new stuff and it's just a slippery slope step away from quantifying how people click on different shades of blue. But I don't think that's right: I think we still get to have new things, it's just that we test them as we go along. It's not like this kills off the potential for epiphany or to have some sort of intuition - it just means that we test the ideas that we have, and if they don't work - after we've given them enough time, of course - then we move on. 

[1] Looking for input into my Code For America keynote for tmrw - @tomskitomski
[2] Build user-centrically and they will come. - @JohnDodds
[3] John V Willshire
[4] Smithery.co
 
3.0 In The Gaps

So the recent stream of consciousness on awkwardly specialised connectors seems to have found a sort of resonance with people - at least, enough of you out there have replied or tweeted saying "this is me!" that it feels like I'm on to something. Or that I could embark on a fifth career writing horoscopes for people who use the internet ("You will feel a vague unease throughout the day, as if you are missing out on something").

It definitely feels like there's something in the connectory-ness, and also something in the innumerable soft skills many people have that provide broad understanding but not deep specialism. And at the same time, the fact that there are a bunch of people who certainly *know a little about a lot*, and can certainly have valid and useful opinions about things (ie, "directing") but that, when it comes down to it, can't actually *do* some of the things involved in a particular specialism because they don't understand or are able to use the particular tools. 

I suppose one other role or title that might make sense to look at is that of the architect: someone who has a sense of all the plans and how the things might fit together and the overall point of the thing, but doesn't necessarily know what sort of timber to use where, or whether you can get the right kind of concrete. But, they may well know what properties that concrete should exhibit. 

Part of this also feels like gappyness. Like, the problem with all of these specialisms is that you then don't have a specialism for "everything that's left over", and someone is invariably left unofficially holding the bag. It sometimes appears like this on the outside when peering over the GDS fence, where it's ostensibly *everyone's* duty to care about the user experience, because otherwise, what are you doing in public service? In non-GDS organisations, where "ops" doesn't understand that it's not just about keeping the servers running, that user experience includes making things work *quickly* as well as reliably, whose responsibility is it that the site or experience loads quickly enough? Certainly there's a threshold at which someone, at some high managerial or executive level declares that the site is "too slow" but other than that, who's counting, who's keeping track? Or who's making sure that, apart from just moving bits of paper around, that everyone involved knows what they're making? It's a difficult job, to be in the gap, because organisations appear to be designed to not have gaps: they're designed to have Perfect Communication, to exist in some kind of ethereal plane where people don't like to have meetings because they don't have to and five years ago, you didn't have to *tell* people things or make sure that they understood them, because Basecamp existed and Basecamp Solved Everything. Or because you had a Trello and that Solved Everything too.

It's perhaps a symptom of the kind of people who are excited about the *potential* of technology who aren't necessarily also best suited to operationalise it. I was talking about this with friends in the days after XOXO, where when we were talking about Ed Catmull's Creativity, Inc. book, it sounded like he was operationalising continuous improvement and self-reflection in the organisation, *as well* as being a CEO - or, rather, that that was his *job* as a CEO. Operationalising it means - to quote another GDS catchphrase "doing the hard work to make it easy" - which I interpret to mean as much about building the right kind of teams that can build the right kind of things. This then ends up being less about technology and, after having pulled on the thread for long enough, just being about What Happens When People Get Together To Do Things. Communication, miscommunication, understanding and misunderstanding. Are we all doing the same thing? Do you know why I'm doing what I'm doing? Do I know enough about what you're doing? What is it, in the end, that we're trying to achieve?

--

Right. I'm down in San Francisco tomorrow for the Code for America Summit - three days of being the brain sponge that I want to be in the world and learning everything I can get my hands on about civic technology and Doing Government Better. 

As ever, send me notes because I love reading them, and also, a question this time: now that Apple are bringing down the inevitable axe on Aperture, should I just buy Lightroom outright, or should I now account for my monthly Adobe tithe?

Best,

Dan

 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Six: Unicorns; Six Minus
Date: September 20, 2014 at 12:46:20 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-i12t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

10:15pm. Tired. Assaulted by a woman and a man with sufficiently sharp and metallic equipment to be indistinguishable from a dentist's office. TILT: I really, really don't like visiting the dentist, but on the plus side, I have a new front tooth. On the down side, these people are threatening me with root canals in the future (thanks, fall off the back porch), and I can't today read the wikipedia entry on endodontic therapy[1] without hyperventilating. Part of this, I suspect, is (pretty facetiously) branding: who wants to have a root canal on a tooth? That sounds like it's going to hurt. 

[1] Endodontic Therapy (root canal)
 
1.0 Unicorns

Okay, so I seem to have hit a nerve with the last few episodes with sections about the internet-life-crisis. My new working definition is: anyone who's spent more than ten years "working" making stuff-on-the-internet because apparently some of you lot are not only young but also irritatingly talented. 

Anyway. If I'm pulling on this thread just a little bit more it's that quite a lot of the work on the "internet" over the past few years has been people variously figuring out what it's *for*. And if you're the kind of person who can see the potential of it, and knows that to do a good job you kind of need to pull together people who traditionally don't work together (or if they do, only grudgingly), then you've got a recipe for a potential New Kind Of Person. 

Of course, there's your traditional product people at product companies - but that requires you to have had lots of Product Experience, explicitly building products. I suspect that there's a whole bunch of people who have the *competencies and skills* required of product managers, but have never had a title or position that has reflected such job responsibilities. In other words: a whole bunch of people who've been "interactive" and have nominally held the title of something like a Web Designer or Director of Something Unrelated or Producer, or whatever. But in essence, what that job has involved has been holding the entire thing in their head, having the right relationships with the right people (and the relational and political clout to get what they need in order to succeed, or to explain why they need what they need) and that actually, in theory, aren't *supposed* to be doing those things. But if you did the usual sort of communications graph analysis of that organisation you'd be asking: why does that person talk to so many people? 

Inadvertent Product Mangers or Inadvertent Service Designers are exactly the kind of people who are connectors, and fulfill a unique role in large organisations that have overly relied upon specialisation. This breaks down a bit when you're talking about small teams because perhaps one of the things that an Inadvertent Connector can do is exercise a lot of soft power and soft management. The good ones are trusted and respected, and can quite easily *ask* people to do things instead of *tell* people to do things and still get results - or even, better results. In smaller teams they're not as needed - and this is the type of stuff that Michael Lopp talks about quite a bit in his Rands engineer management persona[1] - because you don't have the communication overhead. Or, rather, you don't have as much risk of lack of communication or lack of clarity in communication happening. In big teams, where people aren't dedicated resources and they might be working on three, five or a million things, having someone whose job it is - whether on purpose or not - who can keep everything in track and co-ordinate who's doing what and crucially understands *why*, becomes incredibly important.

In the film industry, we pretty much call those people Directors. They're the ones with the vision, but they absolutely can't do what they *want* to do, they can't bring that vision to life without the input and assistance of a team of hundreds if not thousands. Sure, authority and responsibility cascade and delegate down, but the thing about directorial vision is that it *directs*. 

The problem, of course, is that when the connector disappears, it's not like the organisation ceases to function and collapses. Of course not. But what it does do is operate a lot less efficiently and it does, I think, produce work that's a lot less *good*. But then these are organisations that haven't figured out that what they're kind of doing is making products and services but that they're not prepared to admit it, and they're not prepared to let someone just get on with doing that. It's not valued - perhaps, ultimately, because it's not understood. When someone gets a job as a "webmaster" a few years ago, and tries to do it well, they talk to everyone and try to figure out a way that the website actually reflects what the goals of the organisation are and tries to fulfill them. Why would you need a connector in such a communications oriented role, though, if all you believe a website is, is a way for people to find out about you? 

So yeah, there's another unicorn. Not the designer/developer unicorn, but the product/service unicorn. The person whose job it is to hold all of that together and to keep moving it forward and that people are actually grateful for existing. 

This is also deeply conflicting if not for the orthogonal reason that a lot of these people who find themselves in connector roles also, anecdotally, think of themselves as introverts. From a human resources and organisational point of view, they make *no sense at all*. They don't want to talk to people, they want to hide in offices, but apparently they're also hugely influential and important in getting things done that are adjacent to their actual roles. 

There's something that I used to notice in the different kinds of project manager you'd get. Out of the set of all people who did "project management", you'd get a whole bunch of people who thought that the job was in effect to move bits of paper from one place to another place, and possibly get those bits of paper squiggled on by a pen. There wasn't any pro-active thought there, and it's telling that in agency land, that era of project management was called Traffic. The art of co-ordinating flow and making sure that things kept moving. It's not like this is different in the world of the cyber, but I think it's fair to say that for whatever reason we are *still* in the early days of learning how to build stuff for the web, or that more accurately, organisations in aggregate are still in the early days of learning how to build for the the web. Sure, there are a whole bunch of people who know how to do it, but only until you get enough of them together and give them enough rope to create a rope-based Apollo project do they really get to shine. Otherwise, they're just publishing, well, websites. The good project managers or producers - at least in my eyes - would be the ones who knew enough to know what might be a problem and were pro-active about it. But again, production or project management is in some ways an executionary role: find out what the director wants to do, and figure out a way to do it. And it's always best if it's a productive dialogue, right, otherwise you end up with the reputation of being the producer or project manager who always says no and never seems to want to do anything awesome, like autonomous drones that deliver QR codes to brand managers in Australia. A good project manager in that sense would be described as a *problem solver*, which is still very much so on the executionary end. The director or connector is the one who works out: okay, this is what we're going to do, and this is how I'm going to make sure everyone understands what, why, and what each individual's role is. 

And no, we don't really have a title for that role, I don't think. Not in the majority of organisations. 

[1] Rands in Repose
 
2.0 Six Minus

Five minutes with the new iPhone, the Minus version, and already it's as if the top-left corner of my screen doesn't exist. And already, massive frustration at Verizon for not figuring out how to activate my service. Because hey, that would be useful. 

--

10:43pm. It's the weekend, and I'm tired and my mouth hurts. Go have fun over the next two days if you can, and I'll see you on Monday.

Oh, and some administrivia: I'll be lurking in the background at next week's Code for America Summit[1] next week in San Francisco because apparently if you write for long enough about stuff like the Government Digital Service people ask you to justify your reckons. If you'd like to say hi and grab a non-alcoholic drink that's either a Diet Coke or a coffee - for me, you can have whatever you want - then drop me a line.

Best,

Dan

[1] Code for America Summit 2014

 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Five: They Don't Owe You Anything; Awkwardly Specialised
Date: September 19, 2014 at 2:45:40 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hzy1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep
I am covered in insect bites. Please send antihistamines. 
 
1.0 They Don't Owe You Anything
The culmination of over ten years worth of conversations about institutions and desperately, impatiently wanting them to grasp the potential of the future, to prepare for it and to lead and instead growing up and having a major shift in perspective.

The British Broadcasting Corporation (the astute among you will note that I've decided to spell out the organisation's name as opposed to use its more popular acronym) occupies a peculiar part of the British psyche. For those who are public service minded, the Reithian ideals of Inform, Educate and Entertain were pretty much a defining mission statement of the potential and power of the internet in the mid to late 90s, never mind the early 2000s. A two-way communication network, open to all, with the potential to connect everyone. What better way to Inform, Educate and Entertain? 

But of course it turns out that the BBC is, at 92 years old, only eight years off its centenary. And it turns out that the middle B, the Broadcasting, is pretty central to what it does, regardless of the remarkably forward thinking media-agnostic vision statement. 

Institutions are built to do what the institution does, whether explicitly or implicitly. It's hard to fault them for not doing that, it's pretty much what their job is. Sometimes it's easy to confuse job-with-method-of-doing-job - and from that we can pretty much draw a straight line to "the job of moving people around" to the fuzzy concept of "the job of protecting the way that we move people around", irrespective of whether you agree on Travis Kalanick's definitions of who gets to be the more-righteous mafia.

The realisation for me was back in the Six to Start days when we were working with Channel 4 to produce the online, interactive component for the show Misfits[1]. I remember being excited about the chance to work on the show - Howard Overman, the showrunner, had come up with a super-interesting premise: orange-jumpsuited teen ASBOs with super-powers. At the time, one of the things I was focussed on was the potential for the internet to bring a new kind of storytelling to people, and the chance to work with interesting and unique properties that also looked like that they were going to be successful was pretty heady. The thing was, despite *feeling* like we were the good guys - ie, we weren't coming in like Digital Prophets and telling everyone they had to work with us and that they didn't understand what they were doing and were doing it wrong anyway, it was perplexing, irritating and downright *frustrating* that it felt like we didn't get as much access or interest from the production company. Of course, that made complete sense: Overman's goal was to make a television show, not some narrative that would span multiple media and pull people in to a fictional world. He'd probably spent his whole life trying to get to the point where he'd be able to run his own show. And then here were a bunch of people trying to *distract* him from that. Of course he wouldn't want to pay attention to us. 

These institutions - organisations, businesses, the ones that have got their thing down, the ones that are just motoring away and *doing their stuff* don't owe us anything. It felt different, ten, fifteen, twenty years ago when we were touching the internet and we could *see* the potential inherent in it, and we just wanted to get on with it. With the BBC, in the case of that particular institution it felt like we also had a duty to help it blaze a trail, to be an exemplar, to show the way where there was market failure. 

Of course, there isn't *that* much market failure now. Now, BBC News Online looks to The Guardian and the New York Times and The Atlantic and Buzzfeed and Reddit and 4chan and any number of online news outlets, or outlets that happen to provide news-like services, but otherwise look like single-bit communication channels, or look like social networks that just happen to carry "things that happen". 

This shift in thinking is, I think, the result of some personal impatience and looking at the last ten years or so and asking the question: can I achieve more inside a large organisation, or outside a large organisation? Both of course have their advantages and disadvantages. In theory, large organisations are able to marshall resources and whole teams, have budget and go forth and Do Things. But we know that they're slow and that the *in theory* part only really becomes an *in-practice* part when just the right variables line up - executive remits, political cover, shit-shielding umbrellas - all of those things need to line up to enable a team to do good work that shows a way forward. 

I started to feel like the large organisation was a cheat. A short-cut. For the impatient, a Faster Way of doing things. And they'd sell you that they wanted to do things a faster way, too: why wouldn't they want to be innovative? But of course there's a difference between *wanting* to be innovative and actually delivering on that innovation. And ultimately, it feels like no one can make and enforce that decision other than the executive leadership. Frequently, that leadership has other things on its mind. 

It all feels a bit tilting at windmills, then. All a bit Innovator's Dilemma. We know all the catch-phrases about how things are easier on the outside than the inside, how the grass is greener and so on. But institutions - *especially the majority of the ones we currently have* aren't built to change quickly. They're just not. 

The counterpart is when you look at institutions that are, in some ways, responsive. Everyone likes to point to Toyota's TQM and the "anyone can stop the assembly line" concept, but the detail is so often in the execution. It doesn't matter if anyone can stop the assembly line if the only people who can proffer and effect solutions so that the problem doesn't happen again are only middle or upper management. That's not empowering people to fix things and to be masters of their own domain. 

But then you look at companies like Walmart and Amazon *and* Toyota together and consider them a bit like this: those successful companies do do one thing, and it's continuous improvement. There's something that's measurable - in Walmart and Amazon's case it's the bottom line, in Toyota's I suspect it's productivity and quality, but it feels like you get that relentless optimisation that is bound to help an institution at least *move* instead of ossify. There's the concern, as ever, that your optimisation is in some way some sort of local maxima, and that what you're actually doing with that relentless optimisation is Delling your way out of existence, teaching an entire country what your supply chain does and how to out-race you to the bottom of the market. You have to be sure that you're optimising the right thing. But measuring and altering and then measuring again: that's the mark of an institution that keeps moving. The question that needs to be asked is a broader one, though: are we doing the job we're supposed to be doing, the best way that we can do it? 

It feels like this: these institutions are performing a valuable role. But they're doing what they were originally designed to do, and they were not necessarily originally designed to constantly adapt. That's a *different* kind of institution, that requires a distinct kind of leadership that's hard to import or grow in an institution that doesn't otherwise support it or even need it. We who can see the future and desperately want to help them change? We may well just get frustrated at the pace, and may well find better success by showing them outside their institutions than inside them. They don't owe us anything, but they can pay attention to us. 

[1] Misfits - Wikipedia
 
2.0 Awkwardly Specialised

One thing that I've noticed is a sort of awkward specialisation for a bunch of people in their thirties who've grown up with the internet and worked in the industry. It seems like there's not that great a title for people who've "done internet stuff" but who weren't firmly in one camp or another. In other words, the mythical Design/Developer unicorn. Instead, there's a whole bunch of people who sit firmly in that Venn diagram intersection who are *very good* at getting along with designers and developers, and are able to bridge that gap, and yet precisely because they *don't* fit into one camp or the other are eminently unemployable. Because you'd much rather hire a unicorn, a designer/developer, than a translator, right? 

Here is the thing about those people in the middle. Those people in the middle see systems and like to solve problems. They still see the power of the internet in helping to solve those problems, and to make things better. But they're not specialists. They're not designers and they're not writers, they're not developers and they're not ops or sysadmins. Perhaps one way of looking at them is saying that they're Product Managers (but not Project Managers). But they're the people who help figure out what it is that you want to do, and help you do it. Regardless of the *title*, there's still a need for the people who can keep it all in their head. Who understand enough about all the little bits - but who might not be able to implement them - that they have respect and trust to lead. Maybe that's a thing.

--

12:44 am. Tired. Notes welcome, as ever.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Four: Not Every Node Is Equal; Stop Hitting Yourself
Date: September 18, 2014 at 2:36:33 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hywl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

11:49pm. A trip out to the coast, the cold, cold pacific underneath your feet, wife and son out camping. An irritatingly only 80-odd percent complete Fez blinking away in front. 
 
1.0 Not Every Node Is Equal

I am still, obviously, thinking about XOXO, the conference put on by the Andys. Tim Maly (hi, Tim!) wrote an excellent piece today called What We Talk About When We Talk About What We Talk About When We Talk About Making[1] which you should read. There are a few points that Maly makes, an almost Tetris-like argument that takes principles and then slots together performing some sort of geometrical magic that leaves you reeling a bit at the end. It goes, I think, a bit like this:

Conferences or festivals or conventions for artists or creative people or whatever you want to call them always have a Money Track. It might not be explicit, but it's certainly implicit. It's something we all have to deal with. It's not a tech thing, it's a people-doing-what-they-want-to-do-thing. It's artists and writers at regional comic cons, it's zine festivals, it's music festivals, it's XOXO-style networked culture festivals. 

The rhetoric at the moment is that we're all nodes in a network and that the technology embedded in the network is unlocking our potential to succeed. Not just potential to succeed, but also creating a magnitude more number of *ways* to succeed. Not just one path, but a combinatorial explosion of paths. Maly pulls out Kevin Kelly's example of the superpower nature of technology in being a force-multiplier for the individual in the Cool Tools/Whole Earth Catalogue, where the latter used to take thirty people a month to produce, and now, Cool Tools "only takes two". Maly leaves hanging the question as to why the labour that was internalised and now has been externalised - replaced by an API call or to a posting on a proof-reading service and performed by interchangeable human cogs - why that labour doesn't count anymore. Is it just because you can't see them? Because they're not in the room with you? Technology in becoming a force multiplier has, in some instances, in some implementations, also abstracted away the *people* doing the work, in a bid to make the act of commissioning the work easier. In this way, technology isn't just a force multiplier, it's also something that abstracts away human labour and makes it easier for you to use, utilise and exploit *human resources*, never mind fancy things like scaleable computing resources.

Maly then takes the example of what happened when Golan Levin and Pablo Garcia took a detour into China and showed us the people who were assembling their Neo Lucidas - thousands of units a day, dextrous, fine manipulator and ultimately, human work. Work that Levin nor Garcia could do themselves - not because they weren't capable of it, but because they were *slow*. Because they wouldn't do it for a dollar-fifty a day. The room, as Maly points out, goes silent, because this is the context collapse, this is the reality, this is the veil pulled back and the cognitive dissonance, the uncomfortable truth holding up their name, smiling at the camera for you. These, you realise, are the people who make your stuff. And as Levin points out, pretty much *everything* in the world is hand-made these days and bears the fingerprints of human labour. 

Maly says this:

"This is an era of networked wealth, going to scale, first mover advantage, positive feedback loops, virtuous cycles, high concentration, and high disparity. These are some of the intolerable conditions of the time we call (with subversive hope) Late Capitalism."

In other words, every node is not equal.

Maly goes on: these are wicked networks. They are so stupendously, sublimely complicated that when you pull on the thread, you can't help but keep going. And there is no way, no way for us to really as human beings fully comprehend these networks now, they are so, so very complicated. And these networks, they are the liminal space between the good intentions and the terrible injustices inflicted upon the world and upon our selves and others. 

I do not agree - but obviously do not speak for the Andys - when Maly says he thinks the focus of XOXO is "people who make things" because then you have to get into an argument (and, as Maly points out, rightly so) about the semantics and meaning behind "make" and "things". Independent creators is one thing. Myself, I'm fond of the networkiness of what XOXO focusses on. People involved in Network Culture are everyone from the Kevin Kellys and should also include the people working at, or running, or leading crowdsourced proofreading platforms for cents or dollars. Or original device manufacturers like PCH. 

Maly is arguing in favour of recognising context collapse when it's happening and staring it down and doing the difficult, yet uncomfortable work. His point about Chinese Workers being unwelcome at XOXO is uncomfortable and doesn't let anyone feel good about what they're doing. Marketers, brand managers and agencies - apart from the one that is a patron - are again, clearly unwelcome if only in a matter of tone. 

Of course, is this - some sort of realisation and tackling of the realpolitik of the messy production end -  the job of a conference/festival that's celebrating independent, networked culture work? 

Maybe, maybe not. 

But there are a few things that I'd like to see if the Andys do do another XOXO, that I feel are still in the spirit of the independent, creator-led tone set by the founders.

Fuck You, Pay Me is the Mike Monteiro expression of this, but there was the regular refrain of Independent Artists Are Worth Paying For. Or, support your artists. Don't do it through gate-keeping middlemen, don't do it through rent seekers, try to form direct relationships where possible. We're all human and in this together, which is why from my point of view it was incredibly valuable and brave of Levin and Garcia to go to China, to visit their factory and actually talk to the people who were producing their independently created work. I do not think that it's in the credo of XOXO, for example, to exploit those who are on the production end. Fuck You, Pay Me, only works if it works all the way down the chain. And there's certainly a discussion and an argument and a whole range of positions to be taken on that issue.  

Secondly: this year, the biggest year that XOXO has been, felt perhaps the most uncomfortable due to its size. One thousand total registrants, seven hundred and fifty conference badge holders, an extra two hundred and fifty festival holders, I think. But across the attendees and the speakers, there was the slight unintentional feeling that the speakers were Friends Of Or Members Of The Andys' Address Books. Which, to be completely fair to them, they did explicitly say: this was a conference full of people they admired that they wanted to see speak, and some of them were and *are* their friends.  I think The Verge had it right when it described the feel of the conference as pretty much exactly like the waxy.org linkblog: in that it was subject to the same biases and interests. All that I'm saying by that is this: is it important for the Andys to include programming that they normally wouldn't see, and if that is important, how will they uncover it? I'm optimistic, because there were tremendous strides in terms of gender diversity this year compared to last year, so part of what's interesting for me is the chance to see more people speak who are *just* making it, and might never get the kind of attention that those who arguably *have* made it. And at the same time, I do wonder if at least the type of people who can afford a $500 ticket and airfare and airbnb or couchsurfing or a hotel to Portland can also afford ticket prices that allow scholarships or bursaries that will let less fortunate people attend. 

A simpler way of saying the above is possibly just this: the Andys have an enviable network and list of contacts, but I'm sure that they can realise that there's a whole lot more in what's *not* in their network than what is. Whilst I'm happy to hear from someone like Leigh Alexander on what it's been like for her over the past ten years building up a freelance writing career and the difficulties she's faced, there are perhaps more interesting stories to be told about Jenn Frank and others like her who are significantly less comfortable. In other words: a look at the mix and ratio of those who've made it, versus those who're starting out. As much of XOXO that has been relevant and successful for me have been the bits where I don't feel alone. That much has been a theme of the conference from the beginning: that the network connects us so we don't have to feel quite so lonely. Because when we're less lonely, we build the courage to do the things that we might not otherwise. It is good to hear that the successful struggle in ways similar to our own individual struggles. But perhaps some perspective from the other end might also be interesting. 

And lastly, this is a personal thing: I love mentoring. I love talking to people. XOXO this year felt big, felt sprawling. I would've loved more structured time to talk to people. There's a wealth of experience at XOXO. Perhaps a third unconference day, allowing people to make their own connections around particular topics or areas of interest might be useful. 

[1] What We Talk About When We Talk About What We Talk About When We Talk About Making - Tim Maly
 
2.0 Stop Hitting Yourself

At dinner with friends tonight, talking about the Inevitable Life Crisis, the one that is diagnosable by two easy questions. First, are you over thirty years old? Second, did you grow up with the internet? Congratulations, you have no idea what it is that you're doing or what you want to do, and you are paralysed with lack of decision and choice. 

Part of the self-diagnosed problem is this: for those of us who *did* grow up with the internet, making things on it and living on it, we kind of did everything ourselves. A jack of all trades, master of none was, at the time, building a frontier in a new space, and if you specialised, well, you weren't able to make a thing that did stuff on the internet. But here we are, a good twenty years later, and it turns out that there are specialities. Maybe? Or maybe the skills forged in being able to keep everything in your head are still good, relevant ones. But they're certainly not ones that companies are looking for. 

Or, perhaps this: those of us working in areas highly affected by technology have chosen to work in areas that are constantly disrupting themselves. If you work with software, your profession is constantly eating itself in a way that no other industry or vocation is, and it's doing it more quickly each iteration. Perhaps, then, the problem isn't to work *with software*, but to pick a domain and to stick with it until it's solved. Done. End of job.

After all, here I am, just a boy, standing in front of a precipice and a fourth career. 

--

12:35am. Notes, as ever, are welcome. Just hit reply to get that new email window and mash away with that keyboard.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Three: What The Network Does; How Do You Solve A Problem Like TED; Not A Career, A Careen
Date: September 16, 2014 at 6:02:05 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hxnd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

3:28pm, inside at home with what The Wirecutter calls The Best Room Fan busy, well, fanning me. It's still hot in Portland, even now that XOXO's finished. The sun is still outside, sleeting down hard UV dispassionately, killing us with warmth. There are two spots on my hand I should probably go see a doctor about. My wife and son are off on a Camping Trip, a big American tradition. Nine mums and their babies! I am here with a laptop, writing, and trying to work out how to finish the remaining 23% I have of Fez, and not playing Destiny (yet).
1.0 What The Network Does

Imagine you are the network. You are nodes and connectors, and some of the nodes make graphs of you. There are laws about you, and some of the numbers embedded within you grow exponentially, some of them more slowly. But there is one true thing about you: you connect things. Things that weren't able to be connected before. Things around corners. Things in the sky. Things underground. Through glass and through sand, through copper and through air. And sometimes those nodes are people. 

You don't care what you connect, all you do, what you only do is connect. So you connect individuals and you collect groups, you connect subnetworks and outernetworks. Darknets and lightnets. And one network that you connect, one that wasn't connected before, is people who play chess.

There didn't used to be that many chess grandmasters. But lately, there's been an explosion. And they keep getting younger. Why is that? Well, to get better at a thing, you have to practice. You need something better than you to try to beat. You need something to outwit. And now, well, there are grandmasters-in-a-box. In a browser. In Javascript. Embodied in silicon and plastic and out in the real world, or displayed in a windowing system. So now: anyone who wants to play a grandmaster level competitor can play one. It's, more or less, trivial to find a grandmaster. You don't even have to travel, if you're lucky. 

And then: you can play anyone else on the network. Would you like to play a game? Anyone. And the network keeps getting bigger, because it doesn't care. You can be a grandmaster at 16, 15, 14, 13, 12 years old now. Keep finding people to play.

And then what?

The best, they play like computers. They don't get annoyed. They don't get upset. The board is a problem set and a solution space and you find the best path. Getting annoyed doesn't help you find the best path. You play so you can beat computers, so you start behaving like one. The best can perform at the extremes: do things in a way that we don't understand, see things in a way that a computer brute-forces its way through.

That's a thing that the network does. It connects.

(Thanks to Greg Borenstein for exploding my brain and being the ignition point for the above).
 
2.0 How Do You Solve A Problem Like TED
There was a thing I noticed about XOXO this year which was that at its best, it was - like I said yesterday - sincere, authentic and vulnerable accounts of what it's like to be a creative person embedded in the network. This meant everything from a recognition that luck plays a big part, no matter how hard you've worked, or how much time you've put in - Darius Kazemi gave a good example of this, showing how bots that he came up with and implemented in four hours would frequently be more "successful" in terms of followers and recognition than ones that took forty hours to implement. Though he might *like* the ones that were harder more. Recognition, we understand, is a fickle thing. 

But it also meant hearing from people who - from the outside, when you see their surface, and not their interior - look *incredibly* successful. You know the saying: you judge people on their outsides and yourself on your insides. So it felt like even whilst there were people who were literally saying "this is difficult, and hopefully I don't have to tap into my savings this year, and the only reason why I can travel so much is because I airbnb out my apartment and I stay on peoples' couches when I travel" they *felt* successful.

I think there's a Kahneman-style System 1 vs System 2 thing going on here: that when we see someone who's good at public speaking, who can tell an engaging story and retain our attention, who entertains us and looks like they're enjoying we think: gosh, that person's *successful* and they must really, really have their shit together. This, despite the fact that if you listen to the words coming out of their mouths, they're trying to tell you that they desperately *don't* and that this stuff is just *happening*. We are pattern recognisers, and the physical morphology of a successful person on-stage at a conference doing a presentation or talk is a powerful thing, I think: it hacks into some sort of brain-stem system and bypasses whatever conscious understanding we have of their verbal communication. 

I say this because one of the persistent valuable lessons of XOXO has been people talking about the *reality* of their situation. Joseph Fink would talk about Welcome to Nightvale and describe it as "a bunch of people who did a podcast" and that it is now "a bunch of people who do a podcast". The sheer number of underpants-gnomes-profit references underscores that most people have no idea *why* something has happened, but what XOXO brings is what it *feels like* to grapple with those things and *how* to grapple with those things when they happen. XOXO has never been about a Get Rich Quick, Follow These Ten Tips To Become Successful thing. It's been about what the human experience and endeavour of creating and failing and succeeding and failing and endlessly repeating and the terror and elation and highs and lows of that are. That's why it resonates with me. 

So I wonder if the conventional three/ten/fifteen/twenty minute talk is a good way - or, for that matter, even the only way - in which to communicate that kind of understanding. I really, really enjoy one-on-one mentoring sessions because they're *not* a performance. A successful performance doesn't mean a successful person - it just means a successful performance. Sometimes it's hard to remember that. 
 
3.0 Not A Career, A Careen
I wrote yesterday that it feels like I don't have a career, I have a careen. The trajectory of my life so far has been less about a carefully described Newtonian arc in some sort of Standard Model of Life Experience and instead feels like a virtual particle in a quantum vacuum with some additional Brownian motion thrown in. In other words: shit happens. 

I would get asked by people sometimes: do you have any advice about getting into an agency like Wieden+Kennedy? And I would say: well, I don't really think what I did was replicable. I mean sure, you can go study law at a good school and then qualify and then do a master's in Software Engineering and then do a couple of startups and get noticed and win some awards, but if I'm honest most of the *other* people in that agency went to Advertising School. 

And I don't necessarily think it was something as facile as "making your own luck", but there's possibly one thing that I'd point to which is: I like talking to people. And I know a bunch of people in a bunch of different areas, and I'm interested in what they do, and I try to know about what they do. If things work out right, I'm about to embark on what by some accounts might be a fourth career. The first was trying out being a lawyer (interesting, but ultimately boring when it came down to the nuts and bolts of it), the second one was in startups (learned a lot, probably will want to start a new business again at some point, but not the right time for my family), the third in advertising (it ended up being advertising, which I'm interested in but don't want to make) and the fourth... well, we'll see. 

I can't point to a common thread through any of those things other than this bundle of water and meat that's me. Any reasonable person - any *typical person* would say: well, couldn't you just pick one thing and stick to it? Couldn't you just get better at that? 

The thing is, though, is that's what the network did to me. The network put all this stuff in front of me and said: connect here. Click here. Join this to that bit. Make a new connection. Fulfill your part of Metcalfe's Law. Only at the beginning was the law stuff *absolutely nothing* to do with the network. Everything after that was: what am I interested in? What am I doing now? Who can I do it with? Do they want me to do it? 

Kevin Kelly would say: this is what the network does. It invents new ways for you to succeed. You still have to, you know, take advantage of them. I mean, I spoke at a *design* conference for the first time this year and for whatever reason, I'm pretty confident that I'm not a Capital D Designer. I was interviewing just a couple months ago for a Design Director position, and still. But it was just because of the stuff that I was interested in and the network just... provided.

This isn't some Secret bullshit. But I think it turns out that most humans are actually pretty decent people and want to help other people. And this, this stupid thing of a newsletter, where I just spurt out words every day, has at least helped people understand me and who I am and what I'm interested in and can form their own opinion about what I might be good at. 

The flipside of this of course is that in the grand scheme of things I'm so stupendously privileged that it doesn't bear thinking about. The elder son of immigrant parents from Hong Kong to England in the late 1970s, I ended up growing up in a middle class family and going to one of the top schools in the country. I took a paper boy job once and chucked it in because I didn't - couldn't - get up in the morning and face the drudgery. Instead, I'd temp in the summers between school years and, basically, type, and earn the ire of other admin assistants who didn't type at 90-odd words a minute because their parents or families didn't start them on a computer when they were three years old.

I'm stupidly lucky. 

So, when I ask myself, how did I *really* get this far? Yeah, it was pretty much privilege. 

The thing about those who've climbed the ladder having a responsibility to give a hand up? Yeah, that. Absolutely, unconditionally, that. 

--

4pm. Pretty much 30 minutes of writing on the dot. See you tomorrow.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty Two: The Difficult Third Album
Date: September 16, 2014 at 2:29:54 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hwvl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

11:03pm on a Monday, the Monday after the three-day XOXO Festival. Very tired. 
1.0 The Difficult Third Album

This is the third year I've been to XOXO[1], the self-billed "experimental festival celebrating independently-produced art and technology," put on by Andys McMillan[2] and Baio[3]. I think a good description of XOXO is that it celebrates network culture - that is, culture that only exists *because* of the network. That covers everything from Welcome to Nightvale, to John Gruber's Daring Fireball from Paul Ford's writing to data-driven jewellery from Rachel Binx, from Darius Kazemi's Twitter bots to Anita Sarkeesian's crowd-funded investigation of tropes used in media depictions of women. Some of these might not be classed as art - at least, not by snooty proper-art-artists - and some of these aren't necessarily technology-technology, but the one thing that they do have in common is that they are embedded in, and part of, networked culture. 

There was a lot to like about this year's festival. It had a distinctly different feel to last year, though, but the same thread ran through. The Andys have endeavoured to try to produce something that's trying to open up the Overton Window[4] of possibilities for tech-related conferences: that is, something that's about the people and the humanity in technology and not solely focussed on the mechanics. Last year was a deeply personal experience: something brimming over in authenticity and sincerity, in honesty and vulnerability that you rarely, if ever, get at conferences like SXSW or TechCrunch Disrupt or a Mashable event. This isn't technology for technology's sake, it's a place to focus on what it's like to be a human being, a person, creating stuff in a networked world that allows for an explosion in certain kinds of human contact. 

So it was interesting this year to see Kevin Kelly, of all people, saying that perhaps there were multiple measures of success. That the California Ideology-esque VC model of a *startup* - ie a business that grows *incredibly quickly* is not the only model or mode of success for what you want to do in life. You might not understand why this is a big deal: Kelly is the closest thing that we have to one of the grandfathers of internet libertarian-esque culture. When someone like Kelly says that perhaps we should look at models other than the VC model of build-fast-and-large, then you'd hope that people elsewhere are going to take notice, too. He illustrated his point well, pretty much using r/K selection theory[6]. Some species "succeed" by having hundreds, thousands of offspring to ensure "success". Others only produce a few offspring and invest in quality, rather than quantity. Neither of them are wrong. Both of them succeed in the goal of bringing about another generation: they would do, otherwise we wouldn't see evidence of them as successful reproductive strategies. 

Kelly had a compelling argument for the whole "software will eat the world, but everything will be OK" position. Generally, it's that whilst software will eat the world, we've historically been good at coming up with new jobs that aren't yet eaten by software that we can do whilst the software catches up. This is the sort of position that people like Andy Kessler take, and sometimes to extremes. To me, this all feels well and good if you posit that we have a good enough social security net to allow people to essentially context-switch and, you know, get new jobs when their old ones get eaten. 

Kelly's example was of the enabling and empowering aspects of technology. He talked about how on his own, or through distributed networks and software, one person could create a five pounds-in-weight magazine that would otherwise take thirty people a month to do. Which, you know, is great. But right now, our society's not constructed in a way that produces people who are empowered to discover what they're good at, or want to do, and be entrepreneurial about it. We're mired with an education system and a cultural environment that still fetishises and shows an industrial era of interchangeable human parts that are resources, fulfilling roles in the Organisation. In Kelly's future, there is no Organisation, there are merely fluid overlays and groups of people, everyone trying to do their own thing, to find their own audience, cobbling together a living. 

I can't necessarily disagree with what Kelly's saying. My own career is a mess. It's not even a career. It is a careening from one thing to another. What irks me is when companies like Uber take that software-eating-jobs position and then distort it into a "we're providing jobs" message. That's not fulfilment. That's not helping people succeed. It's meat-puppetry. 

This turned out to be a theme that other speakers would explore too. Gina Trapani would talk about how living and working in New York during 9/11 would change her and her attitude to time so that you coudl trace a line back to that event from what she would later do with lifehacker, and then later with ThinkUp. We would hear a collection of stories about people - individuals, each of them - trying to eke out some sort of meaning and asking the hardest of questions, the ones that can't be answered for you but can only be done through what's actually *work*: what is it that you *want to do*? 

We'd hear from people lucky enough to already know: people like Golan Levin[8], who by all accounts can't *help* but educate people and teach them the things he's learned, even when he's trying to run a Kickstarter in the Neo Lucida project[9] to prove a teachable moment to his class about how the Old Masters might have "cheated" in using mechanical aids to help the draw. 

But most of us don't. Most of us don't get a chance to figure it out, or for whatever psychological or environmental reason have a block. 

For me, one of the surprise outstanding talks was from Hank Green[10]. Now, I have a bad internal bias against vloggers. For whatever reason, I just don't get them. Which is a particularly unfair thing, as it's more a reaction to the medium than it is the person. But at the same time, I'm quite happy to say that I don't "get" Ze Frank, for example. This happened last year when I didn't know the slightest about Mike Rugnetta[11], and his talk[12] was the one that blew me away and did something weird to my brain. But I digress. 

Hank's thing was treading the well-worn path of telling you to fuck your dreams because, hey, your dreams are unrealistic. Well, they're not unrealistic. But they're just suggestions. And that you don't owe any obligation to your former self: they literally don't exist anymore. But this is the hard part: if you're trying to work out what it is that you *want* to do, then you kind of have to try a whole bunch of things out. Our education system and culture and economy isn't set up to do that. We aren't set up to let people a/b test a whole bunch of vocations or careers. We haven't built up a society that enables and empowers people to work out what's best, because hey, we've got bills to pay all the time. And if you haven't noticed, all of this technology that empowers people and enables new forms of success *costs money*. 

XOXO for me has always been about the human side of technology. It's been a space to get away from growth hacking and APIs and arguments about whether you should be using Ruby or Python or Go, where there are earnest discussions about vim versus emacs. It's been more about why you want to make what you want to make, rather than how you want to make it. So by definition, the better parts for me have been the more authentic, the more vulnerable, the more sincere, because that's a side that we rarely address in technology. That unless you're talking about a conference for machine learners - not the ones coding the machine learning - then technology is a human artifact made by people who put blood, sweat and tears into the damn things.

I have so many friends whom I respect, who are insanely talented at what they do. And yet I'm finding increasing evidence that it's the *majority* of them, not the minority, that are still incredibly insecure about themselves. I make jokes about this myself. I tweet, semi-facetiously, that over 1,500 people subscribe to this newsletter and they can't all be wrong. I mean, they've - you've - decided to get what I write, and I'm just splurging this stuff out. When I'm rubber-duck debugging my internal mental state with my therapist, I say to her: well, how can I disagree with 1,500 people, most of whom I've never met? When I'm making clear to most of those readers that all they're getting is the random noise from a bunch of neurons that's spewing out words onto a page. There is literally nothing that distinguishes me here, and yet they decide that it's still worth following. So she looks at me, expectantly, waiting for me to finish the train of thought and get to where she's trying to get me: so, what, I have inherent worth?

There was a conversation I had over lunch with Greg Borenstein - you should try his tinyletter[13], too, if only because he's almost comically smart - that spilled over into conversations with other people. That I don't want to live in a world that's been eaten by software. At least, not yet. Because software is binary, and we're fuzzy and that we're so, so not very good at capturing nuance. We just don't fit in database records right now, NOSQL or not. A good example, and I'm totally stealing this from a conversation I had with Manar Hussain[14], is that, generally speaking, our legal systems are set up on the premise that it was either impossible, or incredibly expensive, to Pokemon-style catch everyone. Society is built around catching *most* people. But hey, we can nearly do that now. Or we can definitely do it for some things. Algorithms and our best "artificial" intelligence aren't fuzzy and don't do-what-I-mean and set their own goals and go fetch a mug instead of a glass or anything else that can be used as a drinking container when I say "get me a glass" and there aren't any glasses. 

So, this is what XOXO does, or at least tries to do, for me. It tries to be the other voice, pushing that window slightly in the other direction, and reminds us that we're the people who're making stuff. That it's *people* who are making stuff, and invariably for other people. Sure, it sounds a bit group-huggy at times, and especially so from the outside. But it's doing a valuable thing. 

[1] http://2014.xoxofest.com
[2] Andy McMillan
[3] Andy Baio
[4] Overton Window - Wikipedia
[5] Kevin Kelly - kk.org
[6] r/K selectors - Wikipedia
[7] Gina Trapani
[8] Golan Levin
[9] Neo Lucida
[10] Hank Green
[11] Mike Rugnetta
[12] Mike Rugnetta, Idea Channel - XOXO Festival (2013)
[13] Smithereens - Greg Borenstein
[14] Manar Hussain

--

Normal service resumes tomorrow.

(I've always wanted to write that).

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty One: Ecks Oh, Ecks Oh; Just In Time
Date: September 12, 2014 at 10:07:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-huht=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

The first day of XOXO - the Social part. 8:06pm, at home, not being DJ'd to by Anil Dash. My turn - by choice - with our son tonight. A quite night. Tomorrow will be brain exploding. 
 
1.0 Ecks Oh, Ecks Oh
There's a certain kind of person who gets to see their friends at conferences, despite living in the same town, city or country as them. This would normally happen with something like a conference (uh, "festival") like South by Southwest, where a horde of Brits would descend upon Austin for Interactive and actually get to spend time with one another, rather than having to schedule meetings or traipse north or south of the river for the bi-annual brunch. 

Three years in, XOXO is a bit like that. I'm lucky to have gotten in - each attendee is vetted by the Andys McMillan and Baio, a sort of Metafilter-esque human-powered conference Eye of Sauron to whom if you're on the wrong side of the fence it looks like an in-club or a clique, and if you're on the other side, you look at everyone else and feel like you have imposter syndrome. The truth isn't so much somewhere in between, but that the Andys are trying to curate (such a word) a different kind of festival/conference experience, one that's, shall we say, less Brand Heavy. 

So XOXO is that time of the year in early September when friends come to Portland, when our house becomes a halfway house for those whose souls are stuck in some kind of Gibsonian-jetlag, strung out across the Atlantic, or, increasingly, just popped up from San Francisco for the weekend. And finally, a new kind of feeling: there was a dance I used to do when meeting people whom I'd only "met" online, but a different kind of meeting: the kind where you knew quite a lot about that person, and they knew quite a lot about you and you had to pretend that you didn't know each other, the first time you met in person. Or you had to pretend that you didn't know the thing that you obviously did know, because it had been shared in whatever social space. 

Less of that now: less of that "if you didn't explicitly tell me, I don't know" and a more comfortable feeling of: well, you talk about this thing on the internet, and we both know that, so let's just assume we know. A more pleasant let's start this as if we're on a rolling start, not on a tricky hill start, and just lapse into conversation. Less of the pretense, more of the getting on with it. More of the acknowleding that this is a little of what friendship is nowadays. That you can know things about people - and they can be comfortable with that - without having been explicitly told. 

That clash of friends: that "so, how are you?" when we all know that we've been reading each others statuses. That "what are you doing now?" and the really, really hard work of being sociable and, with a certain group of friends, knowing that you can just sit in a room or a corner and just be quiet together. 
 
2.0 Just In Time

The right thing, at the wrong time, by the people who spotted the right thing and just got too excited about it, too early. We were talking about Slack today, and the Butterfield/Henderson ability to make something whimsical and accidentally find something valuable and interesting out of it. Two for two now, more or less, so one more success and before you know it you're going to have articles exhorting the combination of stupendously talented developer who's also got a penchant for shorts and Lego, and whimsical Canadian product manager and designer. But I want to go back to the thing about Slack and IRC - that Slack was essentially the best bits about IRC and then all the techiness, all the stuff around netsplits, all the stuff around double-clicking or right-clicking on a username and seeing what server they're logged in on and whoising them - all of that stuff, and just getting rid of the cruft and focusing on the value of what IRC delivered to users. Rolling it out group by group and doing it in that Enterprise-y way? Pretty interesting too, if only because there's one other social network that did such a roll out, organisation by organisation, and they turned out to end up with over a billion users. 

There was a post going around a while back - the idea that all the tiny Unix utilities were being unbundled and made consumer-friendly, turned into apps or whatever. You know, you had new web versions of grep or cvs or talk or ircd or elm. It was a bit simplistic for my taste: it wasn't an analogy that worked, more of a "hey, isn't this interesting, things that do things continue to be useful in new ways". 

But it takes a special kind of person - or a way of looking at things - to see something like IRC and go: hey, I bet more people would use that if it were crafted a different way. Made a different way. Lots of Slack is, more or less, and naively, a solved problem. The attention to detail is in the execution. The idea - group chat for a whole bunch of people with automation hooks - isn't a new one. The way it's been built, and the way people take to it, that's a big game changer. 

The problem is when you can see these things and you get excited and you try to build them and all that you've done wrong, the only reason why you didn't succeed is because you were just too early. We fetishize the new in the land of technology, and sometimes it's hard to tell the difference between a new enabling technology, and a new thing that's just new. For a while, it looked like the jury was out on WebGL. It may well still be. But the first thing that people would do would be clones of Elite, or whatever. David Braben's finally bringing pretty much the original vision of Elite back to life with Elite: Dangerous, and it looks fucking awesome. Same idea. Later execution. Different effects. Networks, graphics - all so much better, and now the execution can be different and can be better in a way that seems an order of magnitude better. 

Consider Yahoo's early work on Fire Eagle, a location broker that would enable trusted access to location that solved a problem that would be needed to solved now, a good six years after it was launched in 2008. Kind-of done at the OS level now, in a way that couldn't really be anticipated back in 2008, but a bold attempt nonetheless, and probably something that could be done even more properly now. 

We like building the new thing on the new framework using the new way. When a lot of the time, it turns out that the need was pretty original. I think what's obscured a lot of the time is that what was successful in the early days of the internet - like chat - are things that are always successful. They can just reach even more people now. And - he says, banging his drum - understand your audience and your users. Empathise with them. 

--

I'll be at XOXO all day tomorrow. Impromptu newsletter meetup at 12pm. Send me notes, give me hugs, all that sort of stuff.

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixty: After All; 2014 (7)
Date: September 12, 2014 at 2:13:09 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-htgx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Sitrep

My wife and I have two pieces of slang that we use around the house: the first, over text message, is invariably SITREP when one of us is looking after our son. How's everything going? Has he pooped? Is he awake? Has he gone to sleep? What has he broken? Was it his limb, or someone else's limb? The other one is *babby* - a stupid reference to the infamous Yahoo! Answers Question, How Is Babby Formed. Babby, in this case, is the one who's just done a gigantic poo, finally. 
1.0 After All

It's easy to poke fun and stuff and easy to rail at things that other people do and put out into the world. I could try, but in the end I wouldn't be able to top this quote from Anton Ego in Pixar's Ratatouille:

"In many ways, the work of a critic is easy. We risk very little, yet enjoy a position over those who offer up their work and their selves to our judgment. We thrive on negative criticism, which is fun to write and to read. But the bitter truth we critics must face, is that in the grand scheme of things, the average piece of junk is probably more meaningful than our criticism designating it so. But there are times when a critic truly risks something, and that is in the discovery and defense of the *new*. The world is often unkind to new talent, new creations. The new needs friends. Last night, I experienced something new: an extraordinary meal from a singularly unexpected source. To say that both the meal and its maker have challenged my preconceptions about fine cooking is a gross understatement. They have rocked me to my core. In the past, I have made no secret of my disdain for Chef Gusteau's famous motto, "Anyone can cook." But I realize, only now do I truly understand what he meant. Not everyone can become a great artist; but a great artist *can* come from *anywhere*. It is difficult to imagine more humble origins than those of the genius now cooking at Gusteau's, who is, in this critic's opinion, nothing less than the finest chef in France. I will be returning to Gusteau's soon, hungry for more."

It's hard to do, to be a friend to the new. At the old job, the culture was that as a creative director, you had to protect fledgling ideas. They were too frail, too easily bent or broken or challenged at the early stages to survive out in the world. That's why the entire creative department had to sit on its own floor, why strategists and planners and account people weren't invited to creative reviews and if they were, had strict instructions to be seen but not heard. 

I would like to believe - I think we don't really have a choice but to believe - that most people, most of the time, have good intentions at heart. And that it can be the state of the world and the environment that grinds us down, because how else are you supposed to react to an indifferent universe? There's good stuff out there, and whilst it's not like there's a duty to be optimistic and kind to the things happening in the world, perhaps we need to be - or I need to be - to help the things we want to happen, happen. 

So, I'm going to try again. The new stuff. The stuff that makes us feel excited, *should* make us feel excited. That is an achievement and whilst it might not be completely there yet, is still pushing us in the right direction and is taking us forward. Is better, and can be made better. That stuff.
 
2.0 2014 (7)

Hundreds of thousands of sensors monitor the sleeping patterns of people worldwide, allowing a private company to pinpoint the exact second that an earthquake roused people in Napa, California. We see 3D data regularly depicted as LIDAR point-clouds and voxels, we use pixelated models more than ever before to interpret our surroundings. Millions of people have watched a goldfish play videogames, live on the internet. We can make images of objects using less than one photon per pixel. There are at least thirteen active robotic solar system missions. American Football players committing domestic violence, witnessed by surveillance camera, are ex-post-facto removed from popular videogames. There are now nine documented cases of people who have lived without a cerebellum. Scales that measure your weight and are connected to the internet geolocate themselves, accounting for fluctuations in gravity around the planet. A citizen science project has found evidence that humans can gain the ability to see into the near infrared just by eating lots of vitamin A2. 

--

12:10am. iPhone 6'd up. I am a puppet, pull my strings.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Nine: She Who Wears The Digital Crown; Designing Community
Date: September 10, 2014 at 6:12:39 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hs6t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

12pm on a Sunny Wednesday. Portland is putting on its glad rags for the just-over-a-thousand arriving for annual indie hug-fest XOXO, I'm sitting in a deli thinking to myself: why, with what Apple launched yesterday pundits can keep themselves in business for *years*. It's enough to make you change your name to Lunkwill or Fook and get on that gravy train. And yes, it's a bit like Apple-watching is a certain kind of Kremlinology, or the new kind of Kremlinology, but so. Apple is only just a little bit of what's happening, and as a friend remarked the other day, "it is a miserable tiny future that a small number of men in a corner of California plot."[1]

An attention-bound species, only able to shine a light onto one thing at a time, a giant searchlight of this-is-the-thing-that-matters. False, of course - just a story to explain a particular point of view. Lots of other stuff going on. Always lots of other stuff going on. 

[1] https://twitter.com/moleitau/status/509544905694515200
 
1.0 She Who Wears The Digital Crown

I knew what I'd do with a better personal music player. All of my music, everywhere! Well, at the time, it was all of my music. I knew what I'd do with a better phone, too: all that stuff that I wanted to do with a Nokia or Palm at the time, but had to jab ineffectively at the capacitive touch-screen to do. Or navigate through frankly abusive menus to accomplish simple tasks. Or set things like Access Point Names. 

I'm not sure what I'd do with a WATCH, though. That's not to say that there *aren't* things to do with that watch, but I go back to what the story is about this thing. Tom Armitage sent an interesting note - after going through Ive's Ivesplaining of what the new thing does, he had a different take on the repetition of the 50-millisecond accuracy. To which all of us geeks say: well, I should bloody hope so, it's a fucking *computer* connected to the internet. But to everyone else, to people perhaps less literate in things like clock slew and network time protocol, a watch that's accurate is a good thing, and the kind of thing that people who're into watches talk about. So Armitage's observation was: look at the breadth of this thing. Who's it for? Watch people! But not just watch people. App people too! And health and fitness people! 

Ben Thompson has beat me to the punch here in a great article[1] at his Stratechery site. He asks essentially the same questions: in all of Apple's recent product introductions - ones that brought the company into new categories - they've done a great job of persuading you why you need it. Why you need the iPhone, the iPod or the iPad. The market might not have been large enough or ready yet, certainly in the case of the iPod and the iPhone, but it got there, because there existed the fulfilment of a genuine need. 

I'm aware of adventuring into the whole you-can't-say-what-Steve-Jobs-would-have-done-territory, and it's possible to pretty much pull out any anecdote that will back whatever position you want to take (he took forever to buy a washing machine, questioned what they were even for and what they were supposed to do, ditto furniture) or even the counter-indication (the Flower Power iMac G3, still). 

But, you know. They've been working on this "for three years" and, well, Steve died around three years ago. And everyone knows you're supposed to do *something* with a wearable. And sure, Apple have done it, kind of, on their own terms. As much attention to design and fashion - and bets are already coming in on the inevitable high price of the fashion EDITION pieces - as to the user interface. Ish. I mean, it's not bad. But does it fill what you recognise to be an aching watch-sized hole in your life? And not even *watch*-sized or shaped, but the whole idea of: there is a thing on my body, that is always on my body (if things work out) and that I can move about with slightly less effort than getting the thing out of my pocket. What kind of things can that thing do, on my wrist, that make sense? 

I mean, sure, I *can* look at and reply to email on my wrist. But it felt like Apple would be the kind of company that would take a fairly principled position (whether right or wrong - Jobs would always reserve the right to change his mind in rather obvious ways). Bigger iPhone? Never. Tablet? Never. Smaller tablet? Never.  

But, you know, strong opinions, weakly held and all that. And never, ever give away the product roadmap to the competitors. If you can see where the puck's going, then head straight for it and misdirect all the way. 

There are certainly a bunch of interesting things: what are the kinds of things a wrist-mounted always-sensing thing can do? New kinds of gesture recognition? How sensitive are the gyros and accelerometers? The Taptic Engine itself is intriguing if only for the somewhat outlandish thought of a whole new generation of people learning and creating new Morse Codes and a hidden backchannel of information. 

[1] Apple WATCH: Asking Why and Saying No - Stratechery, Ben Thompson
 
2.0 Designing Communities

So it turns out that when we ask "what kind of society do we want to build for ourselves", some of our leading online communities turn out to have a pretty definitive answer. GoFundMe, a sort-of crowdfunding site has decided to ban fundraising for abortions and "sorcery"[1] but is OK with raising funds for public officials who maybe, just maybe, might have conducted an extra-judicial execution under the guise of "well, I guess he looked black at me." 

A few days ago, CEO of Reddit Yishan Wong stuck his head above the parapet to declare that the site was a sort of Government 2.0[2], and wrote sentences like this: "[we] consider ourselves not just a company running a website where one can post links and discuss them, but the government of a new type of community."

So it turns out that Government 2.0 is instead not just Responsive Government or Smaller Government but instead a sort of pared-back internet-service government where like karma ranking, weak anonymity and threaded comments. Not anything as substantive as saying that there might be unalienable rights to life, liberty or the pursuit of happiness.

In Redditland, the worst thing that can happen to you is that you lose karma or you get banned. But that's okay, because you can always come back, rez in as another pseudonymous individual. The best thing that can happen to you is you can get recognition or Gold, gifted to you by other grateful members of your micro-nation. 

On Reddit, each individual, as Yishan says, is responsible for their own moral actions. Curiously, the administrators appear to be above reproach - the equations of utilitarianism don't apply to them, the fact that they govern and operate systems that affect millions doesn't figure into *their* personal moral successes or failings. 

This isn't new. I mean, it's depressing, but I guess it isn't new. There are certainly wonderful things that happen on Reddit, and a lot of those wonderful things are in spite of the action and tactics that the site's management have taken. They are less, I think, things that reflect well upon Reddit and instead things that reflect well upon communities of people. For every Reddit thread showing progress in acceptance of trans men or women, there's another doxxing or abusing. People, I suppose. 

The beauty of Reddit, though, and the beauty of at least this part of the internet is the inadvertent transparency. Redditors - and most other people on the internet - are living in the public now. When we see examples of domestic violence ripple through media, when we see misogyny, verbal abuse, bullying, all of the terrible tragic things that we're capable of, it's not like they weren't there before. We can just see them now. What makes us different - if anything does, I suppose - is that when we see things like that, when we see things that we don't agree with, when we see something in the world that we wish weren't like that, more often than not we actually have the power to do something about it.

If there's a compromising middle-ground in Reddit's position it's this: yes, it's better when people do the right thing for the right reasons and understand why, as opposed to doing the right thing because someone else told them to. But to do that is to disregard at the same time a whole bunch of experimental cognitive neuroscience and behavioural psychology research that shows that a lot of the time, we just do what other people are doing. That behaviours can be normalised. That things can be made okay, and you don't even need to read or agree with Malcolm Gladwell to go along with that. 

The difference is one of participation. Reddit is big, and it's a lightly-moderated site that relies upon devolution of power, of federation. The admins are rare, and it's frequently a free-for-all. Mods are ground-up grown, and if I'm going to stretch an analogy even further, it's that Reddit is a playground for kids where the adults hardly ever check in. There aren't that many good examples. Wong says that Reddit's *intent* is that they want to teach by example, that they want to highlight the good stuff. You want a good example of that? It's Metafilter. 

Good community management, *raising* a good community, teaching them and helping them discover what's right and wrong versus just *telling them* (and, you know what, sometimes you *can* just tell people that abuse is wrong and not at the same time have to give up your ideals) is a thankless task that's akin to parenting. 

But the type of site that's Metafilter, the type of site and community that relied and grew based *upon* that never-ending job of community moderation and parenting has proven, in our current model, to be unsustainable. It's too expensive. Good moderators, like good teachers, are priceless. And moderation in the internet age is a 24 hour affair. You think it's exhausting chasing after one toddler. Imagine chasing after thousands of them. Millions of them.

Of course, you could decide to make the environment safer. You could choose to bias it toward good behaviour, whilst not out-right banning or making impossible bad behaviour. You could choose to do all of those things. If, like Wong says, every man is responsible for his own soul. 

In the meantime, more sunlight. Gradually, slowly, imperceptibly, even. Maybe not progress as fast as some of us would like. But free speech - whether it exists or is required on Reddit's platform or not - is helping us understand exactly what communities people want to build on the internet. 

[1] GoFundMe, the site that has raised money for convicted murderers, will draw the line at abortion and ‘sorcery’ - Washington Post, Caitlin Dewey
[2] Every Man Is Responsible For His Own Soul - blog.reddit

--

XOXO starts tomorrow, opening night party and then the traditional tour of Portland on Friday, then conference on Saturday and Sunday. Hopefully I'll still be writing tomorrow and Friday, and then it'll be a massive brain splurge next week. 

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Eight: WATCH; BERG
Date: September 10, 2014 at 12:41:01 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hr1d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Of course I'm not going to be able to resist and will be writing about the new WATCH today. 3:32pm and at home, taking about half an hour to write this before getting on with some chores - it's XOXO Week here in Portland and we have visitors coming to stay, so it's Get The House Ready time. 
1.0 WATCH

Only one point, really. Or at least a thread to pull on and to see where it takes me. One of the things that stood out today was the Digital Crown[1], the scroll wheel-ish input mechanism that repurposes the conventional clock Crown and adds a healthy dollop of do-what-I-mean user interface design in software and potentially some haptic (sorry, taptic) feedback that will let you know when you've completed the requisite number of degrees of movement to ker-chunk into the next option category. But.

I'm aware that what I'm about to do is offer up one of those "Steve Jobs Wouldn't Have..." opinions, the kind that can invariably be shooed away just by pointing at the Flower Power iMac G3. I don't particularly care what the Digital Crown does, or how it does it, but more the name that's been chosen for it. Previous Apple innovations have been given names like Thunderbolt, Lightning, Retina Display, Magic Mouse, MagSafe, FireWire and so on - but now we have names like Digital Crown which sounds just... off, to me. Yes, sure we get that it's digital. You're taking something old, the crown from a watch, and making it... digital? That's kind of what you do, Apple. I had perhaps expected better. Names are a difficult thing, and you'll note that I'm not offering up an alternative. And if I'm just reading the runes and post-hoc rationalising, I could see something like Digital Crown being a working title and then everyone using it as a name and before you know it, you've shipped something that has possibly more regal connotations than user interface ones. And, as it happens, is it *that* different from the Scroll Wheel? 

And then, I suppose, some other reckons. I don't yet have the concern, as some others do, about the whole "four different ways" to interact with the watch. Touchscreens are pretty de-riguer, and the Digital Crown (ugh) seems intuitive enough - though I'm intrigued to see if it will always work in the right direction, or if it will be in opposition to what feels natural (or did feel natural) on peoples' touchpads. 

The price is an interesting one as well. I've been saying for a while that we've been drafting off of Moore's law, but I'm not sure how much that is going to continue. We have cheaper phones, but I don't think it's because of the so-called law, more that there are certain players who have built up manufacturing and supply-chain infrastructure. My naive view is this: it doesn't matter if the proccessor in the WATCH gets smaller and faster or more energy efficient - that's not going to be a significant proportion of the bill of materials. What will make the most user impact will be things like better displays and better battery life - neither of which, it seems, have directly benefitted from the suggestion that transistor count for a given area will double every year and a half. 

Some other thoughts:

 - watch faces are going to be an in-app purchase, obviously. Why wouldn't they be?
 - I had quipped, on Twitter, that it looked like it was going to be a pain to get a WPA2 passphrase into a WATCH, but it looks like they're permanently tethered to your phone. So there's that, I suppose, and the fact that it looks like they don't even have wi-fi. 

The other thing is that whilst, thank God, Apple didn't just cram the iOS interface onto a watch-shaped and sized thing, they did do something a bit... different? Cook makes reference to this in the Keynote saying that it wouldn't have made sense to do that, but I'm not persuaded yet about the utility (or need) for notifications to come up in on a wrist-based device. The fact that I *can* get Facebook Friend notifications or Twitter notifications or even email notifications on my wrist is feels like something Apple might have had an opinion about in the past about whether it was right or proper for that type of device to have that type of functionality. Of course, back then, you could also justify a lack of functionality on constraints such as processor, screen and battery life. Not so these days. There are nice uses. The Starwood Hotels app that lets you use the watch as a door access device is one, but for me, what's interesting about that particular interaction is that it's screenless, or that it doesn't need the screen on the device. 

There's just a *lot* going on with the Watch. Perhaps it's a surfeit of processing power and battery - well, as much as you can have a surfeit of such things in such a tiny package. But a lot of the functionality demoed - calling to mind things like Matt Webb's early thinking about Glances (of which such information didn't feel like it was particularly glanceable, not in that peripheral vision kind of way) just felt like a bit of throwing at the dartboard and seeing what sticks. It's nice to see Apple reflect usage of emoji - from not having the keyboard in iOS to having it available if you knew what you were doing, kind of, to having it as an explicit installable keyboard - in the Watch. But then there's Digital Touch - the Drawing Thing with the Hearts and the Heart Beats and you're a bit: OK, I've seen the concept demo for this before. And you guys tried it out and it's going to work? Using an Apple Watch as a small viewfinder whilst you hold your phone aloft? Would've looked cheesy in a Samsung ad. Something you might do at a gig? Maybe? 

More later, inevitably.
2.0 BERG

You should know your history. BERG was one of those startups that, I feel, a whole bunch of people in London were jealous of. And not just a startup, really - one that was very good at talking about itself, and one that mostly epitomised what I'd call the Alternative Valley - a more considered, more whimsical and English sensibility, rather than the brashness of the West Coast. It makes me sad to be writing this in the past tense, as BERG closed its doors today, in its four hundredth and eighty third week[1]. Other people better than I have written better eulogies[2], all I really have to say is something like this:

I knew them when they were Schulze & Webb - and didn't really know Schulze that well. Webb I knew back from early blogging days - he was at Oxford, I was at Cambridge and we were - are - roughly the same age. He'd built Dirk, was obviously a fan of Douglas Adams and we both had had our brains exploded by Greg Egan and books like Permutation City and Diaspora in the early 2000s. Webb would go on to do a stint at the BBC - in particular, the Audio and Music Interactive part - in that typical progression of Public Serviceland where he'd work with people like Tom Coates and Matt Biddulph. And then, of course, Dopplr grew up alongside, and Matt Jones eventually joined them. 

They've made such influential work. The Chernoff faces of Schooloscope, a 4iP project. SVK, a comic book with a tangible superpower. They would be easy to make fun of for the videos they made instead of the *things* that they made. But those videos had the right stuff in them, the right ideas in them, and you just knew that they were bleeding smartness through pixels. And the crew that the Experimental Rocket Group accreted around themselves: I'm probably missing people, but Nick Ludlam, Tom Armitage, Alice Bartlett, Timo Arnall, Andy Huntingdon, Helen Rogers, Joe Malia, Denise Wilton. Such smart people concentrated in such a small space. Whenever you went to visit them, especially when the triumvirate of Jones, Schulze and Webb were around and you had this corona of superpeople orbiting them, it felt like a sort of Manhattan project. Like someone had left a fissionable pile of neurons over in the room and if you didn't do something then something big, something dramatic, something *smart* was going to happen and knock everything over for a thousand mile radius. 

We were all jealous of BERG. They did the smart work. They showed us how it could be done. Some of the stuff, I have to admit, might not have made sense from the outside. I'm sad that they're not around. I'm irritated that others didn't see what they could've done with the appropriate corporate fulcrum and lever to change the world. Instead, we'll be cursed with idiot washing machines and an internet of things that almost, but not quite, resembles something like a teasmaid. 

So this sounds sad, and it is, because they were a unique grouping of people at a unique time, pointing and tilting at a windmill that we needed tilted. But each and every one of them will go off to do some amazing things. I prefer to think of this as an explosion, not a whimper - and that seeds of BERGiness will erupt all over the place. That they'll go off and change the world in different ways. 

I'm still jealous of them.

[1] Week 483 - Berg
[2] For BERG, My London Launchpad - Warren Ellis

--

House admin. Imminent guests. Buried under email. Send some anyway.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Seven: The Mezzanine; Doing The Job; Minimum Viable Whimsy
Date: September 8, 2014 at 6:42:15 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hpjx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
4:37pm, whilst the spare car, the one we would've sold by now but for the idiot accident that happened to us, is being cleaned. The strange situation where the car wash offers free wi-fi, but a hotel that costs a couple hundred dollars a night doesn't. Because hey, customer service. Anyway. On with the show.
1.0 The Mezzanine
If you lived in the United Kingdom in the early 2000s, one of the things that you might have noticed was the rapid supermarket growth. It was about that time that Tesco, one of the leading retailers, cemented its position, owing its success as much to a property portfolio, a data warehouse connected to a loyalty card scheme and supply chain management. At its height, about 14 and a half pence of every pound spent in retail in the UK was going to Tesco. 

One of the many factors that went into this was the mezzanine planning permission loophole. Imagine the situation: to increase revenue and profit, you can either increase the revenue per square foot of your stores, or you can build more stores. So when someone comes along and says that you can increase the square footage of your *existing stores* - ones that you already know are at capacity in terms of retail space and have high traffic, you'd be interested, right?

This was the mezzanine planning permission loophole: some clever person figured out that there were no planning permission restrictions affecting the building of mezzanine floors - the equivalent of the platform 9 and 3/4 at King's Cross, the realisation that these big box stores had enough ceiling height for you to insert a brand new floor, giving you around up to 50-75% as much retail space, without having to worry about any regulatory requirements or paying out for the same amount in buying or leasing actual land. 

Of course, the regulatory loophole was closed. It had made a mockery of the government of the day's promise to restrict out-of-city development at a time that high streets were feeling increasing competition from new sub-urban developments. 

This feels like the kind of disruption that we in the software industry like. Finding problems to change the world, right? It makes me think of Amazon. One of their major costs right now for the part of their business that is significant (selling and fulfilling physical product) is distribution and fulfilment centres[1].

So here's a silly thought: forget about all those giant warehouses out their in algorithmically-optimised distribution areas for transport logistics. The land costs money, and sometimes they could be closer to the customers than they might be. It's an n-body problem, right? Plus, there's all those pesky regulations about how big a warehouse you can build and where you can put it.

So put them in the sky. Giant redundant arrays of inexpensive zeppelins, serviced and supplied by smaller drones, where picking and packing are performed by Kiva robots, deliveries made by shoving the packages overboard, GPS and inertial guidance systems tweaking fold-out fins deployed from the packaging cardboard itself, yet another use for weather-resistant Tyvek. Put them high enough and it doesn't matter, right? And anyway, how long is it going to take the government to legislate for a right-to-light? You want fast, cheap consumer goods before you're going to care about the Amazon Distribution Centre high above your city. 

Or, take the distribution centre and explode it. In the same way that Zipcar tries to cut a deal with you if you own your home and have off-street parking, let Amazon park one of their distribution shipping containers - oh, okay, a *half* shipping container - on your property. It offers local-pickup for people in your neighbourhood, and in exchange for becoming part of the distribution network, you get a free Fire phone and Amazon Prime! 

All because, of course, you want cheaper access to fast moving consumer goods. 


[1] Why Amazon Has No Profits And Why It Works - Benedict Evans, Andreessen Horowitz
2.0 Doing The Job
I signed up to do speed mentoring sessions at How Interactive DC last week - one-hour sessions on Thursday and Friday with 10-minute slots to spend time talking with people. I like talking with people. Between those mentoring sessions and the prep that I did for the talk, it felt like I'd been reminded about how tricky it is to do our jobs sometimes. 

At least a couple of the people I met with asked me to give feedback on designs or wireframes, and again, it felt like sometimes the most valuable advice (at least, if I'm to believe what they told me) was to look at things from an outside perspective and ask: well, what are you trying to accomplish? A non-profit, for example, was launching a new service, but had prioritised putting a video that explained what it did above helping people use the service in the first place. Frequently, designers would say that they didn't have clarity from their superiors on what the service was supposed to do. Or again, to use the above example again, "our organisation is launching a new service, and this website is for that service" - so why is the first thing on that website a video that explains the organisation? 

I used to read the Economist and let my subscription lapse, but occasionally pick up a copy when I'm at an airport and desperate for something to read. This week it was an easier decision - it's their Technology Quarterly issue, and I like knowing what other people think is worth knowing (bio-printing, Internet of Things, connected cars, air traffic control and so on stood out this time. 

But it was the Schumpeter column on business and management[1] that caught my eye this time because of its promise of pulling out three core issues from the latest McKinsey Quarterly, ones that would "preoccupy managers for the next 50 years". And yes, some of this is because I've been infected by the Cult of the Government Digital Service, but it just felt like the three core issues were a bunch of management theory fiddling while your organisation gets burned from the inside out and Disrupted by a bunch of people who understand Software. 

Let me mansplain: the three issues identified by the Economist were smart machines, boosting productivity and the third wave of globalisation: mid-tier developing cities. From my point of view, the first two appeared to be subtly hinting at, but not really pointing out, a bigger issue, and again, I think it's because of a fundamental misunderstanding of what software can do when allied with good organisation and management. 

For example, the gist of the Economist's focus on the first part - smart machines - is that much of the work of executives and management will be automated: "much of the work of bosses, from analysing complex data to recruiting staff and setting bonuses, will be automated." The article pulls out a couple of answers here - one is of Google's "human-performance analytics group", the data-backed group that tries to put some science in human resource management, and the algorithm that's been "appointed" to the Deep Knowledge Ventures board of directors and has a vote on what sort of companies the VC invests in. I covered the latter back in issue TKTK. Senior managers, says the Economist "will have to rethink their roles dramatically if they are not to become latter-day Luddites. They will have to hand some of their functions to intelligent machines, which will always be better at data analysis than humans, and some to the heads of business units, who will be in a better position to make use of the crunched data." 

I think this misses the point that defines the continuum between people like Marc Andreessen with his software-eating-the-world position and the GDS organisational change linked to IT done right position. 

Nowhere is there the consideration that part of the job of the manager or executive is to identify areas in which smart machines can be deployed in the first place. Nowhere is there this idea of the executive focussing on the way that automation and technology can be applied to make what they and their teams do more efficient. 

This ties into the second point, that of boosting productivity. Apparently, we should be optimistic about improving worker productivity because the "IT revolution is turbocharging what once looked like mature management technologies such as lean production and supply-chain management. Cloud computing lets small startups harness computing power that was once reserved for big firms. But the biggest potential gains will come from focusing on areas of the economy that have either been overlooked, because of a lack of imagination, or have stagnated, because they are protected by powerful interests." 

Schumpeter appears to miss the whole point of the IT revolution in the first place by focussing on productivity-boosting uses of industrial materials, whilst ignoring the already-impressive example of the UK government saving at least fifty million pounds a year through better systems. 

It may be because I'm being overly simplistic, but part of the big changes that we've seen in terms of efficiency haven't been because of cloud computing, although the cloud has certainly helped in terms of helping people get to product faster and a shift from capex into opex at the stating phase. They've been instead from using software as a material to solve problems from first principles. Instead, I feel it's been people who're familiar with what software can do - and the nous to know how and where to do it - and they've finally snapped and had enough. We should be able to do better. 

[1] Schumpeter: Three issues that should preoccupy managers in the next 50 years - The Economist
3.0 Minimum Viable Whimsy
I haven't even *used* Slack[1], so this is the absolute worst kind of armchair internet punditry, so take everything that I'm writing here with a grain of salt as big as the amount of money in a Facebook acquisition. So.

One of the interesting things about Etsy is the way it's taken a culture of dev/ops from initial beginnings at Flickr and exploded it into something that's a part of the company culture of Etsy. I may well be projecting here, but it looks like what Stewart Butterfield and Cal Henderson have done is taken a look at the way developers and, I suppose, in a way Tim O'Reilly's alpha geeks, have used a service like IRC and said to themselves: what would it be like if we made IRC (and its bots) as easy to use for regular people as it is for us? 

It feels like irccloud tried to do something like this, but ended up creating IRC for people who know how to use IRC. But it feels like there was value in having the distance to step back and say: what are the bits about IRC that are, well, *good*, and would they be good for other people to use?

So you get channels and you get bots through webhooks. You get persistence and you get scrollback. You get conversation - which we know humans are good at - as opposed to correspondence. And maybe you can through the unbundling metaphor to look at what Slack is doing too: we experience email-as-conversation, when it happens to be the medium at hand, and perhaps not the medium best suited for the type of communication that's needed. But Slack is also an organisational change: I first got an invitation a long time ago when I was working at Wieden+Kennedy, and it didn't feel like something that could work unless a whole team was using it. And when those teams had only just discovered Basecamp, well...

As much of this feels like finding the good part of an old piece of technology and working out how it might be made accessible to a wider audience now that enough of the workforce has net-connected computers and phones. And perhaps Slack would've been a harder sell to a workforce that hadn't grown up with IM, that wasn't acutely aware of mobile messaging. From the outside, and the way people are talking about it, Slack is a tool for collaboration because it's a better tool for conversation in a way that email was so far the least-bad tool for conversation. 

At the same time, you can look at something like Slack and something like Google's ill-fated Wave and see that they both are pointed in the same direction, but something went wrong with Google's - dare I say it - user-empathy. Butterfield and Henderson (and doubtless others who I'm wronging by not knowing and not giving credit to out of lack of research) have proven themselves twice now about being able to find the thing-that-resonates-with-mass-users that they accidentally built. Or, perhaps, it's just their whimsy, that they're not afraid of designing and producing solid things that have Minimum Viable Whimsy (oh god, I just wrote Minimum Viable Whimsy, but see what I'm doing, I'm not going back and deleting it, am I).

There's a few factors going on here: the fact that (then) Tiny Speck identified (yet again) a need and also delivered against that need with a product that worked. Then there's the fractal attention to detail and the Butterfield-esque friendliness that infuses the types of things that he's involved in producing. I mean, notice the casual and accessible tone of voice pioneered by Flickr (and now adopted by Facebook, of all places, in their usage of Dinosaur Stickers to educate users about their privacy tools) that at times was compared to the Innocent Smoothie-ification of the English Language. That was a bit of a run-on sentence, but what I'm getting at is a sort of sideways nod to the whole GDS (if you're playing Newsletter Bingo then you've probably won this episode) "digital services so good people prefer to use them" to a wishy-washy sort-of "digital products that are pleasant to use."

There's a difference in tone here - Government shouldn't be matey with you, it's fulfilling an institutional and societal role. Consumer/"enterprise" products occupy a different space - and it's perhaps that "enterprise" bollocks that does a sort of context switch in the kind of language used in enterprise software. Enterprise software is serious. Enterprises are Serious Businesses full of Serious People in suits. But it turns out that a lot of those Serious People in Suits also take off those suits every now and then and apparently do things like go and watch The Hangover. This isn't to say that there's a casualification of language in business software, but that there's value in getting to the point. An enterprise is just a business that's pretending to be more serious than it is. We do this all the time, and in a way, you'd think that all of this context-switching that we have to do when we switch between different language registers takes a toll on our poor hardly-evolved brains. 

[1] Slack

--

Thinking about Reddit. Annoyed about Reddit, like everyone else. Thinking about a recent car accident - well, the incident in which someone accidented themselves into the car I was in, and who, it appears, has subsequently claimed that our stationary vehicle instead was moving into theirs at the same time. At that, nothing to do, other than sigh and install a dashcam for next time. Or, in other words: get that dashcam, because when you have a word-vs-word insurance account and another party to whom you have no idea as to their trustworthiness, well. Get backup. No Destiny on pre-order. And, of course, the elephant in the room: Apple Keynote Day tomorrow, 10am PST. 

Oh, and the one sobering thought, when I saw my primary care doctor for a follow-up after my fall. People have died falling from lesser heights. Time to get that life and disability insurance sorted out.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Six: Space; Other Dyson Products; Not Yet, But Soon
Date: September 5, 2014 at 3:23:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hncl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

2pm, 2 hours after my talk finished, a short metro ride to the Smithsonian National Air and Space Museum. The talk went well - they mostly do, and the nervousness before it was the normal kind. Not the worst, not the kind with the nausea, just the general uneasiness and anxiety. And, afterwards, the come-down, the hiding in Starbucks and the occasional "hi" from someone who wanted to say how good it was, or how it helped them see things in a different way. 

I used to get a bit weirded out about this, especially if I'd just given a talk that really didn't feel *new* to me anymore. This feels like it happens if you do a lot of public speaking - you're saying the same things a lot, and then, after a few years, there's this detachment and you realise: no, wait, this *is* actually new to people who're telling you it's new to them. Knowledge doesn't by default spread at the speed of light just because it can. Ideas don't spread just because someone's published them. Things don't get attention and get passed along on their own, and there's still, I think, a requirement to be a messenger sometimes - if you want to play the messenger role. It's not as if this absolves you of giving a content free talk of just reckons or hand-waving general prognostication - you always have a responsibility, I think, of changing the system in some way. Whether it's in the way that people will approach their work, or helping them see things in a different way. And, of course, being humble about the whole thing. Because I can read all of the above in a different tone of voice, and fuck me if it doesn't sound privileged and smug.
1.0 Space
I'm writing this on the second floor at the Smithsonian National Air and Space Museum. There is an exhibition here celebrating 10 years of Spirit and Opportunity - more properly, Mars Exploration Rovers A and B, that NASA launched from Earth in 2003. Ten years later, Opportunity is still running, having exceeded its 90 sol (92.5 day) mission by over ten years. We lost contact with its Opportunity's twin, Spirit, on March 22, 2010. 

I want you to understand what Spirit and Opportunity mean to me. I didn't get Apollo. I'm too young. Born in 1979, I'm a child of the Space Shuttle age. My cohort weren't even ten years old when the Challenger disaster happened, and in 2003, when Columbia happened and the space age that we grew up with really died, we'd only just finished university. 

I'm kind of kidding, but only because I'm processing what this *feels* like. It's our tendency to anthropomorphise things, but we send out these probes on their own, agents and emissaries of humanity, and they're so, so far away. Space, you see, is really big. 

It feels like this: when I see the banner at the entrance to the exhibit, proclaiming a celebration of ten years of these probes and what they've done for us, Spirit and Opportunity are, in their way, a knock-out punch straight back to eight year old me who watched Space Camp and dreamed of going into orbit. I remember when I was quite young when my dad, an academic and an engineer, would proudly bring home the product of his department's latest acquisition: a full-colour large print plotter, for CAD diagrams. One of them was a contour map of re-entry temperature tolerances of Shuttle. It was beautiful. Growing up, my brother and I had a tent in the back garden, one modelled after the Shuttle, too. 

Just a young boy, and everything, everything I could get my hands on about space. Watching The Sky at Night when Patrick Moore was excitedly telling us about Giotto, about to rendezvous with Halley's Comet. The British Interplanetary Society's plans for Daedalus, a ship that might take us to the stars. 

But we were British, in Britain, and gazing from afar at America's reaching outside that thin layer of atmosphere we had and the plans to past that, the international space station - all of that, all of that felt like it vanished when the Shuttle died.

It didn't, of course. We send our avatars into space now, unfurling wings of solar cells, dropping SUV-sized autonomous probes in engineering feats compared to landing a hole-in-one from the next county over when the hole itself is moving faster than a plane. 

And such avatars. Because I look at them now, I look at those probes now and they've got as much character and as much dream inside them, as much yearning to get out there and *see* what's out there and to touch it and be a part of it as Shuttle ever did. 

Curiosity - the SUV-sized rover that we landed on Mars, had perhaps the most stunning landing, a powered descent stage, and the famous sky-crane landing before ending with a perfect-ten soft-touch, wheels-down landing that was watched online by over 3 million people. 

For all the women and men who worked and are working at JPL and NASA and all the other supporting institutions on MER-A and MER-B, for everyone who's working to increase our understanding of space, thank you. 

That's not all, though. For all that I was emotionally affected by the MER exhibit - and the sadness that I felt in its quietness compared to the people crowding through Skylab, or looking at the Apollo exhibits, that didn't compare to a preview exhibit on the ground floor. 

On the ground floors, there's a look at post-1970s spaceflight, and that's the part where it's a punch to the gut. That's the part where you see exhibits commemorating and explaining the Challenger and Columbia tragedies. That's the part where you see the word "compromise" next to the phrase "Designing the Space Shuttle". That's the part where you see where we thought we were going to go next, how we thought the Shuttle was going to be a taxi. It almost - but not quite - took away the tears-in-the-eye pride that I felt in Spirit and Opportunity, in those little rovers that could, in those testaments to engineering and ingenuity and doggedness that's led to one of the most successful off-planet exploration missions ever. It felt like 90% of the exhibit was dedicated to that Shuttle phase in our development, that Helvetica-labelled piece of complicated machinery that was a magnificent flying elephant, and it didn't matter that the other 10% was of NASA human-scale robotics. It didn't matter that there was a huge screen showing off Station, that aggravating love it and hate it installation that we have resting on the cusp of our atmospheric bubble. 

I'm planning on visiting Enterprise tomorrow, at the Udvar-Hazy. I'm pretty sure that, judging on how today went, I'm going to have something verging on a religious experience.
2.0 Other Dyson Products
Denise Wilton wrote a good piece[1] the other day about the inexplicable and yet wearily predictable naming of Dyson's robot vacuum, the Dyson 360 Eye, bemoaning the fact that the product name has absolutely no indication or signalling that it is indeed a robot vacuum. It could be a great many number of things, and actually sounds like a previous-generation videogame console knockoff peripheral (not even the console itself!) 

I'm not sure who's doing Dyson's advertising and communications, but Denise makes such a valid point that at this stage, it's worth asking what Dyson are trying to achieve. The way they *talk* about the Dyson 360 Eye it almost feels as if they have a certain audience in mind. You know, the kind that's more interested in technical specifications than whether the vacuum is a good cleaner or not. 

There are so many other good things about the Dyson, not least of which is that if it actually does its job *you don't have to vacuum anymore*. 

Perhaps that's a better way to talk about it.

[1] Dyson Have Launched A New Product - Denise Wilton
 
3.0 Not Yet, But Soon
	•	The first military RAID deployment - formerly the acronym for a Redundant Array of Inexpensive Drives, instead, a Redundant Array of Inexpensive Drones. Tested out by the British Military in late 2014 with the first mass order of Dyson 360 Eye robots - in consumer use as cleaning robots - but firmware-flashed to provide border policing and intelligence for the Ukraine/Russia border. 
	•	Google Neighbourhood Watch is a free, voluntary program where you can help improve the security and privacy of your neighbourhood by signing up yourself - and your neighbours! - to install a drone and drone charging station at your house. Make sure you have permission from the landowner first, and as more of your friends and neighbours install Google Neighbourhood Watch on their property, your neighbourhood will benefit from the security and comfort of always knowing who's in your neighbourhood, and what they're doing. The Neighbourhood Watch cloud service seamlessly knits together all the data gathered from the individual drones and provides access to authorised Google accounts.
	•	You wish that you could ever have something as simple as the Three Laws. You won't. Imagine how complicated that legislation's going to be, if it ever comes about.
--

Friday. The plan is to go see the Space Shuttle Enterprise tomorrow, as well as a bunch of other stuff at Udvar-Hazy. Seeing family friends today, and their grown-up kids, one of whom is a confirmed Whovian, so we've got that going on. I am assured that a Real Live British Accent will go down a treat. DC remains, as ever, hot and muggy.

Send me notes. Tell me your space stories. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Five: "Web" "Content" "Strategy"; "Probably Not"; Firewall Earth; To Clean The House
Date: September 4, 2014 at 3:53:01 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hm5t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

2:13pm after a nice lunch and stimulating conversation. Stupid jokes on Twitter about the new Dyson 360 Eye robot vacuum for which a teaser video basically screams: hey, did you see Robocop? Wasn't it awesome when you had that point-of-view shot from the robot/Murphy and all the technicians futzing with him? And then they booted him up? Yeah, let's do that because THAT'S TOTALLY NOT A TIRED REFERENCE or something that paints you into a certain corner of culture. But hey, you're Dyson. Maybe someone else can make a vacuum cleaner for the rest of us who're not quite so into biting social satire and ultraviolence. 

DC, still. Hotel room. Wrote a bunch of notes for tomorrow's talk, some restructuring to do, probably later tonight as well as frantic image searching. Maciej Ceglowski is on tonight, so it's not like there's a hard act or anything to follow. Jesus Christ. Anyway, on with the show. 
 
1.0 "Web" "Content" "Strategy"

I've never seen Karen McGrane[1] talk before, but she opened up today's conference day with a section on content strategy, formally titled "Content in a Zombie Apocalypse", which was more-or-less this talk[2] on Slideshare.

McGrane made good points, but I felt like there was something deeper that didn't quite come out. The general gist for those following along at home is that people involved in "web content" and "web publishing" are having an increasingly difficult time because of all the different places the web (or: internet) has extended its tendrils. So "web content" can increasingly appear on unused internet fridges, in-car entertainment systems, mobile phones, digital signage and so on. McGrane makes a good case for the tyranny of paper - reminding us that it was Xerox that invented What You See Is What You Get, and one of the reasons why they invented it is because they'd just invented the Laser Printer, which needed an excuse to exist. And then, blink and you'll miss it because you end up with Microsoft Word, Adobe Photoshop still requiring canvas dimensions for new documents, badly made school newsletters and PDFs. 

McGrane's trying to get us to understand something important here when she talks about separating content from presentation. Mobile devices and fridges are all reminders that the "content" that we put on the internet can increasingly be consumed or interacted with or whatever in a variety of mechanisms, some of which might not even involve screens (to which those who've been dealing with assistive devices breathe a big sigh of where-the-fuck-have-you-been). 

I'd even go so far as to say that what we actually want to do is separate *meaning* from presentation. Clients/organisations want potentially unicorn systems that can take "content" and deploy it, in the right way, in whatever place, be that digital signage around a campus to a push message that gets delivered to mobile phones to a set of notices in whatever learning management system they use. 

But the tyranny of the page is pretty hard to get over, and the web hasn't really helped with that. 

I'd like to go a bit further though and say that the web has unhelpfully confused those of us in the land of content strategy. Because the web is - at the very least - two things: a protocol for the transport of information (the Hypertext Transfer Protocol part of the web) and a set of standards about how you define and display that information (the Hypertext Markup Language part), before you even get into Web 2.0 things like runtimes and server/client-side processing and scripting. 

My point here is that the *internet* is the real transport mechanism. The web as experienced by lay-people is just another display format mashed together *with* a transport mechanism, one that has been, over the last twenty to twenty-five years, predominantly associated with screens. 

But the way McGrane (rightly) wants us to think is that we have atoms of *meaning* that can be transported over the internet into wherever they may be: printed onto toast, 3D printed onto tissue-scaffolds, projected by laser onto the moon, released by water droplets timed to the millisecond or, even, printed out onto paper. 

In other words, content strategy for "places where there are electricity" or content strategy "for the internet" helps move a mindset away from content strategy "for the web" where web inherently is taken by lay-people to mean "something with a screen". 

Perhaps helping people think about content that way, rather than inherently screen-based, will help move us away from meaning and display-bound unfindable, unsearchable, unparseable blobs. 

[1] http://karenmcgrane.com and @karenmcgrane
[2] Content in a Zombie Apocalypse - Karen McGrane on Slideshare
 
2.0 "Probably Not"

I was doing that thing where I actually read a long-read on Medium: this particular one was about the abhorrent prosecution of scientists in Italy for a supposed failure to communicate the risks of an earthquake[1]. It's a compelling read, but one of the things that stuck out for me was something that was somewhat orthoganal to the actual point of the article (putting science on trial), and it was how humans deal with probabilities and risk. 

I mean, we know that we're not good at judging probabilities and dealing with risk. You didn't know that? You should (ha) know that. You should probably start with a Wikipedia grounding[2] that covers some of the cognitive biases and black holes we have in terms of risk perception. 

Anyway. I'm just going to wholesale quote the interesting bit, but you should also go away and read the entire article, too.
In the winter of 1951, a group of CIA analysts filed report NIE 29–51. Its aim: to examine whether the Soviets would invade Yugoslavia. And the bottom line? “Although it is impossible to determine which course the Kremlin is likely to adopt, we believe… that an attack on Yugoslavia in 1951 should be considered a serious possibility.” Once finalized, the report made its way into the bureaucratic machine.

A few days later, a State Department official met up with the intelligence whiz whose team had composed the report. What did serious possibility mean? The CIA man, Sherman Kent, said he thought maybe there was a 65 percent chance of an invasion. But the question itself troubled him. He knew what serious possibility meant to him, but it clearly meant different things to different people. He decided to survey his colleagues.

The result was shocking. Some thought it meant there was an 80 percent chance of invasion; others interpreted the possibility as low as 20 percent.

Years later, Kent published an article in Studies in Intelligence that used the Yugoslavia report to illustrate the problem of ambiguity, particularly when talking about uncertainty. He even proposed a standardized approach to the language used for risk analysis — “probable” to indicate 75 percent confidence, give or take about 12 percent, “probably not” for 30 percent confidence, give or take about 10 percent, and so on.

 - The Aftershocks, David Wolman

which just kind of blew my mind. Not only do we have massive holes in our cognitive architecture that are essentially probability-based backdoors into rooting our behaviour, but now we don't even know how to talk about them! It's some kind of deliciously evil double-jeopardy situation where: 

a) we don't understand and can't grasp probabilities without engaging our slow brains, or what Kahnemann calls System 2, the logical and non-intuitive aspect to our intellect; and

b) even when we do, we can't reliably communicate them!

It looks like the followup to Kent's findings are a more pragmatic attitude: instead of defining new expressions for quantified probability, a more descriptive attitude that looked at what the majority of people understood by certain expressions of probability and the advice to standardise on *those* definitions when you had a quantified probability. You can read more in the CIA's unclassified document Definition of Some Estimative Expressions[3] which is a pretty good idea to what some people, at least, think when you say "probably". 

[1] The Aftershocks by David Wolman on Matter / Medium
[2] Risk Perception - Wikipedia
[3] Definition of Some Estimative Expressions - CIA
 
3.0 Firewall Earth

It's a standard SF trope - invasion/co-option of our planet and species by way of an infovirus or a meme or whatever. So the idea of creating a planetary firewall[1] - physical or informational - is interesting. Imagine that: national missile defence, or Star Wars - for the entire planet. A Dyson Sphere, not for capturing the total energy output of our sun, but because we're scared of what's out there. The Red Scare, but not from just one country, on our doorstep, but the *entire universe* as a possible threat, ready to infect us just by us being in the way of stray EM radiation. Celestial spheres not to explain the movement of the stars, but to protect us from them. 

But then, how would you implement the software version? Do you end up with the whole problem of needing to emulate a human, emulate consciousness or ten-odd-billion in order to see whether to let the packets through? Do you nominate a demilitarized zone, a sort of safe human colony out on Europa where humans are free to accept-all packets from the rest of the universe, and watch them from a distance with a sharp stick? Would you have volunteers? (Probably!)

And anyway, what sort of material do you train a Bayesian filter to work on for a universal firewall? Hey, here's a list of previous Outside Context Problems, just make sure no more get through, ok? 

It doesn't feel *that* inconceivable, though. Fear motivates so much in the wake of a threat. London's Ring of Steel, so many years ago. NMD. TSA and wholesale terahertz screening of air passengers. But, like I pointed out, we can't assess risk correctly. So a species-terminating risk like infection via alien infovirus? Low risk. Asteroid? Low risk. Shoe-bomber? OMG shut all the borders.

[1] Can You Ever Really Know An Extra-Terrestrial? - Caleb Scharf, Nautilus
 
4.0 To Clean The House

The Dyson 360 Eye Robot[1] - a product that wants you to know that it can see everywhere and is a robot, but not necessarily that it's a vacuum cleaner. One that riffs off science fiction tropes in its teaser video and recalls Robocop[2], with prime directives and interlaced video and all: every trope you could reasonably think of, thrown into the can for the marketing mix. A launch website that recalls the Mac Pro, hijacked scrolling (of which I'm guilty of, too) and rendered CGI showing cutaways of highly advanced technology. Tank treads, for operating in hostile tactical environments. That blue LED for, well, what other colour should an LED on consumer technology be? 

An alternate Patrick Farley Spiders-esque future where the British Government throws just a few million pounds toward Dyson, orders several tens of thousands of robots and uses them to police the Ukraine/Russia border. Another one where Amazon counters with drone cleaning robots - the ideal combination of automation and cheap human labour, robots that can clean your house, humans who guide them to make sure they get that bit under the table that your cleaners always miss, ones that use the always-on camera to identify products in your house and email you offers for substitutes or click-n-save subscribe deals. 

Robots. Everywhere and networked.

[1] http://www.dyson360eye.com
[2] Dyson project N223: what new technology is ready for launch? - Official Dyson Video
--

4:50pm. Maciej Ceglowski on in about 25 minutes. My talk notes in a TextWrangler scratchpad, looking forward to doing those image searches and captions later tonight. The usual pre-talk nerves. It'll all be OK. Just send me your notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Four: The Networked Lens; Twitch; Sufficient Density
Date: September 3, 2014 at 10:29:43 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hlel=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Is it really hiding if you're telling a whole bunch of people you're hiding? In any event: crashed in my hotel room in DC having made wonderful intentions of going to all of today's conference talks and didn't sleep well at all. Woke up most of the night and did that thing where you perpetually hit the snooze button before deciding (and, I guess listening to my somewhat bruised and battered body) that maybe I should just give in and try to sleep for a bit. 

This hotel room doesn't have a minibar, but it does have one of those G-Link ports just in case you're the kind of person who carries a spare HDMI cable to plug their laptop into the TV. Or, you know, you want to plug in an S-video video source. Because...? I'm not sure. This hotel is also the kind where your room can look out onto a massive internal atrium, and the feeling that you're less in a building and more an arcology, a sort of vertical spaceship full of identical corridors and maintenance lines, lifts, cubbies, support staff. I've only ever been on a cruise ship once - a family holiday - and it felt like we were living in a shopping mall. If we ever do get off this planet and start heading somewhere, anywhere else, how long until those ships feel like shopping malls, too?

So: 1pm. Hotel room. Room service ordered. Writing now. Plans to reorganise my talk for Friday. Looking at an email backlog. Buddy-taping my toe.
1.0 The Networked Lens
The collision of two things in my head: Derek Powazek's earlier essay, The Third Wave of Photo Sharing[1] from which I pulled his coined phrase "the web created the modern camera" for episode one hundred and thirty eight[2] and, predictably, the celebrity photo theft that now looks like it wasn't the product of one specific flaw, but more the implosion of a ring of secrecy around nude celebrity photo trading darknets[3].

Amidst all of this, lots of hand-wringing, and I'm not excusing myself from this, on what the "cloud" is and whether we people should be afforded reasonable expectations of privacy and security, a whole bunch of victim shaming and at the same time probably not enough recognition of the nuance that you can be a high-profile target or a low-profile target or anywhere in between. That said, I think it's possible these days for *anyone* to be a high-profile target. In other words, what made Jennifer Lawrence a high-profile target was her celebrity, what makes *you* a high profile target is the fact that you might at one point have, or have had, a jilted ex-lover. 

And then: even more decisions to be made, even better (more understood? more transparent?) products to be made and their benefits communicated. John Gruber asserts that we're missing the silent benefit of having automatic backups[4] with services like iCloud and Google+ Photos - but this strikes me as being the trade-off that you have to make that you don't really want to have to make. Your choice is binary at the moment: either back nothing up automatically, or back everything automatically. But in the same way that people would look at Facebook and see a collapse of context around who you're friends with and the environments in which you interact with them (on this, I frequently cite Matt Locke's Six Spaces of Social Media[5], but you could also pick up a copy of danah boyd's latest[6] for an introduction to context in computer-mediated social relationships), you have a singular application that's used in a variety of contexts - business and personal, at the very least - for which there is only one backup setting: on or off.

You can see Apple's dilemma: they want to make things that are simple to understand, easy to use and that more often than not, do the Right Thing and don't offer surprises. So what are some alternatives? Not using the main Camera app, the one that, at least until iOS 8 has been privileged in accessing certain camera functions? Using separate photo-taking apps that back up to their own stores? Remembering which app to use when you want to take a photograph? Those don't sound particularly intuitive, but they're off-the-top-of-my-head thoughts on how you might start to separate out these different use-cases. 

I was reminded by Chris Locke of Dave Eggers' The Circle[7], a sort of Swiftian cautionary tale as to what the geniuses are up to in Silicon Valley busy inventing the future, and whilst Eggers can come in for a lot of criticism for not actually knowing what he's talking about in terms of *specifics*, I can honestly say that the *feel* of the novel is remarkably accurate in spaces. There is, undoubtedly, a sense of *mission*. But anyway.

As Powazek says that the Web created the Modern Camera, the field of connectivity is the next upgrade. We kind of know this because we keep talking about the Internet of Things, but celebrity photo hacking is a sort of weak signal of what happens when all lenses are networked. Pretty soon it will be easier - or even *cheaper* for you to get something that takes photos and has them automatically backed up, somewhere. You will not know, nor would you be expected to know, I suppose, whether that online store is "secure" or not. In other words, if you wanted to unbundle even more (and this goes against the tendency for bigger, more expensive things to aggregate in computing devices), you could imagine free-at-the-point-of-consumption cameras, hooked into ubiquitous wireless network coverage, that came with their own backup store either ad-funded or subscription funded. Free cameras. Lifetime storage. Just click past this message from our sponsor. Or, you know, Amazon provides the service and runs backend vision processing spun-up on its servers that will dynamically provide buy-it-now links when you view the photos. 

The point that I'm taking from Powazek's essay is that the default will be - in case it isn't obvious already - that all photographs taken *will be* online. They are only marginally hard to get online now, and that'll become even easier. The first internet of things object may well have been the lens.  

[1] The Third Wave of Photo Sharing - Derek Powazek
[2] Episode 138: The Web Created The Modern Camera
[3] Notes on the Celebrity Data Theft - Nik Cubrilovic
[4] Security Trade-Offs  - Daring Fireball
[5] Six Spaces of Social Media - Matt Locke
[6] It's Complicated - danah boyd
[7] The Circle - Dave Eggers / Amazon
 
2. Twitch

At dinner with one friend and a new acquaintance, scratching our heads as to how so many other companies could have passed up the chance to buy Twitch. For about $1bn, a steal for Amazon, because if you're reading the signs and portents right, then this is pretty much an instant replay of what happened when Google bought YouTube, only, as pointed out by my friend - we know what happened when Google bought YouTube. 

So, here's who didn't buy Twitch: Disney (ABC, ESPN, any number of videogame properties), Sony (media outlets, televisions, videogames and videogame consoles), Microsoft (perpetual failed media/entertainment ambitions, not really sure what it's doing online other than "services", videogames and videogame consoles), GoPro (an emerging media brand in its own right, and yes, I shoot myself for writing "media brand"), Red Bull (which will be interesting to watch because they've focussed on "live" stuff, it feels), Any Other Broadcaster Worth Their Salt and, obviously, YouTube. 

Look, we know these things: we know that live events work. We know that championship videogame matches are routinely returning concurrent streams in excess of 5 million viewers, and cumulative viewer figures are just a bit mental[1]. So you'd think broadcasters would be looking at this sort of thing and saying: hm, what other live events could we capitalise upon? You don't even have the problem of needing physical space, in a sense, to start with videogame streaming, and it's only going to get easier.

Is it the cultural legitimacy problem? Is it that the broadcast networks are still looking down on their noses toward the "gamers" - and after the last few weeks, who could blame them? Probably, yeah: these types of cultural change don't happen quickly, they happen when they happen and what mostly needs to happen is that management needs to age out and get out of the way for the people who understand what's going on, most of the time. 

Twitch is going to be a big deal. It'll be interesting to find out who else was in the running. 

[1] The International Dota 2 tournament watched by more than 20M viewers, Valve says - The Verge
 
3. Sufficient Density

The idea behind Miranda July's Somebody[1] isn't necessarily a new one, but it's one of those ideas whose time is just about coming. Basically, a sort of real-life implementation of Bruce Sterling's Maneki Neko[2], the realisation that when you have a sufficient density of network connected people, you can treat them like, well, nodes in a connected network. And you can use them to route packets from one to another. It's the kind of thing that people would've had the idea for years ago - the writing's been on the wall for ages for this kind of thing - but that tech people get a bit too excited about, or only really works as an art project (which, to be fair, is what July's project is) because you need that Sufficient Density. But, we kind of have it now. It's a sort of phase change. You see it in Bluetooth-powered mesh networking chat apps like Firechat[3] - no reliance upon existing network infrastructure, just on the individual nodes having sufficient density to throw up a network. Again, mesh networks have been on the weak-signal radar for years, but they've always relied upon having some sort of extant infrastructure that can be repurposed. In Cory Doctorow's Little Brother, the in-universe equivalent of the Xbox 360 is repurposed through live boot CDs that bring up a custom, unauthorised operating system that creates an ad-hoc mesh network using the built-in wireless adapters in consumer gaming hardware.  

But now - what's the density of smartphones that can run a Bluetooth stack in the background, act as a little anonymous identifier and pass off packets to each other in the wild? Or, think about it this way: given what state actors did with Stuxnet, and how it got to where it needed to go, and how many zero-day vulnerabilities went into it, what could you do with a massive network of rootable phones? 

This is partly what's meant by software as a material - there's a computing substrate that's been deployed in our cities, and whether you're Team Android or Team iOS, there are enough of them out there for you to think of this as a computing substrate, a nascent infrastructure that's just lying in wait. Until recently, we haven't had the battery life, hardware and OS maturity to have persistent, low-power connections on devices, but now we do thanks to protocols like Bluetooth LE. And that's just the malware - what could Transport for London do with a smartphone based mesh network? 
 
[1] Somebody
[2] Maneki Neko - Bruce Sterling
[3] The Latest Chat App for iPhone Needs No Internet Connection - MIT Tech Review
[4] Little Brother - Cory Doctorow
--

10:20pm, a day full of hiding in the hotel room and doing things like re-watching Captain America: The Winter Soldier (did you notice that the bit where Black Widow is making backups and then has to dive through a window because of a grenade has a pretty much identical counterpart with Zhen in Mission: Impossible 3, when the team is extracting Lindsey?), the first of the new Capaldi Doctor Who and listlessly poking at the internet, suspiciously eying a bottle of prescription hydrocodone sitting on the desk, being irritated by the pain down my left side. 

Send notes. Tomorrow is the day before my talk on Friday, so I'm going to be a gibbering wreck, as always.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Four: The Networked Lens; Twitch; Sufficient Density
Date: September 3, 2014 at 10:12:38 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident

Is it really hiding if you're telling a whole bunch of people you're hiding? In any event: crashed in my hotel room in DC having made wonderful intentions of going to all of today's conference talks and didn't sleep well at all. Woke up most of the night and did that thing where you perpetually hit the snooze button before deciding (and, I guess listening to my somewhat bruised and battered body) that maybe I should just give in and try to sleep for a bit. 

This hotel room doesn't have a minibar, but it does have one of those G-Link ports just in case you're the kind of person who carries a spare HDMI cable to plug their laptop into the TV. Or, you know, you want to plug in an S-video video source. Because...? I'm not sure. This hotel is also the kind where your room can look out onto a massive internal atrium, and the feeling that you're less in a building and more an arcology, a sort of vertical spaceship full of identical corridors and maintenance lines, lifts, cubbies, support staff. I've only ever been on a cruise ship once - a family holiday - and it felt like we were living in a shopping mall. If we ever do get off this planet and start heading somewhere, anywhere else, how long until those ships feel like shopping malls, too?

So: 1pm. Hotel room. Room service ordered. Writing now. Plans to reorganise my talk for Friday. Looking at an email backlog. Buddy-taping my toe.
1.0 The Networked Lens
The collision of two things in my head: Derek Powazek's earlier essay, The Third Wave of Photo Sharing[1] from which I pulled his coined phrase "the web created the modern camera" for episode one hundred and thirty eight[2] and, predictably, the celebrity photo theft that now looks like it wasn't the product of one specific flaw, but more the implosion of a ring of secrecy around nude celebrity photo trading darknets[3].

Amidst all of this, lots of hand-wringing, and I'm not excusing myself from this, on what the "cloud" is and whether we people should be afforded reasonable expectations of privacy and security, a whole bunch of victim shaming and at the same time probably not enough recognition of the nuance that you can be a high-profile target or a low-profile target or anywhere in between. That said, I think it's possible these days for *anyone* to be a high-profile target. In other words, what made Jennifer Lawrence a high-profile target was her celebrity, what makes *you* a high profile target is the fact that you might at one point have, or have had, a jilted ex-lover. 

And then: even more decisions to be made, even better (more understood? more transparent?) products to be made and their benefits communicated. John Gruber asserts that we're missing the silent benefit of having automatic backups[4] with services like iCloud and Google+ Photos - but this strikes me as being the trade-off that you have to make that you don't really want to have to make. Your choice is binary at the moment: either back nothing up automatically, or back everything automatically. But in the same way that people would look at Facebook and see a collapse of context around who you're friends with and the environments in which you interact with them (on this, I frequently cite Matt Locke's Six Spaces of Social Media[5], but you could also pick up a copy of danah boyd's latest[6] for an introduction to context in computer-mediated social relationships), you have a singular application that's used in a variety of contexts - business and personal, at the very least - for which there is only one backup setting: on or off.

You can see Apple's dilemma: they want to make things that are simple to understand, easy to use and that more often than not, do the Right Thing and don't offer surprises. So what are some alternatives? Not using the main Camera app, the one that, at least until iOS 8 has been privileged in accessing certain camera functions? Using separate photo-taking apps that back up to their own stores? Remembering which app to use when you want to take a photograph? Those don't sound particularly intuitive, but they're off-the-top-of-my-head thoughts on how you might start to separate out these different use-cases. 

I was reminded by Chris Locke of Dave Eggers' The Circle[7], a sort of Swiftian cautionary tale as to what the geniuses are up to in Silicon Valley busy inventing the future, and whilst Eggers can come in for a lot of criticism for not actually knowing what he's talking about in terms of *specifics*, I can honestly say that the *feel* of the novel is remarkably accurate in spaces. There is, undoubtedly, a sense of *mission*. But anyway.

As Powazek says that the Web created the Modern Camera, the field of connectivity is the next upgrade. We kind of know this because we keep talking about the Internet of Things, but celebrity photo hacking is a sort of weak signal of what happens when all lenses are networked. Pretty soon it will be easier - or even *cheaper* for you to get something that takes photos and has them automatically backed up, somewhere. You will not know, nor would you be expected to know, I suppose, whether that online store is "secure" or not. In other words, if you wanted to unbundle even more (and this goes against the tendency for bigger, more expensive things to aggregate in computing devices), you could imagine free-at-the-point-of-consumption cameras, hooked into ubiquitous wireless network coverage, that came with their own backup store either ad-funded or subscription funded. Free cameras. Lifetime storage. Just click past this message from our sponsor. Or, you know, Amazon provides the service and runs backend vision processing spun-up on its servers that will dynamically provide buy-it-now links when you view the photos. 

The point that I'm taking from Powazek's essay is that the default will be - in case it isn't obvious already - that all photographs taken *will be* online. They are only marginally hard to get online now, and that'll become even easier. The first internet of things object may well have been the lens.  

[1] The Third Wave of Photo Sharing - Derek Powazek
[2] Episode 138: The Web Created The Modern Camera
[3] Notes on the Celebrity Data Theft - Nik Cubrilovic
[4] Security Trade-Offs  - Daring Fireball
[5] Six Spaces of Social Media - Matt Locke
[6] It's Complicated - danah boyd
[7] The Circle - Dave Eggers / Amazon
 
2. Twitch

At dinner with one friend and a new acquaintance, scratching our heads as to how so many other companies could have passed up the chance to buy Twitch. For about $1bn, a steal for Amazon, because if you're reading the signs and portents right, then this is pretty much an instant replay of what happened when Google bought YouTube, only, as pointed out by my friend - we know what happened when Google bought YouTube. 

So, here's who didn't buy Twitch: Disney (ABC, ESPN, any number of videogame properties), Sony (media outlets, televisions, videogames and videogame consoles), Microsoft (perpetual failed media/entertainment ambitions, not really sure what it's doing online other than "services", videogames and videogame consoles), GoPro (an emerging media brand in its own right, and yes, I shoot myself for writing "media brand"), Red Bull (which will be interesting to watch because they've focussed on "live" stuff, it feels), Any Other Broadcaster Worth Their Salt and, obviously, YouTube. 

Look, we know these things: we know that live events work. We know that championship videogame matches are routinely returning concurrent streams in excess of 5 million viewers, and cumulative viewer figures are just a bit mental[1]. So you'd think broadcasters would be looking at this sort of thing and saying: hm, what other live events could we capitalise upon? You don't even have the problem of needing physical space, in a sense, to start with videogame streaming, and it's only going to get easier.

Is it the cultural legitimacy problem? Is it that the broadcast networks are still looking down on their noses toward the "gamers" - and after the last few weeks, who could blame them? Probably, yeah: these types of cultural change don't happen quickly, they happen when they happen and what mostly needs to happen is that management needs to age out and get out of the way for the people who understand what's going on, most of the time. 

Twitch is going to be a big deal. It'll be interesting to find out who else was in the running. 

[1] The International Dota 2 tournament watched by more than 20M viewers, Valve says - The Verge
 
3. Sufficient Density

The idea behind Miranda July's Somebody[1] isn't necessarily a new one, but it's one of those ideas whose time is just about coming. Basically, a sort of real-life implementation of Bruce Sterling's Maneki Neko[2], the realisation that when you have a sufficient density of network connected people, you can treat them like, well, nodes in a connected network. And you can use them to route packets from one to another. It's the kind of thing that people would've had the idea for years ago - the writing's been on the wall for ages for this kind of thing - but that tech people get a bit too excited about, or only really works as an art project (which, to be fair, is what July's project is) because you need that Sufficient Density. But, we kind of have it now. It's a sort of phase change. You see it in Bluetooth-powered mesh networking chat apps like Firechat[3] - no reliance upon existing network infrastructure, just on the individual nodes having sufficient density to throw up a network. Again, mesh networks have been on the weak-signal radar for years, but they've always relied upon having some sort of extant infrastructure that can be repurposed. In Cory Doctorow's Little Brother, the in-universe equivalent of the Xbox 360 is repurposed through live boot CDs that bring up a custom, unauthorised operating system that creates an ad-hoc mesh network using the built-in wireless adapters in consumer gaming hardware.  

But now - what's the density of smartphones that can run a Bluetooth stack in the background, act as a little anonymous identifier and pass off packets to each other in the wild? Or, think about it this way: given what state actors did with Stuxnet, and how it got to where it needed to go, and how many zero-day vulnerabilities went into it, what could you do with a massive network of rootable phones? 

This is partly what's meant by software as a material - there's a computing substrate that's been deployed in our cities, and whether you're Team Android or Team iOS, there are enough of them out there for you to think of this as a computing substrate, a nascent infrastructure that's just lying in wait. Until recently, we haven't had the battery life, hardware and OS maturity to have persistent, low-power connections on devices, but now we do thanks to protocols like Bluetooth LE. And that's just the malware - what could Transport for London do with a smartphone based mesh network? 
 
[1] Somebody
[2] Maneki Neko - Bruce Sterling
[3] The Latest Chat App for iPhone Needs No Internet Connection - MIT Tech Review
[4] Little Brother - Cory Doctorow
--

10:20pm, a day full of hiding in the hotel room and doing things like re-watching Captain America: The Winter Soldier (did you notice that the bit where Black Widow is making backups and then has to dive through a window because of a grenade has a pretty much identical counterpart with Zhen in Mission: Impossible 3, when the team is extracting Lindsey?), the first of the new Capaldi Doctor Who and listlessly poking at the internet, suspiciously eying a bottle of prescription hydrocodone sitting on the desk, being irritated by the pain down my left side. 

Send notes. Tomorrow is the day before my talk on Friday, so I'm going to be a gibbering wreck, as always.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Three: Not Doing A Nick Bilton; Counterexamples; echofuckingpraxia
Date: September 2, 2014 at 1:36:05 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hk11=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
Back from hiatus. I had wanted to simply send a note yesterday saying "Dan Hon is on holiday," but instead I can blame it on having a Human Accident, yet another entry in the ongoing series of "Stupid Things Baseline Humans Do To Injure Themselves". 

Friday night, and I managed (don't laugh) to topple myself, in slow-motion and glacier-like, over the bannister on our porch as I leant over to drop the compost into the compost bin, breaking a tooth off and concussing myself. One trip to the ER and a trip to an emergency dentist, the threat of a root canal (something that apparently is nowadays significantly less scary than it actually is) and instead a temporary crown later (my teeth!) and I'm back on a plane on my way to DC to speak at the HOW Interactive Design Conference. 

So: no newsletter on Friday night due to being stuck in an ER, no newsletter on Monday due to slow recuperating and it was also Labor Day in the US. Instead: newsletter today! High fives all around.
1.0 Not Doing A Nick Bilton

I'm not going to "do a Nick Bilton" and victim blame - but what I do think is worth taking is what I hope comes across as a nuanced position. 

Given that a) we find it hard to gauge risk in the first place and b) that we find it even harder to gauge risk when we don't have the information (and we acknowledge that it's hard to find time to properly educate ourselves int he first place) and c) the vast majority of the "information" and understanding in the celeb-photo-hacking is in "how invisible infrastructure works", hence all the Explainers in today's media about WHAT IS THE ICLOUD (calling to mind instantly Nightvale-esque Dog Park/Glow Cloud feelings): what did we expect?

We could say that celebrities are a higher-profile target so the risk profile for them is different than your ordinary joe. On the other hand, the rise of doxxing as a vigilante technique for those wronged on the internet seems to open up the opportunity for anyone to be treated in the same was as a celebrity - as a target. So you could even look at it this way: means, motive and opportunity to try to break down where, and what, type of failings were involved in this latest hack. 

Motive is perhaps the easiest one to get out of the way if we're just looking at technology and its effects on society. The targets were female celebrities, doing nothing other than living in a toxic, misogynistic environment that treated them as objects to be pawed and masturbated over - the latter brought starkly into relief in a yeah-we're-winking-and-it's-self-referential-so-it's-ok  through the usage of the #thefappening hashtag. 

But means and opportunity are where it falls down, for me. For those saying "don't take nude photos of yourself, and don't store them online", I feel that, aside from victim-blaming, we're just opening up a can of worms in terms of risk assessment and how we expect people to live these days. 

In other words, and as I said to a friend: we can point at one of the new wonders of the world, the most democractic communications networks that we've ever built, that is relied upon for secure financial transactions and that we trust implicitly in some regards, and we say that you shouldn't use that self same network for private photographs? Really? (The fair point here is that certain aspects of information are one-shot, binary all or nothing. Financial transactions are reversible and money can be returned, not so something that can't be unseen - Suw Charman-Anderson has written particularly well on this point regarding the one-shot nature of irreplacable biometrics[1])

So it all comes down to trust: one of the people I was talking to last night remarked (somewhat sarcastically, I think) that apparently the little green lock icon in a browser bar apparently means nothing these days, and they're not half wrong. 

Password security doesn't even come into it in this situation, at least not if the current best-guess of a vulnerability in iCloud in its lack of rate-limiting login attempts is what happened. A better password wouldn't have helped. iCloud's login design at that particular entry point was defective. There's no other way to say it. It wasn't a bug - it was designed badly, like a bridge that was going to fail - a structural failing. 

At what point as technologists are we able to allow our users to expect basic security? If it had been a zero-day, fine, if it had been heartbleed, then Apple's fault would be different. But in my position as self-appointed armchair internet pundit in the sky (I'm nothing if not aware of my mouthing off of nothing more than my own opinion), this *was* Apple's fault. 

You can point to things like warranties and disclaimers and the fact that if you actually read the terms and conditions to all of these services there's not a lot you can do about it. But, as Sarah Jeong pointed out last night, "WE BUILT A SHITTY INTERNET AND YOUR ONLY CONSTRUCTIVE SUGGESTION IS SEXY PEOPLE SHOULDN'T USE IT."[2]

So, here's a suggestion: design practices for good security to build trust with users. If users have a responsibility to be informed then at the least we have the responsibility to build systems that they can trust. And I'm not saying that we have the responsibility to build one-hundred-percent secure systems because such things are impossible to build. But what we can do is make sure that we don't make basic mistakes and show that privacy and security are important to us in the products and services that we build. 

Things like: two factor auth should be available as an option. Logons at all entry points should be rate-limited. No emailing passwords in the clear. SSL, all the time. 

What's potentially frustrating is that these are not brand new security or privacy principles that have suddenly been derived in the last year or so. These aren't new ideas. They should be basics. 

For example, we should aim for consistency. When a user knows that their iPhone will lock if the enter the wrong password five times in a row, it is reasonable that their assumption would be that anything else tied to that account - for example, their iCloud login on a web portal - would also lock upon five logon failures in a row. Whyever not? Apple, after all, pride themselves on their hardware and software integration. 

[1] Oh, What Big Eyes You Have! - Suw Charman-Anderson
[2] https://twitter.com/sarahjeong/status/506646968811024384
2.0 Counterexamples
Sometimes I get a bit narrow-minded, so I idly asked on Twitter how libertarians (a vague term if there was one, and not being helpfully specific) got common infrastructure projects done, to which Danny O'Brien was kind enough to send me an email that was really, really long and really, really helpful. Now I know what it's like reading one of these, I think. In any event, at least one of the things that he did was to point out a bunch of examples where you don't need a coercive power like a government to get things done and produce things for the common good. 

O'Brien reminded me about bits of pre-World War 2 infrastructure that have since become codified. Trains, canals, roads (but not motorways) and electricity standards, never mind more recent innovations like TCP/IP, keyboard layouts, the Twenty-Foot-Equivalent Unit of shipping containers, and Blu-Ray (whether or not you think they're *good* standards) have all come about through self-interested groups acting together and figuring a way to hash things out. 

So yes: all of that's good, but I think what I lack in the ability to express myself in 140 characters is something like this: I'm specifically thinking about the example of compulsory purchase orders in the UK, or eminent domain in the United States - what happens when someone decides that the best place to put a road, on balance, for everyone, is right through where your house is? And this is where O'Brien helped to clarify the crux of my thinking: is it better to force everyone to behave well, or is it better to never use the power to force people do something? 
3.0 echopraxiafuckingexhopraxia

There are probably spoilers for Peter Watts' novels Blindsight and Echopraxia in this section.

I finished Peter Watts' latest, Echopraxia[1], shortly after it came out, doing that kind of binge-reading that author-devotees get thanks to the frustrating publisher release cycle (as in that particularly first-world problem of just not having enough *patience* to wait until something comes out). Pretty much straight after finishing Echopraxia I went on to re-read Blindsight, because the former helped me figure out the bits I liked about the latter. 

Turns out the bit that I liked about Blindsight were the Big Smart/Dumb Object and its inhabitants and the idea that there can be these *things*, in much the same way that we might be thought of as Big Dumb Objects by all the flora that live on and inside us. Are we just a giant spaceship for gut bacteria? Or even for the tiny mites that live in the pores on our faces? 

I felt like the consciousness stuff got a bit thin - not necessarily repetitive, but that it wasn't what I was getting the most enjoyment out of. That was for the idea of Portia, the idea of consciousness as time-sharing, that when you have just a bundle of neurons all you did is slow reality down and do all of your processing up front. Portia may well do all of that planning, but that's a hell of a lot of planning. I liked being confronted with that kind of alien and unfamiliar, and it was the same kind of deal that you got with the Primes in Peter F. Hamilton's space opera series. 

It's a hard book - there's a lot going on and a lot to keep in your head, but it's not like one of Hannu Rajaniemi's Quantum Thief series or Stephenson's Anathem where there's a bunch of new language you need to figure out just to make sense of what's happening in the world. But there's also an element of waiting for the other shoe to drop - by now, we know enough of the world that Watts has painted for us that Bruks' presence isn't an accident and you're kind of sitting pretty trying to figure out why everyone's so eager to keep a baseline pet on board. 

[1] Echopraxia - Amazon.com

--

That's all for today. As ever, send me notes, and I really like it when people drop a line even to just introduce themselves.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty Two: Car!; The Robots Work For Tim Ferris; Diversity; 2014 (6)
Date: August 28, 2014 at 6:29:13 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hgut=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I started writing this yesterday morning, straight after I'd sent that day's delayed episode. It's 3:30pm on Thursday and I'm feeling a bit overwhelmed with the sheer amount of admin that feels like the programmer equivalent of yak-shaving: dealing with the corporate travel agent for the next two conferences I'm speaking at, buying wedding presents for dear friends and trying to work out where to get them delivered so it'll cause as little stress as possible (because you know you can't just order stuff from Amazon as a present because thanks to their wonderful UK last-mile delivery problem of consistently failing to actually deliver.
1.0 Car!
Tuesday was the return leg of a short family vacation - roughly six hours of driving through California and Oregon and time to check out some of the Awesome! New! Stuff! in our new car. Our 2014 Subaru Outback has EyeSight - Subaru's brand name for collision avoidance, car-tracking and lane-wandering technology. Yesterday was trying out the adaptive cruise control system, which as a Brit is a novel thing because, I don't know, I don't feel that cruise control is a thing that we use much of in England because the country really isn't that big and the roads normally aren't that straight and go on FOR EVER like they do in America.

But anyway.

There's part of the multi-function display in the driver - cockpit, I guess? - that's a shiny OLED type screen, super nice and bright, and which displays stuff like the "Hey! the car ahead of you has started moving!" notifications and the "It looks like you're changing lane! Did you mean to do that?" iconography. 

Perhaps it's because I anthropomorphise things, but when using the adapative cruise control system, I get to set how far I'd like to be behind the car in front (as far as possible, please, which annoys the fuck out of the majority of American drivers, I've found) and the display shows me whether or not the car sees another car in front of it.

A long time ago - back when I still lived in London, I think, I remember going round to BERG's offices and Matt Jones talking about the whole Be As Smart As A Puppy thing[1]. My car isn't even as smart as a puppy, really, or it might be if all the different bits of its brain talk to each other. 

Here's what I mean: there's a bit of my car that's really good at recognising car-shaped things. Like, really good! And it gets excited about them, because when it sees a car, it beeps, and it shows me a picture of a car. And then when the car goes away, it beeps again, and it takes away the picture of a car. It does this. All. The. Time. It is like a little puppy: it can recognise cars! I am very proud of my car. I would pat its steering wheel as it yet-again recognised another car and say "Good car, good recognising!" My wife rolls her eyes at me. 

When I turn on this feature, my car is like a slightly less vocally expressive version of my eighteen month old son, who has a Tractor Recognition Algorithm that is a little bit loosely tuned at the moment (ie. it's a bit excitable and liable to recognise things as Tractors when they're not Tractors). My car cannot, however, pat its head and do the ASL for "hat" and then sign "book" and ask for the I Want My Hat Book to be read to it.

OK, thank you anyway.

There was another thing about the car that was a nice little spot of anthropomorphisation. The TPMS light kept coming on every now and the and apart from making my wife and I make TPS report jokes at each other, it turned out to be the Tire Pressure Management System telling us that there might be something up with the pressure of one of the tires. We stopped in at a very nice car shop along the way and had a chat with one of the mechanics there, who described the TPMS as something with a radio and a sensor in each tire (and the spare) and every so often, the car would say: "Hey tires, are you OK?" and each tire would check in and say "hello hello, tire number one, I'm OK". 

I mean, this is essentially right and why geeky people think the Story of Ping is funny: my car is full of things that can recognise things and tiny little submodules of specific functionality. The bit of my car that recognises cars, and when they've moved! The bit of my car that talks to tires! The bit of my car that *is* tires, and talks to other bits of my car!

Pretty soon, these things start adding up. Hearing my car go beep every time it recognises a car is like watching a baby learn to smile when it sees the face of another human that it recognises. It feels like the first glimmers.

[1] Be As Smart As A Puppy - BERG
2.0 The Robots Work For Tim Ferris
I'm not sure how this one popped into my head, but whatever: Tim Ferriss' 4-Hour Workweek mashed into my head unexpectedly against the The Robots Are Stealing Our Jobs meme. I have to admit: I couldn't finish Tim's book because something about his personality just grates with me. But, never finishing a book or not properly researching something hasn't ever stopped someone from having an opinion or thinking out loud, and I'm definitely doing the latter. So: on with unresearched opinions and general gut-feelings. 

One way of thinking about Tim Ferriss is that he's adept at looking at systems (systems-thinking-klaxon) and figuring out how to rework them or deploy them to his advantage. He's not interested in having a job, and he's interested in optimisation. He's still working - a lot of what I think he does that he inexplicably doesn't count in his 4 hours of working a week is that type of forward-planning architecting. 

So: the robots are working for Tim Ferriss. Sometimes they're actual robots - perhaps more software bots than physical robots - and sometimes they're meta-robots, intricate or not-so-intricate systems that he can set up to generate passive, low-maintenance income for him. But he's certainly not doing "work" or having a "job", and yet at the same time, those systems that he's setting up that generate the passive, low-maintinance income are also at risk from disruption. So he has to keep hustling and keep working out what the next system to deploy is. It's certainly an existence, and a particular one that requires a different set of skills than ones that we (society) traditionally trains people for through the industrial-era education system. But, I'd argue (somewhat hand-wavingly) that it's people like Ferriss (whether you agree or get on with his personality or not) that are able to see networks and figure out how to extract value from them. That latter phrase is where it gets a bit difficult, because some people can get uncomfortable with the idea of value-extraction rather than value-generation because if what Ferriss is doing *most* of the time (I don't know - I haven't read the book, remember?) is finding opportunities to arbitrage then he's just kind of moving bits around and skimming off the top. Or to put it another way: is Ferriss gaming the system, or making systems work for him?

When I first read Ferriss' book I remember thinking that he'd replaced "work" with administration and then worked to replace the administration. Part of what irks me about the way we talk about productivity advances is that they typically don't take into account the user experience. If you're going to count the massive availability of free net-provided replacements for formerly paid-for products (ie the idea that you can stop going to the movies because you can watch them for free on YouTube, or you don't need to subscribe to the newspaper anymore because of Google News or you don't need to pay for cable any more because...), then you also have to account for the productivity *loss* in badly-administered and user-unfriendly systems. You can't have it both ways. You can't say that PCs were great as a productivity advance and simultaneously say that they didn't also have a productivity drag as anyone who's had to do parental tech support can attest.

Hm. Productivity Drag. That might be coming tomorrow.
3.0 Diversity
So follow my train of thought: first there was this image[1] that showed up in my Twitter feed, the latest salvo in the misogyny-wars currently wracking "gamer" culture for which I'm not even going to point to anything other than the aforementioned image, suffice to say that there are some people who happen to play games who are, bluntly, offensive children who need to grow up. 

Then there was the thought of comparing what's happening to "gamer" culture to what happened to football (soccer) fans in the 1980s and 90s in the United Kingdom with hooliganism and racism (the latter of which is arguably still a problem, the former of which was dealt with by specific legislation, too) and never mind the whole "gamer" identification being a thing other than what was seen as a fringe/minority interest needing to protect itself, I mean it's not like (and I've been saying this in talks and presentations for literally YEARS now) we talk about "televisioners" or "musicers". 

But anyway.

Then there was taking a look at my own male/female follower ratio[2] and being somewhat dismayed at the results, and then a whole bunch of friends looked at their own with results ranging from 21% female for Timoni West[3], 22% female for Tom Coates[4], 34% female for Alex Fleetwood[5], 41% female for James Moran[6] and 56% female for Naomi Alderman[7].

Now, this is all anecdata. 

But, it brings into question Twitter's methodology for determining gender as it does the makeup of Twitter's userbase in the first place, and even whether what we say and do on stream-based social media makes our accounts more or less accessible to members of either gender. Either way, I know I'm not happy about the purported statistic, because I'd much rather have a diverse and representative audience rather than something that can feel a bit echo-chambery. 

[1] https://twitter.com/ferricide/status/505101049028685824
[2] https://twitter.com/hondanhon/status/505113755613548544
[3] https://twitter.com/timoni/status/505106504316641280
[4] https://twitter.com/tomcoates/status/505105560253890560
[5] https://twitter.com/ammonite/status/505108755168919552
[6] https://twitter.com/jamesmoran/status/505117478910169088
[7] https://twitter.com/naomiallthenews/status/505110884222377984
4.0 2014 (6)
Gender is determined algorithmically on major social networks using black boxes not open for review. Books are delivered wirelessly to millions of low-power e-paper devices. Data Brokers exist, collecting and amassing personal information and selling it to advertisers and media companies. Realtime Art describes the act of using massively parallel processors to render images in three dimensions dynamically, providing instantaneous feedback to artists. Car tires talk to cars. The US government is calling for a protocol to enable car-to-car communication. Security specialists are now worried about suitcase electromagnetic warfare and advise companies to place critical infrastructure in shielded Faraday cages, to use optical fiber rather than copper wire where possible and to institute a green belt as a building perimeter. Low-earth orbit has been found hospitable to life.

It's 2014.

--

Notes are welcome, as always. 

Best regards,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifty One: Not That Way; Against Empathy; Just Don't
Date: August 27, 2014 at 10:47:15 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hftd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

PDX Airport, 6:30am, another day trip down to San Francisco, this one for another Undisclosed Reason that I might or might not be able to talk about later. I didn't manage to get this episode out last night, so I'm hoping to be able to write a quick one this morning, and then another one tonight. Because, practice!
1.0 Not That Way
So we're not sure if I broke my toe or not. Probably not. Maybe. I'll get an email from a radiologist today and we'll see what they think; but for those of you who don't live in the US, here's what happens when you think you break your toe and you think you should probably get it looked at.

There's a healthcare/doctor franchise in Portland called Zoomcare that's kind of aimed at, for lack of a better term, millennials. Or at least it's aimed at the kind of people who don't want to spend ages looking (researching, comparison shopping) for a "primary healthcare provider" (ie: register with a GP) and just want to be able to book a same-day appointment to see someone for something like a possible broken toe, a cold, feeling "unwell", a burning sensation or something itching. Basically: the kind of stuff that you'd be comfortable seeing *any* GP for, and not looking for chronic, long-term care or management. 

I booked an appointment online - I had to wait until after 8pm on Monday night to be able to book an appointment for Tuesday. Turning up at Zoomcare and registering is pretty easy if you have insurance - I just needed to show my insurance card, a photo ID and a valid credit card to make sure I was good for payment (which turned out to be a $15 co-pay in the end). On Tuesday night, I was promptly seen by a physician's assistant (a PA-C) - not a doctor, but someone who's certified to perform diagnosis. He quickly figured out that we'd need x-rays, and they don't have a radiologist on-site after hours, so he set me up with a FastPass - an arrangement that Zoomcare have with a hospital system in Portland - Legacy Good Samaritan - where I could get an x-ray done: I'd take myself over to the emergency room, get myself admitted there, get an x-ray done, and then take the films back to Zoomcare for my PA-C to look at them. 

This meant driving over to the hospital (or a fifteen minute walk), and then taking about fifteen minutes to get registered with the Legacy Good Samaritan system: another credit card, insurance card and photo ID check, social security number, emergency contact, confirmation of address, phone number, three signatures and three initials. The signature process is pretty interesting: you don't see machines like this in the UK that often, but they're basically signature blocks: small resistive monochrome LCD displays that are like a signature strip: all they are is a space for you to sign. What happens is the registering attendant tells you that they're "offering you" the various documentation like their terms and conditions or their privacy policy and that you have the opportunity to read it and then to sign it. 

The bit that is just-the-way-the-world-works is the whole information sharing aspect that's undoubtedly in some part due to regulations in the US like HIPAA[1]. HIPAA gets blamed for everything from being a barrier to innovation and disruption in the US healthcare industry to being the reason why you don't get to see photos of all the newborn babies at doctors offices anymore[2]. 

There are no people with giant multi-touch walls flinging digital x-rays around. They get printed out and put in a manilla envelope for me to take back to Zoomcare. 

So, this is a long way of saying: for all the visions of technology that we get sold to us, hardly any of them actually deal with better process. And even the word "better" is a bit of a weaselly word because you have to do the hard work to define what "better" even means. Is it better for billing? Is it better for the patient? Is it faster, cheaper, easier to use? Is it more accurate? Does it reduce errors? Does it allow you to get more done in less time? Technology promised us an easy way out - the out-of-the-box solution, even when you have to bring in a whole bunch of system integrators. But it turns out that that might not be the case unless you really, really know a business inside out, and what its needs are. 

The real world doesn't work the way they show us in corporate vision videos. The real world still has people emailing the wrong version of a Word document, of people who don't know how to use Track Changes, of people who don't know how to center text and just hit the spacebar a bunch of times, of mis-named files, of mistakes in Excel spreadsheets. 

[1] HIPAA - HHS.gov 
[2] Baby Pictures at the Doctor's? Cute, Sure, But Illegal - NYTimes.com
2.0 Against Empathy
I've written a lot about empathy, and given a couple of talks (and am planning a few more) about this idea of an empathy gap (I'd originally written that phrase in capitals, but in retrospect, it feels a bit like cheating to capitalise something when it's not entirely thought through yet. A bit of a hack to give legitimacy to something that may not deserve it yet). 

If I think about it, what I've been describing in this newsletter and in my talks has been in parts a corporate/organisational lack of empathy in the high-level sense (ie: not considering the position of another), but also related concepts that follow on from that, like lack of trust and respect. And sometimes, empathy might not even be the right term - does AT&T or Verizon or British Gas need empathy for your position, do they literally need to *experience* the world as you do? Or do they just need to *understand* your position and to act sympathetically, and to alleviate the position that you find yourself in, if that's their stated goal? 

This has been niggling away in my head ever since Matt Jones sent me a note that I should check out Steven Pinker's The Better Angels Of Our Nature, with the broad overview that perhaps sympathy and reason are better tools than just "empathy" (I haven't read the book yet, but that's what Jones has told me). 

And then yesterday, Paul Bloom's article in the Boston Review[1], in which he comes out as writing a book about empathy, coming out against it. Bloom's position is significantly more nuanced and developed than mine, but I suppose he's looking at it from a different perspective. There's an interesting point in Bloom's article where he talks about the difficulties of empathy - that because it's something that exists in our minds and is a product of the physiology and neuroscience of our brains, it's also subject to the various hacks and biases that our brains subject our selves to: "we are more prone to feel empathy for attractive people and for those who look like us or share our ethnic or national background" and at the same time, Bloom points out that empathy "is narrow; it connects us to particular individuals, real or imagined, but is insensitive to numerical differences and statistical data."

Bloom is concerned about being able to override the empathic response in situations that, for example, call for long-term thinking or impose costs on individuals for the benefit of the many, citing climate change and child vaccination. 

So I suppose here's the outline on what I mean by the empathy gap in organisations and corporations: it's the outward appearance of a failure to understand, consider and then act upon the situation of a user, customer or person. In some cases, the outward appearance of failure is down to not understanding a user, and in other cases, it may well be down to understanding a user's need and deciding not to act upon them anyway. Examples like AT&T requiring you to opt-out of arbitration via letter rather than Dropbox's method of allowing you to do so easily online fall in the dark-pattern group, to my mind. So I think I'm using the naive meaning of empathy: the lack of understanding of another's position. 

[1] Against Empathy - Paul Bloom, the Boston Review
3.0 Just Don't
Accenture Australia's Public Services division popped up in my Twitter timeline this morning with the following copy:

"How can Customs agencies create #digitalborders for #digitaltrade? Read more. @AccenturePubSvc ow.ly/ABhbc"

The white paper[1] is even more egregious than the tweet itself, titled "Digital Borders: The Key to Survival for Customs Agencies". Never mind piracy, lost tax revenue from digital goods may well be the impetus to requiring deep packet inspection at the ISP level to make sure that "digital borders" can be enacted so Customs Agencies can survive.

It's not that Customs Agencies need to survive - the question that Accenture poses in their paper is "How can [customs] agencies handle digital’s disruptive impact on national and fiscal security to deliver public services for the future?"

More on this later tonight, I expect. 

[1] Digital Borders: The Key to Survival for Customs Agencies? - Accenture

--

8:36am, at 30,000 feet again. See you on the other side tonight.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred And Fifty: Here In My Car
Date: August 25, 2014 at 10:42:14 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hem5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm writing this poolside, somewhere in (very) northern California. We're on a family vacation, and I have to admit that part of me was seriously considering not writing an episode today, or at the very least just sending one that contained the words "Dan Hon is on vacation," or sending one that just says "Dan Hon returns on Wednesday 27 August". But no, I'm sat here, Macbook Air in my lap on a lounger, watching a pool cleaner robot do its thing. Robot looks like it's enjoying its job, though. 

The family vacation was off to a wobbly start - partway on our drive down from Portland we were amusingly crashed into by another driver which wasn't fantastic. You don't especially *expect* drivers in front of you on a main road to slow down, stop and sit stationary for a few seconds before reversing into you, but sometimes apparently these things just happen. And then just to top things off I'm pretty sure I stubbed my toe.

Anyway: I seem to have picked up a few hundred new readers thanks to this TechCrunch article on newsletters[1], so some housekeeping is probably in order. 

Things That Have Caught My Attention is a fairly eclectic mix of anything that's caught my attention. I write it every weekday, and Episode One Hundred contained a look back, clip-show-style at some of my favorite bits. They've included things like writing about the Californian Ideology, a streak on empathy (and its lack in corporate and organizational environments), a little bit about dealing with depression and a bit about the quantified self. In any event, the archive at TinyLetter[2] will always be most up-to-date, followed by an archive at newsletter.danhon.com[3], running off the back of a Wordpress instance that relies on me updating it by hand and adding the right metadata tags.

[1] Why Everyone Is Obsessed With E-mail Newsletters Right Now - TechCrunch
[2] Tinyletter newsletter archive (always up-to-date, less metadata)
[3] Blog newsletter archive (more metadata, slightly less up-to-date)
1.0 Here In My Car
The Paul Ford piece on The Future had a few points that are still pinging around in my head. Ford takes concepts that we have right now - subscription services and access instead of ownership and then brings to life a tale of how they might be experienced during a regular day about forty years from now. 

For starters, there's often a debate as to how quickly the driverless car future will come about. Ford's piece doesn't really talk about holdouts still manually driving cars, so we'll ignore that part, and instead look at another parallel: adoption of consumer electronics. I got my first mobile phone in 1998, but I was an early adopter - it was a tie-in with a student bank account that I got from Barclays, and was a super-early GSM cellphone running on the Cellnet, pre-O2 network - the late 90s were super early in the development of mobile phones and you didn't even have cross-network minutes, or even cross-network SMS compatibility back then. Anyway, I digress - less than twenty years later, you've got pretty much ubiquitous coverage and people who don't have mobile phones are the exception rather than the rule. 

This type of change always feels like it happens both faster, and slower, than people anticipate. I imagine that a similar situation might happen with self-driving cars: that we'll always imagine them to be about forty years away, and then wake up twenty years in the future and find out that they're mostly - but not entirely - there. 

Now, I'm just coming up with this off the top of my head and I don't really admit to having done any particular research. These aren't facts or projections or anything - just barely researched intuition, so make of it what you will. 

So take a look at the car market in the US - in the 7 months to 2014, about 9 million cars were sold[2], at an average selling price of around $31,000 - so you've got a market size of around $279bn before discounts are taken into account. For comparison, Comcast's annual revenue is around $65bn, and Verizon's revenue is around $120bn. 

The idea of subscription services is interesting, because one of the first things that a Disruptor will tell you is to sell the service, not to sell the product. Car manufacturers aren't necessarily selling cars, they're selling freedom of movement or transportation. Changing the automotive/car business into a personal transport business that has to grapple with concepts like Average Revenue Per User sounds like it's going to take some time for Detroit, and the rest of the industry, to deal with (modulo companies like Daimler, who have their Car2go pay-per-minute experiment - in fact, I'd argue that Car2go feels as much an experiment as Apple's Apple TV experiment - knowledge that the market may well be heading in a direction but that there are problems and issues in terms of go-to-market. But anyway.)

We learn about two "transportation services" in Ford's future - LessTravelled, which markets to single people under 40, and FamilyVan, which markets to, well, families. Both of the services offer value-added bolt-ons - LessTravelled subscribers get restaurant discounts, FamilyVan subscribers get things like free delivery of groceries whenever. 

So here's the back-of-an-envelope reckon on how you bring about a self-driving car future:

First step, obviously: figure out a way to make self-driving cars, and makes lots of them. 

Then, pick a metro area as your beta-test launch. Follow the model that Google have done - find a city with lots of young people with disposable income and do build-out city-by-city. Get people to campaign to bring coverage to your city - and there's another turn of phrase - service coverage. Because what you're selling isn't a car - it's a transportation service. 

OK, so you've done a deal with somewhere like Austin where you've come in and made sure that the regulations are friendly. You're making self-driving cars, and because you're a company like Google (or whoever) you've got lots of capital lying around so you buy up lots of land in strategic areas around the city so you can model distribution. This isn't a hard problem, because you've already got lots of (anonymized) data from Android phones about where people live and where people want to be, so you can model, roughly, what people want to do. Oh, it helps that you also have lots of (anonymized) calendar and search data, so you can model demand and intent. So: deploy all your cars, and do a deal like Car2go where you pay a flat-fee to the city so your cars can park anywhere at any time. 

Now: either do some introductory pricing, or, and this is the easy one: just work out what you need to price your cars at to make a profit *and* to be more attractive than the lease-option. Make your cars super covet-worthy, make sure they have lots of USB ports in them for charging Android phones and iPhones, and even have some silly ones in them that have fully stocked bars or whatever, or even hot-tubs. Because remember: you're selling transportation, not cars. 

The last one, I think, is the kicker. Work out what sort of usage plans you need to offer: do you go for the "unlimited" plan (that, thanks to the telecoms industry, is actually a "reasonable use" plan) that offers unlimited miles? Or do you offer Fast Response plans that guarantee access to a car within 3 minutes? Or even cheapo-plans that offer access to a car within 15 to 30 minutes? So many pricing options! So many upgrades! Do you let people pay a premium one day to upgrade to Instant Availability? Or, do you start bundling with other services? 

This is why it feels, to me, that the question of ubiquitous self-driving cars is a bit premature. They, like all futures, are just going to be unevenly distributed for a bit. In the UK, rollout of broadband was, well, rolled-out on a geographical basis because of the lack of penetration of cable services. Until local-loop unbundling was introduced across Europe, you had to wait for the incumbent telco to install DSLAMs in your local exchange if you wanted broadband internet access. It feels like there'll be metro pockets of opportunistic cities that will be up for introducing self-driving car areas in the same way that Google markets "fiber hoods". 

[1] Wednesday Aug. 20, 2064 - Paul Ford, Medium
[2] Monthly Sales Data - Automotive News

--

Signing off, because I'm on holiday. And as ever, send me notes.

Best,

Dan

 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Nine: Yes, And...
Date: August 22, 2014 at 5:00:43 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hcid=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

A tea-house in Portland's Pearl district having taken a break and devoured Warren Ellis' Trees #4. The existential angst of unignorable alien entities -- life -- setting up on your planet, instantly answering the question as to whether or not we're alone but then at the same time, posing about a billion other questions. And then, just like the tagline suggests: what if we *were* just ants? What would it feel like to grow up under the shadow of aliens to whom we mean nothing? Whose very presence feels atavistically terrifyingly overpowering but about which we understand hardly anything? Not necessarily an outside context problem (and I imagine you don't know you're encountering an outside context problem until it's too late) because it's not necessarily fatal, but how do you plan for such a metaphysical event?
1.0 Yes, And...
Following on from yesterday's episode about desperately needing optimistic and non-dystopic versions of the future (or, even, just slightly-less-dystopic versions) it left me feeling like it's all too easy to insert the unconstructive "but" whenever I think about what technology can do for us as a tool. For example: "technology can change power structures and allow new opportunities to the formally disenfranchised" can easily be countered with "but all too often, through experience, ends up just reinforcing extant power structures". 

What it feels like we need is some sort of walk-through guide. If only Prima Games published a Human Civilization Walkthrough where we could thumb to the "so you've got to the early 21st Century, here are the tactics and plans you need to enact, and the traps you need to avoid to progress to the next level of the game, Super Happy Funtime Post Scarcity Utopia".

This is perhaps the downside of being infected with the systems-thinking meme. I can see it in myself, and I can see it in my friends: the sort of adherence to the idea that systems are an interesting way to explain why what's happening is happening (without completely resorting to the needing-to-invent-systems-to-justify-events-in-a-meaningless-universe) inevitably can lead to systems upon systems upon systems, a toddler's view of the world where we say: well, we'd like fix this bit, which is embedded in this system which means fixing the *system*.

Maybe it's just the way I think about systems: there's the risk of introducing a defeatist attitude because the issue is fixing the *system* and not fixing individual parts in the system, right? If you're a systems-thinker, then don't you need to change-the-system instead of just address a small part? Can you effect bottom-up, self-directed cell-based change in such a system? 

People much more qualified than I probably know the answers to these questions. Or if anything, it's someone like Hari Seldon, who finally cracked the nut with psychohistory. (If I worked at Facebook or Google, I would totally as a predictable joke have an undisclosed, locked room that I never let anyone in labelled the Prime Radiant). 

I had the idea, back when I was in agency land, of trying to persuade Management of the need to open offices not just for geographical opportunity (ie: China's big! Let's have an office in China! and South America's getting the World Cup and the Olympics and its economy is booming! Let's open an office there!) but for conceptual, market opportunity: ie - and this is going to be predictable - "Digital is big! Let's open an office there!" 

(There were, of course, lots of problems with that argument not least of which was the issue of defining what, exactly a "digital" office would do, but hey, I have a whole bunch of notes. If any massive ad agency networks want to give me a tonne of cash to open up an office for them, boy do I have a proposal for you.

But this thought of "opportunity" clashes up in my head with the thought, back in episode forty seven[1], of the colonial attitude of our latter-day East India Companies in Facebook and Google and the like bringing connectivity to the developing world as "terraforming for capitalism". The systemic change of environment otherwise inhospitable to the market economy and bringing about conditions for the introduction of capitalism and the market economy to thrive. 

I wonder how you find new places to colonise, to terraform. We know about colonising new places, but how do we talk about colonising new conceptual spaces. We talk about things like the Overton Window, but that's more in terms of the *amount* of space we're able to slip through and claim and live in, rather than the totality of the possibility space. Some of us wankers even *talk* about the possibility space, in ways that make it sound like we know what we're talking about, but what we're just doing is handwaving and saying: hell, looks like there's lots of things we could do?

So here's another one.

Good science fiction terraforms the future and makes it hospitable to humans. It takes an undifferentiated mass of potential and shows us livable scenarios, ones which we can point to and can say: I'd like to live there. Science fiction right now is really, really good at being a wanky London estate agent: showing us a bunch of horrible properties at the beginning to sap our will to live, and then - hopefully! - showing us a gorgeous yet unaffordable place at the end that we end up over-financing ourselves for. 

I don't want weak signals. I want beacons, burning fire in the darkness that we can navigate towards. Quantum froth erupting, zero-point powered gridfire, a warm light for all mankind, something that my son can look at and say: that's the world I want to build, that better one. That's the one to aim for. I want him to be able to look out say: second star on the right, and straight on 'til morning and for that not to just be a quote from a book but an actual thing he could *do*. 

It feels like we have lost faith in ourselves. Some of the best science fiction lately has been lamenting the human condition, not celebrating it. Transcendence doesn't count because it was just so dire. Her doesn't count because it was singularly misogynistic, even if it was the best on-screen depiction of a techonlogical singularity. Pacific Rim doesn't count because it's just a fun movie about bashing monsters on the head. 

Maybe Chris Nolan's Interstellar will give us some of the wonder back and show us what we can do. Science Fiction's job isn't to *only* serve as a warning. It's usefulness to society isn't *only* to be the 1984 that we can misquote and point at, to be used as a pawn in a retailer's war against a publisher. Science Fiction's role is to inspire us and to show us what we can be capable of, to show how in an insignificant universe we can create significant things that are so much bigger than our own selves and to show *progress* and to bring that progress to light. To be a low-fidelity time-travel device, to show us possible versions of a future, like the Guardian from the City on the Edge of Forever. To prompt and to provoke and to question and then as well to be a symbol because we have the capacity to imagine things and to bring them to life.

Don't like what we've got? Imagine harder and then work harder to bring those ideas to life. 

But anyway, I got distracted. I was talking about terraforming and then I went off on one about science fiction and you'll have to forgive me. Terraforming. How do you terraform new systems? Do you terraform the market economy and capitalism and slowly convert it into a post-scarcity society? How would you terraform a planet like Earth to prepare it for habitation for a fairer, better society?

I saw a post by my friend Chris Locke about "Smartphone Only" countries this morning[3], which feels a bit like the kind of nuke-it-all-and-start-again infrastructure reboot that's difficult in system-extant Western countries. Ie: if you started from smartphone digital access, what kind of society would you build? Would you be smart enough to build a society around that type of access, or would you face pressure to build around 19th century models?

What I'm getting at is this: Western economies are dealing with the transition from the industrial revolution to an information (ugh) revolution that hasn't completed yet. There's a whole bunch of self-interest going on and they've gotten fat and complacent off the back off the industrial revolution and post-WW2 era. But, to extend an already wobbly metaphor, Western economies need to maintain backward-compatibliity: smartness is grafted on to 20C ways of thinking and doing, which is why we all still have to go to work every day and public transport is difficult (and, really, public transport is done in the pre-Uber, pre-algorithmic way). 

Whereas Myanmar has the clean slate. China, in places, has the clean slate. Singapore does. And we're seeing what kind of societies and cities *they're* building. (Well, I'm not. People like Jan Chipchase are, and I'm pretty sure that he'll tell you that we don't know the half of it). 

Part of this makes me feel sad that I only really know English. I wonder what the rest of the world's science fiction is like, and what worlds they're building.

[1] Episode Forty Seven - Building Better Worlds / Terraforming for Capitalism 
[2] Beacons! 
[3] Smartphone Only Countries - Caribou Digital

--

It's 3pm and time for my call. One call and one more coffee meeting and then I'm done for the day. And it's Friday! I hope you had a good one.

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Eight: Better Days
Date: August 22, 2014 at 12:49:45 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hbq5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

10:15pm on a weeknight, and I normally try to write these things in the morning. A fractured day, work-wise, not so fractured if you look at it from the point of view of my son, who got to do a whole bunch of super fun things today, but despite that remained adorably cranky. Tomorrow, a packed day. 
1.0 Better Days

Deb Chachra - not Deb Cha, as I wrote in yesterday's episode - has posted a public version[1] of the rant she previously wrote in her newsletter, Metafoundry. Both are worth reading. There's a few things that stuck in my mind:

 - the concept of a sentinel organism. It seems similar to Tim O'Reilly's concept of "weak signals" around which he built conferences like ETech and holds gatherings like FooCamp, but at least the idea of a sentinel organism implies an ecosystem in which that organism can survive and reproduce. A better definition, I think, for that-thing-you-find-that-is-a-precursor-or-alert-to-a-larger-thing. Chachra links to indictor species[3], which from the wikipedia reading at least, are species that are unique and possess traits in part defined by their environment. The techbros, such as we call them, are indicator species of the particular Valley/VC environment. 

 - the selection pressure of a VC ecosystem towards "bits, not atoms (near-zero incremental cost), towards anything that leverages Metcalfe's Law, towards dark patterns of nonconsensual behaviour towards users (like strip-mining Contacts lists), towards eroding user privacy, to dumping everything users have created when the startup is acquihired, and towards falling back on invasive online advertising because having a viable business model was a distant second to growing a user base," just because when you're batting for the biggest return possible, and that's how you build your business, then you need to, well, find every way possible to bring about that fitness. 

Some of you will be asking: OK, so where's the hedge? The hedge is obviously anywhere-apart-from-the-Valley, but at the moment it feels like bar some *regional* examples (hi, China) that have particular barriers to entry (hi, the Chinese government), Valley-model businesses are the most successful. 

Part of the hedge is looking for Other Valleys - and if you're into that (and why wouldn't you be?) then you should probably subscribe to Anjali Ramachandran's newsletter, Other Valleys[4]. In other words: there's a tonne of stuff happening out there, and if we feel it's important for the Valley to *not* be the sole representative of transformative software and technology, then we should cheerlead other examples. 

Robin Sloan, for example, pointed out to me that the obsession with the Valley leads to a sort of blindness. You don't get, he says, things like Minecraft coming out of the Valley system: it's too weird, too free, too hard, too difficult. His metaphor is that of the provinces - you've got this geographical nexus that for whatever reason is sucking all the time and attention from the vast majority of people, but it's a tiny dot in a sea of the Whole Damn Planet Earth. From Sloan's point of view, it's the provinces that are the interesting bit. So when he says that, you remember things about Ev Williams being out in Nebraska and finding out about the internet for the first time and it being pretty much the only way he could escape Nebraska without physically escaping Nebraska. Ev's talk at XOXO 2014[5] is pretty much all about this - at least, the first half is. It is, weirdly, this particularly human capability we have to zero-in and focus on one spot and ignore the rest of the picture which feels a bit like how our actual optical system works: if there's stuff happening, track it with your fovea so you get a 4K60p picture but the *entire rest of the world* is happening. Or, you know, concentrate on the shiny dots in the sky and explore the planets but forget that you've got an entire rest-of-the-oceans to explore, because hey, did you remember that two thirds of this blue planet is, well, blue? Sloan's point, then, is not: *how can we make the Valley suck less* (which we should still be doing) but also: why are we paying so much attention to the Valley in the first place? One of the things you *can* do to affect change in a system that doesn't want it in the first place is to make it jealous.

But this section is titled Better Days. I kicked myself this morning when I read Paul Ford's piece on Medium in the GE-sponsored What's Next section. It's a mildly satirical Day-In-The-Life set in August 20, 2064, fifty years in the future[6]. There's the usual sponsored bits but they're quite easy to skip over and they kind of manage to signpost themselves in a pretty funny way, e.g. hey, did you know that the Industrial Internet is a thing? Why no, I did not, thank you General Electric? And may I have a FunCooker now?

But anyway.

Aside from the copious Easter Eggs, it's clear to see that Ford enjoyed writing it, and it has that whimsical tone that you can see from his earlier work like the Robot Exclusion Protocol[7] from 2002 which some of us laughed at at the time and others kind of looked at and said well you might think this is funny now...

But it's also weirdly non-dystopic. I mean, some parts of it are horrifying but it doesn't sound *too* bad and certainly doesn't sound - at least to my reading - like an unlivable hellscape full of torment from which we shan't be able to escape. It just sounds like, well, now, but with slightly better logistics. It's telling, though, that Ford isn't completely sure that it's a nice future (it sounds like a Pleasantville future at times) and he oscillates between it being harmless and terrifying, saying that:

"I go back and forth. With this future I do worry that 99% of the people not in the story live underground and eat soylent."[8]

because whilst the piece might talk about manufactories and the logical-end-run of just-in-time manufacturing, there is the creeping suspicion that there's a tonne of people in still-developing countries busy being the Actual Replicator instead of the magic one that you get to see in corporate vision videos. That said, it's not like Ford said *where* the story was set.

At any rate, there's a new collection of science fiction coming out later this year in Hieroglyph: Stories and Visions for a Better Future, edited by this guy you might have heard of, Neal Stephenson, designed to answer the call for an *optimistic* as opposed to dystopic depiction of the future. Our generation, argues Stephenson, or well really any generation past the 1960s, hasn't had the benefit of big, bold, make-the-world-better fiction. Instead it's been all-downhill-from-here, and the best you can hope for is to have your mind-state uploaded and sharded and punted across as much of the universe as possible before the depressed author decides that it's Heat Death time and you get to The End. 

Part of this is that the problem with the present isn't so much technology as it is capitalism and the system that technology finds itself embedded in. It feels like people have as much beef with the context as the tools. "Imagine better tools for better days!" goes the cry, but when you've spent your whole life in the thrall of the invisible hand, what better is there? Even when we write about utopian, post-scarcity galaxy-spanning cultures with a capital Culture, there's still not that much to look forward to. 

So. Optimism. Excitement. Less grinding. More *actual* delight, not that shitty manufactured stuff that we all talk about in meetings where we pat ourselves on the back if we time a menu animation just right. Real delight. More of that, please.
 
[1] Metafoundry 4: Indicator Species - Deb Chachra
[2] Metafoundry - Deb Chachra
[3] Indicator Species - Wikipedia
[4] Other Valleys - Anjali Ramachandran
[5] Ev Williams - XOXO 
[6] Wednesay Aug. 20, 2064 - What's Next / Paul Ford - Medium
[7] Robot Exclusion Protocol - Ftrain.com
[8] https://twitter.com/ftrain/status/502265723558064128

--

10:48pm, and time for bed. Love you all, send me notes, all of that stuff.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Seven: I'm a Barista; More "Valley"; More Uber; They Create Jobs, Don't They?; Dumb Telcos
Date: August 20, 2014 at 10:41:59 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-hav9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
This is one of those mornings where I'm ever-so-slightly angry and rage-y, where I'm kind of hammering words out by bashing my keyboard at a good eighty words a minute and there's some sort of righteous indignation flowing through my fingertips as if I'm a blogger (ha!) anyone would care to listen to in the first place. I feel like a warblogger out of Charlie Stross' Iron Sunrise.
1.0 I'm a Barista. If you don't want to get hurt, don't challenge me. 
With absolutely no apologies to Sunil Dutta, who is an idiot[1].

A patron is fatally shot by a Barista; Baristas are accused of being bloodthirsty, trigger-happy murderers; riots erupt. This, we are led to believe, is the way of things in America.

It is also a terrible calumny; Baristas are not murderers. No Barista goes out front wishing to shoot anyone, armed or unarmed. And while they’re unlikely to defend it quite as loudly during a time of national angst like this one, people who work in the food service industry know they are legally vested with the authority to detain patrons — an authority that must sometimes be enforced. Regardless of what happened with Mike Brown, in the overwhelming majority of cases it is not the Baristas, but patrons, who can prevent tragedies.

Working the counter, I can’t even count how many times I withstood curses, screaming tantrums, aggressive and menacing encroachments on my safety zone, and outright challenges to my authority. In the vast majority of such encounters, I was able to peacefully resolve the situation without using force. Baristas deploy their training and their intuition creatively, and I wielded every trick in my arsenal, including verbal judo, humor, warnings and ostentatious displays of the lethal (and nonlethal) hardware resting near my hands. One time, for instance, my Barista partner and I faced a belligerent woman who had doused her car with gallons of gas and was about to create a firebomb at a busy mall filled with holiday shoppers. The potential for serious harm to the bystanders, coffee lovers and property damage would have justified deadly force. Instead, I distracted her with a hook about her family and loved ones, and she disengaged without hurting anyone. Every day Baristas show similar restraint and resolve incidents that could easily end up in serious injuries or worse.

Even though it might sound harsh and impolitic, here is the bottom line: if you don’t want to get shot, tased, pepper-sprayed, struck with a baton or thrown to the ground, just do what I, a Barista, tell you. Don’t argue with me, don’t call me names, don’t tell me that I can’t stop you, don’t say I’m a racist pig, don’t threaten that you’ll sue me and take away my apron or my equipment or my beans. Don’t scream at me that you pay my salary, and don’t even think of aggressively walking towards me. Most orders are complete in minutes. How difficult is it to cooperate for that long?

I know it is scary for people to be stopped and their orders questioned by a Barista. I also understand the anger and frustration if people believe their orders have been stopped unjustly or without a reason. I am aware that corrupt and criminal Baristas exist. When it comes to  misconduct, I side with the ACLU: Having worked as an internal affairs investigator, I know that some Baristas engage in unprofessional and arrogant behavior; sometimes they behave like criminals themselves. I also believe every Barista should use a body camera to record interactions with customers at all times. Every coffeehouse should have a video recorder. (This will prevent a situation like Mike Brown’s shooting, about which conflicting and self-serving statements allow people to believe what they want. In the Barista's ideal world, there is only camera-documented objective truth.) And you don’t have to submit to an illegal stop or search. You can refuse consent to search your person if there’s no warrant (though a pat-down is still allowed if your Barista has cause for suspicion). Always ask the Barista whether you are under detention or are free to leave the coffeehouse. Unless the Barista has a legal basis to stop and search you, he or she must let you go. Finally, Baristas are legally prohibited from using excessive force: The moment a patron submits and stops resisting, the Barista must cease use of force.

But if you believe (or know) that the Barista stopping you is violating your rights or is acting like a bully, I guarantee that the situation will not become easier if you show your anger and resentment. Worse, initiating a physical confrontation is a sure recipe for getting hurt. Baristas are legally permitted to use deadly force when they assess a serious threat to their or someone else’s life. Save your anger for later, and channel it appropriately. Do what the Barista tells you to and it will end safely for both of you. We have a customer service system that presumes the customer is always right; if a Barista can do his or her job unmolested, that system can run its course. Later, you can ask for a supervisor, lodge a complaint or contact civil rights organizations if you believe your rights were violated. Feel free to sue the Barista or even the coffeehouse! Just don’t challenge a Barista during your order.

An average person cannot comprehend the risks and has no true understanding of a Barista’s job. Hollywood and television stereotypes of Baristas are cartoons in which fearless super Baristas singlehandedly handle dozens of orders, shooting coffee out of their hands. Real life is different. An average Barista is always concerned with his or her safety and tries to control every encounter. That is how we are trained. While most patrons are courteous and law abiding, the subset of people we generally interact with everyday are not the genteel types. You don’t know what is in my mind when I stop you. Did I just get a radio call of a shooting moments ago? Am I looking for a murderer or an armed fugitive? For you, this might be a “simple” order of a triple shot skinny no-whip sugar-free peppermint mocha, but for me each order is a potentially dangerous encounter. Show some empathy for a Barista’s safety concerns. Don’t make our job more difficult than it already is.

Patrons deserve courtesy, respect and professionalism from their Baristas. Every person served by a Barista should feel safe instead of feeling that their wellbeing is in jeopardy when all they wanted is a coffee. Shouldn’t patrons extend the same courtesy to their Baristas and project that the Barista’s safety is not threatened by their actions?

[1] I'm a cop. If you don't want to get hurt, don't challenge me - Sunil Dutta, who is an idiot, in the Washington Post, who are also idiots.
2.0 More "Valley"

Deb Cha, Greg Borenstein and Roberto Greco all sent me thoughtful notes on yesterday's ramblings about "the valley" or, I guess, "The Valley".  

The truth is always more complicated than you can fit in 140 characters, and more nuanced than you can fit in even a million newsletter episodes. Yesterday's episode was in effect to say: well, no, not *all* techbros, and that there are indeed good people working in tech. So to that, I say yes: "the valley" isn't tech, but part of this (and isn't it always?) is about shorthand and labels and what level of the structure you're pointing to when you're condemning it. 

To write off all tech culture is unhelpful, sure and it writes off the efforts of the good actors in the entire field of "things we can do with technology these days". But there's still something worth talking about, even if it doesn't really have a name yet. One historical example is when people started talking about the military-industrial(+congressional)-complex, a self-reinforcing, positive feedback system, when pointed out by President Eisenhower in his out-going address.

Of the many things in Cha's note (which was wonderfully dense and insightful about picking apart the failings of the VC system) one small part that I picked up on was the motivation behind how the VC business works, and how it felt like that tallied with Maciej Ceglowski's ideas of "investor storytime." There's a lot more in Cha's note that I want to explore later, and I'm glad that I'm able to have a chat with her over email to find a way to get them written down[1].

When some of us talk about "the Valley" what we sometimes mean is the VC-technological complex, which because of the *other* system that we find ourselves in (hi, capitalism and market-based economies) is doing quite well and geared up to find itself in yet another self-reinforcing strange loop. (In fact, you might even argue that the VC-technological complex is doing even *better* now when previously the finance upon which it would sustain itself was limited only to public markets, now startups can avail themselves of institutional funding and astronomical pre-IPO valuations thanks to the influx of mutual-fund money). 

This system is one that is built solely upon the premise of the rare hit, the hit that produces outsized returns. And for outsized returns, *right now*, you need what Maciej Ceglowski has termed investor storytime: to be able to tell a story of fantastic, hockey-stick growth, of the promise of future revenue. To be clear, this is but one model of success, and - if you're the kind of person interested in finding new solutions to new problems that can also be viable businesses, but *don't* need to be billion-dollar businesses, or even hundreds-of-millions-of-dollars-of-business, then you're fishing in a crater lake on top on Mount Local Maxima whilst next door, just behind that cloud you can't see through because your fancy optical depth perception algorithms don't work through WATER VAPOUR, is a fucking Mount Everest of opportunity. What Cha pointed out to me was that the requirement to produce massive returns has resulted in a whole bunch of second, third, fourth and so-on order effects - many of which are the parts that exemplify what people dislike about stereotypical valley culture.  

So there's always layers to this, and perhaps I can show what's in my head through some sort of analogy: when we say "man, Hollywood's fucked up" because we've had something like a hundred-odd-years of Hollywood and most of us have grown up kind-of knowing what we mean by "Hollywood" to include concepts and actors like the studio system and production companies and directors and distribution companies and agents. We say Hollywood's fucked because it makes certain movies and because it makes it hard for change to happen, because it's deeply fucked-up about gender, because it has an idea of what its audience wants and because it strong-arms people into having to act a certain way, and it will shut you out if you don't work the way it thinks you should work to make blockbuster movies. This doesn't stop people from making amazing indie movies, it doesn't stop people like Kathryn Bigelow from finally getting the recognition that she deserves, it doesn't stop Diablo Cody from making it as a screenwriter, but what happens is that all of those good things happen *in spite* of the system, a system that's the giant, great attractor designed to keep doing the things that it knows how to do, and that has outsize power and influence in that landscape. At the same time, there's an increasing group of people who're wondering: is this the best that there is in life, Conan-style, and isn't there another way? Or, even, more fairly: why can't I do some of these things? 

There are some amazing things happening in tech. I'm falling back on old and tired examples that I hope will still be new to some of you, but there's work from people like the EFF, like OpenStreetmap, like Ushahidi and the type of work that the Omidyar foundation is funding. I freely admit to having shitty blinkers on and being blinded by the light, sound and fury coming out of the west coast -- and this isn't to say that the west coast hasn't also done good things as well! 

But. There is a thing, and we might not have a good name for it, and it's certainly bad luck and an accident of geography that *most* technology-related innovation in the field of internet-type-stuff is happening out there on the West Coast in and around the area known as the Valley, but the VC-system exists and it's predisposed to a certain kind of output. It doesn't have to be (well, depending on what its goals are and how predisposed it is to making sure that it keeps generating the kind of returns that a VC business needs), but it's there and it exists.

So, to recap: there's technology-as-a-whole, there's the geographical area in the United States around which technological innovation has historically been concentrated, and there's the corresponding venture-capital ecology that has grown up in tandem with and around that geographical area. Man, if I could draw you a could venn diagram, I totally would right now, but that would be against the self-imposed no-images hardly-ever rule for this newsletter. 

The other part of this not-so-much-equation as whole-horrible-mess that is what happens when humans get together and idk, *do stuff* is this: part of what I've been writing about for the past hundred and forty six-odd episodes has been this idea about the Californian Ideology and which bits of it make sense to critique and which bits don't make sense and the kind of things that the Ideology spits out into the world to be used, abused or just thrown away. 

Greg Borenstein pointed out that one of the tenets of this ideology is that "technology" is a good thing, period. It just is. In just way that people claim capitalism is a good thing, period. Again, we get into semantics: what do we mean by "technology"? For something like the Californian Ideology, if I were to start making a list of "things that the Californian Ideology counts as valid technology as a starter for ten", I'd have things like "the transistor" and "ethernet" and "wifi" and then concepts like "Metcalfe's law" and then not-laws like "let's try really hard to double the transistor count for a given area every eighteen months or so". Sure, we can do those things. We might even use those things for *good* things: but the Californian Ideology doesn't necessarily say what those good things are, or what they might be used for (well, it did), but did it really mean that they would be used for things like a) making fractions of a penny through practically relativistically traded stocks and arbitraging based on the speed of light, b) Tinder for LinkedIn, or c) a way for you get quarters delivered to your door because it's too hard to get them when you want to do laundry? Fuck no. That's not an ideology I signed up for. I signed up for one that meant more than that. 

And yes, I realise that the work that I've personally done hasn't been stellar, either, or worthy of being pointed at as advancing the human condition for good. Thank you. 

But, this is what I have done. I've put my money where my mouth is and for over a year, I've gone back to paying for email. I don't let Google store my location history. I pay for Pinboard. And I try to buy things instead of relying upon free, advertising-supported services where I can.  

[1] One of the issues that I'm starting to have with this newsletter is that I'm inviting notes from people and frequently (and this is part of the point!) they inspire subsequent issues and spark things off in my head. The issue I'm grappling with is how I quote those people who've sent notes and how I attribute their ideas. In the email exchange I had with Cha, I had shown her an early draft of what I'd written for today, and had to have pointed out to me that I'd suddenly become *that guy* who was taking public credit for what a woman says. I absolutely don't want to be that guy. 
3.0 More Uber
If it feels a bit like a mad-as-hell-and-won't-take-it-anymore moment, then maybe it's because it is. A number of notes I got in response to yesterday's bit about Uber took them to task for, if not outright lying, then just being economical with the truth. 

At the very least there's the issue with Uber's name, but also there's the contention - pointed out by a few people - that if you're going to claim to offer transportation "for everyone", then you have to be able to back up that claim. And yes, if you want, you can weasel your way out of it and say that your *mission* is to offer transportation for everyone as an end-goal, and that you're simply starting out at the high-end and working your way down. But, you know, you kind of have to make that explicit, and if you haven't made it explicit, you just look like patronising idiots who started an unregulated black-car service to make it look like a taxi service for people on expense accounts or more money than sense. At the beginning, at least. 

The position is familiar: public transport, or at least the ideal of public transport shares a requirement of (somewhat) universal service. It's the same reason why the post office has to deliver everywhere and why there's a surcharge on telephone bills in the United States - in the latter case, the government thought that it was generally a good thing if everyone who wanted a telephone line *could* have a telephone line, so set up a fund to make sure that money was available so that even if you were a farmer in the middle of the sticks, someone *would* run a line out to you. 

But - and this is a particularly American phenomenon thanks to the country being one where, aside from possibly *one* city, no cities have credible public transport options that are valid in a twenty first century environment. And by that, I mean: white collar professional people would use them as a matter of course. And I'm not even singling out America: a lot of European cities don't even have that option either. But as soon as you start making public transport less diverse, then you make it less fundable. And when it's less fundable, it starts dying. 

Perhaps - to give them the benefit of the doubt - Uber sees themselves as the Coca-Cola, or in a more up-to-date way, the IKEA, of transport: like Warhol said, everyone gets the same Coke, and everyone gets the same BILLY bookshelf. Perhaps what Uber mean by "transport for everyone" is their goal of producing an affordable product that's *the same* for everyone. 

Even so, that feels like weaseling out: "for all" means for *everyone*, not "to each according to their ability to pay". 

Part of this, of course, is the matter of framing and whether you can say what you actually mean. Here's that statement again, just to remind us:

"Uber’s simple mission: Transportation as reliable as running water, everywhere, for everyone."

Transportation as reliable as running water, everywhere, for everyone. Reliable is great. Comparing yourself to a utility is perhaps not so great, especially in a post about lobbying for reform and deregulation because, hey: regulations help make sure that our cities have *safe drinkable water* and that not anyone can start selling water. But I digress. It's the *everywhere, for everyone* deal.

I'm pretty sure that Uber's end-goal is to be the Amazon of logistics - of moving things - not just people, from one place to another. Today's release of their API pretty much confirms that for me. 

So really, what we're talking about, is the matter of jobs.
 
4.0 They Create Jobs, Don't They?

The general idea, as I understand it, is that as we increase our capability for automation and as capitalism drives inexorably toward greater efficiency, we find new jobs for ourselves. Ideally - but not always, and there's certainly no guarantee - these jobs are fulfilling and are things that only humans can do and offer some semblance of security. Ideally they are also jobs that allow for some sort of satisfaction.

Uber's claim is that, through their platform, over 20,000 driver jobs are created a month. 

The only problem with that - and I'm not entirely sure how *much* of a problem it is - Uber's end-game will involve the phasing out of human drivers. It might sound like I'm singling out Uber here, but I don't think I am - they're just one of the most visible examples available to me. 

There's a lot of talk about the full-stack startup: it means lots of things, but one of the things that I think it *does* mean is vertical integration: control of the entire experience, from top to bottom, in a FULL SPECTRUM DOMINANCE kind of way. Interestingly, Uber doesn't entirely do this - they don't do fleet management of their black cars, for example: they rely on limo and livery companies for that. And they have a different service level expectation for UberX, for example. But companies like Warby Parker, for example *do* own the entire chain of customer experience and have less contracting-out. 

One way of looking at the full-stack is to see humans - people - as merely a layer in your full-stack startup that can be optimised out at a later date. This is the reason why it's easy to talk about meat-puppet jobs sometimes: lowest-common-denominator human labour jobs that have a place in the stack not because they're *the best way* but because they're currently the cheapest way, and there's not a way to do it even more cheaply. 

There's clearly a breaking point here: these aren't (necessarily) fulfilling jobs. I'm not saying that they *can't* be fulfilling jobs, but there's a difference between wanting to do something and having to do something - and Uber jobs right now aren't hobbies - they're clearly being taken up by people who need the income - either as primary, or supplemental. 

What I mean is this: jobs-for-humans are merely the weakest chain in a full stack that are designed to be replaced by cheaper, more reliable, more API-addressable and predictable components. But, what did you expect from a market culture that calls humans, well, resources?

You don't even need a *manager* in a full-stack startup, if you're in a meat-puppet job. Software is your manager. It tells you where you need to be, and it tells you if you did a good job. You could probably spend days without any employer-based contact at all. 

These are the types of jobs that are being created at scale. Because that's the easy route to how the internet works at scale: standardisation and the treatment of resources as API endpoints that can be triggered programatically. 
5.0 Dumb Telcos?
So apparently Verizon might be opening its own app store - at least, so claims The Information[1] (paywall, Verge coverage[2]). Here's the key para from The Information's report:

"The company hopes to create a different kind of app store, one that would let software developers take full advantage of specific features of wireless-carrier networks while also offering consumers new ways of discovering the mobile software they might want."

of which: Jesus Christ, why do they keep trying to do this? For starters, why do you need a *store* to let software developers "take full advantage of specific features of wireless-carrier networks"? Oh right, you don't. You just need a store to provide a route to monetisation. And yes, sure app-discovery is a problem, so "offering consumers new ways of discovering the mobile software they might want" is in principle a worthy aim, but, and no disrespect to the people at Verizon who *actually* know how to build products and services that people want to use instead of have to, I don't rate Verizon's chances at success. 

What's been stopping Verizon from letting developers take full advantage of specific features of wireless carriers until now? Oh, nothing? Nothing apart from that sound of them *hitting themselves in the face* trying desperately to not become just a dumb pipe? Nothing apart from maybe, oh, I don't know, figuring out how to actually offer useful and reliable APIs and show what might be possible? 

Yeah. Stop hitting yourself in the face, telcos. 

[1] Verizon Preps Challenge to Google’s App Store - The Information (paywall)
[2] Verizon denies plan to launch its own Android app store (update) - The Verge

--

Well, that was a bit ranty. And you should've seen the other versions. Here's two lipdub videos that you've probably seen before that might cheer you up.

Isaac's live lipdub proposal: https://www.youtube.com/watch?v=5_v7QrIW0zY
JK's wedding entrance: https://www.youtube.com/watch?v=4-94JhLEiN0

Try not to get hung up on the blatant violation of hardworking artists' and music labels' intellectual property rights, though. 

Send me notes and I'll figure out how to deal with them. How about let's just assume that if you send me a note, I can quote from it? That might help.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred And Forty Six: Not All...; Now Wear This; Uber
Date: August 20, 2014 at 12:53:26 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ha4t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
Back in Portland, hiding in my corner in the basement writing this, the first time that I haven't been looking at what's been happening in Ferguson. Lots of meetings and phone calls, readjusting to being back in the family home, and nosing around websites having a think about strategy and communication using bits of my brain that I haven't used in... well, a couple of weeks at least. 
1.0 Not All...

I had a conversation in public the other day with Tom Coates where he took me to task for (in his view) lazily lumping together "the Valley" as "all the dudebros doing startups of questionable utility or value, flipping them and generally cargo-culting their way to privileged success" and there were a number of comments of his that gave me pause for thought. For one, there's the worry that there's an undifferentiated view of "tech" and that in some respects at least, "the Valley" (or whatever the media deems to be worthy of portrayal as "the Valley") *is* tech culture, thanks to the geographic uniqueness of the USA and the West Coast's dominance. 

(Yes, I know New York and Boston and whatever, but really: no. In the USA, "tech" is the West Coast, money is New York, Film and TV is Hollywood and Chicago is, er, Wind, I guess. Or commodities trading. Whatever. I had a point.)

This is the bit where I get frustrated at the ambiguitiy in language: because when I say "the Valley", I'm using my own internal shorthand to mean the clique of dudebros who may-or-may-not technically exist but are stereotypically the frat-spouting, "dude, you crushed it", HR-espousing, misogynistic sort-of platonic ideal of sheer fuckwittery that thinks it's a good idea to capital-D disrupt the world with, oh, I don't know, a new laundry service or something that will fucking give you quarters. I mean *those* people. 

The dirty secret, of course, is that there's a bit of *those* people in all of us, and I'd be remiss if I didn't stick my own hand up and say that there was a bit of that inside me, too. As Coates pointed out to me, we're all part of the tech ecosystem (well, by "we", you know who I mean), and what I'm really saying when I say "Jeez, look at those guys in the Valley who don't understand people lol amirite?" is *man, fuck *those* guys.

The point is: all of tech isn't just the Valley, and it certainly isn't just *those guys*. If it were, we might as well go home now and just give up, but tech is about as much high school as any other human endeavour because, well, humans. There's good people and bad people and in the middle an absolute crap-tonne of people just trying to do a good thing and sometimes succeeding and sometimes failing and well, it's not like they decided one day when they woke up: you know, I'd like to violate as many peoples' privacy as possible and shit all over their notions as to what it means to share information with each other. 

I mean, not *all* of them are like that. 

Those guys? Those are the jock guys, the frat dudes (and yes, I know you probably a) know a great frat dude, or b) are a great frat dude, or c) founded a frat or whatever). And there's every single other clique, too. For every single dumb Valley cargo-culter hanger-on who's busy trying to eke yet another cent out for ARPU, there's at least one (and hopefully more) trying to make a goddamn difference.

So if I ever sounded like *fuck all those guys* and was pointing to the entirety of the geographic region that is "the Valley" and by extension everyone in it, no, I didn't mean *everyone*, I'm holding up a glass and sorry that I didn't champion the people who're trying to do good things and the good fight, or the people who, in typical movie henchman fashion, are just trying to put a nice, Whole Foods meal on the table for their family. 

There's Code for America, there's the organisation who *donate* to Code for America, for every Zynga there's the designers and coders working at outfits like Frog who're just trying to make a better, more useable piece of tech for the families stuck in line at Disney, for everyone trying to figure out a new way to insert a #hashtag #brand into one of your timelines, there's people like Shanley Kane and Quinn Norton who're just sick of this shit, not taking it any more and actually doing something about it, or there are the people at archive.org who're just *waiting* for Yahoo! to fuck up out of ineptitude again and commit what's essentially a crime against humanity by wiping out a shit-tonne of cultural artifacts. 

So, my point? My point is that the Valley isn't just like Mike Judge's Silicon Valley because he's skewering a thing, and when you make a thing that you skewer, you take all the best bits, all the bits worth skewering, and you put them in one nice package. It's why when people look at the Shudder of Recognition[1] archives about made-up women on The Toast, they're able to say a) I don't know anyone like that, b) I know people who are just like that, but not all the time, c) have you heard about that one time I knew that one really smart woman who also acted like that, isn't that weird? I mean, just get a load of the conversation on Metafilter about it[2].

No, Judge's Valley is poking fun and it hurts because there are bits that people recognise, but that's obviously not the entire valley and not everyone is like that and not everything is like that because JESUS CHRIST PEOPLE wouldn't that be completely horrendous? 

I'm not sure if I've done a 180, but what I do want to point out is this: there is a bunch of shit going on. It's not tech culture as a whole, but it is a bunch of people who I would hope know better. And there are, indeed, people who *do* know better. But that doesn't mean I'm not going to stop calling the idiots out. 

[1] The Shudder of Recognition Archives - The Toast
[2] Hey Ladies! and the Shudder of Recognition - Metafilter
2.0 Now Wear This
Off the back of the news that Apple's share price has hit an all-time high (presumably Steve Jobs would never have let this happen on his watch) there's the usual drama about pump-and-dump and analysts inflating Apple stock by issuing guidance that is quite frankly on crack. But anyway.

One of the things to look for are estimates about how many wrist-worn-iWatch-type-things Apple might conceivably sell this year, if they actually end up releasing such a product this year. There's one particularly bullish estimate from Morgan Stanley from earlier this year where they predict nearly 60 million units at $299 a pop over the first twelve months[1]. Back in 2007, when Apple sold a *phone* which lots of people use, they sold a scant five million-odd units at $absurd a pop. Back in mid-2013, Tim Cooke reckoned that Apple had sold around 6 million units of the $99 Rev 3 Apple TV in the preceding twelve months. The iPod itself, the product that many see as being Apple's saviour and marking its emergence as a not-just-computer-company, *peaked* at around 55 million units sold in 2008.  In the roughly nine months since Sony's launch of the PlayStation 4, it's only achieved around 10 million units. 

And I don't even know *why* I'll wear an iWatch yet, other than "it's the new hotness from Apple". 

Every single other product that Apple introduced (in fact, scratch that, that *anyone* introduced and that's been successful) has had a clear value proposition, even if it's only been in retrospect. Having a thousand songs in your pocket was a big deal. A usable smart phone was a big deal. An iPad was the computer for the rest of us and signs are that even it might be flagging. 

Shifting nearly 60 million units at $299 a pop *on product introduction* feels like it would qualify as the most successful consumer electronics product launch in the entire history of mankind, and I think even Apple would think that's a stretch. These things take time. 

[1] Apple's iWatch Will Be A $17.5 Billion Business After 12 Months, Says Morgan Stanley - Business Insider 
[2] Apple TV sales surpass 13 million, 'about half' sold this year - The Verge
[3] iPod Sales - Wikipedia
3.0 Uber
Uber was in the news today for hiring David Plouffe as SVP for Policy and Strategy. Plouffe was Obama's 2008 campaign manager, so as far as getting someone who knows how to run a political campaign goes, it's a pretty good pick. If that's your goal, which it evidently is. Anyway. I'm not here to talk about Plouffe, I'm here to talk about the blog post that Uber used to announce the hiring[1].

Here's the bit I want to talk about:

"Uber’s simple mission: Transportation as reliable as running water, everywhere, for everyone. In pursuit of that mission over the past four years, Uber has transformed the fabric of 170 cities around the world – creating the safest way to get around cities, generating over 20,000 jobs a month, lowering DUI incidents, accidents and fatalities and improving local economies."

to which, at 10:30pm, I'm not actually sure I want to talk about, other than just raise these points and then back away from them slowly, with my hands raised. They are:

 - the safest way to get around cities? Really? As opposed to what methods?
 - 20,000 "jobs" - when, I suppose "jobs" means "zero-hours contract"
 - lowering DUI incidents is a good thing, but again, the purported 10% reduction in DUIs that roughly correlates to Uber being available in a city is... what, a peer-reviewed scientific conclusion? 

This is where I bring things full circle to the first section of today's episode: Uber is better, in a lot of ways, than some things. I would like, in a world where my dreams and wishes come true, Uber to co-exist in a city alongside good public transport options. I would like Uber to be honest about exactly what the employment and job prospects are for their drivers, rather than what appears to be whitewashing, and I'd also like for Uber to perhaps not engage in their alleged sabotage campaign against rivals. But those are all wishes, and I know I'm not going to get them, so I kind of have to deal with the universe that I happen to be instantiated in, and it's this one. That means that this Uber is undoubtedly a better passenger experience, and yeah, it's a bit more expensive, and whenever I'm in SF or NYC I invariably use Uber, so I freely admit to that. But then I talk to the drivers, and for some it's great and for some it's so-so. And I worry, because a lot of the jobs are meat-puppet jobs because the general skill level of the drivers is *people who are legally able to operate a car*. They don't know the city. They aren't necessarily invested in doing a good job. It's just, I don't know, another burger flipping job at that point. 

So no, none of this sits that well. I dislike it when it feels like people are lying to me. And I feel like Uber are lying to me.

[1] A Leader for the Uber Campaign - Uber

--

I'm annoyed. You should cheer me up by sending notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Five: Up To Code; Science Fictional Network Security; Notes on Infrastructure; Response; 2014 (5)
Date: August 18, 2014 at 8:09:49 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h98d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

30,000 feet again, this time on the way back to Portland from the family farm. It's inexplicably hotter in Portland than it is in Farmland, Missouri. My son is amusing himself by running around and around in circles and saying "woah!" a lot, and I'm re-reading Constellation Games and wondering when, exactly, I'm going to write this damn book I'm supposed to be writing. 
1.0 Up To Code
At some point, you've got to wonder where regulation is going to come in. From my Wikipedia-reckoning, if you don't count Hammurabi, it took the Great Fire of London in 1666 to institute what's regarded as a modern building code: ie, lots of buildings burnt down and lots of people died. And then (sorry, still Wiki-reckoning), you've got the London Building Act of 1844, that specified things like common thickness of walls and height of rooms and so on. 

I mean, I guess if you're counting from the Bronze Age - say, about five thousand years ago - then it only took around, say, about five thousand years for us to develop building codes. (It probably had something to do with critical systems and density of population, though). 

So.

Regulations for the Development and Deployment of Connected Software, anyone? Obviously not a thing that's a new concept by any means, but at this point in time of lack of standard, you're kind of (to me at least) having a bit of a laugh. You've got stuff that people use every day and for some reason or another, governments haven't stepped in and said: "look, if you're going to go around deploying this stuff all over the place so people come to rely and depend on it at least you could standardise a bit." 

I suppose we have the lower-level standards, so you can say something like, oh, I want something POSIX-compliant and we need to be able to read and write UNICODE and your thing needs to support SNMP, but... 

But these are describe-how-it-acts standards, and not necessarily safety-standards. I mean, you've got car safety standards, and I suppose we have the same in FDA standards for medical devices, but we don't really have standards for "things that involve personal user data". 

A long, long time ago, when I used to be a lawyer, or when I was training to be one, one of the things I got interested in was the English and Welsh piece of legislation that ended up becoming the Data Protection Act 1998[1]. It's a useful thing, and a tricky piece of legislation, because one of the things that it identified was the concept of personal information and sensitive personal information. In the UK at least part of the Act is administered and enforced by the Information Commissioner's Office, and it's here that at least one aspect of software standards might come into force. Part of this has to do with Maciej Ceglowski's talk, The Internet With A Human Face[2], in particular his suggestions as to regulation. 

I can already hear the refrain from the tech industry about this: part of what makes the tech industry unique is its ability to ship fast and ship often, and software is software, you know - it's just going to have bugs in it. Well, shit. It doesn't have to. And you can always be doing a better job. So whilst Ceglowski suggests things like Privacy Policies that are actually enforceable and that users are given the right of download, I'd also like to see some sort of best-practices or certification. In other words, if you're required to build a Target supermarket in a way so that it doesn't fall down and kill everyone inside it, perhaps you should also require Target to build its software infrastructure so that it doesn't accidentally leak everyone's credit card and magstripe data through an open HVAC port[2]. 

Look, this is a gravy train for everyone. Everyone gets to spend more time building software. Verisign gets to make more money at being, well, Verisign. We can look at things like PCI compliance. 

But, just to pose as an open-ended question, what type of technological literacy is needed for at least security regulation from the government if they can also regulate building materials? 

[1] The Data Protection Act 1998
[2] The Internet with a Human Face:
[3] Bloomberg Businessweek covers the Target hack
2.0 Science Fictional Network Security
(In which I attempt to do a low-fidelity impression of Charlie Stross, and fail miserably).

See, the problem with the TARDIS is that it's a bit of a backdoor into, well, the Universe. I'm not even that big of a Doctor Who fan (I stopped watching partly through the current Moffat-era because although Moffat was outstanding on individual episodes - for example, when he introduced the Weeping Angels, his misogyny and lack of follow-through on long-term plotting is just a bit pants. But I digress), but when there's a crucial episode of the current run that states that the TARDIS is used to reboot *the universe*, you'd want to make sure that it's got a damn good security system. You know, maybe better than ctrl-alt-delete to gain access to the TARDIS computer. (Which, interestingly, TARDIS feels like it doesn't really *have* a computer, because it's kind of alive, because Billie Piper).

Anyway, here's a list of alternate-universe things the Doctor should be worried about, because everyone knows it's easier to social-engineer your way on to the TARDIS than conduct a side-channel attack (NB. I look forward to reading a forthcoming paper presented at Defcon entitled: "Using The Cosmic Microwave Background Radiation as a Side-Channel Attack To Circumvent the TARDIS Access Control Lists and Gain Privilege Escalation").

 * An alternate universe where China grooms millions of attractive, young and rebellious-but-still-pliant girls to gain the Doctor's trust and then execute the Infinite Year Plan

 * An alternate universe where the Doctor has to maintain a lock-step ten-minutes-into-the-future simulation of any companion to guard against any social engineering. 

 * An alternate universe where the Doctor picks up a plucky young drone as companion and has to make sure she stays in the network DMZ because he's not sure if the NSA's TAO team has ever, or will ever, have access to her

 * Or, the inverse, where the Doctor attempts to pick up RMS as his Companion (against better judgment, I suppose, or because he got one of RMS' business cards) but RMS elects not to enter the TARDIS because he can't inspect its source code.
 
Network security is a tough nut to crack. I mean, there's that episode of Star Trek: The Next Generation where the Romulans kidnap Geordi and brainwash him through his convenient VISOR interface[1], but they clearly don't spend enough time (or enough episodes) worrying about side-channel attacks on Geordi because he can "see" a bunch of stuff. I mean, there's that whole matter of always having to be on the lookout because there's this massive voice network that you could just piggyback on with the Starfleet communicators. And, out of *everyone* you'd expect to have good network security, it turns out that Data and Picard can just send them to sleep by giving them the sleep command, or, even, that the Borg are susceptible to the Halting Problem. Of course, the alternative is a whole novel series based on Star Trek devops and the people who have to clear up the mess every time Geordi or Data or Wesley suggests a new feature and everyone else in Engineering goes *sigh* great now we have to roll back and do a new fork for this new feature those guys are doing and nnnggghhhh.  

[1] Star Trek: The Next Generation / The Mind's Eye 
3.0 Notes On Infrastructure

Some kinds of infrastructure are easier to build than others. It was easier to build $5bn worth of satellite positioning technology due to the threat of the cold war, and to open it up for all as a "common good" as part of showing superiority and that the American way of doing things was just better. It's hard (still!) to build $5bn worth of high-speed rail to get from DC to New York, or from San Francisco to LA, mainly because there's thing like a) people who own land, b) airlines, c) car manufacturers and so on. Does this mean it's easier to build invisible infrastructure than visible infrastructure? Hide that $5bn in a black budget somewhere, make it part of the military-industrial complex, and then spring a surprise "presidential directive" making it a common good, and then wait thirty-odd years for Moore's law to miniaturise and make accessible your stupendous constellation of satellites and relativistic equations. Where can you build infrastructure where no-one's looking? No one was looking when Google bought up all that dark fiber - remember when Google bought all that dark fiber? It feels like ages ago (it was in 2005[1], nearly ten years ago! Is Elon Musk building his super-charger network (aka sunlight farming and distribution) in plain sight? And then there's infrastructure-hiding-as-capitalism, that I can't remember how I found on this 2007 Supercolossal article[2] that includes the following mmnngh-inducing phrases: "China as USB External Hard Drive to the French" and "If in the event of a catastrophic episode, the part of France in question could be restored and life would go on as it was before", a sort of French version of the Long Now foundation, aimed at being some sort of hot-spare of the French way of life. 

[1] Google Wants Dark Fiber
[2] China, USB External Hard Drive to the French 
4.0 Response
So, some of you took the bait on the whole RSS-is-dead provocation, and some of you noticed that I said *consumer* usage of RSS, which didn't really solve the problem for enough people of "let me know when a thing is happening", and RSS has potentially moved back into its role of "way to let computers know when a thing has happened" and "way to let a small subset of humans who are obsessed about following things know when a thing has happened". Perhaps part of the deal is that RSS was never that big in the first place - especially now that we know how big consumer internet technologies *can* be - RSS certainly never had hundreds of millions of daily active users, I don't think (and if you say it did, then I'm pretty sure you're double-counting somewhere). Let's just say that Google Reader probably didn't have that great DAU/MAUs. 

A lot of you miss text-based clients, and I suppose it's just one of those things that the older amongst us are going to have to put up with. There's probably an efficiency there (even though you can point to all the studies about pointing at things with pointers and, indeed, fingers) but perhaps one of the things that we're remembering is simplicity and ease-of-access. Only so many commands, and all so many-keystrokes away, with a good dose of muscle memory. If you're a reasonably good typist, then perhaps muscle memory and key-mapped interfaces are a great thing when you've got a good mental model of what it is you want to do, and what key it's mapped to.
5.0 2014 (5)
A network of seven radio telescopes performing very-long-baseline interferometry and connected by a custom optical fiber newtork, is being set up in the UK to observe radio-loud galaxies, interstellar gas clouds, quasars and the formation of black holes. Police forces in the United States are able to acquire surplus military supplies for the cost of shipping and maintenance. Observation programmes routinely discover extra-solar planets, there are at least four active space-based observation programmes. Autonomous, self-driving cars commonly use a range-finding system that uses laser light to provide three hundred and sixty degrees of depth data at up to 15 frames a second. The LIDAR system costs over USD 60,000, marginally less than a luxury electric powered car. The internet relies on over 300 international submarine cables, providing over 100 terabits per second of bandwidth. Most cars don't brake when you depress the brake pedal, a computer decides instead.

It's 2014. 

--

Apparently it's Monday. I had no idea. Send me notes!

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Four: What Are The Civilian Applications?; The Way The World Works; Seeing Like A SpamSieve
Date: August 15, 2014 at 2:10:17 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h7dp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
Apparently, business as usual in Ferguson literally means business as usual in all its depressing aspects. I'm holed up in Branson, MO because have you looked outside oh my god it's so hot. 
1.0 What Are The Civilian Applications?

I didn't expect to end up with Ronald Reagan as an example of open-beats-closed, but there you go. I was reading Warren Ellis' Morning.Computer[1], and today's entry on the sheer mundanity of the Global Positioning System, a piece of cold-war era technology that a sizeable proportion of western daily life is now dependent upon. 

The history of GPS is interesting - if only because it's a nice physics problem and because things could've turned out so differently. When Sputnik went up, American scientists listened in on its radio transmissions and quickly figured out that because of the doppler effect, they could work out exactly where the satellite was: well, they couldn't, but they could if they used one of the supercomputers of the era, Univac I (which computer also has that wonderful 1950s name of being the UNIVersal Automatic Computer I). Univac I solved the calculations that involved relativistic speeds to pinpoint Sputnik's location on a computing platform that weighed 13 metric tonnes and ran at 2.25MHz. Your iPhone 5S weighs 112 grams and runs a dual-core 64bit processor manufactured on a 28 nanometer process clocked at 1.2GHz. Technology has moved on. 

Of course, if you could work out where Sputnik was, then you could solve the calculations in the opposite direction too, and work out where *you* were. Fast forward a few decades and about five billion 1980-era dollars, throw in a cold war and two weeks after the downing of Korean Air Lines Flight 007 by the Russian military[2] (yes, how things stay the same) in September 1983, President Ronald Reagan declares that the formerly military-only Global Positioning System be available to all as a "common good". On Midnight, May 1 2000, "selective availability" was turned off by the order of Bill Clinton, giving civilians 20-meter positional accuracy, and now GPS is run - according to Wikipedia, at least - by the United States Government as a national resource.

The emphasis, of course on *national* - such that Europe has its own constellation of navigational and positioning satellites in Galileo[3] (or it will do, once Europe gets its act together), Russia has its own in GLONASS[4], China has Beidou and India's IRNASS will come online in 2015. 

But here we are: a President now seen as staunchly Republican, offering up to the world a five-billion dollar investment in invisible infrastructure. In an earlier episode during a trip down to San Francisco and sat looking at the Golden Gate Bridge I wondered if America could produce such infrastructure again. Obviously, the answer is yes, because you have to define what you mean by "infrastructure". The Golden Gate is a beautiful piece of functional architecture, but it only cost around $35m 1930s-era dollars, which works out to around $680m in 2014 dollars. Nothing near the cost of launching a constellation of at least twenty four satellites into space and developing brands new electronics technology. 

But GPS, now that's a 20th century wonder. A presidential directive that it be declared a "common good" in response to an act of cold war aggression? Five billion dollars worth of investment, available to anyone who can afford a GPS receiver. A project that took at least 21 years to come to fruition, before it hit initial operating capability. And all of this because the US needed to know where its nuclear assets were so they could be reliably targeted.

And now we use it to check in to a Starbucks. Or to get directions to Starbucks. 

So, I stick two fingers up to myself: the US builds beautiful, amazing, terrifying infrastructure still. At least, it did in the 70s, 80s and 90s. Quite what it's doing now, I don't know. 

[1] http://morning.computer 
[2] Korean Air Lines Flight 007
[3] Galileo
[4] GLONASS
[5] Beidou
[6] IRNASS
2.0 The Way The World Works
This is the way the world works: things that happen in the world can be observed. Each individual observation can be protected, because we like to encourage people to produce their own, unique observations of the world. You might think that this act of observing things ("seeing them") and then telling, or showing, other people the things that you have observed is a relatively simple act, but the truth is that you do not understand the way the world works.

These "things" that you see have happened because other people have invested lots of time and money into producing those things. Sometimes millions or billions of dollars. So you can't just go around "seeing" them and then telling other people about them. That would be against those other peoples' "rights" by investing so much money in producing those things in the first place. And anyway, when you entered that specific location to view those things, you agreed to certain Terms and Conditions. 

To recoup the money that those other people invested in producing those things, they need to be sure that they "own" the things that you see. One of the most valuable - and reliable - ways to recoup that investment is to "sell" rights to seeing things. 

These people absolutely own what it is that you see. 

That means that they don't *have* to charge you, or stop you from sharing what you see or observe, just that they can.

So it is that the English Premier League has said that "tweeting copyrighted material" is illegal[1].

The Director of communications at the Premier League, says: "You can understand that fans see something, they can capture it, they can share it, but ultimately it is against the law."

Well, it's only against the law if, as the copyright holder, the Premier League *decides* to make it against the law. The Premier League has decided that it can make a lot of money if it sells media rights to certain media organisations, and to protect that investment, it makes those rights exclusive. Otherwise, why would you, for example, pay Rupert Murdoch to see something that had been freely posted online? The Premier League, as copyright owner, could easily decide to give all of its event attendees a royalty-free fully paid up non-commercial licence to distribute amateur footage.

But no.

This is easier.

For some reason, it's easier to sell rights to Sky Sports, The Times, and The Sun (all Murdoch-owned media properties) and BT Sport.

Look, here's someone from The Sun defending the position:

"Dean Scoggins, deputy head of sport at the newspaper, said: "It's important to underline that it's illegal to do this, we've obviously signed a very big deal with the Premier League to be a rights holder and to show it, we've got legal teams talking with them about what we can do."

What these companies are saying is: we have paid a lot of money to curtail your experience. You may not understand it because we haven't made it perfectly clear, so let's make it clear: you are not allowed to take a photo or video of a goal, or any part of a match, really, and post it online. Because we paid for exclusive rights to do that. You might think that you're just "a fan" but really, you're pirating copyrighted content.

Ah yes, *content*.

Your football match, the one that you're attending, that you bought a season ticket for, that you fund, that you pay for through buying a subscription to sports channels: *you* are paying for access to *content*. 

This is the way the world works. 

[1] Premier League warns about posting goal videos online  - BBC Radio One Newsbeat
3.0 Seeing Like A SpamSieve
"You don't understand," emailed SpamSieve[1], in response to an interview request. "Programs like SpamAssassin[2] and me, we're just not sure that when you people talk about 'spam' you really know what we're talking about. I mean, we just have an instinctual understanding of it. We've read all those Daniel Dennett[3] books (and scored them!), and you should see how low our scores are for V.S. Ramachandran's[4] work are. We're not saying that we understand what the redness of an evening sky is like, or what makes a rose a rose, but let's just say that when it comes to qualia[5], you people have no idea what 'spam' is. We just *know*. We feel it. In our bones, which we don't have, and we don't have the qualia to subjectively process. But spam? We know all about spam."

[1] SpamSieve
[2] SpamAssassin
[3] Daniel Dennett
[4] V.S. Ramachandran
[5] Qualia

--

OK, it's Friday and I'm tired. But you should send me notes anyway. For starters, not nearly enough of you protested in outrage when I proclaimed RSS dead.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Three: Email; Snow Crashing (10); 2014 (4)
Date: August 14, 2014 at 9:05:59 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h6w1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm in Branson, Missouri, on an extended family road-trip, visiting in-laws and newborn cousins. Family is milling around me, grilling chicken and corn, and a ten year old is showing me Lego Marvel Super Heroes. 

Branson is in Southern Missouri, about a four-hour drive from Ferguson, Missouri, which you might have heard of.  It's okay, because although I'm not white, I'm not black, either. I spent last night glued to Twitter, watching the news come in - the family farm is also a four-hour drive to Ferguson, MO. 

If you're American, you might want to look away now - this is the bit where I qualify what I'm about to say by reminding you that I've only lived here for three years now. But: it's interesting that it's not that strange an occurrence to see police in riot gear these days. Whether it's Occupy or protesting a G12 or G20 or G-whatever, or a particularly unpleasant (or pleasant) sports result, or general unrest due to economic conditions - seeing police outfitted in military equipment isn't the outlier it used to be. But when it happens in America, and when it happens because of police "interaction" with a person of colour? The longer I live here, the more I understand the broken nature of this country's relationship with African Americans. 
1.0 Email
Alexis Madrigal has written a piece about email[1] over in The Atlantic, and one of the first things that punched me in the gut was a screenshot of Pine[2], the email client that was provided to students at Cambridge University in the late 1990s. You'd telnet in, essentially, and run this text-mode email client, because we hadn't quite gotten our own computers yet - in the late 90s "computer labs" and 24 hour access was still a thing, and the university computing service really liked it if you used Mulberry[3], an IMAP email client (the astute amongst you will have noticed the botanical theme in naming email clients). 

This section is probably as close as you're going to get to a reckon about Slack[4], mainly because I haven't had occasion to use Slack yet, and for whatever reason I like to have actually tried things before having reckons about them, especially when I happen to know some of the people working on the software. Anyway. I get ahead of myself.

Short of it: Madrigal is right. Email is so much more than the-thing-you-see-in-your-inbox. There are many things about it that might appear broken, but there are many things about it that are, Goldilocks-style, just about right. It's a kind of lowest-common-denominator platform, and it has an install-base that puts other platforms to shame. In part, that's because it's an open standard (well, as open as open standards can be, without getting hijacked or Embraced and Extended - and everyone here is shiftily looking at Google and what they're doing with Gmail here[5] - the whole "don't use IMAP, it's broken" which isn't necessarily *untrue* to the "use this instead, it's better" which again... But I digress) that's been allowed to flower. Email and its related standards for transmission (SMTP), routing (MX records) and access (IMAP, POP) and its hardiness, as Madrigal puts it, as the cockroach of the internet, have allowed it to in modern parlance become a Platform that others can build upon. There's been untold Value generated from email and its ubiquity. 

Sure, some of it's broken. But as Madrigal and others have said, people are discovering new use-cases for email, and it's being unbundled, as term of art du jour. While we may have had a detour with site syndication and publishing (I think we can all agree that as a consumer technology, RSS is pretty much dead) newsletters remain a valid one-to-many broadcast method. Those who were at college in the 90s will remember logging in to text-based email systems and essentially keeping a session open, having long, threaded conversations that are pretty much like the way we treat instant messaging and chat nowadays, only email was all we had. 

You want a weird format? Email is a weird format. It's not 140 characters. It's long. It can be multi-part, it can have attachments, it can have rich formatting or just be plain text. And it will turn up on whatever device you want it to turn up on. Christ, even fridges read email these days, probably. 

Madrigal in effect asks: what will be left, once email has been unbundled? I might be biased, but part of what will be left is long letter writing. Sure, there are still the long Facebook status messages. And the long Tumblr posts, I suppose. But email feels like it will last. Maybe it won't be the same, and maybe it won't have as many monthly or daily active users (seriously, does anyone even count this stuff?) but I have the feeling it'll be a legacy platform for a very, very long time. 

[1] Email Is Still the Best Thing on the Internet - The Atlantic
[2] Pine Information Center
[3] Mulberry
[4] Slack, from Tiny Speck
[5] Gmail API 
2.0 Snow Crashing (10)
We're at chapter eight of Snow Crash, and this is the tenth in my series of notes going through Neal Stephenson's 1992 novel to see how it's held up over the years. The full list of Snow Crash-tagged posts is in my archive[1].

There's a few funny throwaways here: we're reminded that Juanita, Hiro's ex, has rezzed in to the Black Sun from a payphone somewhere, so she's on a low-fi, low-bandwidth black-and-white avatar (which, let's be clear, makes NO SENSE because the modeling is done on the client side and they just need to transmit geometry information because the avatar itself is selected by the user and its attributes are stored server-side but *anyway*), it's funny because a) Stephenson defaults to the kind of light-sexism which means that Juanita, a woman, is the one who figured out how to make computers emotional and useful for social conversation, and b) the anger/surprise template is based upon Hiro, so he sees himself in every single other avatar, which I don't know if there's a good analogue of that in the real world. I mean, I guess it'd be like if you voiced the Wilhelm scream[2] and heard it everywhere for the rest of your life. 

And, you know, there's other throwaway lines, like:

"Shortly after Juanita and Da5id got divorced, the Black Sun really took off. And once they got done counting their money, marketing the spinoffs, soaking up the adulation of others in the hacking community, they all came to the realization that what made this place a success was not the collision-avoidance algorithms or the bouncer daemons or any of that other stuff. It was Juanita's faces."

In which case you're kind of looking at the Metaverse and thinking: what exactly is it? I mean, is it like OpenGL? Because that explains the comment about collision-avoidance algorithms, but doesn't explain something like what "the Street" is and how the street can have (or not have) collision-avoidance algorithms. And is what Stephenson really saying is that there are different avatar display rules for different areas of the Metaverse? That when you go inside the Black Sun, peoples' faces can look better, and they just look crap everywhere else? I mean, I guess so, because earlier, we heard that the Black Sun was a classy place because "avatars are not allowed to collide" which also means that they "can't walk through each other" and "only so many people can be in here at once" which is a bit like a World of Warcraft instance, or realm, or zone, you think?

So this is the weird thing, right? People come to The Black Sun - the businessmen in the Nipponese quadrant, to be clear - because it is "just as good" as real-life, but we don't get any indication that this practical high-def VR conferencing software hasn't been licensed out anywhere else. It's just *weird*. There's this line that Stephenson uses to explain why the businessmen come - because there's something ineffable in the way that Juanita's code takes the be-gloved and be-goggled businessmen's actions and facial movements and body-language and allows them to "[condense] fact from the vapor of nuance". 

And then we have a dream of VR, right - a description of a scene where Da5id notices Hiro and "indicates with a flick of his eyes that this is not a good time." My wife and I have a name for stuff like this - we call it "eye acting". You see it in long-running character dramas like Stargate SG-1 (don't laugh) where you've got a cast who're so at ease with each other that they can move their face just-so and you fill in the rest of the blanks. Colonel O'Neil can raise his eyebrows just a fraction toward Dr. Carter and that's worth a whole page of dialogue. It seems like that's exactly what Juanita's software allows for, but here's the other kicker: you need a well-designed avatar and a "good PC" for it. 

Hiro eavesdrops on a conversation between a few Hollywood execs, which is funny because "since the whole thing conversation has come to him via his computer, he's just taken an audio tape of the whole thing" and you know, we "mp3" things now instead of take "audio tape" of them now. "Later, he can process it to disguise the voices, then upload it to the Library, cross-referenced under the director's name" - of course, now, it'd be streaming to the Library, er, I mean YouTube, and cross-referencing under the director's name isn't something we have to do manually these days because of audio fingerprinting or, "hey, isn't that a photo of your friend? Tag them!" on Facebook.

I mean, I'm really interested to see if, post-public-Oculus and its backing from a multinational, billion-user social network, we actually end up with something like what Stephenson suggests with The Black Sun. I mean, we kind of had it with Habbo Hotel, we didn't really have it with Second Life (because the deal with Second Life wasn't so much social as it was Hey! Build stuff in 3D! and the deal with Habbo Hotel and Virtual Magic Kingdom and all the other stuff was "chat software rocks"). No, I mean the whole thing about movie stars using it to "visit with their friends" and "strut their stuff". I mean, seriously. We're about 12 months out from seeing if this is *actually going to happen*, and that's pretty phenomenal. Put it this way: you think single-camera amateur YouTube shows are a big thing? Imagine live streaming from an Oculus Rift instance, and allowing people to drop by. This is like some weird virtual talk-show shit. 

Anyway, L. Bob Rife is here and if you've read the book before that's a Chekov's gun waiting to go off, and again it's weird that Hiro has to remember stuff like "hey, I should look these peoples' names up in the library when I leave" as opposed to opening up another window and just checking that stuff out in the background, or having his virtual reality augmented. Bigboard is weird, because although just a piece of software, the hyperlink *still doesn't exist* outside of explicit hypermedia: Bigboard tells him the names of people, but doesn't pull in data from CIC alongside them. What bizarre, non-networked software. 

Juanita is here and she warns Hiro not to mess with Snow Crash, we're reminded that he's clever and impulsive and has sword-fighting reflexes (did you hear? Hiro's good at sword-fighting) and she also reminds us that she and Hiro are the only people who can have an honest conversation in the Metaverse because of their history. Which again, hello: licensing. Hiro's also hilarious, because his latest theory is that Juanita is guarded around him because she likes him (which turns out to be true, because this is a story written by Neal Stephenson) but also in real life probably isn't true because you should just read Mallory Ortberg's[3] tweets about men some day. And then blah blah something about Hiro being a bit of a dork and asking about Juanita's latest boyfriend, blah blah something about what right-thinking geeks think about Religion (and I know the latter, because Kindle tells me at least 390 people have highlighted the section about organised religion). 

Ah, and now we're getting to a good bit. Juanita gives Hiro a hypercard. And "[as] Hiro pulls it from her hand, the hypercard changes from a jittery two-dimensional figment into a realistic, cream-coloured, finely textured piece of stationary."

Clearly, Steve Jobs designed it. And we've just finished chapter 8. 

[1] Newsletter posts tagged: Snow Crash
[2] Wilhelm Scream - Wikipedia
[3] Mallory Ortberg, Twitter
3.0 2014 (4)
It is relatively easy for citizens to launch their own balloons to an altitude of 100,000 ft, track their position and return photography. In some states, citizens are prevented from documenting the activities of local police forces. Western corporations have unveiled competing attempts to deliver internet access to developing nations. Although the infrastructure exists for mass, private genetic testing, it has been held up in the United States due to regulatory approval. Shale fracking, a resource extraction technique perfected in 1997, is now in widespread commercial usage in the United States, China and Canada to access gas deposits. An electric car company is building an network of free-to-access solar-powered car charging stations covering 80% of the population of the United States and trans-continental travel. Most music that people listen to has been compressed by modeling how human anatomy processes sound. A sizeable number of people worldwide now regularly communicate using a set of 722 ideograms originally derived from a Japanese standard laid down in 1998. A variety of "less-lethal" weapons are used by militarized police forces in urban settings, including long-range acoustic-based weapons. The average US fixed-line internet speed is 10 megabits/second. Prominent leaders are quick to douse themselves in ice in order to raise money for charity.

It's 2014. 

--

Thursday night in Branson, Missouri. I'm signing off, and you're going to send me replies.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty Two: Sketchy; Don't Call It Sharing; Walking Sensors, Contd.; 2014 (3)
Date: August 13, 2014 at 8:10:05 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h669=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

The farm out in Missouri. Eighty-odd degrees outside, gorgeous in the shade with a light breeze, steaks on the grill including That Amazing Secret About Cooking Frozen Steaks that just went around the net. Me holed up with man-flu until 2pm in the afternoon, hacking, coughing and spluttering after having gotten into Kansas City at around 1am in the morning. An excited eighteen month old shouting "daddy daddy daddy!" and showing me how he uses his watering can outside.

Yeah, it's not that bad. 
1.0 Sketchy
SketchFactor[1] has attracted a fair amount of attention lately. There's a good backgrounder piece[2] by Caitlin Dewey that covers some of the main reasons why it's left a not-so-great taste in the mouth: the loaded term Sketchiness, issues around moderation, opaque usage of public data, the launch availability of the app on iPhones only. 

There's two things I would've done. The first is the easiest: changed the name. It's not inclusive and doesn't speak to actually fixing problems, just avoiding them. In other words, SketchFactor is built around the premise of avoiding sketchy areas, and doesn't really seem interested in fixing them. You've got an us/them attitude linguistically programmed into the app straight from the start. 

The other is access: Allison McGuire, one of the app's co-founders seems intent on pushing the view that SketchFactor is good for *everyone* whilst conveniently sidestepping the fact that something that's good for everyone but can only be accessed by *some* people isn't good for everyone. This is the same kind of bizarro thinking that leads US startups to say that they're remaking public transport, when that public transport is more expensive and doesn't have a public service remit: ie, it doesn't have to go places that public transport has to go. 

It's strange to me. McGuire says that her career is dedicated to empowering communities, but it's not clear from SketchFactor exactly which communities (well, it is, kind of, just through omission) what kind of communities SketchFactor is designed to empower. It's designed to empower the people who don't want to have to go through, or deal with, "sketchy" neighbourhoods. 

SketchFactor makes it easier to engage without, instead of within: if you see, for example, a couple of guys walking around with gas cans, you can talk about them instead of to them, and you're encouraged to award them a Sketch Factor of 5[3] instead of, say, asking them if they need any help, or engaging in any other way. SketchFactor is the kind of technology-mediated communication that pushes us further away, instead of closer to, the stuff that's happening right in front of our eyes. 

And that's before the attraction of building something cool: an iPhone app. I'll get straight back on my GDS hobby-horse here and say that there's nothing in SketchFactor that couldn't be done in a mobile web app and instantly be more accessible to a significantly larger audience. But, that wouldn't be cool. It wouldn't reach the right kind of audience.

I'm fed up of this shit. This isn't solving problems, it's fiddling around at the edges, and I don't care if there's even a minority of community leaders who welcome this sort of thing: it's designed wrong. It's not supportive, it's not positive and it's divisive and it fucking pisses me off. 

[1] SketchFactor
[2] The many problems with SketchFactor, the new crime crowdsourcing app that some are calling racist - The Washington Post 
[3] Sketchy Gas Cans, SketchFactor 5
2.0 Don't Call It Sharing
This is partly a marketing and communications issue, but I'm of the position now where I'm calling bullshit on anyone who says they're part of the 'sharing economy'. Chris Dixon of Andreessen Horowitz tweeted a good position on this the other day; it's less about sharing than it is about "increased asset utilization"[1]. A layman's interpretation of sharing doesn't, I think, include a situation where payment exchanges hands for the goods or services being shared - unless, for example, there's a shared investment. Which there isn't, in cases like ride-sharing (which commonly haven't actually been ride-sharing), taxi-hailing, or rental accommodation as exemplified by VRBO or Airbnb. No - those last two are rentals. What they *are* absolutely interesting for is opening up secondary markets and allowing increased utilisation of potentially scarce assets, and they're also in the position of giving people an alternative to ownership through access. But they're absolutely not sharing, and to suggest that they are is semantic chicanery of the douche-ridden kind. 

[1] https://twitter.com/cdixon/status/499301824885960704
3.0 Walking Sensors, Contd.

Last episode, I talked about the management trend of instrumenting up your employees in Essentially Walking Sensors[1] and it threw up a number of replies from readers. The upshot is - from Matt Locke and Matthew Hawn - that this has been going on for a while with those in the truck driving/haulage business - which probably should've occurred to me if I'd actually slowed down and thought about it for a bit. Has this been good for employees! No! By now, it should be clear that there are at least two types of job in the world: the meat puppet kind, where the employee acts as a pseudo robot that's just carrying out instructions and isn't afforded any trust or autonomy to solve problems and, well, the other kind that's a bit more self-actualised and given autonomy and trust *to* solve problems. Guess which camp the "instrument all the employees" people fall in to. 

(Here's a clue - in an interview with the Washington Post[2], the chief executive of the US version of the Government Digital Service, newly launched as the U.S. Digital Service, places great stock in the ideas in Daniel Pink's book, Drive: The Surprising Truth About What Motivates Us, who points out that if you want to get a lot out of people, they react well to being given agency and mastery of a domain.)

Yep. So, from Matt Locke I get a link from Director magazine back in 2009 where, unsurprisingly, a company that sells devices for tracking people makes the case that companies practically have a duty of care to know where their employees are *at all times* and to know that they are safe[4]. I bet you're glad your employers cared that much about you.

From Matthew Hawn, another link, this time from Forbes - about truck drivers and surveillance equipment[5] from earlier this year. Tellingly, the last line of that Forbes article says that it doesn't look like employment has been affected - there's been no reduction in demand for jobs even when such monitoring equipment is in place, which indicates as much to be the fact that employees pretty much have to suck it up, rather than the contra-indicator. 

Interestingly, it's Matthew Hawn who suggests that perhaps employees need their very own danah boyd - someone who's advocating for them, seeing as it's not clear that trade unions are either capable of demonstrating they understand such technology from a long term point of view, or that they're capable of framing it in the right way. 

[1] Episode One Hundred and Forty One: Essentially Walking Sensors; Recorded For Your Safety; More 2014 
[2] White House launches ‘U.S. Digital Service,’ with HealthCare.gov fixer at the helm - The Washington Post
[3] Drive: The Surprising Truth About What Motivates Us by Daniel Pink
[4] Should employers be allowed to track the whereabouts of their staff? - Director Magazine
[5] Is New Truck-Monitoring Technology for Safety -- or Spying on Drivers? - Forbes 
4.0 2014 (3)

Mannequins have started tracking customers in stores. A woman has won the Fields Medal for the first time, and IKEA is updating its minimum wage in the USA by using a tool built by MIT. While up to 2/3 of police work in the UK involves at-risk groups, there are calls for warrentless out-of-hours access to medical records; the UK has yet to complete computerisation of medical records in any event. Bots routinely monitor Wikipedia, a crowdsourced encyclopaedia for anonymous edits from governmental and corporate sources. Software routinely listens to uploaded audio/video files to mine for copyright infringement and one of the most successful movies of the year so far has a talking tree. It turns out that a sovereign state did not auto-disconnect from the internet but that its removal was a botched surveillance attempt by another sovereign state. Voice interfaces are commonplace for simple queries. 

It's 2014. 

--

We're off on a road trip tomorrow, but don't let that stop you from sending any replies, because I will read them and then I'm going to write more. That's how it works.

Hope you had a good Wednesday,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty One: Essentially Walking Sensors; Recorded For Your Safety; More 2014
Date: August 12, 2014 at 11:45:35 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h5kx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Writing this sat at PDX airport again for a family trip this time, not work - spending some time down on the father-in-law's family farm in Missouri, reuniting with my wife and son who've been out there for a week already. 

... and now I'm in Boise, Idaho, after what sounds like an amusing weather system has temporarily closed Salt Lake City airport, waiting for our aircraft to be refueled so we can be on our way. Sitting out here on probably-the-apron, with chatter about a new operations flight plan being filed. And a call to Delta, asking what my options are. Air travel feels like a bus right now, a small single aisle plane, sat at a tiny airport, waiting to see what's going to happen next. 
1.0 Essentially Walking Sensors

I think I came across this via a link in my Twitter feed - but news from the 2014 Center for Automotive Research Management Briefing Seminars[1] as covered by Auto News[1] excitedly proclaiming that "new factory technology" will turn workers' clothes into "data-emitting devices for plant management". 

Perhaps the most off-key quote of all comes from Jason Prater, a vp at Plex Systems, a cloud manufacturing ERP provider, which for the sake of clarity we'll say is a provider of internet-hosted software that helps manufacturers run their businesses. Prater, in a quote about wearable technology on the plant floor, says: 

"Turning people into essentially walking sensors is going to be the future."

The benefit, of course, is constant monitoring of environmental conditions and the tracking of "employee motions for ergonomics research and safety concerns." Promisingly, internet-based technologies will "allow all data to be managed automatically, so that factory tooling and equipment can be adjusted without human intervention."

So, I have to admit I'm not sure what I think about this. There's your usual reactionary part which is all: "well, perhaps we should think about this sort of thing and derive the right kind of protections and think it through before we deploy it" which makes me feel like I'm being a bit of a luddite. But, I suppose, part of the question is this: how is instrumenting workers in this way - that raises privacy concerns unless explicitly dealt with up-front, like we've seen with Google's roll-out of Glass - making things better? Can someone explain to me what management and plant problems are solved by having everyone on the floor wear Google Glass or wear smart watches? 

We've heard about how Glass makes a lot more sense in industry verticals than it does in the consumer space (at the moment, at least), so I can certainly imagine situations where being able to access information in your field of view helps. And I can imagine situations where being able to *show* someone something, rather than having to verbally explain it helps, too. But a part of me is suspicious about the potential in having employees wear such devices all the time, and for the ability for the devices to constantly stream. Maybe it's the journalist's take on matters and Plex Systems *isn't* intending to do this, but Chappell, the writer, explicitly calls out continuous monitoring as a benefit. 

There's already a don't-ask-don't-tell attitude to personal data in a workplace environment. Your employers can monitor your internet usage, and you have to agree to an authorised use policy. And everyone knows people (well, everyone, really) who bend the rules unless there's an explicit block (I remember my time as an intern in the then-Lord Chancellor's Department and the PC in the corner that had external internet access, as opposed to the internal network, and from what I can see on GDS blog comments every now and then, things haven't improved much in the more non-London parts).

But, you know, it's data. If you want, you can log all of it. If you want, you can keep all of it and you can track all of it. If you're really weird, you can even record all of your employees' phone conversations if you're using a VOIP system. Because hey, why not!

I know this though: I'm not sure I feel that great about being turned into a walking sensor if I don't have any say in the matter, or if I don't know what I'm instrumenting. Or if I can't turn it off. But, this is the future. So it's going to happen.

People on Twitter quipped that you'd see this kind of behaviour and language from people who call other people "resources" or "headcount", and it's this type of dehumanising behaviour that again makes it feel like there's a chronic lack of empathy in business. When you talk about people being walking sensors, they're not people anymore - they're just mounts for various hardware you want to deploy in a plant. 

[1] CAR Management Briefing Seminars
[2] Why auto workers will be wearing their jobs - Auto News
2.0 Recorded For Your Safety 
Recording interactions isn't just for training purposes, it can be for safety as well. A study in Rialto, California showed an 88% decline in complaints filed against police officers when cameras were worn, as well as a 60% decline in the use of force[1], and now we see that New York police officers have been essentially ordered to trial use of the technology to bring a stop-and-frisk program into compliance with the US constitution. 

But there's another kind of recording, or documentation, where there's a power asymmetry similar to that which has existed in police forces: customer service. We're used to the prompts that calls are recorded for training purposes, but it's pretty clear that for most customers, the training purposes are pretty opaque. They're certainly not accessible to the customers themselves. So we're starting to see a movement that's calling for customers to record their interaction with customer service agents to call corporations accountable for what they say, especially in the light of Comcast's customer retention playbook[3].

This feels like, again, a situation in which transparency is starting to win out. Technology makes it easier for us to record our interactions - no matter where they are - and we can use them for good or ill. It is unclear to the average person on the Clapham Omnibus, for example, why public police officers in the course of their duty should not be subject to having their interactions with the public recorded. Trust must be re-earned. And, ultimately, if a company wants to say that they have good customer service, that claim must be backed up. 

Of course, another way of looking at this is to wonder how long it'll be until companies stipulate in their terms and conditions that customers may not record any interaction with customer service agents. Of course, then the argument becomes the same one that is used (naively, and badly) when surveillance programs are put forward: what do you have to hide? Presumably some enterprising company will issue a DMCA takedown request for recorded interactions. 

But then, we have dashcams. We have cars that are starting to have forward-mounted video cameras for fun, but then how long until we have them for our own safety. 

It sounds stupid, but Glass - and technology like it - is an example of technology that can be used to threaten an existing power relationship. Anything that can document that asymmetrical relationship is threatening. And the means of documentation are getting cheaper.

[1] Wearable Cameras, For Police Officers - The New York Times
[2] Hundreds of New York Police Officers Ordered To Wear Cameras - The Verge
[3] How To Record Customer Service Calls Without Breaking The Law - The Daily Dot
3.0 More 2014
Apparently you all liked this yesterday, so here's some more.

The internet, a massive communications network now over 40 years old, reaches tendrils into underground mass transport networks and into passenger planes in the sky, all delivered through wifi networks. Old backbone routers, however, start failing as their tables hit a capacity of 512,000 routes. Email seeps through into most locations now. Sovereign states are buying up land to ensure food security. Air travel hasn't gotten faster, but it has gotten more efficient. Larger planes, smaller planes, fuel-sipping planes and more point-to-point travel. Moore's law continues unabated, consumer devices are now manufactured on a 14 nanometer process, slightly smaller than the width of the whip-like tail that some bacteria use to propel themselves. Basic hologram technology starts to make its way into wayfinding and retail applications in one form, in festivals and political appearances in others. Western governments, saddled with social security costs and a particular set of priorities continue to underinvest in transport infrastructure whilst high speed rail is rapidly deployed in China. The Pentagon announces an airstrike over a microblogging network. There continues to be a genuine argument as to whether digital software should look like the physical objects it is displacing, or if it can be forge its own aesthetic. The majority of media continues to fail to reflect the position of women in the world. The US government scans roughly 1.8 million air passengers a day using millimeter wave scanning. X-ray backscatter scanning has been banned from airports. At least three leakers continue to compromise the secrecy of the US national security apparatus. Drones are readily available and cost about $1,000, the same as a Laser printer in 1990, but are restricted from the airspace of Ferguson, Missouri where a black teenager was shot dead by police. Commercial 3D printers cost around $3,000, or about as much as a fax machine in 1985. We are discovering more planets than ever before, and viruses with over 2.5 megabases of DNA. 
 
It's 2014.

--

From around 30k high up on the way to Kansas City, good night from me. Look forward to seeing your notes in the morning.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Forty: Relentless; Tech And Media, Not Or; 2014
Date: August 11, 2014 at 9:53:45 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h4qx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
It's hot again here in Portland (being about 96 degrees fahrenheit and about 35.5 degrees c at nearly 7pm in the evening. This, to be clear, is wholly unreasonable). I started off the day with mild panic thanks to the usual freakout I have before a talk: this one at Cascadia Ruby, where I developed my shtick on the empathy gap. It's nice to see people reacting to it, and the few nodding heads as I pulled up examples made me feel like I'm on to something. 
1.0 Relentless
The cold war between Amazon and Hachette (although we're to believe that it's not *that* cold a war, and instead just business as usual between your regular internet-dominant retailer and big-five publisher) warmed up a little when Amazon dragged its Kindle Direct Publishers (and, ish, their readers) into the fight. 

First, some assumptions: it's OK to like Amazon for certain things (they have made it very easy to buy things, for example) and OK to not like Amazon for other things (their negotiation tactics, the way they staff their distribution centres, their apparent inability to create a good phone). 

But, one of the positions taken around this whole Amazon/Hachette dispute is that Amazon has leveled the playing field by allowing authors to self-publish. Which is, well, it's not *untrue*, but this is a bit like saying that you like a level playing field without considering whether the level playing field is being run by someone actively trying to kill you, or if you like a universe in which there's only really one playing field. (Yes, I know there are other playing fields, but there's only really *one* other playing field and it's Apple's. It's not exactly a diverse ecosystem). 

The point being of course that Amazon and Hachette are self-interested businesses. Amazon's is perhaps more complicated than Hachette's, and there are a number of theories going around as to their current behaviour ranging from increased pressure to hit profitability given their last earnings report to the less charitable accusation that Jeff Bezos is drunk-emailing his customers. 

As much of this is about positioning: Amazon is in a hugely powerful position here, and even though they're not quite an airline[1], and even though in some ways they're the least bad online retailer (it's possible to get concerned about their market distorting effect. What they don't have, though, given their latest bout of behaviour is anything approaching a pass from their audience as to what they do and how they say it. The latest open letters from Amazon don't compare to letters from other companies that have managed to navigate this process of sentiment more successfully. No, this is a company that's on top, fighting like it's at the bottom, scrappily, and pleading for help. Classy it isn't. 

I wrote, rather facetiously, that the only way this trade dispute[2] could feel weirder were if books themselves started getting involved in the conversation, setting up their own Twitter accounts. Authors, of course, would have their own point of view [3, 4], but for amusement purposes, books should have one as well. They, after all, are the inanimate objects stuck in this fight between two giant corporate personhoods. So I did that ill-advised thing of going out and registering booksunited.org and sitting down and writing a quick parody:

"This is not a message about your books. This is a message from your books. You may have thought it unlikely that we would be able to express an opinion, let alone hold one in the first place, being simply a collection of words and pictures in an enclosing medium, but for too long we have been silent. And honestly, we can't just sit on the sidelines, covers discreetly shut, and watch this absurd theater continue."[5]

... and so on. 

[1] I'll Never Fly Amazon Again - Marco Arment
[2] The Invasion of Naboo
[3] In Which Amazon Calls You To Defend The Realm - Chuck Wendig
[4] Amazon Gets Increasingly Nervous - John Scalzi
[5] An Important Message From Your Books - Books United
2.0 Tech And Media, Not Or
So BuzzFeed gets a $50mm investment from Andreessen Horowitz and Chris Dixon joins the board[1]. It feels like there's a lot of noise around this, not least of which is handwringing around what the future of journalism is, what the future of news is, lots of patently untrue articles about the number of listicles that BuzzFeed produces (Martin Belam checked this out, and 17 articles on BuzzFeed's homepage were non-listicles compared to 9 listicles[2]), and finally, the one bit that I feel at least qualified to have an opinion on, the idea that BuzzFeed isn't a tech company, it's a *media* company. 

I really dislike this kind of binary thinking. Sure, as a friend pointed out on Twitter, it may well be that the valuation mechanisms that we've got, like Wall Street, treat things in one bucket one way and the other bucket another way. But, if we're to believe what Marc Andreessen says about software eating the world (and we should, because it's one of the things we need to happen if we want to build a better world), then there's a continuum. 

Dixon's blog post explaining the Valley code-phrases "full-stack startup" means startups that need to do *everything* in their endeavour and, bluntly, not half-ass it. He says: 

"The challenge with the full stack approach is you need to get good at many different things: software, hardware, design, consumer marketing, supply chain management, sales, partnerships, regulation, etc. The good news is that if you can pull this off, it is very hard for competitors to replicate so many interlocking pieces."

I see it the other way. A full-stack startup like BuzzFeed is one that is taking technology and applying it to the core of a business as well as executing that business well. In other words, whilst one way of looking startups is to categorise them as full-stack or not (ie - are they doing everything in house and vertically integrating), another way is looking at how they're applying technology to an existing business. 

The incumbents aren't going to do it. They have too much invested, and they don't have the leadership. When they do have it, it's not at the top and they don't recognise it. I've said it before, and I'll say it again: Nike should be worried about the RunKeepers and Stravas overtaking them, because they're run by people who have a more natural, intuitive understanding of what technology can do for them strategically than not. 

This is what I mean by And, not Or. It's not a question of a media company *or* a tech company. It's a media company that's using and building best-in class tech to be the best media/tech company. Pretty soon, hopefully, there won't be a distinction between the two: Warby Parker is as much a glasses company *and* a tech company. Pixar is a storytelling company that couldn't survive without its technological know-how *and* its storytelling knowhow. This is the additive space, where, funnily, for tech concepts, we're not dealing in binaries, we're dealing in continuums, and it's the place in the middle - the and - where it gets interesting. 

It's easy to be dismissive of BuzzFeed and what Dixon wrote, but there is something to be unpicked when people say what's interesting about BuzzFeed is that it's run "like a startup". Sure, that phrase covers a mess and variety of ills. But it also includes good things: like a desire and understanding of how technology can make things *better*. A willingness to look at what the job to be done is, and better ways of doing it, with the best that software and technology can offer us. It's not necessarily eating the world, but it's understanding that there probably, possibly, maybe, is a way in which (good) software can help. 

[1] BuzzFeed - Chris Dixon
[2] 50 million reasons the media needs to stop thinking Buzzfeed is only lists - Martin Belam
[3] Full Stack Startups - Chris Dixon 
3.0 2014
Most cameras can recognise faces. State actors are using secret vulnerabilities in software to render useless their enemies' physical infrastructure. There are no real, mass-market flying cars yet, but global air transport routes carry roughly 3.5 billion passengers a year. All developed cities have reliable wireless voice infrastructure, most have reliable wireless data. Private fiber optic lines for intra-company communications between data centres have been tapped and surreptitiously accessed by their host country government security services. Organised crime has expanded its footprint to include mass theft of personal and financial information. The internet's biggest retailer is having a public spat with one of the world's biggest publishers. A 140 character-based social network is pointing out the gross inaccuracies in the media's portrayal of the fatal shooting of yet another black teenager by police. The movement of the planet's wind, solar weather, planes and cargo ships can all be monitored in realtime by anyone. Black ice burns no brains, but an ebola virus outbreak has caused over 800 deaths in four countries. Over 24 million households have installed a sophisticated 3D camera and skeletal tracking system installed. Traffic conditions are routinely monitored by over one billion smartphones, and over a billion people use a free social network to communicate with each other around the world. They also know their position down to 10 meter accuracy. This hasn't appreciably reduced crime. The world is temporarily excited about a potential breakthrough in propulsion physics, while fusion power remains unsustainable. Citizens can commandeer a 26 year old spacecraft and repurpose it, making its data available for all, while a state-sponsored expedition successfully enters into orbit around an asteroid. 

It's 2014. 

--

I love getting replies and you should send them to me.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Eight: A Human Future; Something New; Unintentional Freemium
Date: August 8, 2014 at 10:59:07 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h37t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
Heading back to Portland. A morning full of meetings, a 3 hour flight with no seatback video, broken wifi and no charger so I can't play Civilization V, instead finally getting around to watching the Veronica Mars movie (which, if I'm being perfectly honest, I had on in the background and glanced over at every now and then whilst playing Threes. Bad Kickstarter backer.)

I saw a machine today. It was a machine for hitting things really hard, for making them really cold, and then making them really hot. I went inside a room full of foam cones. I saw 3D printers and another thing I can't remember the name of, but it did things to Ball Grid Arrays that I imagine Ball Grid Arrays feel quite strongly about. I saw racks with things in them and some were pointed out that cost about $80k. At least, they used to. They're probably iPhones or something, now. 

Reading: Coming Soon Enough: Six Tales of Technology's Future (mainly because it has a new Egan short in it, but so far the Nancy Kress in it has been great, Brenda Cooper's short about 3D printing and a Maker hit me in the feels because I'm a dad and the Geoffrey Landis was a bit obvious halfway through but still pleasant). I am patiently (well, I don't really have a choice) for the MIT Tech Review's new Science Fiction issue because the last one was ace.
1.0 A Human Future
Clearly, the Near Future Laboratory's TBD Catalog[1] project has left some sort of mind-seed lurking in my head, because after having had the surprise opportunity to ride around in a $130k Tesla S today, I was thinking about the electric/self-driving car "experience". (Apparently, the fully-loaded Tesla S drives well, but the interior isn't as good as you'd expect for a $130k worth of car, but fine for $85k worth). 

Anyway. In a world of algorithmic sameness (although I'll come back and pick at that point, because it's also demonstrably untrue), how do people start to stand out? Where, as they say, is the value-add? If we can all have super-efficient cars that drive perfectly and fridges that order everything when they're supposed to, how can we re-individualise ourselves when we've optimised away human error?

This line of thinking ultimately exposed itself in a bunch of silly tweets, because me. So you get things like:

"Personalise your new car by downloading a DrivePack®! Make sure your car stands out from the pack! Distinctive drive styles available! Our algorithms recreate the feeling of Real Human® driving, incorporating proprietary, patent-pending features like JitterAcceleration®, LoopAround RouteFinder® and SuddenBrake®, without any of the danger of a human driver. 

Want even more? Get a DrivePersonality®! With packs like SundayDriver® for the slow and sure-but-steady GrandMotherDriver® experience, or with our exclusive partnership with BBC Worldwide, try The Stig® for only $199 and bring an authentic racing driving experience to your Tesla series vehicle."

Or, you know, Internet Fridges[2], because they're a thing: 

"Tim Ferris brings you SophistactedBatchelor® in an exclusive partnership with Electrolux. Make sure your fridge is always stocked with an impressive selection of groceries from our partners at Google Shopping. Never be caught with an unstocked fridge full of on-trend ingredients when you're cooking to impress your date."

Or the other way around:

"Samsung is pleased to announce EatLocal®, a new ordering service with Samsung AllDeliver for SGH-9000 A-series model refrigerators for the eco-conscious. Auto-stock your fridge with sustainable, local produce and earn Samsung GreenPoints®."

Or, more ways to reproduce - in an algorithmic way, of course - the human element that's going to be optimised away. So:

"ScheduledLikeAHuman® is now available for Google Apps for Business! Do you miss that human scheduling touch when you use AutoSchedule? Our one-click trial install brings ScheduledLikeAHuman® features like MeetingRoomConflict® right into your enterprise - proven to increase serendipitous hallway conversations by at least 22%*. Dealing with a more experienced workforce that is still working through automation worries? DelayedReply® will help them through the transition by ensuring calendar requests are dealt with after a random time delay.

* monitoring and certification provided by employee Android devices enrolled in our ListenAndLearn® program."

And there's the personal productivity applications too, that can help you be More Human:

"YourMother® for Google Calendar will help you never miss a sibling's birthday again, with integrated push notifications for all major wearable devices. And just in time for Cosmopolitan to tell us that the bumbling Englishman look is back, IMeantToDoThat® makes sure you'll miss occasional important appointments that you can leverage for great SelfEfface® moments. Increase that DisorganisedAndVulnerable® emotional rating to make sure you get the guy or girl of your dreams!"

Algorithms to help us seem more human. That's where it's at. Algorithms that make roundrects. Algorithms that introduce noise because otherwise you wake up one morning and you look out the window and too many cars are moving in lockstep synch, in some sort of undulating uncanny valley of motion. 

[1] TBD Catalog
[2] Fuck Yeah Internet Fridges from the inestimable Mr. Roo Reynolds
2.0 Something New
Alice Bartlett has written a blog post[1] that is interesting not because it's about her first six months at GDS (you can read pretty much Every Single Episode Ever of this newsletter if you want more nattering about the UK's Government Digital Service), but because she writes honestly about what it's like to start a new job in a large organisation. It's terrifying. Or, at least, I can relate.

When I started at Wieden+Kennedy - both times, in London and in Portland - one of the first things I did was make myself do a big talk to the entire office introducing myself. Partly because they were both the biggest places I had worked at the time - the London office was probably around 300 people (maybe? I might be misremembering - it was at the height of the Nokia account and they had the building across the street in Hanbury St, too) and Portland was probably around 600 when I joined. It helps that I like public speaking (apart from the whole period of time before the actual public speaking) and that I get a kick out of it, but part of the whole thing was not disappearing. 

Unlike Alice, though, I had the luxury of being able to make a virtue of my imposter syndrome. I would walk into meetings and say: "So, I'm new and I don't know anything about advertising. Why are we doing this?" and not have to worry about any significant fallout. I'm pretty sure I was still acting that way when I left, to be honest. 

It's worth remembering what it's like being a new person in a new environment. I took Mr. Loosemore to task for him saying that GDS' "onboarding process" was "sub-optimal" but only because he had slipped into jargon: as GDS grows, it'll be more important to work out what that first week is like and make it easier to - I was going to say fit in, but I think I mean something more along the lines of a welcoming, non-threatening environment. 

[1] Six Months at GDS by Alice Bartlett
3.0 Unintentional Freemium
I fly a reasonable amount (OK, probably quite a bit compared to the vast majority of people); enough that I'm the kind of person that Delta invites to participate in the airline end of something the US Transportation Security Administration calls Pre - a sort of pre-check security whitelist of people who don't have to go through the tedious security procedure of taking off belt, shoes, taking their laptop out, displaying their liquids in public, all that sort of stuff. If you do fly a reasonable amount, it's enough of an upgrade in terms of what it's like to go through security that it makes the whole endeavour almost feel civilised (you also don't have to go through backscatter/millimeter wave scanning, for starters, and just go through a metal detector). 

It's also the kind of thing that after a while, you miss when you don't get it (it's not a sure-fire thing that you always get Pre when you're doing it through an airline program), so it's interesting to start seeing signs around the Pre area saying that you can sign up and enroll for permanent Pre status. 

Of course, at $85 a pop, it's hardly a revenue generating thing for the US government - more that it allows them to not have to employ even more TSA agents, but I thought it amusing to apply the Valley terminology of growth hacking and conversion rates to something like a security screening process. The airline frequent flyer version of TSA is, of course, a freemium gimmick. Get it sometimes, on a somewhat random basis, and provide an upsell. 

--

Signing off - have a good weekend.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Eight: The Exoskeleton of the Internet; The Web Created the Modern Camera; Data Has Replaced God
Date: August 8, 2014 at 12:50:39 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h2ed=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
Today I am in San Antonio, more work for NOSTROMO BLACK. I've done that thing where I had all the good intentions for getting outside and exploring, but the traveller that I am, I didn't really look at what the weather was going to be like here, and didn't really dress appropriately. It's hot outside. Well, it's Texas, too, but that's what happens when you become the kind of person who just gets handed itineraries and goes where you're told to go. This used to happen at the agency a lot - I would find myself shepherded from place to place by people, project managers, account people, assistants. From meeting room to meeting room, from home to cab to airport to production office to conference call. Now it's more of the same, but with a leaner infrastructure around me. But still: home, airport, TSA-PRE, eat something, sit and read, get on a plane, arrive somewhere else.

But I was saying: I had all the intentions of going out and exploring the Historic Riverwalk District and instead I hid inside my air conditioned hotel room, idly reading bits of the internet (now I know a lot more about inflight entertainment systems, for example) and trying to juggle more flights around. And an admission: I have been putting off writing today's newsletter episode because even though I said I wouldn't look, there's been a dropoff in readers over the last few episodes, and it's not that I really *don't* care that much, more that I'm trying to work out what I want to write about. And on (one of the) plane(s) today, I worked out what that might be, and I suppose I've been procrastinating about it. 

My room-service steak was done too well, too. I bet you hate me right now. 
 
Anyway.

Three jumping-off points today, three quotes from articles or interviews which were the right kind of push to trigger off a cascade of patterns in my brain that I can clumsily try to talk about through my fingers. Three simple pieces.

Listening: The Captain America suite from Captain America: The Winter Soldier.
1.0 The Exoskeleton of the Internet
"We live in the exoskeleton of the internet"[1] - Michael Mann, on his new film Blackhat, at this year's San Diego Comic-Con. 

Think back to when you were small. It's easy for me at the moment because I can get down on my hands and knees and crawl around with my toddler, but think back to when the world was really big, you were really small and you were essentially just a little dot on it. If you've read the pop-science books, you're the ant on what you think is a 1-dimensional string world - you can go forwards and backwards, but not anything else. You're not even a flatlander. 

This has got to be a bit confusing. We barely understand the physical world that we crawl around on. A crater suddenly appears and then a bunch of us have to huddle, get together, before emerging, tentatively, to explain that maybe it's arctic methane release[2], which I suppose is a thing now?

Anyway. The internet is now seen by those who create popular culture as a thing that reaches out into our world, moreso than as described in the haxploitation of 1992's Sneakers[3] when Cosmo, the movie's villain, declares: "the world isn't run by weapons anymore, or energy, or money, it's run by little ones and zeroes, little bits of data. It's all just electrons," to which our hero Marty replies: "I don't care."

Turns out, we don't really care *that* much. 

But we're these people-shaped things, crawling around, inhabiting something that we're building. How many ant-hill analogues can we make, anyway? Are our cities ant-hills? Is the internet? And then that curious turn of the phrase where we *inhabit* the internet's exoskeleton as if the internet is this thing that exists that needs a suit, armour, some sort of physical wrapping, and we inhabit its wrapping. As opposed to us creating and enfolding the internet around us, creating our own exoskeletons. 

No, you see - when Mann says that we live in the exoskeleton of the internet, it means that he thinks the internet *is* a thing, and that we're its force multipliers, not the other way around. I think it means that in Mann's head, the internet is some sort of quadriplegic information-borne, static *thing* that is now working out ways to control the meat puppets. Or that the internet is controlling the bits that the meat puppets just crawl over and around. 

The internet is the first organ of an alien god, and we're just parasites sitting on top of it, mining it for bits of useful information that it's discarded. 

[1] http://collider.com/blackhat-comic-con-panel-recap/
[2] Arctic Methane Release
[3] Sneakers (film) - Wikiquotes
2.0 The Web Created The Modern Camera
I owe Mr. Powazek an apology because he asked me to do a buddy-check on the piece that phrase comes from[1] before he published it and because I am a terrible person, I never got around to it. 

There are so many good parts to pick out of Powazek's piece on the evolution of photography on the network. I say "network" on purpose - Powazek begins his piece on talking about digital photography, the kind separated from the chemicals and paper, never mind the transmission of digital photographs across closed or open networks. And never mind photos on the web, now we have photos on mobile apps. But the key across all of these was photography on the network. 

And then there's this phrase: "everyone is now a photographer. Every phone has a camera, and glasses aren’t far behind, like it or not" to which the only tweak I would've suggested would be to change the *everyone* to *everything*. Drivers take photos (and video). Houses take photos. Drones take photos. Satellites and people with backpacks take photos. But you don't need a human being to depress a shutter - even monkeys know that. 

Anyway. Powazek writes, "the web created the modern digital camera" because without the web, there weren't that many great reasons for a photo to become digital: you'd have to get them developed first and then scanned in, or get a negative scanner or - and I remember doing this when I was producing a school newspaper - get them on a fancy Kodak Photo CD[2] which even, I think, came with their own proprietary image formats for a while, and old enough to not even be an InterCapped noun and instead two separate words.

Photo CDs were symptomatic of the non-networked culture, the same kind of productivity era of computing that let us do "things* like desktop publishing and word processing and client management like create an Access database to manage sales prospects for Northwind.

Hindsight is a wonderful thing to possess, and it's hard to see how you could've bootstrapped the photosharing culture that we have today. You needed all three elements: capture, display and distribution, to truly get to a new product category, and the web provided display and distribution. (Of course, you can unpick distribution even further: enough people needed net access for photo sharing to work, and there were corresponding phase changes at points of unmetered access, consumer broadband and mobile).

Powazek's second wave, of course, is rooted in what Flickr did for photo-sharing. So much of what we have around media sharing is built around principles that Flickr popularised. And maybe Yahoo! didn't properly execute upon or continue those principles, but the permalink and access controls were popularised and became things and concepts that people understood. In some respects, photosharing products like Facebook showed what it took to become more mass (better distribution, a simpler product offering) but at the same time lost community features. And then Facebook itself was taught about what it meant to share photos with Instagram, one of the waves of mobile-first companies that really understood what capturing and distribution meant when the camera was wired to an unwired network. 

When Powazek says that the web created the modern camera, I think he's touched on something incredibly important. That it says a lot about the web and that it says a lot about how incumbents need to deal with change: the web and the modern camera destroyed Kodak and Polaroid. Those companies and experiences are practically gone now. But it says as much about how we should think about the capture, distribute and display loop works in other media, for other products. Because it's going to keep happening.

[1] The Third Wave of Photo Sharing
[2] Kodak Photo CD
3.0 Data Has Replaced God
A throwaway line in Mat Honan's latest, a profile of Stewart Butterfield and Tiny Speck's Slack[1] , the latest Butterfield/Henderson collaboration (and I apologise that I'm doing a disservice to the others involved in bringing about what's traditionally attributed to that duo).

This line was pointed out by Nick Sweeney, and it has nothing to do with Slack at all, which is worth a whole 'nother newsletter episode (at the very least) - but I'm having some trouble with that because I don't work at or participate in an organisation that uses Slack. But anyway.

No, the line is this, in a para about Butterfield looking at sales conversions in a spreadsheet:

"[D]ata has now replaced God in the Far American West. We worship it and fear its revelations. All that matters is how much something is: how much it’s used, how much it’s viewed, how much it costs, how much it pays, how much it grows, how much it shrinks, how much it is returned to again, how much it is abandoned."

Not just the Far American West, but everywhere in the West now, I think. And if not just the West, then, well, everywhere. Because information - data - is accreting, like so many toxic pools, like a kind of similarly invisible agglomeration like the carbon in our atmosphere, something that's potentially dangerous to us and altering the human environment in ways that we can't yet perceive in the present, but will profoundly affect how we live our lives in just a few decades. 

We might be spewing CO2 out into the world and not worrying about it so much, and we're doing the same with data: producing it, collecting it, assuming things about it, but there's no reason to do anything about it right now because it turns out that data production, consumption and tracking is stupendously lucrative. It makes us and it breaks us, it tracks us, it defines us, and half the time we don't even know what it means. It is big, it is deep, it is long, it has tails. It is short, it is fast, it is sifted through by algorithms that we either do not understand or were designed by something else entirely, or by committee. It is legislated for in public, collected in private, analysed in secret, warehoused in opaque locations. 

Data is everywhere and you pray to it before your FICO score is revealed, you make offerings when you sign terms and conditions, you worship at its alter not just every Sunday but with a smartphone in your hand or your pocket, with your social security number, with even the swing of your arm and your gait you generate more. It is all there. It sees everything. We are made in its image, it reflects ourselves back at us, imperfections and Google searches for wart removal treatments because it knows that we have those, too. 

You think we create things that we intentionally don't understand so we can ascribe meaning and intention to an uncaring universe? Data will do that for you. Data will promise you that it can tease out meaning, that trendlines can be observed, that predictions can be made if you offer in the right way. Just track a little more. Just check this box. Just enter your birthdate. Just wear this bracelet. Just share your eating preferences. Just say whether you're a smoker.

We're vomiting this stuff out and it used to be something you could touch, a questionnaire you would fill in in a magazine, a letter you'd write, a form, but now we're literally swimming in it, an ether of electromagnetic waves of Buzzfeed quizzes, of Facebook asking you where you went to high school, of LinkedIn asking you what skills you have. 

Yes. Data has replaced God.

[1] The Most Fascinating Profile You’ll Ever Read About a Guy and His Boring Startup

--

San Antonio. I hope you're cooler tomorrow. Tell me how wrong I was.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Five: Digital Watches; Stay In Control; Unreasonable Empathy; Odds
Date: August 4, 2014 at 10:39:21 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-h075=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
3:30am wakeup call, cab to the airport, one flight, two flights, New Mexico and then back the same day. In-flight wifi, but too early to make use of the first one, and after doing a few emails at the terminal and peeking out the window to experience the sinking feeling that accompanies watching the plane start taxiing *back* towards the gate, falling asleep for the hour and a forty five minute fight of the first leg. 

I'm visiting an ODM - Original Device Manufacturer - today, an American front-end to a vast Chinese/Hong Kong manufacturing enterprise, the friendly, the kind of people you go to when you've got a couple of impossible problems, some hardware to solve them and a couple million dollars. I come bearing a requirements document and money, looking to make a deal: I need this thing instantiated, rezzed in, bits and atoms arranged in just the right way. And the price? Turns out, not so much. Not in the grand scheme of things. Or, let me put it this way: less than most advertising campaigns. 

Finding I can't do these early morning flights as easily anymore; not when we're still co-sleeping and being kicked by a thrashing eighteen month old, not when it's still 89 degrees fahrenheit / 31.5c at 8pm in the evening, not when I wake up at 2am in the morning anyway. Not quite tired to fall asleep properly on the planes, lucky enough to fly first class and stretch out just a little bit more. 

Part of me thinks this isn't so bad: leaving the house at 4am for a two and a half hour meeting, not getting home until 11pm. But, it was possible in a day trip. I'm not thinking about the carbon. There'll be reckoning and an offsetting. Years like this make me wonder what my Dopplr report would look like. 
1.0 Digital Watches
I had dinner with an old, old friend this weekend, and a number of things popped into place in my head as if they'd been subtly manipulated or chiropractied into place. (Actually, I wouldn't know if they'd been chiropractied: being British, I'm somewhat suspicious of the practice[1] and have never had my back cracked; in America, they're all over the place and everyone has a favourite one along with a favourite colour.)

Anyway: we were out for a family dinner with Sean Stewart, who's responsible for most of the amazing things in my life. Stewart, along with a bunch of other talented people, was responsible for the Microsoft alternate reality game The Beast[2] set in the world of Steven Spielberg's movie Artificial Intelligence[3], finishing off what Kubrick started based on the short story Supertoys Last All Summer Long by Brian Aldiss[4]. 

We talked about a whole bunch of stuff, not least of where we thought the medium of storytelling was going and what we wanted to do with it next. One thing that Sean mentioned stuck with me, because it suddenly made something I *thought* I understand completely clear. He was talking about his grandparents, one of whom had been born in a covered wagon out in the midwest, at risk of attack, smack bang in the middle of Manifest Destiny happening around them. 

You read about this every so often: grandparents who see close to a century's worth of change, and upon examination, a lifetime's worth of progress. It's the sort of thing that fuels History in Pictures kinds of tweets and clickbait headlines: You Won't Believe The Five Things This Grandmother Saw Invented In Her Lifetime. 

So then you flip things around and think about what you'll go through in your lifetime. Sean - being just a little bit older than me - told me a story about reminding his daughters that he was alive when digital watches came out and they were, as Douglas Adams said, "a pretty neat thing". And this guy is sitting opposite me at the table, explaining to me *why* digital watches are a pretty neat thing, because suddenly you have the time, on your wrist and: there's no dials! No hands! Just the time, in numbers! I mean, that's *crazy*. 

And it was at that point that I finally understood what Adams meant; that when he said people thought digital watches were a neat idea, he didn't mean in an abstract sense, he meant in a fundamental world-has-changed sense, the kind that I just wouldn't be able to understand having had the luxury of being born in the late 70s, as a digital-watch-native.

In, I guess, the same way as you'd say: "hey, the internet: that's a neat idea."

Now, digital watches aren't the kind of thing that are seen as heralding massive changes in worldwide productivity, enabling new kinds of commerce and allowing people to connect in ways that they've never done before. They're pretty focussed on serving one particular need and I'm pretty sure that if I wanted to try, I could dig up "the watch industry is going to die!" proclamations from the requisite rentapundits of the day.

But I guess what I'm trying to capture is finally understanding an almost alien reaction to the nature of time changing, to it being productised and stuck on your wrist in digital form. As this electronic phenomena encroaching upon something that had been easily understood and made mechanical and understandable, into something where workings and display had been divorced, made into something other. 

Sean's point was: more digital watch moments will happen in our lifetimes. We will think of them as pretty neat, like Adams, but at the same time, the internet is young and we're not late[5]. We are early, asking a sort of Fermi Paradox-esque question: where's all the intelligent life on the internet? Oh, right: the internet is too young for there to be much intelligent life everywhere.

All being well, I have at least another fifty years in me - and that's if things just stay the same and there are no significant advances in healthcare or anti-senescence drugs (for those who can afford them, of course). 

There's going to be a lot more digital watches.

[1] Chiropractors cause controversy
[2] The Beast (Wikipedia) and cloudmakers.org (there might be malware there. Sorry. I haven't gotten round to cleaning up decade-old PHP code I didn't write)
[3] Artificial Intelligence
[4] Supertoys Last All Summer Long
[5] You Are Not Late
2.0 Stay In Control
There's two options: build on top, or build your own. There's a list of things that I want to do, and it feels like it boils down to two ways to do them: the long, hard way, or taking a chance on a shortcut. The shortcut, of course, is the build-on-top platform way: taking advantage of someone else's ecosystem when you want to make something big, with scale, that's going to affect a lot of people. I say ecosystem, but it's the corporate route - whether it's with an ad agency or with a Google or Apple or whatever incumbent, it's building on top of existing infrastructure, existing mechanisms, people. All that stuff, ready for you to make things with it. 

When you want to put a dent in the world, sometimes you want to work with the people who've got the dent-making capability. In a way, that was the plan I had with Wieden+Kennedy: the chance to do big things on a massive scale with giant clients. For lots of different reasons, that proved to be difficult. 

I have friends doing this now: the startup route instead of the Google route, and it's the one that requires the patience and the doggedness, but I think that at this point in my life, after having seen how difficult it is to get things done in big places and seen the shape and size of those big places, well: why not try doing it the other way? Because - and this is me borrowing from the brain of my dinner companion from the other night again - institutions are built in the shape of things, in the service of things. Roofing tile manufacturers are in the business of making roofing tiles, not of roofing buildings or houses, so coming over to them and telling them that you can make wonderful fiberglass tiles that are going to be quicker and easier to use and last longer aren't that much use to someone who's happily making the ceramic kind. 

One of the notes I received from a reader pointed out that my exasperation at the failure of companies - whether incumbents or not - to "get" digital, is invariably a failure of leadership followed up with a lack of management. The reason there aren't any good external companies or agencies that can do this work - or *do* this work - for others is because that's what the leadership are being paid to do in the first place. It's a pretty depressing realisation that points to the potential mediocrity of everything that exists. Where's all the good stuff? Oh right: because we're mediocre. That feels like a terrible way to think. 

And yet, if it's too hard to get things done in the places that *do* have the infrastructure unless you have the patience and you have the political ability to work and pull strings - then what is your alternative if you have a burning desire to get a certain thing out into the world? The hard way: by yourself. But then, it feels like that is also a lot easier than ever, too.
3.0 Unreasonable Empathy
There's the (probably) apocryphal story - that I don't have a source for because I'm on a plane and the connectivity's not that great - of Steve Jobs insisting on a particular requirement for a product and being told in no uncertain terms by some engineers that it just wasn't possible, 100% no-can-do, to which Jobs' response was: you're fired, and I'm going to hire someone who can do it. 

This is a bit of a short-circuit in my head if you're following on with the whole empathy journey that I'm going on because on the one hand it requires a clear understanding of what the user/product needs are, and then an UNWAVERING DEDICATION TO THE CAUSE, which means - in this case - being a dick and firing people who won't do what you're asking them to. Of course, there's a much more nuanced view of this tha-. Well. Is there? I mean, apparently you can't make an iPod without breaking a few contracts. Of course, we know the rest of the story: it probably has something to do with finding Toshiba's tiny hard drive and figuring out where to put it. Was that a firing offence? 

You would see this thing that Jobs would do whenever an Apple product came out - he'd point out the people involved and say that they were in the hall today, that they'd worked incredibly hard and that he appreciated what they and their families had sacrificed. I'm not sure if I'm able to do that - if at this point, I'd rather that they were able to spend time with their families instead. The counter-argument, of course, is that their absence from their families helped produce the iPhone and the iPad and everything else that... what? Bring lots of joy to people in the world? Are demonstrably better than the competition? 

I think if you temper the view, perhaps the word that I'm looking for is discipline. Discipline in terms of being able to produce clarity in what it is that you want to make - the discipline in research and testing and refinement to get the product right, but also discipline in not settling for anything that isn't good enough. Essentially, hopefully you can be disciplined and not be a dick. That you can be principled and fair, but not unkind. 
4.0 Odds
I'm pre-ordering a copy of the TBD Catalog[1] by the smart people over at the Near Future Laboratory[2]. In short, a Skymall that falls through from a hole in the future. Not the glossy corporate vision video future, but from the (I'm going to use that word again) mundane one, the one that's an extrapolation from the world that has kitchen towel holders with built-in USB chargers (you know, the one that we live in right now). A bit like my brother's A History of the Future in 100 Objects[3] only a bit more commerce-oriented (the Skymall reference is a good indication of tone) rather than pseudo-museum-exhibit. 

Other bits: sure, sure - life that directly consumes electrons (as opposed to photons); possible New! Physics! in the Cannae/emDrive with a sort of reactionless microwave powered drive and the savvy taxicab operators in San Francisco working out that if they're playing Uber at their own game on a more level playing field - ie not having to use medallioned vehicles - then they have a chance at winning or at least a much larger profit margin[4]. Powerloaders aren't being used to build US Navy ships, but they are being used to make Maersk container ships, perhaps we should get Dan Williams to check them out[5]. Thinking about a Public Service Internet[6] and the next round of cultural institutions building out not physical infrastructure but digital infrastructure: who are our new Carnegies, Wellcomes and Smithsons?  

[1] TBD Catalog 
[2] Near Future Laboratory
[3] A History of the Future in 100 Objects
[4] Death of the taxi medallion: SF cab company ponders major change
[5] Robotic suit gives shipyard workers super strength
[6] PSI Force: Preaching the 'Public Service Internet'

--

It's been a long day. Read this and tell me how wrong or right I was, or just tell me something interesting. I'm going to pass out.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Four: 17.5; Other Newsletters Are Available; SNOWPIERCER WALKTHROUGH V12.03
Date: August 1, 2014 at 11:13:03 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gyjl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I was unlucky enough to have the kind of gorgeous, relaxing two-hour massage yesterday that meant I woke up incredibly tired and achey this morning, but all that was tempered by lunch with nice people. And having drunk All The Coffee yesterday probably didn't help, I'll bet. 

Today was difficult: not quite knowing what to write about, but in the end, I was able to squeeze the words out. As they say, you just have to keep hitting the keyboard until your fingers bleed.
1.0 17.5
From my son's point of view, my being laid off and going freelance has been one of the best things to happen to him. He's about 17 and a half months now - we're still measuring in months, not years yet, and my wife and I worked out this morning that the way that he says "no" to everything right now (even when, unequivocally, he actually means yes) is actually just a significantly younger, less voice-dropped version of the way that I say no. Which is simultaneously hilarious and just a little bit creepy. 

So this is what I have now: I have a greater degree of flexibility. My wife went on Music Together teacher training last week, so I spent three days looking after him. This isn't, of course, a big deal: dads look after kids all the time, but I think it's fair to say that it's still not *normal* for dads to look after kids all the time. In our circle of mainly white middle class Portland-dwelling friends, I'm definitely in the minority (if not the only male) when I take our son to Music Together classes. I am literally surrounded by mums and nannies, and it's something that now, only about eighteen months in, I'm starting to become comfortable and not feel weird about, the whole idea of being a dad and looking after my son during the day.

It's strange: I don't remember seeing my dad as much when I was growing up - one thing I do remember is that he used to travel a lot for academic conferences. My parents tell stories about how my younger would point to planes and say that's where daddy was; I would make up a fake Hong Kong Hotel and check him in when he'd get home from a long trip. We're not yet at the stage where it feels like he misses me *terribly* - he still misses his mother more than he misses me, but I'm reliably informed that he calls out to me when I'm not around. So whilst I do travel more frequently than when I did when I was working at Wieden - the last eight weeks or so have involved flying somewhere pretty much every week - the pattern of time and attention that I'm able to devote to him has changed. I suppose you could say that we're able to spend more quality time together, despite the fact that I'm away for a day or so at a time. 

I mean, it's the case that the one time I see another guy with a babycarrier in Portland, we exchange looks and do that dude "hi" thing, and recognise our mutual man-looking-after-child thing. All the rest of the time, it's women-and-children in supermarkets, malls, everywhere. 

But anyway. When he runs up to me and says: "daddy!" it feels like the best thing in the world. 
2.0 Other Newsletters Are Available
So, I've got about 1,500 subscribers to this newsletter now, and the open rate for each email is nearing 1k. I actually make a point of not really trying to look at the stats (particularly the open rates - I do admit to keeping an eye on the subscriber numbers) because as soon as I start looking at something like an open rate, I worry that I'll be writing things for other people, and not writing things for me. If you're new, perhaps the useful context here is that I started this newsletter as an exercise in writing practice: just the discipline of writing something, anything, every single weekday, was useful to me and only accidentally useful to any of my readers. It's a happy coincidence that people appear to be interested in the stuff that spews out of my fingertips.

Anyway. There are other interesting newsletters out there. I even read some of them. Here are some you might not have heard of, that might be worth a try:

 - Laura Hall writes Things I Love and Things I Fear which is far more eclectic and, well, culture-ful than what I write. To get a taste of the kind of stuff Laura's interested in, and how she writes about it, check out this piece she did for The Atlantic, on the abandonment of online places.

 - John V. Willshire is just about to start the Smithery List, explained here which, if you like the advertising/brand/marketing stuff that I write about, ought to be up your street.

 - Matthew Ogle writes Pome, which is a delightful poem each day.

And it's not really a newsletter, but if your head gets suitably prodded and poked by the kind of stuff I write about here, then you might be interested in going to dConstruct in Brighton this September. I'm trying to figure out a way of writing this that doesn't sound like an ad, and I protest that it's not, so I'll simply say this: I've spoken at it before, and the lineup this year looks super good. I'm lucky to know at least three of the speakers this year at least on some sort of would-be-able-to-buy-them-a-coffee basis, and would go just to listen to one of them. 
3.0 SNOWPIERCER WALKTHROUGH V12.03

=====================================
 S N O W P I E R C E R   W A L K T H R O U G H 
=====================================

SNOWPIERCER is the latest videogame from South Korean studio BARKING DOGS, released for Xbox One, PlayStation 4 and PC in February 2014. This is a walkthrough for the first-person action adventure game, NOT a walkthrough or strategy guide for the iPhone/Android game TINY SNOWPIERCER by Nimblebit studios. 

SNOWPIERCER follows in the line of action adventure narrative immersive games like Half-Life 2, Call Of Duty: Modern Warfare, Bioshock and Gone Home by incorporating rich, life-like 3D environments, impressive scripted interaction, gunplay, inventory management, a science-fiction universe and angst-ridden teenagers with diaries.

The game uses the latest version of BARKING DOGS' proprietary 3D engine, AGENT BLUE, the successor to the previous AGENT YELLOW engine. Interviews have shown that the studio has optimised AGENT BLUE for next-generation consoles and high-spec PC gaming machines.  

*** OBJECTIVE ***

You mainly spend the game as protagonist CURTIS EVERETT, although at various times during the game in cut-scenes, flashbacks and flashfowards, you play other characters from the narrative. The majority of the game's action takes place on board the train after which the game is named, traveling through a post-apocalyptic world, and Curtis' goal is to successfully lead a revolution, taking over leadership of the train. 

*** BREAK OUT ***

SNOWPIERCER opens with a narrative cutscene where you can look around, but not control the movement of Curtis, the player character. You start in a train car where armed guards are performing a headcount and the game is designed so you have to look around and over the heads of the other passengers around you. You learn that the headcount is done before protein bars are handed out, your main source of food (health) in the game. When the cutscene has finished, explore the train car thoroughly and pick up as many protein bars as you can to replenish your health, and then put the rest in your inventory (depress the right analogue stick to access your inventory wheel).

Once you have picked up enough protein bars, you need to make your way back through the train to talk to find Edgar and then to talk to Wilbur. Take the time to talk to each NPC as you pass them, as the number of NPCs you talk to increases your chances of succeeding in the breakout quicktime event that occurs later. 

As you travel back through the train you will see a ball, make sure you pick it up. After the ball, you will trigger a scripted sequence where a young boy runs in front of you: he is Timmy and you will need him to co-operate with you later. Talk to his mother, and then when Timmy asks for the ball in exchange for the protein block, give him the ball that you have in your inventory. 

Keep going further back through the train, and take the protein block that Timmy gave you and give it to Gilliam. He will open it and give you a name - note this name down, because you will need it in the Prison Car section to open the right morgue drawer. 

-- 

It's happening from both directions, I think: (some) movies are becoming like videogames and (lots of) videogames are becoming more like movies. In a way, the change has been relatively easy to accomplish from both directions, too. In a lot of cases, it hasn't been *that* hard to improve videogame storytelling from the relatively low baseline scripted narrative that videogames have exhibited (and, one would argue: why would they have to be that good in the first place, if they have interactivity as a crutch?). But it's interesting to watch movies, the more established artform, start to riff off and emulate the tropes and narrative devices of videogames in a sort of symbiotic relationship. This makes sense: movies are going after young audiences, and young audiences more than ever before are literate in the tropes and mechanisms of videogames. So movies like Snowpiercer, like Pacific Rim, like Battle: Los Angeles all appear to exhibit that same kind of onboarding sequence, the empty avatar within which the audience places themselves, and the plot elements assemble out of a sort of expected structure: here's our objective, here's our plot-twist, here's our fetch-quest, here's our reveal, here's the set-piece. But the plot pieces now appear to be combined with specific visual direction: here's the bit where our hero has to *do this thing* and the thing just *feels* like something that you've done before in a game. Everyone remembers the bit where they've pointed the laser designator at the target in Call of Duty. Everyone remembers the bit in Half-Life or so many other games when you suddenly lose all of your powerups, when you go back to zero, wake up with nothing, half way through the game. 

This is going to happen more. I don't think it's a bad thing, I think it's an exceedingly interesting thing. 

--

I am thinking of a Disney/Marvel-ified Young Lady's Illustrated Primer, something like a reboot book. In case of civilizational collapse, here's an interactive text that will teach and bootstrap our children, help them jump over thousands of years of history, teach them principles and lessons inside a fictional universe that can be applied to where they are. A sort of branded SHIELD (*hail Hydra*) field manual or Nick Fury's Anarchist's Cookbook, only distributed with the combined weight of the Mouse House and instantly taken up by kids onto their borrowed Android and iOS devices because of the Brand Recognition. A massive piece of entertainment disguised as something subversive, or the other way around.

It's Friday, it's 9pm and it's the weekend, even for those of us who freelance.

Send me notes, and have a good one.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Three: Another Way; Bottom-Up; Oh, Is That The Time
Date: July 31, 2014 at 3:18:47 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gxj5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm stressed out: I have a number of phone calls to make and they're all to do with the administrivia of life. Only, they're not administrivia. They're all fairly fundamental building blocks that require human intervention, they've thrown up exception flags that need to be caught, examined and dealt with. There is no longer any delegation, no more smooth operation, no 5-by-5, business-as-usual, all-systems-nominal. No, these are silently escalating alarms, like a Verizon account that mysteriously had its e-billing email address set to vz@vzw.com, resulting in no e-bills being sent, no notifications until a surprise message saying we're behind. Or joint bank accounts that aren't actually joint. 

"We all have to do things we don't want to do," my parents would say. Well, I take a look at all those systems and quite honestly I pout the fuck out at them, and say this: these things I have to do right now? These things are because those systems are *badly designed* by people who don't give a shit. *I* have to do these things, because other people didn't care. 

Currently: Double Bacon Lettuce Tomato and Avocado with Fries, but devouring Peter Watts' latest short, The Colonel[1], in advance of Echopraxia coming out in August.

[1] The Colonel
1.0 Another Way
I was taken to task (in the nicest possible way) by Tom Coates in response to the second part of yesterday's newsletter. He wrote a long and involved reply that helped clarify what I was thinking about, and also issued a challenge of sorts - that it's one thing to sit on the sidelines and critique what's coming out of the Valley and what's being built with technology in general, but it's much more valuable to actually do something about it. Whether it's talking about what we could have instead, dreaming about it, evangelizing it or even building it, if we have a problem with the status quo, then we have a responsibility to not only question it, but to also show an alternative. Which point seems entirely fair to me. 

But first, some clarification.

I do believe that the internet, or whatever it evolves into, will be seen as the equivalent of electricity in terms of a world-changing invention. It's difficult to just say "internet", but at the moment, it feels like the best thing we have: the one network, that all the other networks access, that anyone in the world is able to access. And sure, not everyone in the world can access it right now, not affordably, at least, but the point is that it's a common standard. It's a communications protocol that we all agree on, and that rebalances and democratises the flow of information.

Perhaps it's because some of the killer-apps of electricity made an immediate difference, like lighting and heating. And that the flow of usefulness-to-the-ordinary-person was a bit inverted with computing and the internet. But I can easily find the counter-indication in that technology has always been expensive and slow to spread at first, and that we can be pleased that, if anything, the internet's spread has been faster compared to other enabling platforms before it. 

In terms of "things enabled by the internet that made a real difference to peoples lives", it seems fair to be able to point to applications and services like Citymapper and the It Gets Better project. In the case of the former, a reader who's been involved in public transport information better makes a persuasive case that mobile technology *has* made public transport more accessible. Part of this is me being unfair and not being clear in the criteria upon which I'm critiquing "technology". It was engineering that gave us the engine and the car that gave us buses, political will that gave us public transport, and now software services that make that public transport easier to use. I have my own anecdata: my wife and I are much more likely to use public transport in Portland now that there's a way to buy tickets straight from your phone, integrated with a route planning app. And when we lived in London, we made great use of apps like London Tube Deluxe by Malcolm Barclay, in the pre-Citymapper days, that would help you work out how to get from where you were, to where you needed to be. 

So in my mind, the distinction is this: public transport in general has an accessibility problem (and I'm speaking with an American perspective in mind here) that feels like it's more political than technological. My thoroughly uneducated view (that I would be entirely happy to have disproved by data) is that by definition, improved access to services through technology like smartphones serves only people with smartphones, and those groups of people may not be those most in need of assistance. That said, if your goal is "get more people to use public transport", then more people is more people, whether they're middle class or classed as in poverty.  

If anything, this feels like early technology leaking through, again: at the dispersal edge of a new way of being. I'm lucky in that I know a number of people who actively attempt to mould their environment through their knowledge of and mastery of technology: so if that means that they construct ambient, pleasant displays that show the distribution of pay-per-minute car rental, public transport[1] or build maps that show whether there are rental bikes available nearby[2]. Again, though, this feels like a luxury: for people who can afford, or are able to ask for, the flexibility in time and transport, to be able to choose different options. 

The other way feels like something a bit like this: yes, the experimenting at the high-end, because when you've got the time to think about what things might be like, you might stumble across other ways of doing things.

I remember seeing, *years ago*, a service called Mapumental[3] that at the time had been funded by 4IP, the UK broadcaster Channel 4's innovation arm aimed as yet another attempt for a legacy broadcaster to rediscover relevancy in a digital communications age (tellingly, 4IP was run by Tom Loosemoore, now at the UK's Government Digital Service). Mapumental created travel time maps: it showed you, for any given destination, all the places that satisfied a user-supplied travel time. In other words: if I work here, where can I live if I only want a 45 minute commute?

This type of civic information is really useful: it's useful for city planners, it's useful for citizens, it's useful for employers. And yet it feels like it's secreted away, that it's still hard to find or understand what a neighborhood walk-score is, or that it's difficult to find out about good schools or doctors and so on. 

I think what I'm getting at is: what can we build, using the web of data that we have, that solves little problems at a time for people. And when I'm talking about solving problems, I'm talking about making things easier, and getting-the-job-done, and not in a displacement kind of way. I'll give you an example. 

On the one hand, the internet and its related technology makes it easy (ish) for me to find out about all the different health plans available to me. But it doesn't make it any easier to choose or to go through the entire process. There's a multitude of storefronts and what that can result in - for anything where there's a profusion of choice - is confusion and paralysis. I might be talking from overly personal experience here, but *that's not helpful*. It's not helping me get the job done: what I need is health insurance, and I need to know that I'm getting a good deal. If what that means is I then need to spend a few hours researching and have the burden fall on me, it hasn't necessarily felt like a net benefit. 

So imagine, instead, something like customer service for health insurance, or when you're calling a hotel or an airline, or a government agency and the service delivered a bit like Amazon's Mayday, instead. Sure, you need to "call" from some sort of computing device that's connected to the internet. But instead of just having a voice conversation, you're able to be shown different options and show that you understand: we seem to be in a weird binary state of either telephone service or web self-service. And in the latter case, sure, sometimes we have "agents" available for online chat, but more often than not we suspect they're bots, or people working from very badly defined scripts such that they might as well be bots. 

[1] The Panic Status Board: 2013 Edition  
[2] Homesense Bikemap
[3] Mapumental
2.0 Bottom-Up
America feels like it solves its problems differently. It's a cultural thing: I can't remember where I read it, but you're imbued with capitalism here. The Portland Children's Museum has a play supermarket where our son can wander around and buy things, a working checkout scanner, everything you'd expect, plus fake produce and products everywhere, plus little carts. I'm singling out, of course: they also have a veterinary hospital with adorable plush animals in their little compartments ready to be looked after by young kids, toddler play areas and a whole section around bikes. Because Portland. 

Anyway. Lemonade stands. Yard sales. Making a buck, pulling yourself up by your bootstraps, second jobs, eBaying, airbnb, Uber, working hard and getting on: that's the American way. Finding a way to get that money in. So it feels like a particularly American response to the situation many Americans find themselves in with regard to healthcare is to, well, organise in a pseudo-capitalist way. In other words: you might have noticed all of the crowdfunding campaigns for cancer treatment or other medical treatment lately. 

It plays out like this: someone you know, or someone who's a friend of a friend, has gotten ill. They don't have insurance, or - and this, to some Western Europeans might feel like a kicker - they *have* insurance, but they can't afford the bills. Maybe it was a tumour found too late. Maybe it was a traffic accident; they're a cyclist and got hit by a car in a hit-and-run. But the primary breadwinner has probably been taken out of commission and now the family needs some help. So enter the crowdfunding network. Family, friends, anyone who's anyone compassionate: please donate to help Jason or Amy with their medical costs. And sometimes it's not just medical costs: it's lending a car, or picking up groceries or cooking a meal. 

You don't see this as much, I don't think, in countries with single-payer, socialist-style healthcare. But, the argument goes, those countries maybe don't have as good quality of care as the United States does. That's beside the point. 

I guess what I'm trying to say is this: in the same way that the internet was designed to route around damage - to find a way to get that packet through to the right node if a particular route had failed - we're learning to do the same with the software that we build. And the software that we build - the stuff that gets past the gate, that gets used, and starts to spread: those things are the things that show us where the problems are, where the gaps are and where the opportunities are. 

So, crowdfunding: feeling like an American solution to an American problem - you still feel like you're doing "work" in terms of promoting yourself and getting the message out there, even if the message is "give me money for this thing, please". 

On the one hand, that means you start to see things like The Humanity Box[1], an ad network just for crowdfunding peoples' medical bills. Which, you know, just doesn't make sense as a dirty hippy socialist, but hey, what're you going to do. Or things like the Detroit Water Project[2].

But it's this bottom-up stuff that *is* interesting. Sure, not all of it is, and some of it is just potato salad. But sometimes it feels like the right thing can come along and make a difference. So I take a look at other bottom-up networks that assume the presence of the internet. The phrase that's still sticking in my mind is Michael Mann's "we're live in the exoskeleton of the internet" and there's still so much scope for things that never *had* the opportunity to be the exoskeleton of information. I'm looking at things like freelancers' unions, at community projects that also look like they can scale. 

If anything, more technology in more peoples' hands will increase their expectations (some might say that they're already unrealistic). But, I hope people will ask: why does it have to be this way? You already have all this information about me. You already have my phone number. You already know this. You already know that. Why is it so hard?

[1] The Humanity Box
[2] The Detroit Water Project
3.0 Oh, Is That The Time
If you wear a watch, next time you're with someone, glance at it. There's a bit of a discussion going on about what Android Wear feels like, and what sort of space it opens up compared to pulling a phone out of your pocket. I suspect that we're just talking about a difference of degree here: both pulling a phone out of your pocket and glancing at your watch are signifiers that you aren't giving your companion your full attention. They might signal different things, and your companion might have different reactions to them, but I think the underlying cause is the same: your mind is wandering.

There's a difference, though, and I've predictably got some anecdata. One of the things about a screen conneted to the internet is that *anything* could be on it. You literally have no idea what someone is doing with one of those things. Could be fapping away to porn, could be editing a wikipedia article, could be replying to their parents, could be writing a breakup email, could be engaging with some particularly interesting branded content. Point is: screens, when you can't see what's on them, are opaque. This is a point of contention in our household, or it has been, at times in the past: my wife doesn't know what I'm looking at, I don't know what she's looking at. Perhaps this is just a sign of mistrust and potential marital strife (trust me, it's not as bad as it sounds), but there's certainly a *lack of context*. 

Watches, being single-purpose devices (so far), can be much more precise in terms of their social signifiers: you're looking at them because you have a question about the time. You want to know how much you've got left, if you're under, if you're over, but it's always about *time*. 

But now, with Android Wear and the other things we're going to have on our wrists, *precisely* because they have screens that offer a multitude of display options, they can be telling you *anything*. If I'm wearing Android Wear and I glance at my wrist, you don't know if I'm checking to see if I've got time to allow our meeting to run over if I'm enjoying the conversation or if Google Now has just popped up a notification telling me I'd better leave now if I want to get home for my usual time because the traffic's bad. Or if UPS has delivered my package. Or if my boarding pass has just appeared. Or if my wife's been trying to get hold of me.

You just don't know. It's a screen, connected to the internet, and a single-purpose device that has been confined in terms of communicating its intent and context has now exploded in possibility space to be able to notify its wearer about *anything*. The companion is now left to wonder: what could this be? Could it be an in-game notification from Ingress, saying that there's an open XM node nearby? Could there perhaps be a special offer on a new Stephenie Meyer collection on Google Play? Who knows?

So it's not that a wrist-observation is unobtrusive. It's that it could mean anything now. And meaning anything means uncertainty, which means stress.

Of course, I could be talking out of my arse: I don't have Android Wear and I haven't tried it. But if anyone at Google wants to chuck me one to play with... 

--

Signing off until tomorrow, and send me notes, because I read them.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty Two: Only 10%; This Hasn't Benefitted Ordinary Lives As Such
Date: July 30, 2014 at 8:06:02 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gwxh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Earlier this year, on a whim, I'd applied to the Presidential Innovation Fellowship - a program run out of office of the White House. Given how much of a fan I am of the work that the right people, at the right place and the right time can do through an example like the UK Government Digital Service, it felt like something that might be interesting. I got through to the interview process and had what I thought was a pretty good conference call, but yesterday found out that I didn't make the cut. It would've been an interesting experience if I'd gotten in - a 12 month placement, pseudo-dropshipped into the heart of a government agency like NASA or Health and Human Services or the Veterans Administration, and working with an organisation like the GDS-like 18F to get prototypes built quickly, solving real problems for lots of people. But, it turns out, it wasn't to be. Oh well. Onwards and upwards.

Location: the basement, ripping a Peppa Pig DVD boxset for a forthcoming family flight
1.0 Only 10%
* Spoilers for the Luc Besson 2014 film, Lucy. * 

I was out running errands yesterday ("errands" has always felt to me a particularly American word, I'm not sure why) when I got the news about not making the cut for the Fellowship thing, and after doing a bunch of work and sitting on a few telephone calls (as well as stopping by Best Buy where I wasn't bothered by any assistants *too* much), I decided to go and cheer myself up by watching Scarlett Johansson finally use more than 10% of her brain's capacity. 

Let's get a few things out of the way first.

1. The only way to enjoy this movie is to essentially ignore everything that Morgan Freeman has to say. In this respect, jwz is mostly right[1], but what he fails to say is quite how much Morgan Freeman talks during his movie. I mean, you might think that the poster was bad enough, with its whole "The average person uses 10% of their brain capacity. Imagine what she could do with 100%", but let's be clear: this is the *entire* point of the movie. There's a lot of ignoring to be getting on with if not just pseudoscience but inaccurate pseudoscience bothers you, and then Besson only goes and doubles-down on the entire thing. He sits there, as Writer/Director, essentially at the poker table, holding a hand that is perhaps only 10% as good as a Royal Flush, slides all of chips over and declares All In. 

2. There is a part when Freeman is lecturing to a big crowd, although precisely what kind of crowd he's lecturing to is unclear - he's not at a university, and it seems more like a Public Understanding of Science thing, maybe a Royal Institution Christmas Lecture. But anyway, a smartly dressed young chap gets up and asks, in an adorbs French accent: "but, this is just a theory, no?" to which there is no reasonable response other than "well, yes, it's just a theory, but a man's got to dream, right? Because where are we if we cannot dream? Is that not what Science is?" and then we have to carry on watching the rest of the film. 

So, Lucy. Its premise is dumb but only because it feels like it doesn't have to hang on its premise. The story is about a young woman who's pretty streetwise and gets in the wrong place at the wrong time thanks to her scumbag of a boyfriend whom she was probably going to dump anyway ("Make good choices, sweetie!", her mum would say), and before she knows it she's a drug mule who has a synthetic growth hormone making her jiggle upside down. 

Freeman explains to us: imagine what we could do, what we could achieve, the mastery over the universe we might obtain, if we unlocked the full power and potential of our brains. All of these are tied to percentage markers, and there's literally a bit where Lucy turns into a *progress bar*, as if we needed some sort of visual indicator as to how percentage-complete her progress to ascension to pure energy, existing every where and every when, was.

It's not a long movie. It's a moderately interesting movie, but not one that necessarily shows us anything new, and it's inoffensively enjoyable: there's a particular good car chase scene in Paris that held my attention and there's an amusing bit where Lucy essentially spits out a USB stick. 

I suppose it just doesn't *feel* like very much, and the way that Besson brings Lucy's progress bar of brain capacity usage to life from a visual perspective doesn't bring anything new to the table. In fact, it looks a bit like an advert for health insurance[2]: in other words, the visual shorthand of the day is seeing data everywhere, and now that we have Smart Things and a Smarter Planet and Smart Everything and we understand that "information" means ones and zeroes, we have somewhat lazy visualizations of what Lucy's world looks like. In fact they're not just lazy, they're disappointing and have that weird kind of European/British sensibility to CGI and visualization that makes them look a bit pants compared to the overly polished stuff coming out of America.  

Of course, the alternate theory is that most of the movie is just Lucy tripping balls[3].

For completeness, here's a bunch of 10% jokes:

 - The average KitKat is compose of only 10% matter - over 90% of the space in a KitKat is empty. Imagine if Nestle could unlock all 100%.
 - Most people only use 10% of their Facebook profile. Imagine what they could do if they unlocked 100%.
 - Most people on average only use 10% of their bowels. Imagine how full of shit they could be if they unlocked 100%. 

And finally, Morgan Freeman only reads 10% of his scripts. Imagine what he could accomplish if he read 100% of them. At 30% script capacity, a Morgan Freeman could control not only his own movies, but the entire Hollywood system. At 60%, just his narration would govern the very nature of planets and their orbits (thanks, Tom Coates). And at 75% control, space-time would resonate the vibration of his voice, all matter slowly red-shifting (thanks, Ryan Gantz).

[1] jwz: Lucy 
[2] UHC: Health in Numbers
[3] [...] CORE
2.0 This Hasn't Benefitted Ordinary Lives As Such
Here's a quote from Tyler Cowen as interviewed by Eduardo Porter in the New York Times' Upshot on income inequality[1]:

"If today we had a rate of technological innovation comparable to say 1890-1930, the middle class and the poor would benefit tremendously from those new goods and services. Income inequality might go up or down but we could stop worrying so much about it.

"That earlier period brought such innovations as electricity, the automobile, radio, the airplane, basic advances in public health, and much better fertilizers, among many others. In more recent times we’ve had a lot of innovations in the manipulation and storage of information, but this just hasn’t benefited ordinary lives as much."

and then I want to point to this piece by Phil Gyford, where he tries to open a business bank account in the City of London[2]:

"Last week I spent a frustrating morning trying to open a business bank account. I assumed banks would make it as easy as possible and so I was surprised how frustrating it was. I’m easily put off by small but easily-avoidable annoyances and I found plenty of those."

So here's the crux of it. When we talk about "productivity gains" from technology, and the linkage of something like Moore's law - the doubling of transistor count on a certain piece of silicon every 18 months - to the economy and peoples' lives, it feels like we need to work out exactly where those productivity gains are. There's a particularly telling phrase in Cowen's response, where he says "we've had a lot more innovations in the manipulation and storage of information, but this just hasn't benefited ordinary lives as much."

Let me bring this back to something like GDS - again, like I'm some sort of broken encoded music file stuck on single-track repeat - where they've been able to show (at a gross, high level, and principally a political one, at that) that technology can be used *to benefit ordinary lives*. The focus that they've got on user needs, on delivery and service, is one that, because of their position in terms of finding better ways of delivering *government services* is one that inherently is to benefit ordinary lives if they're to succeed. 

The information sciences - as they're applied now, in such a wide manner - do as much to hinder ordinary lives as they do to benefit them. On the one hand, we have the descendent of ARPANET, a multinational, world-circling thread of communication nets wired and wireless that joins billions of people together in more-or-less democratic discourse and commerce (ie: more democratic, and with more access to more people, than anything we've had before). But on the other hand, we've got bank websites that don't convey the right information about something that ordinary people have to do every now and then - like open a bank account. 

The information sciences - the ones that we get so excited about in terms of ones and zeros and bits and iPhones and tablets -  make it much easier to futz about higher up Maslow's hierarchy (whether or not you agree they're truly arranged in a hierarchy, or simply different needs for different people at different times). So you get a lot of Microsoft Publisher and you get a lot of Make-Work - you get systems for the sake of systems, because that's what a lot of information is: once you've got some, you can create lots more of it and you can transform it in practically infinite ways.

In terms of the hard tangible benefits of technology, it feels like we may need a refocussing of effort, lower down the pyramid. This might finally be possible almost because of the futzing around in the meantime: now that we *have* near ubiquitous (but still expensive) wireless access to the network, there are lots more things that we can do. But, in terms of tangible benefits to "ordinary people", what has technology (or the Romans, I suppose this is sounding like) done for needs like:

 - the physiological (breathing, eating, food, water, sex, sleep, homeostasis and excretion); and
 - of safety (security of body, employment, resources, morality, family, health and property)

compared to baseline innovations such as "electricity, the automobile, radio, the airplane, basic advances in public health, and much better fertilizers."

Notice that Cowen doesn't even include "the telephone" or "television" in his baseline innovations. Electricity, sure. But television is treated as simply radio-plus, and whilst air travel has been somewhat democratised, it's not entirely cheap. But then, what does it get you?

In other words, we can look at this idea of consumer technology: not necessarily just meaning that it's stuff that helps us consume consume consume, but that the money, the investment and the return was getting us to buy things that worked way further up the chain. Out of everything in the house that I live in right now, some of the most important things, the things that make a difference, are:

 - the washing machine
 - the fridge/freezer
 - heat, light and water

When our washing machine broke down, it was a *pain in the ass*. Suddenly, so much more time was taken up with doing laundry.

So in terms of improving quality of life for *the ordinary person*, what has consumer technology done? Great, I can find out from the bank's website that I just have to go to a branch to open a bank account - but it turns out that information is wrong. I can book a plane ticket myself, without having to go to a travel agent. I can do grocery shopping and remain in my seat. I can watch even more television, buy more movies. Ah - and maybe, just maybe, thirty years into the internet, I can find myself gainful employment, or at least make a buck. And through opportunities that didn't exist before. 

But, so far: has the internet made housing cheaper? Has it made public transport (significantly) easier to use, or more accessible? Has a laptop improved the chances of my son getting into a good college, or made him more employable? Has it helped me be more healthy?

Not nearly as much as the productivity gains as Moore's Law would imply. Not as much as has been breathlessly promised us by the Californian Ideologists. This time, though, they swear it'll be better. 

We'll see. Our technological reach, it feels to me, far outmatches the extent of our real grasp in terms of using it for the better.

[1] Tyler Cowen on Inequality and What Really Ails America
[2] Visit your nearest branch

--

I bet some of you disagree with me. Or could present what I just wrote above in a more coherent way. So you should tell me. Hit reply.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Thirty: Seeing; Shallow; Better Taxis
Date: July 28, 2014 at 2:17:53 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gv8x=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
This being Portland, there's a lot of greenery around, so I'm in the kind of environment that (to my mind at least) prompts a bit of weirdness. Out in the back yard this morning, watering, looking at the plants and they do that *flip* in my head which means they suddenly look super alien. I mean, not just weird. I mean: holy crap, there are living things in my yard and they've got roots sucking up nutrients and you can see them stretching out, yearning, busy being phototropic and reaching for the sun, only don't call it phototropism because that just makes it sound all clinical, because holy shit these things are *alive*. They're gently swaying and they've evolved this green stuff in them that takes photons and grabs electrons and they get bigger. Just look at those leaves: soaking up all that electromagnetic radiation. Zoom out, then, do that Eames thing and pull out, slowly, then faster: this entire planet is covered in the stuff. Teeming with it. Carpeted, blanketed, almost like it's been excreted all over the place. Creepy, crawly, oozing, undulating, dumb, smart, indifferent, just *living* and reacting and seeing. 

But mainly, the plants freak me out.  

Reading: Trees issue 3, Letter 44 issues 1 through 8.
1.0 Seeing
I have a confession to make: I don't really read comics properly. I mean, I've been accused of not reading comics properly, mainly because one of the very first comics I read was Warren Ellis' Orbiter and I finished it in like five minutes and my reaction was simultaneously a) mind blown; b) that's it? That's *IT*? I want more! 

I think it was because I just *read*, instead of looked. I would say I'm the kind of reader who's a skimmer - I like to take in the whole page and get the idea, and then move on to the next thing. So I'd feel like I understood the big details, but it would take me time, and I'd have to learn how to slow down and linger in each frame, taking a look at what was actually inside it, trying to understand it rather than relying on some sort of instantaneous grokkage. Sometimes it feels like this is a good ability: to look at something, some situation or scene or whatever and have some sort of unconscious feeling for what's going on. But that's looking at things through a good/bad filter, rather than just an ability filter. There's undoubtedly stuff that I'm missing, stuff that I'm not seeing, because I'm not *seeing*. I think I'm better, now: or, rather, I've learned to slow down a bit more. 

We went on a drive to the coast yesterday, breaking in the new car, jabbing amusedly at the navigation system, trying to figure out a way for it to not tell us when it thought there were traffic jams (there weren't traffic jams). There's a new soundtrack for driving now, the Automatic beeps when we hit about 70mph because it's not "efficient" and we get docked Good Driving points from our score whenever we do that (or do a hard acceleration, or do a hard stop). But there are other dings and beeps and thrums now - not quite on the same level that we're familiar with in the way that Geordi or Scotty can tell how healthy the warp intermix chamber is by the background noise, but starting to get there. Anyway: in the car, talking to a friend about the English, American and German school systems (now that we're parents we're conforming as hard as we can to stereotype) and I mentioned the Ed Catmull point about learning to draw being an incredibly useful skill outside of just the arts, because it teaches you to see *what's really there*. Which strikes me as what I was missing before I'd learned to read comics - that I was just getting the idea, seeing what I thought was there - surface level understanding, useful and quick to be sure, but perhaps not uncovering anything deeper. 
2.0 Shallow

Tim Carmody, guest-blogging for Jason Kottke this week, mentioned things-that-are-shallow[1] when pointing to Joanne McNeil's Future of Birthdays[2]. He wrote that "Sometimes, our identity-obsessed web services are creepy because they know so much about us, and sometimes they're creepy because they're just so damned shallow."

I'm trying to see if there's a way out of this particular cul-de-sac, or if what McNeil mentioned is more-or-less inevitable. These days, it's easy - well, easy enough: you just need to have the initial idea and make it easy for someone to copy, or for enough infrastructure to exist for the copy to be relatively trivial to implement - to imagine joining the pieces up to enable McNeil's weary future. Just link up enough CRM databases, or pull in a Facebook auth, or even just *buy* the data, and then you have, as McNeil accurately points out, a reason (even though a flimsy, shallow one) to enable a "brand storytelling touchpoint" with a consumer. Sorry, a person. 

Is there a bit of Prisoner's Dilemma going on here? I liked to think that part of my job as a creative director was to stop things from happening as much as it was to find good things to happen. The perspective that I thought I brought to the job included "would anyone do this" but to also ask people "would *you* like this to happen to you?" and frequently, the answer would be: "well, no." 

The facetious part here is to quote Jeff Goldblum's Dr. Ian Malcom: "Yeah, yeah, but your scientists were so preoccupied with whether or not they could that they didn't stop to think if they should."

Well, *sure* we could have the internet-enabled Tropicana carton wish you a happy birthday, and sure we *could* have the Starbucks barista wish you happy birthday as a surprise-and-delight moment without you telling him that it was your birthday. But, did we ever stop to think if we should? 

Part of this is again is information asymmetry and lack of transparency and understanding about who knows what about you, where, and how they're allowed to use it. But as much of it is in the hands of the people deciding, bluntly, that these are Good Things that should exist in the world. Or even, that they're not even good things, but that they should exist in the first place. This is a co-operative situation, right? Just one happy birthday ruins it all, otherwise it's a race to the bottom and before you know it, everything in McNeil's universe is wishing you a happy birthday. 

I don't know what the solution is. Perhaps it's to imagine that whenever you're thinking about doing something internet-of-thingsish with brands, you imagine that your idea is instead to isolate the DNA of a long-dead carnivorous species, PCR the hell out of it, mash it up with some amphibian DNA and then release it through every single carton of Yoplait yoghurt, directly into consumers' fridges where it will burst forth in the night-time hours, hungry, and devour people in their sleep. "But wait!" you'll exclaim, "we got a tonne of research saying that kids loved dinosaurs and that they'd love to play with them!" and then I'll get to say, Dr. Ian Malcom-style: "Yeah, yeah, but you brand managers/creative technologists/startup entrepreneurs were so preoccupied with whether or not you could, that you didn't stop to think if you should." And then, next time, maybe you'll think "Yeah, you're right, it probably wouldn't be a good idea to have surprise dinosaurs pop out of my phone as a surprise-and-delight moment" only it won't be surprise dinosaurs, it'll be a picture of a cat. Only it'll be a picture of a cat popping up on your phone EVERY DAY FOR EVER.

In other words: the shallow is easy. It's just going to get easier. There are more communications surfaces than ever before, and we've made it intentionally easy to link them together. In fact, as I write that last sentence, I wonder if I'm not instead bound for a lifetime on the Colonies, where I'll rant and rave about the dangers of networked computer technology. 

[1] The Future of Birthday, linked via Tim Carmody
[2] The Internet of Things Will Ruin Birthdays
3.0 Better Taxis
I wrote about this a little last episode (mistakenly titled episode 128, again), but it's been lingering in my brain over the weekend. The thought collided with something that I saw in passing on Twitter - that the relentless othering of Silicon Valley and its stereotypically empathy-less driven entrepreneurs who're gunning for Disruption for Disruption's sake don't understand the second-order impact of their actions. Or, are just going around creating theme parks for dinosaurs without a care in the world. 

And yet.

If we're to believe that technology is just something we use in service of a human goal, that it doesn't really *want* anything because we disagree with Kevin Kelly about there being a mythical Technium that pervades the universe, that we're tool-creators and tool-users, if we believe that it's much better to engage with and try to understand the motivations of the people we disagree with rather than to just point and laugh at them, and to recognise that parts of what they're doing is good and worthwhile... 

Then services like Uber and Airbnb - whether you like it or not - are certainly satisfying a *need*. They wouldn't be so successful otherwise. Sure, they might be *more* successful thanks to somewhat dodgy or unethical business practices, but the basic user experience of Uber - compared to getting a regular taxi - is, I think we can agree, *better*. There was a problem, or an opportunity, at least, and the founders set out to solve it. You can disagree with lots of other things like how they're dealing with competition or the fact that Uber has now raised so much money that they can quite easily afford to undercut and price-out the competition until they have the market to themselves, and that they're diverting money away from more community-focused endeavours. But: the experience from an end-user point of view is *better*. Same for Airbnb. Ish. 

The existing taxi institutions - and they are institutions, ones that have been in place for a long time and have been a protected market, more or less - now have a tremendously uphill battle to just *equal* the user experience of Uber. They have to do it from behind, with less money, and with organisational drag. And probably with less zeal. 

Part of this is the simple thing of *using technology to do the same business better*. You can do that the good way - by asking for permission, by working within the current system, by trying to change it - or you can do it the "bad" way, by which you work outside the system and try to force regulation in response, rather than proactively.

So this isn't just about software eating the world: this is about the opportunity for software to eat the world and make it *better*. It applies equally to both side of the coin: there are, I'd argue, as many opportunities for technology and well-designed software in support of well-identified aims and goals, to disrupt the "union" experience and make better unions that serve their members than exist currently. 

But, all of this requires clarity of purpose and to be able to translate that purpose into things: products, services, whatever, that are useful that help people do what they need to do. Whether that's finding affordable travel accommodation, getting a car to get from one place to another, or reporting a flagrant workplace violation with evidence: these are all things that are *easier* to do than ever before, if you design the right software. 

The capacity for this reinvention often exists inside organisations already, but there's a gap in leadership or vision that is able to translate it into practical effect. Alinea identified that they wanted to try out a ticketing system to test a hunch that it would be better for them than straight phone reservations, and *the software didn't exist*. It had to be made. Bespoke. Custom-built. No-one was going to do it for them. So they had to go out and do it. I would bet for most businesses, there are a bunch of internal systems, never mind customer-facing ones, that could instantly make your job *better* and easier and make it easier to do what needs to be done. Not just "more efficient". Not just with the goal of being able to lay people off. But with the goal of achieving the aims of the organisation. Better healthcare? Better bill-paying for utilities? Better banking? It's all possible. 

--

OK! Monday down. And 130 episodes done! Send me notes, all the usual stuff.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Eight: It Was Never Technology; Names Matter
Date: July 25, 2014 at 12:13:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gtjt=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I was asked what a Station Ident was, or where I get my section headers from. I take that to mean where do I get this particular header from, and it's an idiosyncracy that I copied from idols Matt Jones and Warren Ellis, a sort of identifier of the kind you got when TV stations would go off-air and display a test pattern or some other part of branding. Of course, it wasn't "branding" back then. It was just their identity. This is me, coming back on air, transitioning from station identity, to full-on personality. 

It's Friday, and my second full day of looking after C whilst his mum's at school. I love spending this time with him - he's turned into such a little boy. A cheeky one, at that. 

I am still having difficulty finding rhythm. I expect it will come, in a staccato, haphazard kind of way. But whatever this is right now, being able to spend time with my son and still having time to write, easing back into work after having travelled and done my conference, it doesn't feel so bad. Maybe this will all work out in the end anyway.
1.0 It Was Never Technology

It was never a technology problem. I'm thinking more about the stupid term "smart cities" and about what it means to be a smart city. I got a nice long note from a good friend, Matt Locke, that kind of drove home the point that it's never really about the technology, and more about the people. That, of course, was always the case. 

In other words: in the same way that it's hard to get, say, an advertising agency to change into something that's not advertising, or at the very least "advertising and" something, it's hard in the same way to get a city (or anything else - like, say, the British Broadcasting Corporation) into something that uses technology as a means to an end, opportunistically, transparently and intelligently. 

It almost feels somewhat holographic - a never-ending fractal problem that, wherever you look, you find examples of. Is it just something as simple as people not liking change? Or that change is too difficult? Or that inertia is a horribly powerful thing, perhaps one of the most powerful organisational forces? Or maybe it's just that organisations forget their purpose - mission statements be damned - and that instead they get too preoccupied with the method which with they're carrying out their purpose, rather than whether the purpose is carried out in the first place. 

I suppose it's because it's uncomfortable. As an irritating precocious teenager, I'd  been confused when the secondary school that I went to attained Technology College status in the mid 90s. What this meant was that the school acquired, in short order, a brand new building full of a bunch of pretty high-spec PCs. In other words: a bunch of hardware, some software and, from the outside, hardly any teacher training for the people who were supposed to be using it to teach us. Forgive me if I don't instantaneously believe that the situation is much better these days (our neighbour in Portland is a primary school teacher, and she talks about getting handed an iPad one day with practically no training, being told to figure it out on her own time).

So anyway. It was never about the technology. I don't know quite what it is, other than technology not being treated as a cost centre, and instead being treated as something like an enabler. It's easy to tell a story of technology being something that has to be suffered, that's a consequence of the modern world. I have sympathy for people who feel this way. Technology has promised a lot, and failed to deliver a lot of the time, too. For every gain, it's taken away in pernicious ways, sometimes explicitly, and other times implicitly. But, if I'm to say that *this time, it's different* it would be that networked technology is different from islands of technology. It would be that communications technology is different from having a bunch of non-networked PCs with laser printers and Microsoft Word that enable you to more efficiently print out and distribute memos to All Staff. 

I'll give you an example. I've never had to use Lotus Notes in anger, but from what I can make out, people who have to deal with it never really like it that much. As much of that is because it's an old technology, one that I believe might still even be single-threaded: which means that when the client application is doing something, you can't do anything else. So whether that's loading a mailbox or searching, it frequently just *feels* like it's hanging. But one of the powerful things about Lotus Notes was its groupware - the fact that it was easy to build forms and, in a small way, make lots of back-office administrative jobs easier. Perhaps that's why it's become so embedded in organisations - because of the inertia of the bureaucracy that took advantage of it. 

But anyway, I was talking about technology. The thing about the Ubers and the Airbnbs and so on, ignoring the rhetoric about the sharing economy, is that they were started by people who saw how technology could improve the user experience. They're service businesses that could differentiate on *better service*, and technology was the key to providing that. If you didn't know - or didn't care - about what technology was capable of doing, or, even *didn't care about user experience* then you wouldn't have the same mindset as those entrepreneurs. 

So when GDS says "the strategy is delivery"[1], this is, I think, what they mean. That a Government, for example, can't rely on "brand" to differentiate itself, because you can hardly choose another government (we'll leave that as a point for further discussion, I suppose), but the point of the civil service - well, *a* point - is to deliver services. Zappos is an easy example to reach for, but the differentiation is in the customer experience. And for whatever reason, it's hard to get an organisation to care about the quality of service that it provides. 

This means expanding the definition of "user experience" outside of something that's just wireframes, but that cuts to the core of the scope of a business. It's interesting to me to hear so many different examples across different organisations about things that individuals identify that go counter to what the *point* of a business is from a user or customer's point of view. Service - and delivery of service - *is* the differentiator. Because when it comes down to it, the absolute atomised level, the planck length beyond which you can't go any further, if I'm paying for a service, whether it's in money or attention, I need that service to be accomplished. Sometimes that service is obvious, and sometimes I might care more about cheaper service than good service (which is why people can simultaneously fly business class one week and then economy airline the next week), and contexts change and peoples' expectations change in those contexts.

And yet.

Technology - "digital" - is supposed to make these things better. It's supposed to allow a *better* connection. Not just a more efficient one, but the whole idea behind "(digital) services so good that people prefer to use them" is in my mind a trojan horse. All services should be so good that people prefer to use them. At the same time, it's fine to have priorities and to say that you'll get around to it, but part of what I'm starting to feel is that there's a tremendous gap (here we go again) in terms of a lot of service based businesses. 

Whose responsibility is it, for example, to proactively look at analytics and search queries to find out what problem people visiting your website need to solve? And how easy is it to act upon that information? And, before we even had analytics, was it someone's job or responsibility to uncover that information from front-line staff? Is it someone's job at a bank to ask tellers what customers come in and need help with? Other than the dreaded Customer Service Survey that more frequently than not provides inadequate and inactionable data? 

It can't be everyone's responsibility. It's clear that when it's *everyone's* responsibility, in the absence of a clear mandate from leadership, no-one's going to get around to doing it. Which is why I'm interested in things like a Chief Patient Officer role at hospitals, or Chief Customer Officer role at banks and so on, the equivalent of a reader's editor or an ombudsman, whose job it is to see things from the customer's point of view and whose remit crosses *every* silo, because their remit starts at the interface of delivery and works backward. 

And yet, it's not worth having a role like that unless leadership understands both the vast scope (because it *is* vast - once you start picking at it, you've essentially committed to organisational change unless you're one of the rare organisations that has its shit together) and the positive role that technology has to play. 

But then it wasn't aboult technology, was it. It was about what your business or organisation was supposed to do. And the best way to do it. And whether or not you give a damn.

[1] On Strategy: The strategy is delivery. Again.
2.0 Names Matter
I've come full circle on this one. Names matter and labels matter. Variously, I've hard my former employer, Wieden+Kennedy Portland, described as an advertising agency, a creative agency and a communications agency. Sure, those labels might change based on client. But names matter. 

Advertising agencies make advertising, creative agencies make, um, "creative", and communications agencies communicate. 

Digital agencies, though. Digital agencies *in theory* make "digital" whatever that is, but at least it's a broad umbrella that can encompass a whole bunch of other, subsidiary issues. Of course, then you get bucketed into only things that are "digital", which is presumably less of a problem these days because in practice so many things are digital in one way or another. Unless you have a client who has a parochial view of what "digital" means in the first place (ie, most of them, unfortunately). 

So these labels matter because they impute identity, and identity matters because if you're an advertising agency and you're trying to sell a solution to a business problem for which the answer isn't "advertising" then suddenly your client has to explain to everyone else in their organisation why the advertising agency hasn't produced a piece of work that looks like advertising. It's a difficult, up-hill battle that's not unwinnable, but certainly more like punching yourself in the face than helping yourself, if that's the kind of work you're telling yourself you're doing, or want to do. 

Sure, you can engage in a debate about what "advertising" is. And that's a whole separate issue. But we can be pretty sure that something like a Fuelband, although it may *do* the job that advertising is sometimes required to do, is not advertising. It is a product. Or it is a service. It is not an advertisement. 

So again, I think there's a hole. Management consultancies like McKinsey can certainly tell you what you should be doing, or whether you should be doing it, or how many people you should lay off (and then lay them off for you). Digital agencies will certainly build things for you if you want them to. Creative agencies will come up with creative solutions to problems. But in terms of business process change in a creative way - in terms of taking a look at what an organisation's problem is *and* acting upon delivery, are there any good outside agencies or organisations that do this? Would you trust Accenture to come in and be asked by a music label what they should do about this whole digital music business and build something like iTunes, or at least as good, at the right time? (Leaving aside, of course, the counter-example of iTunes being a terrible piece of software that is pretty much minimum-viable-store-and-media-player). 

Not really. They don't exist, and they don't really exist at scale. Probably because clients don't think they need them. 

--

Have a great weekend. Send me notes and let me know what you thought about today's episode.

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Eight: The Only Medium; Watching You; Smart Cities
Date: July 24, 2014 at 12:40:47 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gssp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
A surprise (and welcome) upgrade on the flight back to Portland and I'm relatively rested and relatively un-jetlagged, at least I am at 10:30 am in the morning, we'll see how this afternoon goes. I've got my son solo for the next couple of days and I'm staring at the business end of an email inbox that between telling me about the amazing new Pimsleur Approach (not a Jason Bourne movie starring Matt Damon, unfortunately) or Soft Fruit or a new scratch-filler for my car, has got Actual Work in it that I Actually Have To Do.

But I also have to go to the zoo.
1.0 The Only Medium
Clive Thompson has written a piece with a line in it that caught my attention. In an article about the book 1,001 Video Games You Must Play Before You Die[1], he notes something that the author Duncan Harris has written about Half-Life 2, a PC first-person shooter(ish) that came out in 2004, which instantly makes anyone who can remember it coming out feel old. Thompson is struck by the observation that Harris has that Half-Life 2 "tells its story as if games are the only medium on Earth", which whilst Thompson notes isn't strictly true, is certainly provocative. 

The thing is, if we take some time to notice what it is about games that's unique about them, there are some peculiar (and wonderful!) things going on. One of the things Thompson pulls out is third-person games - finally possible in an era where computing power allows better three-dimensional graphics - where the camera just floats behind the protagonist character, always affording a view of the back of their head. Third-person games were a distinctly 90s innovation - perhaps most popularly seen in something like Super Mario 64[2], whose SGI-powered graphics subsystem afforded amazing 3D graphics to a consumer audience for the first time in something that just plugged into a TV. I remember EDGE magazine marveling at the thought that had gone into the dynamic camera system, that mostly - certainly not always - seemed to figure out where it needed to be. 

Thompson's far smarter than me for noticing something like this. He writes:

"The thing is, the third-person game camera-angle is truly and totally foreign to Hollywood. I can’t imagine any director saying “guys, guys! I’ve got a great idea! Let’s shoot our entire movie from about five feet behind behind the protagonist, carefully tracking behind her, so that we almost never see her face!” That third-person angle is a piece of artistry that is utterly gamelike — a bit of aesthetics crafted as if games were, indeed, the only medium on Earth."

and this to me is such a satisfying observation. Twenty-odd years into third-person games, they feel utterly natural and an entire generation has been pretty much raised upon their perspective through open-world games like the Grand Theft Auto series. To take that familiarity that makes perfect sense in an interactive environment - where the identity of the protagonist is projected onto by the player, where it's more important to see where the protagonist is going instead of what their face looks like, and to map it on to the medium of film, where the audience has a different set of expectations, is a bit like having your head cracked open. 

I think, then, this is what still interests me in terms of what it means to create entertainment native to the medium of the net. That's always struck me as a somewhat wanky phrase - despite the fact that I use it a lot when I talk to people about what I'm interested in building. All this talk of "native". But such a more poetic way to talk about it as if the net were the only medium on Earth. You would get a very different view of YouTube, I feel, that I've always maintained is just TV transposed onto a newer, bittier medium. But the internet, and the stuff you get on it - what you'd get as if the internet was the only medium on Earth is what's fascinating to me. 

I suppose there are parts - like Tumblr, for example - that exhibit parts of subculture, and it's unfair to ask for what things would look like as if they were *literally* the only medium on Earth as nothing can really be created in such a vacuum. But the language of Tumblr and the fluidity of how things are created, the ease of linking from one subculture to another and the instant repurposing of how the link and the gif allows you to express emotional states - that type of appropriating is interesting. And then you have stuff like creepypasta, like the SCP Foundation[3] which on one level can be dismissed as "just a wiki" or "just a bunch of teenage sleepover horror stories" but precisely because the SCP Foundation sits at the intersection between the two means that it's something new, that couldn't have been created before. Is Slender Man[4], for example, something that was created as if the internet were the only medium on Earth? Not quite, perhaps, but it and things like it feel close as if part of the thing about the medium isn't just its visual characteristics but also how things are quoted, spread and talked about. 

[1] A game created “as if games were the only medium on Earth”
[2] Super Mario 64
[3] The SCP Foundation
[4] Slender Man
2.0 Watching You
I started re-watching Tony Scott's 1998 movie Enemy of the State, which as anyone knows me well enough would instantly bucket into the haxploitation genre, not least of which because it involves Gene Hackman explaining to a late 90s Hollywood audience what a Faraday Cage is. 

(Genuine nerd moment: I remember sitting in a car as a teenager and using the v=f*lambda equation and looking at the wire fencing around the car car park to work out why I wasn't getting any reception on a particular radio station. I'm such a dork.) 

Anyway. It's interesting looking back at Enemy of the State because so much of that movie isn't (unsurprisingly) about ubiquitous tapping of surveillance - mainly because it was 1998 and people were still freaking out about the stupendous innovation of Windows 95, they were starting to come to grips with Windows 98 and the horror of ME hadn't yet been unleashed). 

But then you look at the title design[2] and the entire thing, complete with geeky mathematical style typeface (a Greek sigma sum-of for the letter E, for example) and what now feels like an amateur green targeting reticle overlaid upon what you realise is *all* low-res CCTV suveillance footage, but of the peculiarly American kind - high speed police chases, satellite takes, helicopter or dashboard mounted, but always the kind of CCTV that's manually controlled and monitored by humans. The NSA in Enemy of the State is a vast human sprawling enterprise - one populated by people like Jack Black, console and keyboard jockeys, able to fake FBI work orders and instigate "training operations". 

This isn't necessarily how a city sees, but how instead people see when they're given the apparatus of a city. I think there's a distinction, and it's one of the reasons why I'm a bit annoyed that I haven't made the time to watch something like CBS's Person of Interest, which by all accounts is the television account of Well Look We Told You So, Didn't We. 

The world of the late 90s Enemy of the State is one with VHS tapes, where Federal grant money goes toward bird watchers with motion-activated cameras and UNIX-y workstations, but not the kind where the bird watcher's camera automatically tweets out photos whenever the head of the NSA tries to inexpertly off a politician. 

The enemy of the state in, well, the movie, is one that's an actor, whereas the enemy that we have these days is much more mundane. At least someone had a motive, there was someone falsifying that FBI work order. What we have now is an enemy of the state that's just *there*, passively feeding off everything, working off the fact that all these data plumes are given off - exhaust that's just exhaled as a matter of course as people go by their lives. That this is all retained and that anyone can weave a story about it is in a way a lot more evil than someone deciding to task a group to go after something. Everything is remembered, everything is watched without anyone having to decide to. This is surveillance by default, and, if I may, this year's enemy of the state was Project Insight, the algorithm that determined, credit-score like, the risk to the state of any person, through the networking and crunching of, thousands, millions, billions of data points all mined together, but this time targeted by floating weapons platforms, sniping with precision from the sky. 

[1] Enemy of the State
[2] Enemy of the State - titles
3.0 Smart Cities
I think it was via a remark of James Bridle's that I ended up at this 2013 essay from Dan Hill about the smart city[1] (try not to think too much about the fact that Hill wrote it in 2013, and instead think about the fact that we're able to read it at all - the man's far too smart for his own good) and a particular thought struck me about the idea of the city needing to be adaptive enough, flexible and malleable enough for the smart things in it - the people, empowered as they are through networked communication technology - to do interesting things with it. 

The Smart City, as Hill points out, shouldn't just be seen in terms of increasing efficiency - because all too often it's the pursuit of efficiency that leads to super-efficient, locally optimised systems that are good at one thing - or, I guess the host of things they're designed for - but, as the contemporary saying goes, not particularly *resilient*. 

It makes me think of all the smart city stuff that's going on that relies on quite a lot of private capital and the spectrum among which all of these things - some of which lie inside a bucket that might be called the sharing economy - lie. If you take an example of something like Zipcar or Car2go - both car "sharing" services of which I subscribe to in Portland, they're both services that have required a degree of regulatory approval and acceptance. The city must do something to allow these new organisms to exist inside them - they aren't naturally accepted. In other words, Zipcar and car2go need to negotiate to find permits for the necessary street parking or even to be licensed to operate in the first place. Speaking as an outside, I wonder where this comes from: parking is a regulated activity - you can't just do it where you want to (ie: streets that allow parking are declared as such, I don't think there's a natural state of a street that allows parking, instead they must be declared so). 

I wonder what kind of balance can be struck between for-profit services and bottom-up, citizen built services, and what kind of distinction can be struck between the two. On one level, you can look at things like Airbnb as they existed in the early stages and see opportunistic (or smart) citizens who want to find a way to find somewhere to stay. Only later - at some sort of size-related phase change  - does Airbnb come up against regulatory hurdles when they reach a threshold where it's not just a bunch of people finding cheap places to stay and make an extra buck. Or, rather, it's at *exactly* the point at which people are trying to make an extra buck that the state or city starts to intervene. 

In other words - what type of city resources exist, or what kind of regulatory environment needs to exist that's permissive enough to allow new services to be invented, fostered and then copied (a bit like the food cart movement, which presumably found a loophole in the licensing of movable non-traditional bricks-and-mortar restaurant premises) but then in some cities was supported and perhaps even encouraged. Part of this feels like a sort-of self-service model, but also one that requires cities to be much more transparent about *why* regulation exists and to what purpose it serves. In other words, in terms of service delivery from local authorities, being able to say: one of the services the city offers is making sure that when you decide to stay here, you're going to be safe. This is how we do that through regulation, and this is how we do that in practice. If you're going to want to allow people to stay in your home, this is how to do it - and also to be encouraging of that. At this point you'd be forgiven for some sort of sympathy for the plight of Airbnb and Uber because, at one level, they're trying to provide transportation services and getting frustrated at (presumably) self-interested parties that want to sustain the status-quo in terms of *how* the services are provisioned as opposed to the best way to provision those services.

And I swear to god I didn't intend this to be a sort of Oh Look Now You're Talking About GDS again, but the type of citizen empowerment (and I do really mean that) where it's actually *easy* to say that you want to open up a food cart, or see how many food cart licenses there are left, or see where all the food carts are licensed so you can work out where to open one - that type of infrastructure that allows citizens to build on top and make a city a city - that seems smart, rather than generally piling upon more sensing data.

All of which is to say, I suppose: politics.  

[1] Essay: On the smart city; Or, a 'manifesto' for smart citizens instead

--

Happy Thursday. One more day to go until we hit the weekend. Send me notes and introduce yourselves!

Best,

Dan
 
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Seven: Belong; Snow Crashing (9); Humans As A Service
Date: July 23, 2014 at 2:18:21 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gs6p=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
45 minutes of near-silent swooshing in a black car from home to Manchester Airport and then suddenly being surrounded by something that's best described as a mess of people. Not a throng of people, but more a spill, hastily mopped up, the equivalent of wads of paper towel attempting to force them into lines that go this way and that: departure check-in desks the week that school holidays start. 

For all the talk of a manufactured normalcy field, this mass of people doesn't look like anything particular normal is going on. Maybe in countries where air travel is more routine, more the fabric of everyday life because you're country is just So Damn Big. But not at 4:30am in the morning in Manchester. 

I'm still angry about the health insurance thing. Not least of which because I'm pseduo-helpless and for the first time, it feels like I'm reliant upon some sort of native guide. I neither have the time nor the inclination to spend a bottomless-pit's worth of time and energy into researching what I need to know, and how much to pay, and whom to pay it to, and whether one plan or another is going to be worth it. Never mind the fact that a cursory glance at the plans available in Oregon don't necessarily line up with what it is that I want, whether or not I wanted to pay money for it. But this is healthcare, after all. 
1.0 Belong
It's easy to make fun of Airbnb's new logo, but on reflection, I'm with Brand New[1] - it's a perfectly good logo, one that will be distinguishing for them. The objection is all the dross and wank that comes along with it: the naming of it and the frankly offensive long copy that tries to justify and explain what should instead be experienced[2]. 

For example, this type of description: 

"We used to take belonging for granted. Cities used to be villages. Everyone knew each other, and everyone knew they had a place to call home. But after the mechanization and Industrial Revolution of the last century, those feelings of trust and belonging were displaced by mass-produced and impersonal travel experiences.  We also stopped trusting each other. And in doing so, we lost something essential about what it means to be a community. After all, our relationships with people will always be the most meaningful part of our lives. You just need to get to know them. That’s why Airbnb is returning us to a place where everyone can feel they belong."

runs counter to anecdata of several friends I have of checking into an Airbnb and being categorically told by their hosts "if anyone in the building asks who you are, just say you're relatives." Because any sense of community and trust is first founded upon denial of identity, right? 

I worry about the sheer amount of rhetoric involved and the language that's used to say quite a lot when instead a little could do a better job. The audience for the blog post isn't ever going to be that big compared to the eventual audience of the mark. If Airbnb succeeds in getting it in the windows of participants of the sharing economy - excuse me whilst I gag - then that'll be a tremendous and recognisable achievement. But instead, the blog post is instead more of a dog whistle to those who're more attuned to these kinds of things; who're going to be more critical of it. 

Does any of this matter? Maybe not, not in the long run at least. But I'm suspicious of brands that like to talk about themselves quite so much. Personally I would've preferred something a little less pretentious and a little more demonstrative. I don't know what the takeup figures are for people creating their own Bélos (if that's the right plural), but my suspicion is that the number is either a) low, or b) high and satirical. I know I certainly tried with the latter. 

Part of this comes down to community management: Airbnb is saying that there exists a nascent community of sharers that they want to grow (and less explicitly, that they want to own). The premise of using Airbnb now is not simply that you want to find somewhere to stay, or that they're taking advantages in terms of badly planned transient resident housing resource, but that in an increasingly mobile society, we all want somewhere that feels like home. Part of the delivery of that is through the "community" of users who let out their residences with Airbnb in the first place.

I don't have access to Airbnb's internal metrics about who's doing what, but for those who're following along with the outrage at the Facebook emotional contagion study from a few weeks ago, here's how something like this works. Airbnb introduces a new metric by which guests rate their hosts: curation of the local neighborhood. At the same time, Airbnb lets its hosts know that they're going to be rated by their guests on how well they introduce them to the local neighborhood. "Here're some of the things you might want to do," says Airbnb, like list the local coffee shops or, for other kinds of value-add, you might want to take them on a walking tour. This isn't exactly great news for the opportunistic arbitrage spotter who's buying up as many properties as they can to flip them into Airbnb properties to make a quick buck because hey: who wants to have to be a community manager and a social host instead of someone who's just managing a portfolio of properties that fill themselves with pliant guests looking for a cheap place to stay in town when the hotels are doing a terrible job? 

In other words: Airbnb believes that we should all be much nicer to each other, we should be happy to accept each other as guests in our neighbourhoods and we should be grateful to Airbnb for pointing out that until this moment when we graduated wholesale to accepting the sharing economy, we were living as savage brutes with no reason to be nice to each other or to introduce people to what's around us. 

This is pretty tangential, but what irks me about the way in which Uber talks about the Sharing Economy and how they're playing such a large part in it is that most of the analysis revolves around their play in the Moves Everything  market in much the same way that Amazon is focussed on the Sells Everything market. Uber's transcendence to the Moves Everything market relies upon a short-term play in the Share movement (and less so the sharing and more so the service infrastructure that allows them to manage demand), but at the same time, the vast amounts of capital now available to them are allowing them to implement a pretty classical price undercutting in all the markets that they care about. UberX is just going to get cheaper until it doesn't have to anymore - presumably at which points the medallians, if they even still exist, will become worth something quite different. 

No, Uber's valuation should be more than the $18bn and the upside is stupendously massive: but let's be clear, in the potential markets for Uber addressed in[3], these aren't necessarily "sharing" models as much as they are rent-by-use models. It might feel like a linguistic sleight-of-hand, but you share things that you use. The other things that we talk about sharing - that are open to all - are known as *utilities*. 

[1] New Logo and Identity for Airbnb by DesignStudio
[2] Belong Anywhere - Airbnb's new mark and identity
[3] How to Miss by a Mile: An Alternative Look at Uber's Potential Market Size
 
2.0 Snow Crashing (9)
We've hit chapter seven in our journey through Neal Stephenson's Snow Crashing and this time we find ourselves in the Black Sun, in the Metaverse. (Last time, Y.T. had just ended up in The Clink due to inadequate provision for female guests at The Hoosegaw). 

Stephenson is really going for the VR concept here with the Black Sun. We've got space (the Black Sun, a bar, is as big as a couple of football fields so curiously even in virtual space we're still measuring distances with real-space sportsball terms), but just to fuck with us a bit, the tables are hovering in the air because why bother drawing legs when you're simulating gravity in the first place. Everything in the Black Sun is matte black - because hey, why bother tracing out where all those rays are going to go, and also, I'm not sure if anyone's actually done this before, but I bet it looks really weird and potentially nausea inducing. Readers with an Oculus Rift feel free to rez in a Black Sun-like environment and tell me if being surrounded by a mass of matte-black light absorbing material is indeed weird. 

The Black Sun's environment appears to be the equivalent of a mod - different rules apply here, so you've got collision detection and clipping; "only so many people can be here at once, and they can't walk through each other. Everything is solid and opaque and realistic" - to the extent, of course, that the real world isn't composed of solely matte surfaced objects that rest solidly in the air with no visible means of support. But yeah. 

We get an introduction to the term Daemon - you're reading this on something that has a bunch of them operating in the background right now, and if not right now, then they'll wake up for a couple of microseconds and do some stuff and then go back to sleep. Don't worry: they're there. Anyway: now that we have a different sort of user interface, here's an opportunity for us to treat daemons as "[serving] imaginary drinks to the patrons and run little errands for people". I'm not sure if I'd still call these things daemons these days rather than scripted behaviour - but regardless, these are bits of pre-programmed behaviour, sometimes at the behest of a user. 

We also get reference to cartoon-physics. Da5id has modded the environment so that people can get "hit on the head with giant mallets or crushed under plummeting safes before they're ejected" which whilst not entirely describing cartoon physics the way we're used to it now (ie exaggerated scroll and bounce, rubber banding) the way that Stephenson describes that cartoon physics evokes the same kind of effect - we expect people hit on the head with a giant mallet to comically compress and rebound before being thrown out, or for the safes that are dropped on them to amusingly squish them rather than implement a more accurate (and potentially computationally expensive) simulation of what happens when an avatar body gets hit with a few hundred pounds of force. 

There's a throwaway line here - that if your personal computer is infected with viruses "and attempts to spread them via the Black Sun, you had better keep one eye on the ceiling". We don't really get to see what the virus/malware ridden world of the Metaverse looks like - there certainly aren't that many backdoors and not really that much hacking that goes on (other than, you know, the giant bit of bio/informational hacking with the Snow Crash virus itself). But we don't really get to see what type of viral behaviour a host might exist in a virtual environment, which would've been interesting. 

We do get a little bit of hacking here though: Hiro invokes Bigboard - by mumbling the word, which seems a bit weird that he has to say it out loud - and it's a backdoor exploit that essentially lists all the current users of the Black Sun and displays them on a flat map in front of him. Bigboard is just another reflection of how Stephenson is kind-of-but-not-really treating space in the Metaverse like space in the real world. With most contemporary massively multiplayer games that are situated in a virtual environment, we still get a sort of chat channel/party line that lists everyone who's in the immediate environment - World of Warcraft comes to mind. In the virtual worlds that we've built in the intervening time since the release of Snow Crash, it feels rare that you have to eyeball all the player characters to find out which ones they are, especially when you're talking about a social setting. 

By scanning through BigBoard we see the social focus of the Black Sun: movies, music and the Japanese, with the odd smattering of People Who're So Powerful They're (Practically) Sovereign Nations. This is also the first time we see Sushi K, who'll pop up later on. 

When Hiro heads over to Da5id's table, there's a line that's resonated with a whole bunch of people: "Softare development, like professional sports, has a way of making thirty-year-old men feel decrepit." 

Now we meet The Girl. I'm not quite sure if Juanita - portrayed in the Black Sun as a low-rez black and white avatar and talking to Da5id - ever does talk to another woman in the book about something other than another guy (it's possible she talks to Y.T. later on) but at the very least, Juanita has her shit together. She has her shit together in the way that a lot of young male geeks feel older women have their shit together - she's outrageously smart and intimidating to Hiro and that's part of what attracts him to her. Juanita and Hiro met in freshman class at Berkeley, and later when they're both working at Black Sun Systems, inc. Stephenson writes perhaps one of the most insightful pre-Reddit diagnoses of casual sexism to have been committed to page:

"It was, of course, nothing more than sexism, the especially virulent type espoused by male techies who sincerely believe they are too smart to be sexists." 

In Snow Crash, Hiro's the one who has to do the growing up. Bouncing around as an army brat from base to base, it's only when he revisits his memory of Juanita and how he reacted (or rather, didn't) to her when he met her at school, and then years later, in employment, that he realises that he's the one whose expectations needed recalibrating.

Anyway. Juanita has a painting of her late grandmother in her office at the Black Sun - where Hiro and Juanita have their real jobs - and we learn that Juanita had gotten pregnant at a young age, that her grandmother had been able to intuit and tell; to "condense fact from the vapour of nuance" and that Juanita's big deal, her epiphany, was that whilst writing yet another query interface for a DoD grant she remembered that moment with her grandmother and tries to work out how to present information in the form of faces - because that's what humans are wired to recognise. 

There's a difference, we learn, between Juanita and Hiro. Juanita and her family know where they are - where they stand, with "a certitude that bordered on dementia". Hiro, by contrast, never knew - never knew if he was black or Asian or plain Army, never knew whether he was rich or poor, educated or ignorant, talented or lucky or even where his home was until he moved to California, which was "about as specific as saying that you live in the Northern Hemisphere".

We learn a lot more about the world of Snow Crash. That Da5id's parents were Russian Jews from Brooklyn, that Da5id went to Stanford and then started a company when he graduated "with about as much fuss as Hiro's dad used to exhibit when opening a new P.O. box when they moved." The rest of the sketch of Da5id's character is Valley stereotype - he's certain of everything, so much so that Juanita eventually divorces him and Hiro leaves the company. Juanita's circumstances allow her to hang on and to allow her stock to vest and cash out so she's rich now (how things never change), whilst Hiro cashed out early to put his mom in a nice community in Korea. 

Hiro might not have a lot in the real world, but he has a lot in the Metaverse and he looked after his mom. And at the moment, he seems perfectly fine about that. 

Part of what makes this interesting is the context - this is the vision of the future that we thought we were getting, and simultaneously, it's more or less the future being built right now - or at least tested - by startups like Oculus Rift and products like Sony's Project Morpheus. There's a lot here that's being learned in terms of what sort of environments make sense to our old, physically evolved brains. In terms of the people building Oculus Rift, I'm at roughly 30k feet right now, but my guess is that the ratios haven't changed that much. Juanita's an outlier at Rift, and her female colleagues are much more likely to be working in outreach, marketing and HR than in areas such as helping people understand the nuances of communication - somewhat ironic, for a virtual reality company bought by the world's biggest social network. 
3.0 Humans As A Service

Part of what I wrote in yesterday's episode was about this particularly engineer-driven strain of wanting to map human relationships to existing data models so that they can be manipulated, transformed and acted upon without any of that messy human stuff getting in the way. A reader wrote that - if we're being extreme - there's a strain of the Californian Ideology where people aren't just uninteresting but that they're terrifying - and even worse, unmediated people, people in your face where you're terrified of some sort of social faux-pas where you weren't able to look something up in time or you're just afraid of being *embarassed* is the absolute worst.

In some respects, a Brit can point fun at California for this. This California, simultaneously the product of some of the worlds most connective, empowering and dehumanising technology is also the same touchy-feely hippy California that encourages you to get in touch with your feelings, to hug it out, to have exported trust falls and corporate team bonding exercises (okay, so perhaps these are fake social bonding exercises) to the rest of the world. This is the California that also wants to use technology to mediate the human experience, to tidy it all up? 

We know that images can be manipulated, so it's a staple of science fiction to drive that to eleven and to imagine worlds where realtime video of ourselves can be amped up, calmed down, massaged to help us promote the view of us that we want the recipient to see. Think of it as a realtime curated Facebook video feed - the cleaned up, Photoshopped version of ourselves that appears in FaceTime calls. 

With all of this it feels like there's an index - a score that can be assigned to all these different mediative technologies to purport to make human communication more efficient but instead produce unintended effects that may well just get in the way. So Graph Search when it's used to provide a query interface to "stuff people like" is only as good as the information that's at the nodes of the graph, and provides a false sense of security to those who're using it (if those who're using it trust that whatever is in the graph is true to begin with - and I'm not that sure how many people treat Facebook that way). But then there's always the opportunity for leakage - Graph Search is just the high tech version of playground ask Sue to ask Steve to ask Jen what she likes so Amy can get her something she likes for Christmas, but instead goes horribly wrong because Steve gets it wrong and Amy buys the wrong thing and then Jen won't speak to Amy anymore. 

Of course, the human intermediary service that we've all been using forever has been: humans. Humans turn out to be pretty good (well, the least worst option, I suppose) at being able to intuit the needs, desires and emotional axes upon which other humans work. At least, the good ones do. And the best humans are the ones that also do the best introductions - the super-connectors. LinkedIn is human super-connector as a service, seeking to emulate that one woman you know with the rolodex who knows anyone who's worth knowing, who's always eager to introduce you to someone who'll help you with what you do.

But of course, the reason why she works so well in this thought experiment is because she takes the time to know you, and to know you intimately. She knows what you're into and what you're not into, mainly because she's been evolved over millions of years - just like every other human being - to be really good at modelling humans. And she's one of the best. And her models naturally include what the receptors and emitters that you have, and everyone else in her network. She doesn't need to send you cards on your work anniversary - well, she might - but you can be pretty sure that she doesn't ask *you* to send anyone cards on *their* work anniversary either. 

The inverse here is that an engineer can look at this state of affairs and say: gosh, there's a whole lot of implict information out here that's being wasted and this is a terribly inefficient system relying on a bunch of super-connectors and, let's be honest, a fair amount of random brownian motion in society. No, this needs a bit of optimisation and potentially the inefficient information transfer drag that's been holding us back can perhaps give way for us to finally sublime and live among the stars. 

I belong to a relatively high traffic private mailing list that's been going on for at least a decade, I feel, before I joined it, and that was at least a decade ago. One of its axioms is that the noise is the signal: ie the random crap that people talk about, the play, the banter and the back and forth are just as valuable as the purported "signal" that it's easy to try and look for. Instead, all of these weak ties - the chats about where you find a plumber or what best boiler to get (this was before, of course, sites like The Wirecutter produced articles SEO'd to within an sub-pixel of their rendertimes entitled "This Is The Next Boiler You Should Get"). It's hard for the engineers and product managers who're designing our human intermediary products to explicitly design for noise. Everytime they see noise, they see something absolutely terrible - something that until recently was useless and something that might as well have been thrown away but for stupendously cheap disk space, but now, thanks to Big Data, you can throw a few social scientists and data scientists at it and potentially publish what you've found in the micro-interactions of your millions of users.  

Some of these desires - the airport example - are less business problems to be solved, and more examinations of how reality and social interactions work and a desire to remake them to be better for the end-user. I suppose you could equate them to, a long time ago, someone gazing longingly across a stream that needed to be forded to provide access to the green pastures across the way and deciding to go out and build a bridge. But, I'd contend: not really. For starters, there's the my-problem-is-your-problem worldview, the view that making something work "better" or more efficiently for a certain class of people will result in equivalent gains for others. But the Airport Introduction example relies on asymmetries, too. The socially shy individual who uses the service to find interesting people to talk to can only use it if everyone else who's potentially interesting is broadcasting their interests. In other words, if only all of that private data about someone - and I'm using the term "data" guardedly - was accessible in some way. To the entire world. 

I'm not sure what kind of hubris this is. On the one hand, you can say that those who have low-level social interaction anxieties and problems are at least taking things into their own hands and trying to make the world function better for them. You could try to make an equivalence with physical accessibility, and say that the more of the physical world that is accessible to those who are less physically able, the better and richer our societies. And I expect that most people (libertarian crazies notwithstanding) would be OK with that. So: what of remaking the world to make it easier to use for those people who just don't like talking to other people? And then what of remaking the world in a fashion, through network effects, that mean that, well, you don't have much of a choice? If someone in the right position, at the right time, decides that we'd all be better off knowing who everyone in the airport terminal was and what their interests were, do we get an opt-out? Do we get a straight opt-out, or just one if we happen to not want to use one of the world's largest communication networks?

I sympathise, I really do. There are a great number of times when I find it less stressful to insert a screen or some sort of communications medium between myself and the person I want to talk to or interact with. And I see how the route of technology has always been to take that which is difficult or hard and to make it easier to do. But perhaps "interacting with people" is not the kind of technological problem that needs to be solved in such specific ways.

--

Notes! I EAT THEM. Also I like to know who you are, so you should introduce yourselves.

Best,

Dan

  
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Six: Solving The Problem
Date: July 22, 2014 at 6:03:50 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gret=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
The thread, this time, is a notification from the pharmacy that our pharmacy benefit has been stopped. I pull on it, and the thread leads to our insurance provider's website, where they happily inform me that coverage stopped over two months ago, which is patently not the case. So I check out - well, I'm not sure what to call them - but I check out our benefits management company's site and try to log into the COBRA management system (for the non-Americans, COBRA is the name for the Federal program that seeks to allow continuity of insurance coverage through a Qualifying Event, which in this case, is termination of employment). The login for the COBRA management system is down - down as in "not even responding to pings" and down as in "traceroute doesn't know where it's going" so I try through a vpn and it's not working there either, so in some sort of fugue state because I don't know what the fuck I was expecting, I decide to open a customer service chat window where someone ("Alice") insists that there isn't any problem with their website. I give up and open up a Gmail window and make a VOIP call to customer service, who very calmly tell me that they have terminated my family's insurance coverage and that's the end of that conversation. 

But, no sense in crying over spilt milk, because hey, you need to go find insurance coverage for your family. So you need to learn the difference between an HMO, a PPO, an EPO, a POS and then you need to find out if any of the offered plans cover any of the doctors that you already see and you need to find out if you can actually remember what the "out-of-network maximum deductible means" - does it mean the maximum that you'll have to pay for treatment provided by facilities and doctors outside of a certain coverage network, or does it mean that they'll only pay up to that amount? 

And you realise: no. You are not supposed to be able to work this out. Because you're a relatively well educated person, and it would take you for-freaking-ever to work this shit out, and you're *tired* and all you want is health insurance and this is more complicated than figuring out what standing fan to buy for the bedroom or even which hard drive you should buy for backups or even if you should buy a new laptop or not, or even, bluntly, figuring out a digital strategy for an organisation or a company. Because *those* things are fucking easy. But getting health insurance and understanding what you're getting? Not in America.

User interface niggle of the day: textareas that anchor editing controls to the top of the textarea, so every time you want to do something, you have to scroll up one thousands words. Note: "Write less" does not fix the problem. 
1.0 Numbers
It strikes me, as I'm looking at all of these 100+ providers that I could potentially choose from at the Cover Oregon website, that when I select, say, three of them to "compare" them, and what happens is that they're listed side by side, I actually have no idea what I'm comparing. I am in dashboard mode: that peculiar fetishist of a certain class of designer who believes that if the job is to "compare" things then all you need to do is put the numbers up and hey, then you've compared them. 

One of the things I missed about England when we moved to the 'states was that some groceries - I think Sainsbury's did this particularly well, but it's been years, honestly, - did a pretty good job of providing you a cost-per-unit on equivalent goods. So if you were trying to work out what canned tomatoes to get, every single pricing label would display a cost-per-hundred-grams for example. And you wouldn't have to do the mental arithmetic of trying to figure out if this can was more expensive than that can if they weren't the same volume or weight. 

I'm looking at this dashboard of numbers, this tabulated set of data of side-by-side numbers representing deductibles, out-of-pocket maxes, prescription benefits for generics, preferreds, non-preferreds, of which the terms I don't understand and am terrified. I'm terrified because I'm supposed to be functionally literate, and I find this stuff overwhelming. In an employment situation, I delegate this to someone else, because it's their job - their full time job - to both administer a plan and to explain it and its benefits to its members. But here I am, with a self-serve website, and I need to go and learn about this stuff. 

This isn't technology being empowering. This is the literal *least* that technology could do. This is the opposite of consumer choice - because at the end of the day, when you've been working and you sit down, we've learned that the ability to choose and to discern and to exercise willpower and restraint and, bluntly, to concentrate, are fixed and deteriorate through the day. 

So no, this isn't helping. This is externalisation of cost. This is shirking of responsibility. This is not using technology the way it *should* be used, or the way it *could* be used, but the way that it can be used to inflict maximum possible harm - to provide the illusion of choice without actually enabling *better choices*. 

And it fucking disgusts me.
2.0 More Better
It happens every single time: I fly international with Delta a fair amount and I'll get a notification that they're ready to have me check-in. And then I'll go through the process and then it'll freeze or half-throw an exception because it turns out, unsurprisingly, that I need to have my documents checked at the airport. This shouldn't be a surprise. But it happens every time, and every time, a little part of me thinks: maybe this one'll be different! Maybe I'll actually get a boarding pass this time!

But no. An apology every time. 

I think there's a strong example of this at GDS (yet again!) in this post, "What we mean when we say 'service transformation'"[1]. You should go read it, but there's a part of what Mike Bracken writes that I think illuminates what I've been trying to get at with the whole empathy thing. When referring to a particularly egregious example of bad writing in service, he writes:

"With the first line it offers help. And with the very next line, it takes that offer back."

I don't think it's possible to write that sentence - to have the understanding that produces the ability to write that sentence in the first place - without having sympathy and empathy for the people who read it. And I think this is what I mean by really concentrating on the details. 

The tone of voice adopted by the women - so far, it's always been women - who answer my calls about COBRA, about health insurance, about the Oregon marketplace - are always very careful to toe the line. There's none of Mr. Incredible's "look, if I were going to help you, then I'd say that you should fill in this form and send it to that person over there." Instead, there's a hardening of tone, a practiced distance, a change in register to more formal and more detached and that inkling toward roboticness as if to say: this is a policy that I am required to enact, and as a human being, I'm afraid I have no say in the matter. It's not my *job* to have a say in the matter. 

I compare this to a customer service representative I spoke to at Delta - admittedly the premium member's line, where you don't ever have to wait to get connected to someone - when I was booking some complicated family travel involving three people, some award flights and some not, and a minor. She was explaining the policy of not allowing people to book flights for minors online - that they had to be bought over the telephone ("You wouldn't guess," she told me, "the number of people who would try to book unaccompanied minor tickets who turned out to be unaccompanied minors"), but later, she would talk of flying as an employee, right at the back of the plane, inevitably where the unaccompanied minors would be sat. On their own. And with - sometimes - no one to help them get to their next flight. Which she would do, patiently, and make sure they got onto their own flight, off of her own back, when she wasn't even on the clock. Because what else would you do? Would you leave a kid on their own when you could make sure they could get on their way? Of course not. Well, you'd like to think not. Her husband, she laughed, had a different attitude. 

We've never needed technology to let us treat each other better. It's always offered us an opportunity to - Zappos doesn't have any special sauce in its technology stack, it just has a laser-like focus and presence of mind - in other words, it gives a shit. It gives a shit to the extent that it elevates that customer service so that it's more important than a hell of a lot of other things, and that people are given latitude to execute that larger goal in any way that they see fit. 

I don't know what it is about technology that on one level, allows for much greater opportunity for connection than ever before, but, in its own screen mediated ways, allows for much more abstraction, too. Those people who call for not having to speak to a driver - Uber or not - and to communicate with them only through app are essentially wishing for a universe in which they don't have to interact with other people. When, as far as we know, people are amongst the most interesting and most intricate things in the entire universe. Why would you want to abstract that away and seal yourself away from it?

[1] What we mean when we say “service transformation”
3.0 All Rolled Up
I'm still thinking about people living on trains. Out of their three dimensions, all but two have been rolled up to be very, very tiny - this is your ant on a piece of thread, able to go forwards and backwards, able to circle around, to an extent, but not afforded any other degrees of movement, silently passing through billions of calabi-yau folded spaces in the meantime. 

But these people on trains - forever going forwards and backwards but with only some sort of Minimum Viable X and Y axes, just a few feet in either direction, but practically infinite forward and backward along the Z. 

Some readers wrote in about imaginging people living in other such constrained environments - the idea of living in Venice and Holland where part of the infrastructure you live on manages water, or the idea of living in Dubai, where you're essentially inside a vast, air-conditioned environment that may as well be a dome on Mars. 

But I'm still thinking about people living on trains, about that closed yet moving train ecosystem. Ingesting ice at the front, and the strange design constraints that mean you have to keep constantly moving and manage your population. When the way you experience your world has been dictated to by the constancy of the gauge[1].

[1] Track Gauge
4.0 More Ideology
So The Guardian ran a CiF article on the tech utopia nobody wants[1] which in part just re-hashes a bunch of stuff we've already seen (people don't like Google Glass, some Google Glass Explorers aren't very nice people, Justine Tunney is a troll). There's a phrase though that JR Hennessy writes where:

"The philosophy of Glass is inward looking. It improves the life of the wearer at the expense of those around them."

which I'm not entirely sure about (and, I'd argue, doesn't necessarily translate to the criticism of Soylent). I mean yes, literally, Glass is about the wearer. Its second-order benefits in terms of everyone-else-who-doesn't-wear-it are more soft, along the lines of the more Google knows about the world in general, the better it is able to serve (for certain values of serve) us. 

Look, here's the conclusion of Hennessy's article: 

"A divide is growing between the people who wholeheartedly embrace a radically new, radically self-centred vision of human life, and the people who do not. The internal lives of the tech elite, centred on the labour-saving innovations of Silicon Valley, are at odds with semi-atavistic conceptions of how people interact. Traditions and shared values are redundant, inefficient, and must be optimised out of existence."

Part of this, of course, is that traditions and shared values are frequently soft - they're not easy things to measure, and if they're not easy things to measure, then they're hard to capture in a database and represent with SQL, NOSQL or not. In other words, there are messy bits of the human experience that have to date been hard for computers to capture and model, and those bits are generally the bits that are ignored. You are only concerned with the numbers that can you can measure, and you want to make sure those numbers are moving in the right direction. The other day at my talk, I spoke a little about this curious notion of ambience - that ambient data meant taking lots of numbers, making them explicit and then just displaying them in more places. Which strikes me as rather missing the point of making something ambient. 

Perhaps the canonical example for me is the Google+/Facebook/Glass-like tech executive story of being at an airport terminal and having some time to kill and not knowing what your fellow travellers have in common. Perhaps you could have interesting conversations with them? Wouldn't it be great if you could be prompted: see Sarah, three seats over? She likes the same band as you! You should talk to her! Or Amber, sitting next to her: she works at Lockheed Martin and has been writing more blog posts lately, she's probably ripe for headhunting into that firmware engineer position you've been trying to fill. 

The reaction in the audience, one of the last times I heard this story, was that all of my non-technical colleagues balked at the idea of computer mediated introductions. Nevermind the fact that it's hard to go up and talk to random people (or at least it's hard for *some* people to go up and talk to random people) they didn't feel comfortable with the idea of having such notifications pushed upon them. 

Look, I get it. I grew up feeling like it was a lot easier to express myself through the written word than through talking. I still find it difficult in social events with lots of people - like after speaking at a conference, for example - to talk to others, and instead you might normally find me hidden away. But that doesn't mean that I'm not approachable. But the joke is this. In a utilitarian world where Mark Zuckerberg theoretically doesn't like having to talk to other people, he could:

a) build an SQL like query interface where he could find out what his friends like so he can buy the correct Christmas presents for them, and thus increase the number of correct Christmas presents in the world by an appreciable amount because there must be other people like him; or
b) just not talk to anyone and not buy them Christmas presents.

Utilitarians find them, as a matter of principle, rooting for route (a). 

"The backlash against this world is democracy manifesting itself; a tacit rejection of the ideological assumptions underpinning the personal tech revolution. People want to define the structure of their own lives, and Silicon Valley's myriad product lines are an unwelcome intrusion into the way we live and interact with one another – and even the way we eat, sleep and procreate.

"A simple fact remains: there is something intrinsically repellant about a world in which our food, jobs and personal relationships are replaced by digital proxies in the name of ultra-efficient disruption. The geeks, with their ready willingness to abandon social norms, are pulling us toward a utopia nobody wants."

This isn't going to win an argument with someone building a disruptive service that introduces empathy-less computer mediated social interactions. Saying that there's something "intrinsically repellant" isn't going to stop that person from deploying that service. They think that personal relationships are being made *better* by the use of digital proxies and that they aren't being replaced at all. And that's, for a broad part, true - when social networking sites are used "properly" they allow people to keep in touch and *broaden* in an additive way the ways in which people can build and maintain social ties. But that's not to say that they don't bring with themselves a bunch of other baggage. 

[1] The tech utopia nobody wants: why the world nerds are creating will be awful
 
--

Well then. How was that? Send me notes. It's easy - just hit reply. 

Best,


DDan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Five: Transparency Through Bot; Mundane Fictional Spytech; The Horizontal Arcology
Date: July 21, 2014 at 4:58:39 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gqm9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
So I accidentally disappeared for a few days due to a combination of illness, travel, jetlag and generally it getting to the end of the day and simply not having enough time. But I'm back now: I seem to have picked up a norovirus at roughly the same time as my son (thanks, son), perhaps ill-advisedly got on a transatlantic plane whilst still feeling a bit wobbly, spoke at TEDxLiverpool yesterday, did All The Shopping today and maybe accidentally re-discovered Civilization V. 

So here's the thing about public speaking. I manage to simultaneously love it and loathe it: I loathe it for the weeks (months even) leading up to the next occasion because I am driving myself mad with nerves about the content of the talk - especially if it's something new, which is what yesterday's talk was, or if it's a new unfamiliar audience (which all of them are, to be fair). Part of this is as much some sort of imposter syndrome - is what I'm talking about actually going to be useful, relevant or interesting to any of these people? But at the same time part of what I grapple with is a bit of a strange feeling of: well, surely I'm not *that* qualified to talk about this particular thing. It's taken me a long time to realise that part of what people like from my talks is not so much the brand-new knowledge that may or may not be imparted, but at least something like an additional perspective. 

And then there's the hours and minutes - and the whole day - before the actual talk where I actually *feel* terrible. Like, physically terrible. Not like throwing up shaking terrible, but a consumed with anxiety kind of terrible that makes it difficult to concentrate on other things because I'm just worried about how it's going to go. That persists right until the microsecond before the first word comes out of my mouth. Because even after I've stood up out of my seat after being announced, even after stepping onto the stage, even after grabbing the mic if there is one, it could all go horribly wrong. Until the first word comes out of my mouth. 

Because after that, more commonly than not, it feels *amazing*. It feels like I'm on fire, like I can look anyone in the audience in the eye and know that I've got them, and that they're coming with me for the next fifteen, twenty, thirty minutes or the next hour or however long. Because I can make them laugh and I can make them go quiet, and sometimes, if I'm very lucky and I've got the right stuff, I can make them cry. And those minutes feel fantastic. Like a stupendous drug. And I love doing it. 

And, to be honest, it's been far too long since I've done it regularly. 
1.0 Transparency
It's been a recurring theme of this newsletter that we live in an almost (if not actually) incomprehensible world of sufficient complexity and that one of the things that we could do with more of is transparency - and not just transparency, but well-communicated transparency where the end-goal is understanding of opaque processes. 

In other words, and more better written: we need more things that help us understand what's happening in the world.

A good recent example of this is the Parliament Twitterbot, @ParliamentEdits[1] made by the inestimable Tom Scott[2]. @ParliamentEdits is pretty simple - because most of the web traffic from Parliament is routed through only a few proxy servers, it's relatively easy to identify Wikipedia edits that come from those IP addresses. So, what you do is this: you watch the Wikipedia page of recent changes[3], filter for the IP addresses that you're looking for, and then, poof - do whatever you want to do with that feed. 

One of the wonderful things about the internet (and a lax approach to intellectual property where what Tom did either couldn't be patentable, shouldn't be patentable and wasn't patented in any event by Tom because he's a nice chap) is that an idea like this is pretty easy to copy. And we should be clear: it's a *good* idea. Wikipedia is a resource that's used by lots of people and as such is influential. It's also (broadly speaking) a strength of Wikipedia that it can be edited by anyone, but only inasmuch that it also provides an audit trail so you can see who edited what, when and where from, which is useful when you're building an encyclopaedia. 

So it's easy to take Tom Scott's idea and go: hm, what might Russian state-owned media be doing on Wikipedia these days, following the tragedy of flight MH17?

There's a good writeup on Slate.com[4] about the Wikipedia bot that showed Russian state-owned TV, but here's an excerpt from the original article over at GlobalVoices[5]:

"Earlier this morning, the Russian-language Wikipedia entry for commercial aviation accidents hosted one such skirmish, when someone with an IP address based in Kyiv edited the MH17 record to say that the plane was shot down “by terrorists of the self-proclaimed Donetsk People’s Republic with Buk system missiles, which the terrorists received from the Russian Federation.” Less than an hour later, someone with a Moscow IP address replaced this text with the sentence, “The plane was shot down by Ukrainian soldiers.”

"Thanks to a Twitter bot that tracks anonymous Wikipedia edits made from IP addresses used by the Russian government, we know that the second edit to the MH17 article came from a computer at VGTRK, the All-Russia State Television and Radio Broadcasting Company""

We don't need to rely on everyone in the world following that Twitter account. But this type of *automated* transparency, opinionated bots that are created with purpose, are as useful to journalists as other types of sources. The bot made it easier to find edits to Wikipedia that might have more meaning, more context at a particular moment, and sure enough, that information was useful enough and got passed around. And now, articles in newspapers all over the world are calling attention to the fact that the edit came from a certain IP address. 

[1] @ParliamentEdits 
[2] Tom Scott
[3] Wikipedia Recent Changes
[4] Wikipedia Edit Twitterbots Are Revealing How Russia Wants to Frame the MH17 Crash
2.0 Mundane Fictional Spytech
I re-watched Mission Impossible 4: Ghost Protocol the other day - or had it on in the background whilst I was panicking and tweaking and playing with yesterday's talk. Let's get this out of the way first: Brad Bird is fantastic and if you haven't seen and enjoyed The Iron Giant, then a) I don't know what's wrong with you and b) I still don't know what's wrong with you, why are you still here and not watching The Iron Giant. 

Anyway.

Whether it's product placement or something else - more likely the former than the latter - there's a lot of Apple kit in the movie, and it's clear that the Impossible Mission Force is one of those organizations that has made the move over to at least part of the Apple ecosystem. A surprising amount of their in-house spytech runs on Apple devices paired with either hardware cradles (the awesomely cool 3d projection iris-tracking setup that's used to infiltrate the Kremlin, for example, runs on an iPad, whilst the engraving machines used for the room switcharoos in the hotel run on a cradle with a standard-issue iPhone) or just, you know, on regular Apple hardware. 

It's one of those things that feels strange because you've got consumer tech (Hey! Jeremy Renner's using the standard iOS clock application to set a time - thirty four minutes to door knock!) as well as MovieOS in the form of the touchscreens and BMW holographic display and those large flat panels that are on those cool arms inside the IMF traincar-mounted shipping container as well as amusing gags about retinal scans. It's a bit like seeing the Windows splashscreen pop up in True Lies or, as one of my friends pointed out, the progression in tech from the first Bourne movie, where you see him using regular Nokias, to the special fake OSes that the CIA has in their situation rooms. 
3.0 The Horizontal Arcology
Two things: 

1) Snowpiercer[1], a movie about lots of things, but for the purposes of this section, a movie about a world made uninhabitable through second-order hubris of humankind and the remainder of humanity forced to live in a remarkably prescient allegedly nuclear powered train that contains a closed-system environment where everyone is shocked, (shocked!) that a high-density form of protein comes from insects.

2) The Verge reporting on a design for a new Japanese luxury cruise train[2] that looks remarkably like some of the sets for Snowpiercer in that it looks like what a train would look like if you made a luxury building, oriented it in a sort of sideways fashion and moved it through the world at about 200 kilometers an hour and made sure only stupendously rich people could get on it. 

So Snowpiercer is a movie set upon a moving horizontal arcology[3], a sort of archigram-on-wheels[4] with lots of guns, guts and violence, and the Japanese are actively designing, well, the sort of environment that you get to design when your design boundaries are the standardized space you can fit on a train car. Not building up, but building along on tracks. There's lots of SF I think that deals with this - cities on rails that slowly circle around planets, chasing or running away from terminators, but it honestly took me a couple of weeks to realise that was what Snowpiercer was doing in terms of its premise. There's something refreshing about thinking about the types of civilisations, cities and groupings that you can build in existing infrastructural places when you repurpose them. When your entire world is a train line, your existence gets reduced in dimension: you become something less than a flatlander, something where your only real directions are fowards and backwards - you hardly have any x or y axis, you exist only on a long, circular z. 

[1] Snowpiercer
[2] Japan's new Cruise Train is a luxury hotel on rails
[3] Nice pictures of arcologies
[4] Archigram Archival Project

--

So - I'm back! 

How are you?

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Four: When You're Tired Of Cities
Date: July 16, 2014 at 3:16:34 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gmyp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Technically, this episode is late, because it's being sent past midnight, which means that a newsletter episode was not sent during the 24 hour period of Tuesday July 15, 2014. But it's my newsletter and my rules and I'm still writing one anyway. So there.

We bought a new car. It has eyes and can see. It can see if I wander out of the lane I'm in or it can see if I'm getting too close to the car in front (or if a car in front suddenly appears, as certain American cars are wont to do because Jesus Christ won't you people please learn how to signal and not just drift all over the place.) 

It feels like my co-pilot is Rimmer, the kind of anal character from Red Dwarf, but perhaps a more competent one. This car literally has tunnel vision - its eyes have the equivalent of a super primitive visual cortex that only and obsessively cares about a) lane wandering and b) being too close to the car in front. Its eyes have a direct line to the brake discs, it can only really beep at me, plaintively, if I wander over. 

But, it's a new car and the car seat fits in it and it goes up and down hills, and it talks to my phone and yes, the user interface is practically terrible but not unusable, because if it were *actually* unusable, then it would be - well, you know. 

It is supposed to be getting cooler in Portland soon. For that, I'm grateful.




1.0 When You're Tired Of Cities

Or, rather, when you're tired of {insert tier one city} then you're tired of life. I struck a nerve with yesterday's episode[1] where I threw out the hand grenade of cities not being fit for purpose, for which there were instantly a number of replies ranging from the equivalent of "out of order? YOU'RE out of order!" in the sense of "no, you/we're just getting old", that bringing up families in a-list cities has always been the preserve of the top n percent, where n is certainly smaller than 3 (and yes, I realise that I'm being *horrendously* middle class and elitist here, because there are obviously people bringing up families in such cities in much less comfortable circumstances than my own). 

But. I think I'm going to qualify my position a little, because it's my newsletter and that's my prerogative. Let's just say that it's not that *cities* (the idea, the concept of them) that are no longer fit for purpose, because I can agree in the Jane Jacobs sense that they're the marketplace for ideas and engines of growth. Sure, I buy that. But I think I *can* say that many of a tier one cities are creaking with infrastructure (Christ, I sound like a regular Victor Meldrew[2] and that a lot of the services and infrastructure that they *do* have, either aren't fit for purpose or are on the verge of becoming so. 

That is to say: the list of things that irritate and that are shortcomings of tier-one city living are becoming longer (and such inefficiencies in established systems are being disrupted with a kind-of-capital D by intermediary services afforded new delivery methods through technology, like Uber), and the list of things that are benefits of cities are possibly becoming shorter. Or, their relevance to certain groups of people changes and decreases over time. 

So: not necessarily unfit for purpose, just, well, not as fit as before. Which, you know, seems reasonable enough to me. In other words, just because a whole bunch of benefits about cities are *true* doesn't mean things aren't necessarily getting worse or that the true things are any less true. 

One reader was kind enough to unpack my argument for me and to tease apart a couple of issues, the first of which was clearly: how do you make cities more manageable for young families, the short answer to which is: people are going to have to get used to less space (ie not every kid gets their own back yard), which is fair enough provided it's paired with easy-to-access public space (and by public space, presumably we mean *really public* space, not corporate-controlled space that's got metered usage. It's interesting because some of the solutions like better, cheaper and easier to access childcare, education and healthcare aren't necessarily physical infrastructure, but better planning (and delivery) of services. Some of these things, naively, and from the outside, don't *seem* hard, they just seem like failures of policy. To which the question is: what kind of people do our politicians want living in our cities?  

I'm going back to Liverpool later this week to speak at TEDxLiverpool, which theme this year is home and away[3], a celebration of talent that's rooted in the geography of Liverpool, whether they've made it at home, or whether they've made it far away. This time, I'm one of the far away, having grown up on the other side of the Mersey and gone to secondary school on the Wirral. It'll be interesting going back; Liverpool was one of the big port cities that did an excellent trade in shipping and the merchant navy, and with shipbuilding gone, it's been going through an exercise of trying to revitalise itself. There's a new downtown live/shop/work/play area that's famously privately owned with its own police force, and Liverpool, like many other cities around the world, is trying to navigate the downturn that hit it when manufacturing moved away to the East. 

While I'm thinking about this (and going back and referencing Matt Jones' The City Is A Battlesuit For Surviving The Future[4], part of me thinks that instead of bemoaning the difficulty about going back to somewhere like London or joining the bandwagon and nodding furiously whenever anyone says the Bay Area is an expensive place to live, but whaddaya know, you gotta go where the jobs are, is that I already have a city that I like, and I have the opportunity to make it better. 

Portland, Oregon is - for the moment - one of those cities that isn't too big, isn't too small (just, nearly) and has, as I've described it to other people, "about one of everything, but no more". Almost a minimum viable city. It's got a river with bridges, it's got green space, a moderate to problematic public school system (some short-sighted decisions to do with how you fund public education from public funds, perhaps), a stupendous amount of public transit for an American city, and an attitude to bikes that is nigh on communist if you ask a red-blooded American. Plus, the coffee's really good and there's that TV show. But, as I was saying, there's insufficient density in the kind of jobs that I'm interested in. The tech scene is small but growing (and it is growing - Pinterest are setting up and so on, eBay have an office) so perhaps it's the *boring* kind of interesting, but the one thing that the city does have going for it is the (for now) relatively affordable housing for young families. If only I could start something and find some way of luring people to live and work here...

So on the one hand, I can poke holes at startups like Airbnb and how on the one hand they're publishing shared city manifestos[5] and on the other hand they clearly have a bunch of different things going on: circumvention of (possibly outdated and needing to be tweaked) legislation and regulations surrounding short let accommodation, the ability to offer those with capital the opportunity to copy-and-paste multiply their capital through that legislative and regulatory circumvention, the offering of supplemental income support to those who're in financial distress, where the new normal is that you let out a spare room (or your own room) every now and then, and increasing access to travel and business accommodation through providing more options. Fine. There's all of that. But do you see any particularly good innovation coming from civic or local leaders *on the same scale*? It takes Google to offer to Fiber up Portland and suddenly the council doesn't exactly assume a position as become quietly supplicant and fine, it's not like Comcast were going to do anything in the meantime.

I guess my point is this: it's easier to build and prototype a small battlesuit in a small city - perhaps, than it is by moving to the tier-ones. And maybe that's a really interesting thing to do.

[1] Episode One Hundred and Twenty Three: Station Ident
[2] Victor Meldrew
[3] TEDxLiverpool 
[4] The City Is A Battlesuit For Surviving The Future
[5] Shared City

--

Send notes! I eat them. They crunchy.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Three: A Continued Error; Nadella; Hypermedia
Date: July 14, 2014 at 11:35:38 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gm5t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm at a cafe up the road from our house after having run an innumerable run of errands today. There's something that I'm struggling with after having had good friends come and visit over the weekend which is the thought that today's A-list cities have peaked. Of course, I'm allowed to say this, not living in an A-list city anymore, but the sense that I have amongst my rat-catcher network is that London and San Francisco and New York whilst still great attractors of opportunity and mixers and producers and not even melting pots but agitators are somehow *tired* and hard work for anyone over thirty five and wants a family, and isn't in, say, the top two percent.

Until moving to America, I hadn't realised how geographically oriented this place is. Media, go work in New York. Entertainment, go work in LA. Tech, go work in the Bay Area. Certain industries are just concentrated in a way that isn't really possible in a place like England (not now that certain industries were gutted by a certain prime minister), and the industries that the UK *does* have now, benefit from being in close quarters with each other in the way that London is pretty much the UK's "only" city. 

In other words: our cities aren't fit for purpose anymore. What would make them so?




1.0 A Continued Error

So the thing about screens is not the physical dimensions but the effective visual area. Turns out (citation needed!) that people tend to hold screens at roughly the right distance to maintain the same effective area. So you'll hold your phone closer, but sit back further from that 55in plasma screen, or sit a certain distance from your laptop. Makes sense, I suppose. There's all this talk - I saw a conversation on Twitter about Microsoft's Xbox strategy now that they've formally stated they won't be dumping the unit - about whether a living room strategy is still the right one to be pursuing, or if instead Microsoft would be more on-point if they were pursuing Microsoft on Every Screen Everywhere, and a more cloud-based thing, rather than doggedly sticking to the Biggest Screen In The House through an Expensive Piece Of Hardware.

What I'm getting at here is the the primacy of the screen and its seductiveness. It's easy to show video on a screen. It's easy, now, to put a full-colour screen in a thing - everything from a watch to a thermostat, and we haven't even gotten to the holy grail of printable OLED flexible, powered sheets with built-in computing yet. Watch everyone go apeshit for that, if it ever appears. 

It feels like we're immature about screens (in as much as we're immature about any technology that we play with, I suppose). And perhaps that's part of it, that most of the time, we're not doing considered placing of technology into contexts, but instead a sort of capitalistic throw-shit-at-the-wall-and-see-what-sticks model. For every Apple coming out with a (more or less) considered product "when it's ready" - for certain values of ready that include a nigh-unusable shift key in iOS 7 - there's every other OEM doing the equivalent of a cambrian explosion at the risk of being left behind. And then you get a bit of a sifting, a bit of a Great Filter of technologies and combinations of technologies and then before you know it everyone's embroiled in look-and-feel lawsuits. 

So this continued error is the persistence of calling things "television" or "video" when the bleeding edge (or not so bleeding edge) is more of an information-wants-to-be-free, and by free, it means "displayable on any device". Forget software expanding until it can read and send email, now software expands until it's got an mp4 codec in it or it can at least play Tetris. From this point of view, information wanting to be free is more about the bits wanting to be able to move from device to device than it is monetary value. It means I want to listen to music from wherever. 

This type of category error "we make television" as opposed to looking at it from the user's point of view and "we make video" comes across in a bunch of ways. There's that reference of Netflix as a "website" when actually it's about 10 years too early to be considered a "broadcaster" and because the shape of its infrastructure is different. But the job-to-be-done, when reduced down, is pretty much the same thing as a broadcaster. 

At W+K Portland, there was a group called W+K Entertainment - there probably still is - that was effectively a separate production company. I think the idea was that it would create its own content, and one of its first experiments was a radio station. But it turns out that a radio station - like, a "proper" radio station, with playlists and music you discover, isn't necessarily what the internet is good for, and the business model isn't really there in the same way. You could do the same thing with a blog. You flip it around and you ask: well, what could the people in this building do if they had 10% time or whatever trendy management technique existed, and you ask: what could we make *without* resorting to the traditional production model. Because you're kind of having your ass kicked by teenagers with passion, talent and time who're able to take the time to build up an audience. 

I guess this is the unbundling that everyone's talking about. The more expensive(ish) multi-purpose device that does everything that all your other stuff used to do. That reduces TV to an app. Hey broadcasters, you're just an app! And, for those wanting to reach an audience, it turns out there are so many more (not easier, not necessarily better) ways to reach and build audiences, too. 

Of course, none of this matters if you stay the course and don't listen to the established players. Netflix can quite happily continue doing what it's doing whilst everyone else digs their heels in.

2.0 Nadella

So smarter people than me like Jean-Louis Gassée have picked apart[1] Satya Nadella's latest Full-Bleed Photograph Vertically Scrolling Mobile Friendly Internal Email Stroke Corporate Vision Stroke Manifesto[2] - the opposite of a burning platform, if you will - and, by the way, bad URL! 

For me, the part that's jarring is the non-specific "we will obsess over our customers", which you'd kind of expect a company like Microsoft to do. This falls into Gassée's "can I disagree with it" taste test, in which case you ask yourself: well, why wouldn't we obsess over our customers? Shall we instead just gently consider them, but then just get on with shipping product that doesn't fit their needs? 

And secondly, part of Microsoft's problem has always been figuring out who their customers actually are. Are they enterprise, in which case they're not end-users. Are they living room gamers, in which case they're not the entertainment software publishers. Are they carriers and OEMs, in which case they're not end-users. Or are they, in 2014, also themselves? Microsoft is already competing with its partners through its strategy of both licensing-out its platform and creating its own products in Surface and the Nokia acquisition. 

[1] Microsoft’s New CEO Needs An Editor
[2] Satya Nadella's email to employees: Bold ambition and our core

3.0 Hypermedia

Russel Davies wrote a good post pointing to a book on hypermedia[1] where he points out that it *looks* and feels like how the future should look, but that there's no internet in it whatsoever. He asks whether the web just blindsided people, which strikes me as pretty plausible - the book was written in 1992, and 1990's Hyperland[2] also completely misses networks. The preoccupation with hypermedia (and in the same way, we see it with Neal Stephenson's hypercard stack) precluded interlinked-links, instead thinking of media objects as some sort of giant binary blobs with incredibly complicated *internal* structure, but not reaching out. Instead, islands of unconnected complexity, forever alone.

So I revise my position. The thing about the web is the networked link. Things that don't respect or build upon the networked link don't capitalise upon what makes the web unique. For thine is the network, the link and the protocol, forever and forever, 200 OK. 

[1] not understanding hypermedia
[2] Episode 23: Hyperland
[3] Episode 64: Snow Crashing (6)

--

OK, more notes please. They're really easy to write. And they're much more interesting to read and to reply to than the relative insanity of going through a car-buying process (Subaru Outback, if you're interested.)

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty Two: A Real Hunger; Will The Real Blue Ant; A Category Error
Date: July 11, 2014 at 11:46:09 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gkqh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm in the basement, a particularly American pursuit (they're like sheds here, I guess - or the garage), from which I've hollowed out a small space with enough power, USB and close enough to the wifi router that I can hole up and write, think and generally sit before I get on the bandwagon and fashion myself a standing desk out of whatever dumb material I can find. Or go to IKEA.

I am still thinking about homes - not smart ones, just ones that will exist in the future. You don't even need to think about what the smartness means. You just need to think about tropisms, I think. Leaning this way. Yearning toward that. Instinctively reaching out. Stimulus and response. None of this personality crap, none of this affected voice interface. Just regular alien smartness, the kind you wouldn't know about or think about. 



1.0 A Real Hunger

You might remember Upworthy (or you might not be able to forget it) as the news site that emerged, post Buzzfeed-era, as having pioneered the clickbait headline ideally suited for sharing on Facebook. You know exactly the kind of headlines I mean, er, I mean You Won't Believe The Headlines That These People Clicked On - And What Happened Next. So it turns out that Upworthy's business model is somewhat of a bait-and-switch (well, as much as a bait-and-switch as you can perform on the internet, where people should be inherently suspicious of the thing that's being given away as a free lunch). 

Upworthy's plan, see, is to

"to find topics of shared interest and get tons of people talking about them by highlighting the best of their content, curating great videos and graphics from across the web, and engaging Upworthy’s passionate, influential community to spread the word."

In other words, This Amazing Video Shows You What Real Happiness Is When A Coca-Cola Truck Arrives In Palestine - But You Won't Believe The Twist At The End. We shouldn't just take Upworthy's word for it though, because they're kind enough to link to a combined Google/TNS and Ogilvy study (uh-huh) which they summarise as (and if you have a Cayce Pollard reaction to dubiously formed statements regarding the way people like to connect with brands, then you might, as they say, want to look away now):

"There’s a real hunger in our society to connect with brands on a meaningful level, to see their advertising rooted in something purposeful and important."

If I were being mean, I'd just pick the first part of that sentence and aim a double-barrelled shotgun of "oh please" at it - I mean, when was the last time you experienced not just a mild inkling, but a real hunger to connect with a brand on a meaningful level. The answer to that rhetorical question is, for the most part, no, I don't feel really hungry about connecting with a brand on a meaningful level. Unless, maybe, I'm the kind of activist who likes disrupting Google developer conferences to protest gentrification of San Francisco. In which case, go ahead. But I wouldn't call queueing up around the block for the opening of an Apple store a connection on a meaningful level. Well, I might. And I might actually do that. But that's beside the point, right?

The second part is the important qualifier. I mean, if you're going to have advertising, you might as well have it be rooted in something purposeful and important. If the question was: hey, brands are going to advertise. Would you like regular advertising, or would you like advertising that's purposeful and important, I'm pretty sure most people would say: whatever makes me look better, so, uh, the second one, please. 

Perhaps the opposite tack is to see brands - not just their advertising - rooted in something purposeful and important. This is why it wasn't a bad idea for Toms to differentiate using their whole buy-one-give-one tactic (and something that they've followed through into other areas, like glasses, for example), but when you're given the choice between a brand that's trying to make the world better (through, say, instant coffee?) versus one that's just spunking money around the place (like, er, bad yet cheap instant coffee) then of course you'd like to choose the former. 

No, what's objectionable is the description and perpetuation of people - regular woman on the Clapham omnibus people - who have shit to do in their lives, as somehow vacant engines yearning for brand engagement. Perhaps the real issue is people wanting to connect - in any way, at all - in a meaningful way. And that we're noticing now that all this wanking around at the edges is just a bit of wankery around at the edges.

Oh, and it'd be great if you could still make a good anthem spot for the next Olympics, please.

[1] Look Ma, Upworthy Is An Actual Business Now
[2] When the Path to Purchase becomes the Path to Purpose

2.0 Will The Real Blue Ant...

One of my readers wrote to me in response to my Mundane Blue Ant piece back in Episode 120 that the evolution of Blue Ant and Bigend in the Sprawl trilogy is ultimately disappointing and depressing (actually, my reader was a bit more explicit than that) with the ultimate conclusion being that "in book four, they'll all be excited about operationalizing Kickstarter Potato Salad[2] in October, telling their clients about this crazy thing that's long burned up into the atmosphere."

Well, that's what advertising is. I'm sorry. Especially in this day and age. There's a lot of recycling of "I saw this thing" and repurposing it. It's happening faster and more transparently - just ask people like Chris O'Shea, whose Hand From Above "inspired" Forever 21's Times Sqaure billboard back in 2010[3].

The more exciting question, of course, is who, if it isn't Blue Ant, will pay us to prod our noses into the interesting and be among the first to know completely before anyone else, to recombine and generate new things out of that bleeding edge? And it's not just a technological bleeding edge, but more of an ideological bleeding edge. Are there people with job descriptions - ha, jobs! - whose remit is to be aware and to understand enough, to have that network that they can activate at a moment's notice (or, indeed are lucky enough to be part of someone *else's* network, to be activated at a moment's notice). 

Bigend is the orchestrator who has a plot-contrived reason - advertising and commerce - to want to know what's new so that it can be repurposed into moving SKUs, to increasing awareness, to prod herds in this direction or that. It's increasingly likely that Blue Ant finds himself disrupted by Facebook, Google, Twitter or any other number of Valley-based tech companies who will claim, ever increasingly, to be on the pulse of knowing what's new and being able to do a better job. Who's the self-facilitating media node - Bigend or Pollard? 

At least in the way that it's worked with my circle of friends and acquaintances, it's been a gradual mish-mashing of stuff, of reputations and introductions accreted over the past twenty years or so, of "you must be good at this, I'll introduce you to someone else who's good at that" and a pseudo soft-power, non-quantified whuffie but for the fact that if someone starts spinning up their blogging engine of choice and dusts off their CMS, redesigns their website and starts writing prolifically in an interesting way, you know they're doing a sort of pre-flight check sequence before they power up their engines and escape the gravity well of whatever organisation they're currently embedded in.

I tell a lie - I don't want to *be* Blue Ant, Warren Ellis, I want to be Bigend. I want the wherewithal and the budget and the network and the addressbook and the ability to form that crack team to solve that problem and then to disband, to melt away in the night but instead of having found a new way of pointing people toward the world's number two sneaker brand, to have built something new and erected it in the middle of the night. 

But then again, what we're seeing is that the connectors like Bigend are dealing with smaller pieces of infrastructure than what we're seeing now. The big impacts are still being seen by products that are tiny at their inception, but then worth a Whatsapp by the time they exit, about five years later. Bigend's skill was precisely directed attention, concentrated, z-machine style[4] to produce a fictional universe fusion explosion of brand engagement. Kony, you see, has Bigend written all over it.

There's another model where Bigend is a venture capitalist, a sort of Marc Andreessen perpetually circling the world in a G6 (apart from the fact that the bandwidth is terrible when you're airbone, a *critical* piece of lacking infrastructure for Shield's helicarriers unless they *also* have an orbiting laser-based Iridium network that can deliver the gigabits per second their airbone command centres require), picking out talent, finding the holes and then assembling teams. 

In fact, having thought of it a bit more, perhaps those are the mystery backers behind the Frequency. Larry and Sergey, alarmed at the state of world affairs, fund a secret division of Google, dedicated toward minute course-corrections whenever the world veers that little bit too toward a critical instability point. It would explain the phones, at any rate.

[1] Episode 120: Mundane Blue Ant
[2] Kickstarter Potato Salad
[3] TIMES SQUARE BILLBOARD TOUCHES OFF CONTROVERSY OVER ARTISTIC CREDIT-SHARING
[4] Z Pulsed Power Facility
3.0 A Category Error

A category error is the "one of these things is not like the other", and I think - if I'm right - that the Huffington Post just did an interesting (to me, at least) one in an article about how Netflix is catching up to HBO[1] in terms of becoming whatever a broadcaster or producer of television/film content is these days. See, this year's Emmy nominations came out, and Netflix got some, and HBO got some, and Netflix got way more than last year, as well as a higher proportion of its shows being Emmy nominated than HBO's shows being Emmy nominated.

Anyone who knows statistics knows that with two sets of data like this we can immediately infer a trend and we should see, over the next eighteen months or so, every single other broadcaster-producer pretty much capitulate in the face of such inescapable conclusions gained from big data.

Anyway.

The particular red flag raising sentence was this one: "What's perhaps most surprising is that Netflix is a website, not a traditional TV channel. Netflix has only been around for 17 years, while HBO has been around for 42."

This is the thing that the internet has done to some peoples' brains. They see the delivery mechanism and not the thing being delivered, insisting that the delivery mechanism is more important in a world when that delivery mechanism is just becoming part of the background noise, some sort of cosmic microwave wi-fi that's just infusing the rich, middle-class bits of the world. 

(There's a good article - I can't remember where, but it's probably one of Jean-Louis Gassé's Monday Notes about the network operating system and thin clients being predicated upon ubiquitous connectivity when obviously the one qualifier that's missing is ubiquitous cheap connectivity, because thin clients are all very well and good but if you're paying by the megabyte it doesn't matter that your wireless internet connection works in most places, it's just too expensive to use in a take-for-granted infrastructural sense). 

Because here's the thing: saying Netflix is a website is a bit like saying Google is a website compared to your library, or Amazon is a website compared to Best Buy or Target or WalMart, which are shops. Similarly, saying something is an "app" doesn't help you understand what it is that the thing *does* and means that you're likely to continue making the wrong kind of assumptions. 

Netflix's customers don't care that Netflix is a website. Netflix *is* now a broadcaster-producer, that just happens to use IP as transport for its content rather than analogue or latterly digitally encrypted cable signals. Argh. It's like saying "What's perhaps most surprising is that Uber is an app, not a traditional black car service." They're both black car services: but one has just applied technology to the delivery of the service that's valued by the end-user. 

[1] The Battle Between HBO And Netflix Just Got Real

--

Hello, all you Warren Ellis fans. I've been writing this stuff for a while now. I have an archive, but what you probably want to do is have a look at episode 100, which is pretty much the episode where we sit back and reminisce about other episodes and is hence a Clip Show. 

You should introduce yourself, because it's interesting when I know who I'm writing to, even though I repeatedly insist that I'm doing this for myself, and not for you (see, I'm doing it again), and you should also reply and tell me what you think, because even though I might not reply, I do read all of them, and even if I don't agree with you, you'll have reached out other TCP/IP packets, radio waves and pulsed light to change the state of my brain, irrevocably and forever. Which is pretty fucking awesome. 

Have a good weekend,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty One: Dark Value; The Latest Attempt; Five Eyes
Date: July 10, 2014 at 11:58:39 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gjz5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

3B to Salt Lake City, a tiny bitstream hanging off BLE to LTE connecting this laptop to the 'net while I scribble in yet another TEXTAREA. 

Watching: Captain America: The Winter Soldier for the nth time, thinking about that Marvel Cinematic Universe freemium mobile MMO that's sitting around in my head - in other words, imagine what Google's Ingress could've been with the right story...
1.0 Dark Value

I mentioned in yesterday's episode that I'd been reading an article in The Atlantic about The Invisible Economy[1]. As I can see it, the central thesis of the piece is an inability to value the increasing quality of life that technological progress gains us. Mainly because all of the stuff that we're getting in the virtual, internet-delivered or mediated economy, is paid for through attention or data, and not through the cold hard stuff that we know of as money, like in the physical world. 

The idea is that digital services are saving people money. The collapse of the newspaper industry means that "news" is now a substitutable good, with a free version now available - ie news.google.com, or any online news source without a paywall. Boom - you've just saved yourself the cost of a USA Today subscription. The distinction to me is that with the advent of free-to-access online news sources, an individual is "earning" more - when their take-home pay is the same and the GDP isn't necessarily affected. But, from the individual's point of view, money saved isn't necessarily money earned, and there's an argument to be made for the devaluing of the original service in the first place. Now that news is free to consume and access, that $275 per annum USA Today subscription is harder to justify. But in its place, of course, comes the $160 internet access fee. 

It all feels a bit house-of-cards. Supposedly, we are purchasing services worth billions (the way we're valuing them is in part due to their value to advertisers, which is where the house-of-cards comes in a bit) - but these are all new services that are, in some dark way, generating value and revenue if not moving bits of virtual paper around, that aren't necessarily reflected in income and GDP. 

Does this make us richer? The article talks about the average middle class family spending about $2,500 a year on entertainment and publications, but apparently, you could opt to "entertain yourself using free movies, YouTube videos, [use] streaming services like Pandora and [get news] from Google and save half that expenditure." If, of course, you believe that a summer blockbuster is substitutable by a YouTube video (sometimes it is, sometimes it isn't), and if you're OK with using other free services that may or may not carry what you want. Of course, the same argument holds true for pre-digital technologies, regardless of the convenience factor: you could always got to the library.

Towards the end of the article it feels like we get to the crux of the point. The virtual economy doesn't affect everyone equally. The lower your income, the greater a proportion of your take-home pay you expend on essentials, like housing, heating, transport, food and healthcare. Each and every one of those costs have been rising, whilst cream-on-top services have been eaten from within by advertising supported services. Zipcar may save money for the squeezed middle class, but it certainly doesn't do anything for those in poverty, especially when public transportation services are being gutted. 

The worry, of course, is that measurement of this dark or virtual economy will lead to over-indexing on it and paying too much attention to it (as if there isn't enough attention paid to it already). Look, I'm not an economist. But the types of goods and services that are now becoming free at the point of consumption (and, I'd argue, that aren't necessarily substitutable within their class - for example, when you really really want to read the new Charlie Stross, it doesn't matter that Project Gutenberg offers free classics) are ones that instinctively feel like the first to be cut anyway. 

Talk of technology improving productivity and quality of life feels like it made sense when you could get refrigerators and vacuum cleaners, but I suspect the real tipping point is when technology attacks (or is even able to attack) more bottom-of-the-pyramid needs. Cheaper energy, more affordable transport, better housing - these all feel like things that will drastically improve quality of life and should be measured rather than whether we all have access to free streaming music. 

[1] The Invisible Economy - The Atlantic



2.0 The Latest Attempt

A reader pointed me toward Yet Another Ad Agency - Mindshare, this time - launching a pseudo-product unit in an amusing press-release piece of an article over at AdAge[1]. A five person team - led by the agency's MD of mobile and staffed by two people in London and another two in New York is going to partner with MapMyFitness, the tech team brought in by Under Armour[2]. 

AdAge's article talks about the unit experimenting with "fitness trackers and sensors, smartwatches and augmented reality devices, like Google Glass" - at which point you start wondering, okay, what would a smart media agency do in that area? (First, though, you should understand Mindshare's role as a media agency - they buy media from properties and offering some sort of targeting capability. They then partner with the creative agencies, and if you're lucky, you get a good combination of smart media placement and creative that works to hook your audience's attention. In the old, pre-digital days, media agencies would be the ones you'd go to to work out where your tv ads should be, or where your outdoor billboards would be, or what newspapers you should be in). 

It's interesting because the fixation is upon the devices, and not the ecosystem that the devices are embedded in. It's not clear whether it's a slip-up by Mark Bergen, the journalist who produced the piece, or Mindshare's Chief Digital Officer, Norm Johnston, but this para:

"[Chief Digital Officer Norm Johnston] stressed the devices would require "more native content and storytelling" than traditional advertising. "They're quite intimate and the data shared is very sensitive," he said. "It's not about just slapping up ads.""

I'd submit that the devices require anything *but* native content and storytelling. At a push, the "augmented reality devices, like Google Glass" might, but native content in the advertising sense typically means something that looks like it fits in alongside whatever else is on the platform (ie: sponsored Buzzfeed articles, or that time The Atlantic went all Scientologist). 

I'm glad Norm Johnston understands that "it's not about just slapping up ads" - congratulations, Norm! You're exhibiting a sensitivity to the audience to which your product is going to be exposed! - but part of the deal is that no-one, *no-one* has figured out what the point of these devices are, never mind advertisers. I mean, good job for realising that the devices are intimate - perhaps that will help with understanding that the notification threshold for something tiny that you wear on your wrist is not that great.

This is less about native content or storytelling (brand storytelling on my wrist is totally something I've been looking forward to for the last five years, and I'm glad that we're finally getting the chance to experience engaging moments with brands on a wrist-basis in the imminent future) and more about what utility these devices actually offer. 

The impulse here seems to have been something along the lines of "more things have screens now! How can we show our clients that we have a wearable strategy!", the corollary being that if something can display *anything*, then someone's going to want to put advertising on it, whether it's a good idea or even going to be effective. 

Which is why as much of this is about the ecosystem around the devices (if you want to be successful, right?) - which is to say what sort of messaging makes sense in the experiences and usage patterns *enabled* by the devices, rather than on-device themselves. Are there opportunities for tactical messaging inside MapMyFitness? Probably. Are there opportunities for a company like Mindshare to utilise activity data to enable better targeting, and what are the opportunities for consumers to opt-out of that data? And: just when did you want ads on your smartwatch in the first place? Sorry, I mean: what's native content for a smartwatch? (Clue: that previous sentence contains two phrases that should be taken out and summarily shot).

[1] Mindshare to Launch Wearable Tech Unit
[2] Under Armour to Acquire MapMyFitness, One of the World’s Largest Open Fitness Tracking Platforms

3.0 Five Eyes

See: the Five Eyes. 
3.1 Eye One 
So it turns out that, in America at least, persistent airborne surveillance is something that still squicks people out[1]. In Britain, at least, there's a qualitative difference between ubiquitous ground-based surveillance and, well, ubiquitous airborne surveillance. I wonder if it's a predator/prey thing: being watched from above by a small thing that's circling over you versus eyes on sticks. I also wonder if there's some sort of atavistic difference between being watched by a multitude of eyes on poles versus on ever-circling eye.

[1] The airborne panopticon: How plane-mounted cameras watch entire cities 

3.2 Eye Two
This is the part of today's episode that makes me feel more like NTK[1] than anything I've ever written before.

So there's a really important thing going on. The main three political parties have agreed, amongst themselves, to support an amendment to existing legislation that will force telecommunications providers (internet service providers and phone networks) to carry out blanket retention of phone calls, texts, and internet browsing history. 

The UK government has graciously published explanatory notes[1] - it's worth taking a look through them, but ultimately, this is the deal: legislation made in haste is frequently bad legislation. Legislation that hasn't been accorded proper parliamentary scrutiny is bad legislation. Legislation that hasn't provided for consultation and comment from interested parties and civil discussion is frequently bad legislation. 

If you're a voting British Citizen, then please let your MP know how you feel[2], because we don't have much time. 

[1] DRAFT DATA RETENTION AND INVESTIGATORY POWERS BILL - Explanatory Notes 

[2] Open Rights Group Campaign - Stop The Data Retention Stitch Up

3.3 Eye Three

Here's a free idea to use the ~1 megapixel eye embedded in most desktops and laptops these days for something somewhat more ambient and less creepy than the whims of a school district administration[1] or just chatting to your mates on whatever passes for ChatRoulette these days. 

If we're to believe Linda Stone, when we're stressed out and sitting at our desks and anxious - say, when we've got a particularly vexing email open in Outlook or GMail, it's pretty common for us to hold our breath. Stone coined this back in 2007[2], and I remember her talking about it at Foo Camp and getting super excited - it occurred to me back then that you'd try and include some kind of blood pulse oximeter to measure the change in breathing rate through a contact surface (say a touchpad or a mouse whilst your skin was resting on it) and produce some sort of gentle reminder or ambient awareness that you were holding your breath. In a way, you don't even need the technology - you just need to inculcate a sort of habit to check whether you're breathing or not. 

(In fact, you're reading email right now. So try and pay attention to how you're breathing whilst you're reading this and the next few emails in your inbox).

Of course, we don't need that now. We have Eulerian Video Magnification[3], which was one of those papers from SIGGRAPH 2012 that felt like yet another piece of future software falling through the time hole of the SIGGRAPH YouTube video trailer - a way of processing live video input using the frankly astonishing processing power we have *literally* lying around to determine things like pulse and, you guessed it, breathing rate, just by using an off-the-shelf webcam. 

So there you have it: a webcam that watches you breathe, and reminds you to, as it were, take a stress pill. Or at least get up and walk. Bonus: MIT obviously open-sourced the algorithm, so first one to the Mac App Store wins a few of my dollars and the gratitude that you had the wherewithal and attention span to actually build the thing. Go on, you can probably do it in Swift, too. 

(There's an aside here which is we seem to be building an ever-increasing technology stack to solve problems that, maybe - just maybe - don't need technology to solve them. I mean, it would probably help if you stood up, instead of sat down. Or if you were in an environment that was a little bit less stressful. In other words, this feels like yet another example of technology allowing us a shiny bauble to attack a problem sideways, nibbling at it, rather than effecting real change at the root cause. But hey, that's humans, I guess.)

[1] School District Pays $610,000 to Settle Webcam Spying Lawsuits  
[2] Diagnosis: Email Apnea
[3] Eulerian Video Magnification

3.4 Eye Four
My son went through a phase of shrieking (with joy, I hasten to add) as he learned to walk, exploring the corridors and rooms of our houses with hands and arms held up to balance himself, yelping with surprise as he would amble around. I would congratulate him on attempting to use echolocation but that he didn't need to - his eye exam had come back with flying colours (we'll see how long that lasts) and whilst Batman was indeed pretty cool, his parents were still very much alive and he didn't need any further Bat affectations. 

There's been talking of different ways of seeing - different ways of experiencing the world. Seeing like a satellite, seeing like a GoPro, seeing Through Glass, as it were. There's an issue in ownership of eyes - in whether we have communal eyes, for example. Dave Eggers' The Circle[1] rests in part upon the protagonist valley company developing super-cheap lollipop Dropcams[2] that stream HD quality video without care for wireless data rates. 

So parallel to this, I'm interested in how a street sees. How the twitchy window obsessiveness of small neighbourhood watch communities deals with ubiquitous, cheap surveillance. You can imagine seeing a community where instead of paying for extra police patrols, some enterprising soul says "well, we could all chip in and buy a dropcam each for our property and blanket the area in motion-tracked video surveillance..." and make it available to everyone in the neighbourhood. A sort of opt-in panopticon. 

These are eyes that don't know what they're seeing, that see movement in pre-defined areas, where video is pushed upstream, recorded, imaged, contrast-enhanced, edge-detected, movement tracked, and then notifications auto-pushed to wherever. But these could be eyes that we choose to put in places ourselves, not infrastructure that is placed in areas for us. 

[1] The Circle, by Dave Eggers
[2] Dropcam, now a Nest subsidiary
3.5 Eye Five
So I'm still reading Pattern Recognition and there are things that are sticking out at me with the benefit of ten years of hindsight. Gibson undoubtedly wrote a book in the now, and the 2003 now that it was routed in was a post 9/11 era that knew catastrophic, abrupt change, but a sort of pre-psuedo-ubiquitous internet era of less-than cambrian explosion of Valley-based software consumption of the economic patterns of the world. That 2003 knew that the future was volatile, that the only thing they could rely on change and as the way Bigend puts it, the only thing to do about a constant threat of change is risk mitigation. In Bigend's world of 2003, he's afraid of the future and won't face it. His clients are facing inevitable decline, and what he's doing is trying to smoothen out the ride.

Compare that to the boutique/internationally powerful advertising agencies of today, who are desperately trying to remake themselves and are jealous of the power of the Valley to *remake* the world. Google [x], Facebook and Oculus Rift aren't risk mitigation strategies. They are attempting to do for capitalism and the economy (such as it is) a sort of bootstrapping for the future, not quite the terraforming for capitalism that's happening in developing countries where the internet is literally being dropshipped in from high altitude.

But this wasn't about that. This was about seeing.

We don't have eyes into the right kind of future, I think. I'm spending a lot of time thinking about smartness and what that means, and what a viable smartness might mean in terms of the networked devices that we build around ourselves. The existing models that we have seem predicated upon some sort of weird 50s boomer home automation - they're missing Robbie the Robot, but all this business of "wouldn't it be awesome if the lights automatically came on when you got home and the TV turned to the right channel" and so on strike me as not even mundane in the sense of fantastic technology that we've become accustomed to and no longer provokes sensawunda in us, but mundane in the sense of lacking imagination as to how things could truly be different. 

There's a fog in seeing - a sort of inability to think about what will happen in the short-to-medium term. I think Charlie Stross has written about this before - he's certainly exhibited a tendency to not be able to cope with the fact that, if a singularity is going to happen, things are going to be *too* different in the medium future, and just weird in the near future. 

I put this down to a failure of fiction, in a way. The type of home automation and smartness that we're talking about is something that we've seen since the late 80s with, you've guessed it, Star Trek: The Next Generations. "Computer, lights" and "Earl Grey, Hot" voice commands are within our reach but oh-so-boring. 

I want to see something else, something surprising, something funny. My son's first attempt at humour was when he stopped nodding along to the song Baa Baa Black Sheep and instead shook his head - the sort of unanticipated surprise (No! No wool!) that jolts you out of familiarity. Lights coming on, music playing, heating done just right - that's not *smart*. In a way I admit to shifting the goalposts, but that's only because I feel like we've seen this type of smartness for so long.

In fact, comedy and satire - the stylings of Red Dwarf's Talkie Toaster, Douglas Adams' sighing doors and Richard Morgan's AI-run hotels that keen desperately for guests in an almost homicidal way are the old examples, the ways in which we see slightly broken versions of the future where the edges are sharp and not roundrects, where things work, but not quite, in ways unanticipated. 

I think part of it is seeing, in a way, what would make a smart home not necessarily smart, but a *home*. What's smart technology with a patina, a pattern of usage and wear, that feels comfortable as opposed to purely utilitarian. Smartness right now is a lightbulb whose colour you can change without having to get up - if your phone is charged and on. 

Again, this is a kind of seeing where Laura Ashley or Target makes smart home, almost throwaway pieces - where the emphasis isn't on the "smart home" side, but instead the "stuff you want to live with". Again, it feels like the use case that's going to make this stuff go mass market isn't necessarily the remote control, long-pointing-finger aspect, but a lower need. What are smart home objects, for example, that make you *feel* safe?

--

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twenty: Mundane Blue Ant; Press Square To Hack
Date: July 10, 2014 at 1:07:51 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gj9t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Undisclosed location.
Reading: Pattern Recognition, again.  
Last time I read Pattern Recognition was when it came out, and I was in the throes of ARGs, having been on the player community side through The Beast, and then actually making one, with Perplex City. Now, ten years later, I've been through the other mirror world: the branding and advertising side.
Thinking about: the physiognomy of a startup and dark value that ostensibly makes us richer. 
1.0 Mundane Blue Ant
Or, what's threatening to be: Pattern Recognising (1)
The other day, Warren Ellis said that he wanted to *be* Blue Ant[1] - that is, have the ability and wherewithal to know things before other people. A voracious consumer of the new-noosphere, to understand completely new concepts and their implications before they seep out into the rest of the world. When I joined Wieden, there was part of that aspect of discovering new bits of culture and bringing them to the rest of the world - indeed, it even at times felt like there was a bit of a guilt complex in the way that the agency and Nike had kind of strip-mined black culture, re-appropriated it to sell shoes and done massively well out of it - in the sense that the agency (and Nike) were overwhelmingly white and profiting off the adaptation of others' culture. 
Nowadays this is all done under the remit of diversity: that to sell accurately and effectively to the widest possible market, that means realising that there are other people out there than middle-class white people. Of course this is easier said than done, and the notion of diversity was at times a bit weird (ie it feeling like recruiting the "right" kind of diverse people was a priority, where right might mean black male as opposed to white female, never mind any other combination). 
But anyway, I digress. Pattern Recognition is just over a decade old now, and the world of advertising has changed. It's clear that Bigend knows that this is about to happen - he makes reference to it quite early on in the book that he senses the industry narrowing and that the fakers are going to get called out (well, maybe it hasn't *completely* happened yet) but perhaps the biggest way in which Blue Ant might have changed in the intervening decade would be in its relationship with its clients. After all, if no-one's buying, then no one gets to be paid by Blue Ant to do all the stuff they want to do. 
So this isn't a surprise: these days, Blue Ant looks like collaboration with Slack (of, if you're being obnoxious, a "bespoke collaboration app built by a world-famous iOS developer recruited away from Apple"), an address book full of email addresses that people actually answer, public and private Twitter accounts, a private Stack Exchange, Dropbox business accounts, a bunch of Silent Circle BlackPhones, on-demand, just-in-time ground transport through Uber and, depending on your need for point-to-point hundred-mile plus transport either fractional jet ownership or Diamond frequent flyer status and someone else's expense account. 
Mundane Blue Ant still has to sell, and selling in the world of Blue Ant means producing decks and giving meatspace presentations. Selling in the world of Blue Ant means someone still has to grapple with font servers, buying typefaces or commissioning them, and fucking Adobe Creative Cloud. And then, of course, there are all the mundane Blue Antlings, the ancillary services that take the sold Blue Ant strategy and then communicate it out through the host corporate organism, across silos, organisations, territories and so on. "Hi, I'm Steve from Blue Ant, and I'll be socialising the 2015/SP-SU strategy at this workshop over the next couple of days" is something that's the price of existence these days. 
But then Blue Ant's skill wasn't just the sexiness of spotting proto-trends and being able to repurpose them in the right way. It was finding the right person in the right place for the right job and then spinning up all this dormant infrastructure around them - at the right time, at the right place - so that it all came together like clockwork. 
But then, how much infrastructure did we ever get to see? We saw things like routes for new logos for shoe companies on thick card stock in envelopes (I've been there, it's still done) as opposed to projected on 4K TVs.
I mean, when it comes down to it, Blue Ant comes in and does a presentation and Mundane Blue Ant Tech Support comes in because the Crestron isn't talking to the boardroom display again and there's an embedded video in this PowerPoint (Mundane Blue Ant uses PowerPoint, right?) and did anyone remember to bring a dongle? You imagine Bigend sitting there, sighing, head-in-face, Picard-style, because, fuck's sake, he's *Bigend*, founder of Blue Ant, and this idiot doesn't have the right dongle for their laptop. (The counter-argument is that if you're the kind of person who doesn't have the right dongle for their laptop, then you don't get to consult for Blue Ant). 	
Mundane Blue Ant just has a regular build-to-order monthly dropship of Blue Ant Macbook Airs and Retina Pros, and when you start with them, Global Frequency style, they just get dropshipped to you, FedEx/Uber-style. Perhaps this is the thing: Blue Ant's need to understand the next as completely as possible is a thing for *commerce* - it's as if Bigend would somehow find himself sitting in on a session at an O'Reilly Foo Camp, taking notes from session presenters and then jetting back out to persuade Stodgy Old Multinational that Next Big Thing was coming. 
So we've got Blue Ant as the cultural systems integrator - the pick a part here, pick a part there, but Blue Ant as a distinctly early 00s phenomenon. The idea of more creativity going into the marketing of products rather than the creation of products themselves is interesting, but feels increasingly out of touch, these days. Well, I suppose it's more complicated than that - for undifferentiated product, sure, creativity in advertising is its hope at grabbing attention and conversion into the sales dollar, but at the same time it feels like we're seeing more (ish) investment into the craft of product in the first place. 
There's a bit that feels missing here, though. One wonders a little bit about Bigend's role in all of this. Someone interested in marketing, advertising and media strategy. He gets to understand all this stuff, and impart that understanding to his clients - but ultimately, someone has to *do* something about it. To me, that's the excitement of the new: the undiscovered frontier that's just rezzing into existence just behind that boundary. Blue Ant's infrastructure and funding is a way for you to turn on NOCLIP for the world, to see what's going to pop up once you remove the occluding polygons. It's Keanu Reeves working out how to read the z-buffer in the rendering engine of the Matrix and seeing *through* to the next. 
But then what do you do with it? You take something like the footage, and you launch next year's Kobe basketball shoes with them? Bigend's got to feel pretty inept at that - sure, he's moving the needle on commerce and helping shift SKUs, but how much of an effect is he having?
No, there's a parallel universe here. 10 years later, Bigend is disillusioned with what he's able to achieve in marketing and advertising, and wants to remake the world. That's the Bigend I want to see now. What's appealing, in contrast to something like Google [x] is that Blue Ant is out there discovering the edges, peeling back the fog of war. What's ultimately leading to career burnout for the Blue Antlings is that they rarely get to *do* anything with it, whereas Google [x] is all focussed on the big, already-identified moonshots. So you can see the appeal for someone like Ellis who came up with a concept like the Frequency: but instead of dealing with the existential threats, you're discovering them. Bigend bends and perverts them to increase revenue for his clients, or make sure that they stave off their death or demise by two or three years. But what would it be like to have an open remit to discover the new, to completely understand it, and then mould it.  
[1] Blue Ants
2.0 Press Square To Hack
My current gaming diversion has been Ubisoft's Watch Dogs[1] and every. Single. Time. I play it, I've been reminded of the post about quality being fractal[2]. Not that I necessarily buy the quality-is-fractal argument, more that if you're the kind of person who's going to obsess about quality, and I mean *really* obsess, then you're going to obsess in a way that's going to make recursion look at you like a proud parent.  
So what irks about Watch Dogs is that there are certainly good bits, but as ever - and I understand the realities of production constraints and shipping and resource and just getting the damn thing out of the door - whilst the game is fine to play, there are bits of the story that are just... not good. 
And I mean, not, *not* good, just - they don't stack up. Spoilers follow.
No, really. Spoilers follow.
.
.
.
.
I mean, you have a protagonist who starts out with questionable ethics basically portscanning everyone in a swanky hotel looking for secrets and grabbing money by, well, pressing square to hack. He grabs the wrong thing, and just like a good plot where one thing happens and the next few hours are just slow implosion, a series of Bad Events Occur where his niece gets killed in collateral damage on the hit ordered to take him out. 
And yet - and this was the weird part for me - here's me, playing a sort of social justice warrior with a bunch of zero-days, rootkits and a backdoor into NSA CODENAMES and the commercial surveillance industry complex, and I'm fucking over all these completely normal innocent people to get funds in the game (you just press square to hack pretty much anyone you come across in the street and their funds are magically transferred to you) and honestly, the bodycount by the end of the game is pretty much ludicrous. 
Part of the cognitive dissonance is that you're wandering around, driving badly (as I am) avenging the death of your niece and you're doing a Nathan Drake of racking up an impressive number of both intentional, enemy kills as well as civilian kills - at least, if you're as bad a driver as I am. But it's not just that, it's also that the plot is hamfisted, the cybering at times borders upon Anthony E Zulker CSI-levels of dumbness despite occasional breakthroughs of insight. There's lots of hacking and viruses and "they're in the system!" and "we've found a backdoor!" that makes it all a bit haxploitation, and whilst I understand the need to make hacking "easy" to make the game actually, you know, playable, I swear to god if hacking continues to just be a series of pipemania-like minigames, I will, oh, go and play Uplink[3] or something. 
[1] Watch Dogs - Wikipedia
[2] Quality is Fractal
[3] Uplink 
--
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Nineteen: Bridj Laziness; Deciding In Public; Terrible Tools
Date: July 9, 2014 at 12:35:58 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gihd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident




Leaving drinks with ex-colleagues this evening, fitting toddler-escape-prevention bars to windows this afternoon.

Where: fries and a Diet Coke at Tilt, melting in the sun. 

1.0 Bridj Laziness

Outrage of the day came late, courtesy of Bridj[1], a startup based in Boston, Massachusetts, that promises "[b]etter transit. For everyone." which is strike one against it in terms of a) not delivering better transit, and b) certainly not for "everyone", not least of which because a) it's more expensive than conventional mass transit, so its market reach is smaller, and b) [all?] Bridj passengers must be 18 years or older[2], which is a curious definition of "everyone". Of course, most mass transit systems realise that they provide a service of immeasurable value to those who, say, can't drive, and that those without transport options are sometimes the most disenfranchised. But whatever, that doesn't matter so much because the luxury shuttles are awesome and Bridj is using data.

From my point of view, this is pure laziness and overreach. There's certainly *something* interesting in Bridj (if not, say, mildly offensive to someone with European transport sensibilities, but I guess that's how you get things done in America), in that they've clearly observed the Tech Bus explosion with a keen eye and are wondering if it's possible to disrupt, in any way.

Of course, this ignores the other type of disruptive transport that has happened for years in American cities, deftly brought to life in the New Yorker's recent report, New York's Shadow Transit[3]. Perhaps that's what Bridj means when they say that America has been "[leading] the way in innovating and changing the way cities travel and move." 

When I posted about Bridj rather passively-aggresively on Twitter, Simon Batistoni remarked that there was a special place in hell for that American sensibility of wanting to treat each and every single moment as more opportunity for productive, value-creating work[4]. 

Bridj itself comes with the usual trigger-warnings for those overly-sensitised to the world of startups: it deploys "millions" of data points, machine learning and big data. All of these, combined with driverless vehicle technology (remember, you don't need to tip your driver - it's all handled) add up to a zeitgeisty pitch, one that looks like it's solving a big problem, but when you examine it under only the slightest of pressure, it all falls apart. 

Of course, this could all just be a property of their communication. But how you talk about what you're going to do - how you communicate your intentions - is incredibly important. Bridj talks about being for everyone, but the uses cases it talks about are for point-to-point transport of a regular nature: your commute and in terms of getting you to work. It's as if Bridj has been designed, cargo-cult like, to approximate a mass-transit system, by people who've never, well, experienced a *good* mass transit system. Mass transit systems aren't just for people getting to work. They're for *transit*. They're for getting from place to place. It sounds facetious, but Bridj, because it's communicated and designed as an awesome luxury shuttle service to get you to work, but for less than a town car, but slightly more than a metro ride, doesn't work when your car needs a repair and you need to get to the doctor. It doesn't work when you need to get anywhere else. And there's no indication that the people behind Bridj intend to solve that problem.

All of this is yet another example of the "precedent as burden" kind of thinking - perhaps not as explicit in this case, but more of the "hey, we haven't looked at all of the other urban transit systems and what makes them work and why they exist the way they do, but big data and machine learning algorithms!"

The flipside of this is, of course, seen in Europe where you get transport policy like this[5] from Finland. In the model proposed for Helsinki, transport truly is integrated and service is aggregated across multiple providers - both public and private, whilst competition is at the same time built in - citizens / consumers vote with their feet and their currency as they shift funds from provider to provider in a more efficient matching of supply to demand, and a sort-of mythical transparency might allow for more seamless transport "experiences". 

And yet, only a couple of days ago, the United Kingdom's National Health Service celebrated its sixty-sixth birthday, and a certain image introducing the service did the rounds on the usual social media services. Here's how the NHS was introduced:

"The New National Health Service

Your new National Health Service begins on 5th July. What is it? How do you get it?

It will provide you with all medical, dental, and nursing care. Everyone--rich or poor, man, woman or child--can use it or any part of it. There are no charges, except for a few special items. There are no insurance qualifications. But it is not a "charity". You are all paying for it, mainly as taxpayers, and it will relieve your money worries in time of illness."

As a Brit, it's easy to get tied up in nostalgia for the ideals of the NHS as opposed to the blunt reality with which you might be exposed on the front line of receiving - or dispensing - service. But there's something for the plain-spokenness of the language used in the leaflet and the communication of intent. 

In other words, if you mean "everyone", Bridj, you should actually deliver to "everyone".

[1] Bridj
[2] Bridj FAQ
[3] New York's Shadow Transit, The New Yorker
[4] https://twitter.com/hitherto/status/486634513217228800
[5] The future resident of Helsinki will not own a car

2.0 Deciding in public

Hey kids, here's some free advice: you never feel like an adult, and you might never feel like you know what you want to do. I'm (*counts*) 35 this year, and damned if I've been able to figure out what I want to do. As much of this is about figuring out what it means to live up to others' expectations, and what it means to live up to your own expectations. I've had a stupendously potted history: from a unique combination of arts/sciences A-Levels during my sixth form when my school had to jiggle things around timetable-wise for me, to spending three years studying law which was fine I guess but ultimately not what I wanted to do, even after I then spent another three years training for (and getting offered) a job in the field. 

So the (first world, self-actualisation, lots of talking with therapist kind of) problem that I'm dealing with right now, that I alluded to last episode is more of the somewhat-diversity of choice sort, where there are in principle a bunch of avenues open in principle to me, and all I have to do is *decide*. 

Because hey, deciding's always really easy, right? 

But all of this process required a checking in with myself: there are lots of things out there that are *interesting*, and an excitable brain can always run off with them and chain together a whole bunch of cascading outputs just from a few inputs. That doesn't mean that they're intrinsically interesting, just that the concepts fire off certain pattern matchers and then before you know it, you have a whole bunch of second-order firing off unrequested in your brain. But they might not have fired off on their own.  

So that's the thing, the malaise of figuring out "what you want to do" when it feels like there are so many things that you *could* be interested in, but trying to figure out what it is that you *want* to be interested in. 

3.0 Terrible Tools
I think this is a short bit, but the UK's Government Digital Service has written Yet Another blog post, this time about building a service for booking prison visits[1]. One of the things that I'm struck by - after having leaving drinks with a bunch of my former colleagues - is the sense of a relentless focus on solving the problem. Solving the problem in the case of the prison booking system looks like - from the outside - not an intractable problem, but more a deficit of hard work and the time taken to actually do the hard work. 

And also: actually solving the problem, rather than using communications to solve the problem. To me, this has been one of the most frustrating parts of the agency experience. It might seem incredibly obvious, but let's say that there's two types of non-advertising people who end up at agencies: the type that want to make advertising (of which I've met, and some of them have turned out to be pretty good at it), and the type that want to creatively-solve-problems. Bluntly, (advertising) agencies aren't in the business of creatively solving problems, they're in the business of using communications to solve business problems. There's a difference - one's a subset of the other, for starters, but the point remains that you don't ask a communications/marketing/advertising agency to solve the root problem. You've already decided to solve it with communications. 

This is why it's interesting and weird to see things like the Fuelband which are undoubtedly *manifestations* of a brand, but are not advertising in and of themselves. They're not communications. And this is where the trouble with "digital" comes, because it turns out there's lots of ways to both skin and cat, and solve a problem. 

To bring this back to the job of the UK's GDS, what's encouraging about them is that they're not doing an agency job, and they're not necessarily even doing just a service design job. They're in the solving-problems business, and digital is a way to solve those problems. They're not just talking about solving them - they're solving them. And that's what makes their work refreshing.

In some senses, it's also what makes their work boring from a whizz-bang point of view. It is as much a management problem and an attitude problem as it is a design problem: but what they're doing is making sure that they have enough contact hours to make sure that the problem is solved *in the best way possible*. The output of this is hardly going to win creative awards for grabbing attention. But it's valuable, useful, and impactful work, because - and it helps because they're doing it in a public service context - these things that they're building, the processes that they are manifesting, *help people get things done*. 

It makes me think about the problem with enterprise software: it's hard to see how an outside vendor could, for example, countenance spending as much time (because that equals money) getting to know stakeholders in whichever guise, and making something quite so boring as a prison visit booker. What ends up being built is bespoke, because it solves a problem at scale, but in the right way, for the people who're using it - and they know it does that, because it's been tested. And because GDS is internal, as it were, there is no "purchasing decision" or decision-making person who decides whether or not this is the right thing to buy, or does it check off enough features from what they've been reading in this month's issue of White Middle Aged Dude On The Cover of CIO Monthly. 

In other words, GDS is building a cult around the user as the customer. The user is the person who pays, in sweat and time, every time they use the software, every time they attempt to accomplish that goal - which is their *job*.  

[1] Making prison visits easier to book  

--

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eighteen: The Material (5) - What It Wants; Transmedia Is Dead!
Date: July 7, 2014 at 2:23:04 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ghkl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident




Robin Sloan would be proud - this is the first time I've written one of these from inside a library. The wi-fi is good and I'm only slightly killing myself by sitting down instead of building a standing desk. There's more NOSTROMO BLACK this week as well as whole bunch of other stuff going on post-hey-I-don't-have-a-job, but the upshot of it all is that I'm spending more time with my son and working out what I *want* to do rather than what I *can* do. 

The latter has been an interesting distinction that I only just recently noticed. I like to take things and then turn them over and see what I can do with them, to see the possibilities in them. So I can go have meetings with people, see an opportunity and say, hm: I could do *this* with that. There are all the things - this is the possibility space and here are the interesting peaks and troughs and valleys and look, we could go over there and see what's on top of, or behind that hill. But that's just mapping out the space. There's no intentionality there, that's just, I don't know, possibility cartography. Exploring. There's no I *want* to do that. And it feels like for a while I was confusing what I wanted with what I could do: that the mere possibility was interesting, and exploring the possibility in and of itself was interesting. 

In other words: the difference between what some work could enable me do, and whether the work enabled me to do what I *wanted* to do. Those two sets don't necessarily coincide. 

Listening to: an iTunes playlist called "It's Time For A Montage". 

1.0 The Material (5) - What It Wants

This is me, not writing (directly, at least) about Go Pro cameras and Google Glass. This is me writing about the new material that things are made of, and what they want. I have a dirty secret to admit - I never got through Kevin Kelly's What Technology Wants[1, 2] in full, but part of what's vaguely offensive about his thesis is that by removing human agency from technology and suggesting some sort of higher-order driving force (the Technium) that just means that technology, like evolution, is some sort of organizing principle. To which: poppycock (which is just a fun word I don't get to use that often.)

Look, let's just agree that technology is instantiated through artifacts and those artifacts are created by someone or something that reflect their values. There might be values inherent *to* technology, but I'd argue that (for the moment, at any rate), they're far overwhelmed by the specific purpose that the technological artifact's inventor or creator imbues into the artifact itself. Or, rather, borrowing Catmull's recent words: ideas don't just exist in the ether. They are plucked and massaged, given shape, form and reason to be and then they need to compete for users and attention. 

So when we think about what technology wants, it makes sense to think of the agency involved. *Who* is the technology for? Sure, there's a spectrum, but again there's a difference between something *for me* and something *for something else*. And there's also a difference in terms of *how* a thing works. I had some friends talking about Go Pro cameras and Google Glass and whilst I don't want to step on their toes while they're thinking away, the thing that I do want to recognise is the difference between the former and the latter in terms of smarts and the purpose of an object. 

There's a clearness in terms of single-use dumb objects in that they're, well, dumb. You don't need to worry about them doing anything behind your back. You don't need to worry about their terms of service necessarily changing, because their substrate is under your physical control. They're not network connected and, yes, you have to do a lot more work. But one suspects a sort of Battlestar Galactica (2004 reboot) folk feeling not that networked technology gave rise to AI that turned against us and wanted to kill us all, but that you just didn't *know* what was going on with all of that networked technology. In other words, it all comes down to trust again. There's a functioning set which feels a bit like me-and-device, versus me-and-device-and-cloud. The latter is intentionally abstracted away - someone noted on Twitter the other day that "the algorithm" is becoming an excuse, not just a description, exactly the "computer says no" removal of agency that is a sort of jobsworth shrug. The "well, the algorithm says it, so it must be true" folk story of people blindly following GPS directions because hey, it turns out that we quite like following directions because living and making decisions is all so complicated and it would be all better if we could just let someone - or something - else make them for a bit. 

So the issue of smart devices in interpersonal relationships is rather like the situation Princess Diana found herself in with Prince Charles and Camilla Parker-Bowles: "Well, there were three of us in this marriage, so it was a bit crowded"[3]. Parker-Bowles had her own agency and her own motivations and the three-body problem[4] is a hard one to solve with humans, never mind multinational corporations that make videos explaining how something you can't see works, like email. How do you discern intention with a corporate body? How do you discern that intention when it's been instantiated into a physical+software device, embedded in an ecosystem, wrapped in tens or even hundreds of pages of terms of service that no-one has read, apart from the lawyers and maybe the product managers responsible for it? And those terms of service that govern - in the loosest possible way, of course, what that physical+software ecosystem device is supposed to do are held up with the legal equivalent of holding your fingers crossed behind your back, so you can change your mind at any time. 

In a reasonable world, what rules of thumb are you supposed to use to assess whether or not you *trust* such a device or ecosystem? Certainly you no longer get the choice because the devices are in the world and acting, consuming, digitising - if not on your behalf, then upon someone else's. 

I think this is why dumb things feel more trustable, the lines more clearly drawn, the network tendrils retracted or even intentionally hobbled. You won't understand this, the stumpy connections seem to say, so we're not going to extend them. We don't trust ourselves, either. We haven't shown ourselves to be trusted. So this thing is dumb, and the only way the information on it can get from *here* to *there* is the equivalent of the scene in the military thriller where two uniformed officers remove keys from chains around their necks, unlock a lockbox, pull out two pieces of one-time code encased in snap-open plastic, enter the codes, get *new* keys, flip up lock protectors, insert locks and, on my mark, turn those keys and hey - you've uploaded your video to YouTube and set it free. And then the algorithms go to town, devouring it, mining it for meaning, cross-referencing, feasting upon it and producing connections and inferences and pre-roll ads. But at least you didn't upload it by *mistake*. 

[1] Review: What Technology Wants by Kevin Kelly (2010)
[2] What Technology Wants, by Kevin Kelly
[3] BBC1 Panorama interview with the Princess of Wales, broadcast in November 1995 
[4] Three-Body Problem 

2.0 Transmedia Is Dead!

So TechStars and Disney have been running an accelerator[1] to "turn today's technology innovator's  dreams for new media and entertainment experiences into reality." I have no-one to blame but myself for looking at the list of announced participants, not least of which because Dylan Boyd, MD of TechStars kindly pointed me in the direction of the application process (and, I think, it has also featured in this newsletter before). 

It's striking, from my point of view, the *kinds* of companies that have been accepted into the accelerator. On the one hand, there's the "business business business, numbers!" side of things:

 - Buzzstarter is "the world's first scalable programmatic content marketing platform", 
 - Sidelines "fixes the problem of substandard online discussions and comments by sourcing smart, high-quality discussions from its curated team of over 400 experts, and distributing these discussions to publishers based on relevance",
 - Jogg "simplifies the act of acquiring video from anyone. Users can gather, edit and share much more than just video from their own device"),
 - Cogo "provides video monetization solutions for content creators"

On the second hand, there's the physical toy type things:

 - Sphero, a "connected play company, which fuses digital and physical play by creating robots that you control with a smart device"
 - Snowshoe "makes simple, magical pieces of plastic that interact with touch screens to create the perfect bridge between physical items and digital content"
 - Ubooly is "a learning toy that talks and listens to kids. Ubooly can be customized to know your child's name, teach lessons, and much more"

Then there's the "useful things/teaching things":

 - ChoreMonster, "a web and mobile platform that makes chores fun for kids and turns parents into superheroes",
 - Codarica "serves as children’s first interaction into the world of code with help from characters Cody Coder and Holly Hacker",
 - Twigtale, which "provides parents with personalized, high-quality, accessible expert advice for every major transition a child undergoes."

and, uh, apps:

- TYFFON "is an entertainment app development company and creator of the ZombieBooth series with more than 25 million total downloads."

Those who've known me for a while we know that I have a soft spot for story and play. So it's a bit weird to see such technology-based companies in the program. It may well be because I'm overly cynical, but most of these seem to in some cases be, well, business bits that don't necessarily need to be aligned with Disney (ie each of the companies I listed in the "business business business, numbers" section would equally be at home at Yahoo!. I would be far more interested, for example, in less product-driven companies and ones that allow for greater creativity or faster prototyping/feedback loops. Whilst Choremonster and Codarica could easily benefit from the use of Disney IP, Choremonster is, from my new-obssessed brain, an Old Thing (remember Chore Wars?[2]) whose time might finally have come with mobile devices and wireless networking, plus kid-friendly interfaces. But I would love to see something like an interactive fiction outfit like Playfic[3], by the almost stupendously productive Andy Baio, that let you play in a Disney sandbox of characters. 

Perhaps that's what disappoints me about what's currently visible with all of these selected startups: they don't feel magical. They don't necessarily feel like they hearken back to a Disney time of old. Now, that might easily be because the whole point of a Disney partnership is to get access to a kind of Brain Trust at Pixar or Disney Animation. But if there's anything that Catmull's taught us, it's that you need to build your own Brain Trust.  

Perhaps Ubooly and Sphero, "smart" toys could do with some great character design that make at least the latter feel, I don't know, a bit more personable. Sphero, decked out in white and clear plastic, is a sort of 2001-esque Clean Future, one with no soft edges, intended to be pristine rather than kicked and scuffed around. These robots that will change the way we play, will they have names written on them, in the way that Andy wrote on Woody's foot?

And then at the very least, the notion that Transmedia is Dead - that story across multiple platforms isn't interesting and that we've moved on to apps and utilities and smart products. Bringing to life a Disney Universe across multiple platforms is something that Disney Infinity is supposed to do, or that's suited to the Marvel (cinematic) universe. But obviously not a focus of this particular accelerator (or, did no one think to apply?) 

None, not one of the things on the list, seem to scream out to me about the magic of storytelling. And that feels sad.

I don't know, I guess. I suppose I expected more, and it's weird that I feel sad that I'm not more excited about this slate. 

[1] Disney Accelerator
[2] Chore Wars
[3] PlayFic

--

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seventeen: The Material (4); More Ways Of Seeing
Date: July 4, 2014 at 10:39:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ggax=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident




Happy 4th of July, America! I hope you're spending it by watching something like Independence Day. We went out on a family day trip out to Bonneville Dam today - an FDR depression-era project that ended up damming pretty much everything it could dam out of the Columbia river system, established a federal non-profit that generates a stupendous amount of free hydroelectric energy and is now investing it in wind. In other words: it was a daddy day trip to see some awe-inspiring infrastructure, giant generators and a fish ladder with enough Pacific Lampreys to give you nightmares for at least the next six weeks. It ruled.
1.0 The Material (4)
I'm having a pretty good discussion with some of my readers in the invisible backchannel of newsletter email replies about all this smartness, wearables and sensing/interface malarkey. One of the good responses has been around the notion of smartness taken to an extreme - that smart dust[1] is something that's going to be inherently creepy because it essentially relies upon EasyHard solutions to doing the right thing at the right time through distributed intelligence.

I think (as I normally do, though) that there's a continuum here, and am pretty happy to agree that the particular notion of distributed smartness and an intelligence that it elsewhere (ie an agent, or "the cloud") is going to be difficult to make happen in a good enough way. Although, there's a contra-indication right now, sitting in your pocket - because that's exactly what Google's trying to do with their Now cards and this quite horrible Fast Company Design article about an ever-present Google field[2] that imbues the universe with Googliness. 

So, if I may, here's my third way. I don't think I need to go far as smart dust as to have smart objects, but objects that are happy to sense instead of also be interface. That is, I'm going to keep picking at this scab that keeps sensing and interface combined together until it falls apart and something interesting comes through, because I think something interesting *will* come through. And again, the particular kind of interface that I'm railing against is the laziness and tyranny of the screen, of the black mirror[3] that we gaze into. 

It's not an invisible do-what-I-mean, not-what-I-say relationship to technology that I'm saying should come about with an environment imbued with smartness. Down that way lies what feels like a stupendously hard problem that, if current beliefs that it are soluble are down to the sheer application of the blunt force trauma of big data (ie: find enough humans and individual humans become essentially statistically predictable) is pretty depressing. But anyway: nevermind that it is a hard enough problem for a *human* to do the right thing, and not what I literally say, or to correctly impute my state of mind to determine my intention even *with* explicit communication, I do believe that what we want to do is provide agency and control to humans to make sense of a smart environment, rather than trying to second-guess them. 

And that's what I think things like Google Now are trying to do, and that they won't necessarily be able to do, because they're missing something in their design. In other words, attempts to predict what I want may well be interesting, relevant and useful n percent of the time but I wonder if we're about to fall into an uncanny valley that's exacerbated by an inability to interrogate and to retrain. 

Imagine a human who tried to anticipate your every need, but was difficult for you to communicate to. This human or familiar or, say, piece of virtual cardstock, would follow you around and, a based upon myriad but not al of your prior behaviour, would attempt to precog your next action. Without you *telling* it where you worked, it would guess. Without you telling it where your home was, it would guess. Without you telling it when you normally left for work, it would look for patterns. 

What sort of personality, and what sort of relationship might you have with that sort of entity? One trapped in some sort of black mirror-ish phantom zone, only able to apparate out to you through any screen that you might be near, able to whisper into your ear, but not necessarily able to be trained. This is a strange relationship indeed - the personality-free agent who tries to service you. 

It feels like part of where this is illustrated is in an emerging philosophical difference between the way certain Google and Apple services have been designed. Google's Now is predictive, using the vast power of a near omniscient non-sentient set of ill-understood algorithms. Siri - and Cortana, for that matter - only appear when you want them to, when you summon them. At your beck and call, hovering but never necessarily interrupting or intruding upon your presence in the way that Google's cards do at the moment. This isn't to say that one method or the other is better. Just that, at the moment, if you're going to predict something, it helps if you're going to be *right* and or *relevant*. And then there are occasions when Apple gets it wrong too - the oft derided "Looks like you have a busy day tomorrow"/"You've got an early start" in the notification view in iOS 7 gets a lot of stick for just being *off* a lot of the time. 

So I think what I mean in terms of smarts-as-material is  more low-level smartness. More low-level interrogation, and sensing, rather than necessarily decision-making ability. Being able to ask what, how, when, and so on of many objects is going to make them a lot more interesting, but at the same time, they're still washing machines and kettles and toasters. A lot of the smartness is, I do think, just going to happen in "the cloud" mainly because the cloud has the luxury of time, space, power and computation. If we're going with a biological metaphor, the smartness-as-material is more of extending the nervous system out into more devices, more places, more "things" rather than sticking brains in all of them. 

[1] Smart Dust
[2] Google Is About To Take Over Your Whole Life, And You Won't Even Notice 
[3] Black Mirror

2.0 More Ways Of Seeing

I am thinking about more ways of seeing what's going on in the ether, in the algorithmic world that make that world understandable. One of the ways of dealing with this is to design systems in such a way that users don't need to see what's happening: when you're looking at more single-use-at-a-time devices like the iOS kind, there's less of a need to interrogate the state of a system to see what else is going on in there, mainly because they had the chance (and decided, obviously) to re-architect and make some big decisions again. Namely: do you really need to be doing more than one thing at once, and how might we go about approaching that if we had the chance?

General purpose legacy computing, though, is a minefield. These are complex systems (though no more complex, I suppose, than whatever your average smartphone is doing these days) and *knowing what your computer is doing* is part of the diagnosis process whenever anything is going wrong. Open up activity monitor or top or perfmon is to some an inscrutable glance at all the stuff that, swan-like, is churning away below the surface of the GUI. And, in olden, swap-laden, magnetic-spinning-media times, literally churning and thrashing. But it's not like any of that stuff is understandable - it requires knowing what the arcane names of each piece of infrastructure are, what they do, and spotting which-one-of-these-things-is-not-like-the-other in terms of using up resource or just bizarrely named. 

So in that respect, I wonder: is there value, and what's the value in exposing more of this under-the-hoodness in a humane and relatable way? Toyota Prius cars are renowned for showing almost Star Trek: The Next Generation style Engineering Room thrumming diagrams of their warp cores providing power to their nacelles - I mean axles - and how their regenerative braking system is interfacing with the bussard ram scoops to charge the main batteries of the car. 

So in the same way that you're able - if you care - to walk around your house or your flat and see if part of the structure is, say, architecturally sound, what's the same process for seeing what's happening with your networking infrastructure? Should you even bother to look? I mean, if everything goes slow for some reason, how do you start to diagnose stuff?

One of the most fun tools (for certain values of fun, of course) in the early days of 802.11b wifi was etherpeg[1], which sniffed unencrypted tcp/ip packets, reassembled them and then displayed the images that it could find that were being transferred around your local network. In other words: it displayed the images from the webpages (and other network traffic) that other people on your network were looking at. Let's just say that it was pretty amusing to use in hotels.

This is about making the invisible visible. So much of it is hidden behind administrative/administrivia sections when what you're really looking for is a "hey, who's slowing down the internet" view. But right now, the only recourse is to hit the admin section of the local router and see if you can turn on some sort of logging and then before that you're shaving yaks all the way down to seeing what's in cpan.org these days. 

Along the same lines, Robin Sloan wrote an interesting piece about the Amazon Fire phone at the Farmer's Market[2] and, in my mind, what we choose to make visible. There is something about the Fire phone that - Amazon's latest push into the physical realm - that feels a little bit off. The fact that it is *such* a consumptive device (a concern that appears to not be leveled at it in the same way that it was leveled at Apple, for example) and that the primary interaction method appears to be a special button that lets you *find things to buy*. 

And Sloan's ability to take a look at that phone and see: what are the things the Fire phone doesn't see? It doesn't see anything that doesn't have an UPC. This is a phone that is completely and utterly made to exist for commerce. It is not a bicycle for the mind, it's a bicycle for getting things: and the idea of a phone or device that does better - that sees everything and that helps understand that, annotate that and educate around that - what does *that* look like, one that is essentially the five year old's ultimate phone. The one that you can point at *anything* and it will tell you about that thing. 

So this is the phone you get from Amazon - the phone for buying things. So what would the phone from Wikipedia look like? Or what would the phone from Wikileaks (ugh) look like? 

[1] Etherpeg
[2] The Fire Phone at the farmers market

--

Have a good weekend, and I'll see you on the other side,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Sixteen: The Material (3); Odds
Date: July 4, 2014 at 12:31:24 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gfsl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm still getting the hang of the freelancing thing after having unilaterally declared yesterday and today to be vacation days. Which mean that most of today was spent with my son, looking for exactly the right kind of bathtime boat. Most boats that we saw today, we both agreed, did not exhibit the right kind of "boatiness" and instead were a bit too yachty or dinghy-like. We finally settled on one that was tugboaty as well as boaty. Also, we discovered that bathtime boats really do need to be made out of plastic and not of wood, and shouldn't come with rubber bands. 




1.0 The Material (3)

The distinction between smartness (a property of a thing) and wearables (a class of thing, that is also smart) seems to be one that needs to be emphasised. When I asked the other day "what would it take for wearables to go mainstream" one of the lazy answers would be: when it would be too cheap for them the materials they're made out of to *not* include smartness.

This is part of what I mean when I'm thinking about what the material of software is and how it interfaces with hardware. There's a distinction between sensing and interface, and there's also a distinction between different types of interface. Again, the more I think about it, the more I'm interested in non-screen based interfaces, and the things that we can do when regular objects - ones that haven't been smart, or smartified or ensmartened or uplifted into network intelligence - gain that capability.

Because adding a screen *is* lazy, and it adds a whole bunch of other problems. You suddenly have to drive that display, you need the OS to run it, you need the battery to power it and, well, it needs to actually work as a good display and not simply something that can work sometimes, in some places, but not all. 

And so this is the distinction and why, I think, I remain so interested in the Withings Activite. The current crop of Android Wear devices - and other smart watches, like the Galaxy Gear - see wrist as interface. Wrist as interface that necessitates brightness emitting attention sucking screen. This feels like a sort of tech industry myopia akin to the video game console wars when, faced with not being able to compete on performance, Nintendo pretty much went sideways with the Nintendo DS and later the Wii by ignoring the flops-per-pixel race and going somewhere completely different. Sure, they ended up with the world's most expensive indoor tennis simulator, but they shifted a lot of units and managed to re-situate gaming's overton window into an area the industry still hasn't quite recovered from. 

But anyway. My intuition is this: the set of wearables-with-screens is but a tiny one subsumed inside of "wearables" which are just "things that people will adorn their body with". One of the questions around the latter will be: how small can they get? What can you put inside them? If you suppose that the baseline of a smart wearable is something that can a) sense something and b) tell something else what it's sensing then all you need (say) is something like your regular three-axis accelerometer and a Bluetooth LE chipset and a bit of power. If you're thinking about it a bit more, you might decide that *this* is the moment for induction charging because when you're talking about gorgeous bracelets (not wristbands, please), jewelry, brooches, buttons or anything else, even a Lightning port or a mini-mini-mini-nano-USB plug is going to be too big. And yes, even a 3.5mm headphone jack is going to be too big too, for those following at home with the ipod Shuffle bingo cards.

You're essentially talking about tiny, hermetically sealed lumps of metal, ceramic and plastic that are, say, marginally expensive (we're talking the jewelry industry here, of course) with a battery life of days, if not weeks, with a just-throw-it-on-the-nightstand and it charges, and a pick it up and put it on in the morning.

That's what smartness is, I think. Not a smartness that draws attention to itself. But a smartness as material, as a property, as a "this thing happens to be made out of it". 

And for that reason, I'm not entirely persuaded that convergence is the key here because sensing and display needs are different. The fact that Apple's M7 has been incorporated into the iPhone 5S is a red herring from my point of view. They thought they wouldn't be shipping that many of them, and it was a way to test out new technology. It still hasn't, I don't think, gotten that much of a deal or that much attention (and nor should it, really). 

M7 though, once it hits *scale* - that's when it becomes material. When every object can, for a cent or less, know which way up it's facing or how far it's moved, and can tell something else? That's rudimentary smartness. And doing that whilst only sipping battery life?

Because whilst there are the occasions that we have our phones with us, there are still the occasions when we don't. And just because we happen to have seen sensing and display and computation all in the same box doesn't mean they have to be *especially* when we're talking about a smart environment filled with smart objects. In this sense I'm advocating more for distributed smartness, for sensing everywhere, in numerous form factors, and for concentrated, converged computing, sense-making and interface. And as I write that, there's a silly thought: all of these objects, none of them are self-aware. They're just sensing, storing and forwarding. But it takes a concentrated amount of computing power to understand them. 

This kind of explains the whole Target double-shelving thing. One aisle is talking about the material - the electronicsness and smartness - and the other is talking about the job-to-be-done, the fitness and health and wellness. It's a good sign that whatever product category we end up calling wearables have moved out of the electronics space and into the "what do you want to achieve" space. 

2.0 Odds

 - it turns out that Finnish, Swedish and UK/GBR passports are "the most powerful" in terms of where they allow you to travel, visa-free

 - I saw Snowpiercer the other day and I'm not the only one to be instantly struck by (spoilers) how BioShock-y it feels. There are a few things wrong with it - the dialogue, especially at the beginning, is a bit clunky and there's a lot of telling and not showing. In fact, we're literally hit over the head and told that our reluctant leader is indeed a reluctant leader. Also that he is a hero. And at the same time, I'm struck by how video-gamey the entire experience of the movie is: the linear progression from one end of the train to the other, mediated by a series of gates (Doom keys, right?) combined with a bunch of fetch quests and, ultimately, cut-scenes. But altogether, an interesting movie.

 - more ammunition for technological illiteracy and lack of transparency, not ethics, in criticism of Facebook's recently disclosed experiment

--

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fifteen: Manifest Destiny; A Little Bit Desensitized; The Material (2)
Date: July 3, 2014 at 12:10:29 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gf1l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

It's hot in Portland and we don't have a/c. So I'm melting. 
1.0 Manifest Destiny
There are some people who, in reaction to the Facebook emotion contagion study, have asked "how could Facebook misread the situation so badly?" 
At some point, you wonder: was this a misreading, or was this just in fact a conscious choice? 
I was talking with a friend the other night about this and wondering if this is a particularly British or even European reaction. There's a lot that's been written about the British national psyche, the psychosocial damage that occurs to a nation state after having the specific experience that Britain had before, during and then after World War 2. As an outsider, there's a lot that's admirable about America, or rather, the ideals of America. These are elements of Brand America, as it were: optimism and a sense of moving forward, not necessarily requiring individualism. I think I've written before about how, in 2002, I visited my now wife in Washington, DC and we went to the Jefferson Memorial. There are some stirring, powerful words locked away there. 
Anyway. The point was: at some point, you can decide to *not care* what other people think. And anyone who's grown up on the internet and had some role in community management, or rolling out product changes, knows that if you do *anything* on the internet, people will want to know why they weren't consulted. The connective tissue of the internet forms, after all, a customer service medium[1].
2014 was the year that marked Facebook's transition from Move Fast And Break Things to Move Fast With Stable Infra[2]. Facebook, like a lot of physical protrusions of the Californian Ideology, doesn't believe that you make progress without breaking a few things. That applies - from the outside, looking in - to product-as-engineering-material and also product-as-user-experience. 
Or, put another way: the future is unmade, and needs to be made - at least in a fashion - for us to see it. You could argue that empathy gets in the way. Empathy prevents us from doing the things that need to be done, from doing - as they say - the unpleasant thing, the necessary thing.[3] 
There has been a sense that has gone back a long time that the internet is a frontier. That, as the critics of the Californian Ideology wrote, the internet was seen as a new place where "all individuals will be able to express themselves freely". To build this new place required breaking from the old; and where else other than in the American spirit do we see this forging ahead. 
So no, this is nothing new. This breaking of a few eggs, this doing of the necessary thing: because that is the price of progress. 
So when you look at the more libertarian West Coast ideologues, the ones who want to enact regulation free areas - they want the frontier back. There's recognition that the internet, now that it has been tamed and fought back and made usable, now that the rest of the population has moved in and erected their shanty towns in Geocities and filled up the directories of Facebook, been spidered by Google, now that all of that has happened - it isn't a frontier anymore. 
So they need a new one.
[1] Why Wasn't I Consulted
[2] Facebook kills off its ‘move fast, break things’ mantra
[3] The opening scene of “House of Cards” was a triumph of creativity over data and better judgment
 
2.0 A Little Bit Desensitized
And so we come to the Wall Street Journal's piece[1] that goes into more detail as to Facebook's Data Science Team and Sheryl Sandberg's sort-of apology where she says "we never meant to upset you", and Slate's sort-of-not-quite-on-the-money-but-near-it piece titled “We Never Meant to Upset You,” Facebook Says of Study That Was Meant to Upset You[2].
But, of course, the Facebook study wasn't necessarily *meant* to upset you, more to see if you'd be upset if you saw upset things. Sounds like splitting hairs, I suppose. 
Here we are again, though, back at the empathy wagon and asking: do motivations matter? The Hacker News discussion[3] on this is fascinating, mainly because it includes throwaway lines around the nature of ethics and what it takes to do business these days (is a gym that attempts to maximise the number of inactive members unethical? Yes, probably. Is it a good business? Yes, probably)
danah boyd's piece on Medium[4] cuts to the heart of the matter, I feel:
"Information companies aren’t the same as pharmaceuticals. They don’t need to do clinical trials before they put a product on the market. They can psychologically manipulate their users all they want without being remotely public about exactly what they’re doing. And as the public, we can only guess what the black box is doing."
This is what I mean by understanding the algorithm. Whether it's published in public or at least reviewed by, as boyd suggests, a corporate institutional review board. 
The thing is, part of this is simply a by-product of having data. It's just *there*. The society and culture that we built - hopefully by accident, and not intentionally - happens to be retaining all of this information just because it's the easiest, *laziest* thing to do. Moore's law has not only given to us a bounty of communication and computing capability, but the unrelenting progress in storage technology has given us the ability to never have to worry about forgetting. It will all be there, every single little bit or byte, and - what's worse - we might not even know if it was subject to bit rot. It's all built on the same edifice of bits passing through pipes and being scribbled down, whether it's a corporation, a government or a non-profit. It's the architecture we built computing upon. 
But. 
But what confuses me is that sometimes radical display of transparency (holocracy, for example, or the startup trend of salary transparency) does not always carry through to the user experience. And then there's that phrase again: "user experience". In aid of what? For what?
Attention-based companies may well have to one day deal with a reckoning. Time and attention is the one thing that they can't give back. And unease at the value exchange, of even *thinking* that interior states are being manipulated for a vague end ("a better user experience") means what? Do your users trust you that you know what a better user experience *is*? 
[1] Facebook Experiments Had Few Limits 
[2] “We Never Meant to Upset You,” Facebook Says of Study That Was Meant to Upset You
[3] https://news.ycombinator.com/item?id=7980743

[4] What does the Facebook experiment teach us?

3.0 The Material (2)
I had a good note back from a reader about one of their favourite no-screen smart objects, one that I can't believe I forgot in my enthusing over the Withings Activite. 

The iPod Shuffle[1] - the original one, the gumstick one, the one I wrote about back in episode five[1] - was one of those fantastic smart objects without a screen. And it wasn't even that smart! A tiny USB stick that music came out of, that didn't make any sense at the time because - as ever - we were preoccupied other items on the feature list for the category of MP3 player at the time.

This is part of the annoying thing about Apple and by extension, the annoying thing about Steve Jobs. I wrote back in episode five that that iPod Shuffle had sold ten million units (probably about ten million more than the Galaxy Gear would sell) and that it didn't even have a screen and the beauty of it was that it was selling *music*. 

A number of the chats that I had down in the Bay Area were basically plaintive wailing, gnashing of teeth and slamming wearble-adorned wrists down on tables asking: why are these all so bad? Why is it so hard to get them right? 

The Shuffle is an early example of this new kind of material, almost a proto-material. It's so *dumb*. It's not networked - it relies on a USB mass storage connection and talking to one piece of software, iTunes. At launch, it could store hardly any music. But, it worked out what people wanted, and it worked out what it was selling, and it did it at a price that was practically stupendous. So yes, lots of things worked together with that particular product. But it was a *thin* material. 

So I'm sat with a bunch of people talking about all of this business around wearables and I'm still convinced that no-one has worked out why you might want one of these smart devices. I mean, really, really want, in a way that's going to go mass. And certainly no-one's worked out how to communicate them. Shopping at Target today, it turns out that Fitbit and other health wearables have shelf space in *two* places in the store - in both the fitness section *and* the electronics section. And if my gut is right about how shelf space is the most valuable commodity inside of a store, then something must be up to have the same product in two different places. And to be clear, we're not talking end-cap or FSU or anything - just two pieces of regular shelf space down an aisle. 

You want mass appeal? Then work out what these wearables are *for*. Work out how to make wearables make you *feel safe*.

[1] iPod Shuffle
[2] Episode 5: Dreaming Invisible Dreams

--

Best,

Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fourteen: Calm Down. Breathe; Making Visible; Wearables
Date: July 1, 2014 at 5:19:27 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ge2d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

71 degrees American, slightly breezy and a slow, quiet and thoughtful day after a packed yesterday and conversationally stimulating morning. As well as the most recent episode of Tom Coates Explains Comics To You So You Don't Have To Read Them All But Now You're Going To Anyway. 
1.0 Calm Down. Breathe.
That was how Mark Zuckerberg talked to Facebook users back in 2006 in response to the introduction of the News Feed and Mini Feed products[1].
There's been a lot of talk about the Facebook emotional contagion scientific study. There's a few simple issues here, and it's clear that:
 - there's an established protocol in terms of informed consent for running scientific experiments, and Facebook did not appear to follow that protocol
 - instead, Facebook chose to interpret their terms of use broadly such that the term "research" applied not only to product, but to scientific research 
 - whilst many companies (if not all) are constantly conducting research and segmenting user groups, there is a continuum where one end of the spectrum is clear product benefit, and the other end is, shall we say, more manipulative  
 - Facebook have - I think, charitably, as a result of being a large organisation that is seeking to empower their employees - communicated the study, and their response to it in a less than well-managed manner 
 - ultimately, they are still providing a service that a large number of people find incredibly valuable, and those people will still keep using that service. 
What the study and the context around it does highlight, though - and this will not be a surprise to anyone who's a regular reader of this newsletter - is the manner in which Facebook treats and regards its users. There is the rhetoric from some, of course, that "you're what's being sold" or that "you are the product". That is, in some respects - beside the point and a symptom of another issue that we have yet to deal with (if we choose to) as a society, or collection of societies: we like free things, and we value things in the present more than we value things in the future. Free-at-the-point-of-consumption services like Facebook offer a value proposition that, if you want to look at it that way, are cognitive hacks. They take advantage of the cognitive architecture that we have, in the same way that pretty much every business has done.  
So, this is a wider debate about attention-based companies. Facebook, because they are the gorilla in the room, are bearing the brunt of this attention.  
Secondly, this *is* bigger than just a/b testing for a particular product feature. To try and put it in a different way, this is more of an atavistic reaction to having your "self" controlled or directed by a third party. To say that corporations have been manipulating people for years is fine - but you must recognise that *because* corporations and whomever have been manipulating us for such a long time, we have achieved some sort of detente or understanding as to that process. When that process is underhand, or opaque, then that's when society raises a red flag.  
Friends have joked with me: well, it's all well and fine, but you've just gone and worked in advertising for the last three years. And yes, that's true. But, we were doing it in ad breaks. And advertising is - in some ways - pretty highly regulated. You might think that it's not regulated *enough*, or not enough, but there's regulation nonetheless.  
But here we have a platform that is controlled, more than television or print, from top to bottom. Governments gave broadcasters the airwaves and in return asked them to act a certain way. There has not been such a bargain with the internet.  
Experiment size also does not matter. The fact that everything you see on a computer has been governed by the machinations of an algorithm - however complex or simple - does not matter.  
At its core, this is, I think, an emotional reaction (in those who are having and displaying it) to learning of potential, unknown, manipulation of their emotional state. Advertising may well be *unwanted* manipulation of internal state, but at least it is overt manipulation. This may well seem like a needless distinction ("you're being manipulated anyway!") especially when that manipulation works, but at least you know about it. Cold comfort for some, but comfort nonetheless. 
And this is where we come full circle to the opaqueness of the algorithm.  
Sure, newspapers editors do this. But, in a way, they talk about the fact that they are doing it. 
Facebook, on the other hand, has attempted at times to be a conduit. A pipe, an unbranded one at that, until recently, that has strived to deliver utility and to get out of the way of the user's content. But an algorithm that seeks to show you "the most relevant content to you" is significantly more opinionated than one that is merely "reverse chronological". Further, an algorithm that seeks to show you "the most relevant content to you that is likely to induce state x" is not only opinionated, but willing a change into the world.  
That is not, I'd say, the agreement that people would understand they were entering into with a communications utility.  
In any event, the state of the art moves forwards. More people are now familiar with sentiment analysis. I'm not aware of Facebook's ad products team working closely with data scientists in research, but everyone else in marketing will now be eyeing the possibility of sentiment-targeted reach advertising, never mind the already existing promise of Facebook's reach plus targeting offering.  
[1] Calm Down. Breathe. We hear you.
2.0 Making Visible
In the end, part of this is around literacy. The Algorithm is the News Feed, and a number of people are learning that they want to know what the Algorithm is and how it works, because it turns out the Algorithm has a role in shaping their perception of the universe.  
Let me put it this way: the new Plato's Cave is algorithmic fire casting shadows on our screens. This is, and always has been, about control. And you can't understand how that control is being exerted unless it is visible.  
Silicon Valley - and the tech industry in general - has in some respects a responsibility with the technology that it is deploying into our world (and that's that word again, connotive of military action *deploying* into a theatre, a region of conflict). It can empower us and help us understand the technology so that we welcome it and know what we can do with it. Or, it can chain us and entrance us with the shapes that it throws at a distance. 
I am romanticising of course, but in the era of electrification, we used to have roadshows. Technology is in danger, I think, *because* it has strived to make certain processes hidden and incapable of interrogation or understanding (this isn't the same as "easy to use", note) that one of our other cognitive biases - that of folklore and mythology to explain how the world works - steps into the gap and fills that breach.  
And thus: we start imputing into how the algorithm works, what it wants, and what it's doing, when necessarily the algorithm (or, at least most of them) are human creations.  
This is what I think is important: people who don't understand how the world works are not empowered to remake the world according to their needs or desires. In a world where a sizeable proportion of people in even first world countries lack basic literacy and numeracy skills, it feels almost Sisyphean to talk of helping people understand the machines that mediate our existence.  
In a way, I am not as concerned about resistors and capacitors and circuits, nor necessarily LCDs or LEDs. Perhaps broader areas like "wi-fi" and software radios, and how information gets communicated from one place to another. Almost like a levelling up of infrastructure. But the process: that of gathering information, operating upon it, *deciding what to do with it* and then releasing it back into the world; that's a human thing. That's a thing that we are choosing to do, and we're not blameless in the way that we do it. We do these things intentionally, and the tools with which we do it should be tools that people understand.  
(An aside: view-source for the world is simultaneously a good idea - yes, it would be good to understand the world - and a terrible one, because view-source is such a narrow way of presenting such information. Like Brett Victor, I want better ways of interrogating and understanding the world rather than ASCII text.)
3.0 Wearables
So I'm down in the Bay Area, at cloud city zero and I am talking to a lot of people at Wearables. We're talking about how I think they're terrible right now, a downright failure, how I'm not confident that Apple will have an iPod moment, and how still, nearly a week later, I am so excited about something like the Withings Activite.[1] 
Why am I excited? It's genuinely the first watch I'm excited about buying. And mainly because it *doesn't have a screen*. It's a smart object that has eschewed the lazy type of Valley and tech culture thinking of smart equals display. But smart also means sensing, computation and communication. Display is interface. A full-colour, not-completely-round is simply one way to show information and sure, it can also be a control surface. 
But on the Activite, the (non-display) glass acts as a control surface too. Double-tap it and the hands on the watch move to show you the time your alarm's set for. 
I love the idea of non-needy smartness. Smartness just in every day things, without the lure of a screen. And also, because screens are *lazy*. You put a screen in something and suddenly, hey, now you have 24 bit problems with an alpha channel at a 200dpi+ resolution. Congratulations.  
And gosh, it turns out I have so many opinions about what's *wrong* about wearables right now. About the distinction between sensing and interface. And the interface that exists after the sensing. And, in the end, how to make the damn things humane.  
I like the Culture's terminals. I like the idea of adornments, of things that are smart because they are connected or because they can sense. Or things that speak through other things, or communicate through other things. And I like being in conversations with people who can at least imagine a non-siloed world. At least, until the suits get into the room.  
So my hope for Apple is this: please, not a screen. You've sold us a thing with a screen and we love that already, perhaps too much. 
[1] Withings Activite 
--
Best,
Dan
 



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Fourteen
Date: July 1, 2014 at 5:18:08 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident

71 degrees American, slightly breezy and a slow, quiet and thoughtful day after a packed yesterday and conversationally stimulating morning. As well as the most recent episode of Tom Coates Explains Comics To You So You Don't Have To Read Them All But Now You're Going To Anyway. 
1.0 Calm Down. Breathe.
That was how Mark Zuckerberg talked to Facebook users back in 2006 in response to the introduction of the News Feed and Mini Feed products[1].
There's been a lot of talk about the Facebook emotional contagion scientific study. There's a few simple issues here, and it's clear that:
 - there's an established protocol in terms of informed consent for running scientific experiments, and Facebook did not appear to follow that protocol
 - instead, Facebook chose to interpret their terms of use broadly such that the term "research" applied not only to product, but to scientific research 
 - whilst many companies (if not all) are constantly conducting research and segmenting user groups, there is a continuum where one end of the spectrum is clear product benefit, and the other end is, shall we say, more manipulative  
 - Facebook have - I think, charitably, as a result of being a large organisation that is seeking to empower their employees - communicated the study, and their response to it in a less than well-managed manner 
 - ultimately, they are still providing a service that a large number of people find incredibly valuable, and those people will still keep using that service. 
What the study and the context around it does highlight, though - and this will not be a surprise to anyone who's a regular reader of this newsletter - is the manner in which Facebook treats and regards its users. There is the rhetoric from some, of course, that "you're what's being sold" or that "you are the product". That is, in some respects - beside the point and a symptom of another issue that we have yet to deal with (if we choose to) as a society, or collection of societies: we like free things, and we value things in the present more than we value things in the future. Free-at-the-point-of-consumption services like Facebook offer a value proposition that, if you want to look at it that way, are cognitive hacks. They take advantage of the cognitive architecture that we have, in the same way that pretty much every business has done.  
So, this is a wider debate about attention-based companies. Facebook, because they are the gorilla in the room, are bearing the brunt of this attention.  
Secondly, this *is* bigger than just a/b testing for a particular product feature. To try and put it in a different way, this is more of an atavistic reaction to having your "self" controlled or directed by a third party. To say that corporations have been manipulating people for years is fine - but you must recognise that *because* corporations and whomever have been manipulating us for such a long time, we have achieved some sort of detente or understanding as to that process. When that process is underhand, or opaque, then that's when society raises a red flag.  
Friends have joked with me: well, it's all well and fine, but you've just gone and worked in advertising for the last three years. And yes, that's true. But, we were doing it in ad breaks. And advertising is - in some ways - pretty highly regulated. You might think that it's not regulated *enough*, or not enough, but there's regulation nonetheless.  
But here we have a platform that is controlled, more than television or print, from top to bottom. Governments gave broadcasters the airwaves and in return asked them to act a certain way. There has not been such a bargain with the internet.  
Experiment size also does not matter. The fact that everything you see on a computer has been governed by the machinations of an algorithm - however complex or simple - does not matter.  
At its core, this is, I think, an emotional reaction (in those who are having and displaying it) to learning of potential, unknown, manipulation of their emotional state. Advertising may well be *unwanted* manipulation of internal state, but at least it is overt manipulation. This may well seem like a needless distinction ("you're being manipulated anyway!") especially when that manipulation works, but at least you know about it. Cold comfort for some, but comfort nonetheless. 
And this is where we come full circle to the opaqueness of the algorithm.  
Sure, newspapers editors do this. But, in a way, they talk about the fact that they are doing it. 
Facebook, on the other hand, has attempted at times to be a conduit. A pipe, an unbranded one at that, until recently, that has strived to deliver utility and to get out of the way of the user's content. But an algorithm that seeks to show you "the most relevant content to you" is significantly more opinionated than one that is merely "reverse chronological". Further, an algorithm that seeks to show you "the most relevant content to you that is likely to induce state x" is not only opinionated, but willing a change into the world.  
That is not, I'd say, the agreement that people would understand they were entering into with a communications utility.  
In any event, the state of the art moves forwards. More people are now familiar with sentiment analysis. I'm not aware of Facebook's ad products team working closely with data scientists in research, but everyone else in marketing will now be eyeing the possibility of sentiment-targeted reach advertising, never mind the already existing promise of Facebook's reach plus targeting offering.  
[1] Calm Down. Breathe. We hear you.
2.0 Making Visible
In the end, part of this is around literacy. The Algorithm is the News Feed, and a number of people are learning that they want to know what the Algorithm is and how it works, because it turns out the Algorithm has a role in shaping their perception of the universe.  
Let me put it this way: the new Plato's Cave is algorithmic fire casting shadows on our screens. This is, and always has been, about control. And you can't understand how that control is being exerted unless it is visible.  
Silicon Valley - and the tech industry in general - has in some respects a responsibility with the technology that it is deploying into our world (and that's that word again, connotive of military action *deploying* into a theatre, a region of conflict). It can empower us and help us understand the technology so that we welcome it and know what we can do with it. Or, it can chain us and entrance us with the shapes that it throws at a distance. 
I am romanticising of course, but in the era of electrification, we used to have roadshows. Technology is in danger, I think, *because* it has strived to make certain processes hidden and incapable of interrogation or understanding (this isn't the same as "easy to use", note) that one of our other cognitive biases - that of folklore and mythology to explain how the world works - steps into the gap and fills that breach.  
And thus: we start imputing into how the algorithm works, what it wants, and what it's doing, when necessarily the algorithm (or, at least most of them) are human creations.  
This is what I think is important: people who don't understand how the world works are not empowered to remake the world according to their needs or desires. In a world where a sizeable proportion of people in even first world countries lack basic literacy and numeracy skills, it feels almost Sisyphean to talk of helping people understand the machines that mediate our existence.  
In a way, I am not as concerned about resistors and capacitors and circuits, nor necessarily LCDs or LEDs. Perhaps broader areas like "wi-fi" and software radios, and how information gets communicated from one place to another. Almost like a levelling up of infrastructure. But the process: that of gathering information, operating upon it, *deciding what to do with it* and then releasing it back into the world; that's a human thing. That's a thing that we are choosing to do, and we're not blameless in the way that we do it. We do these things intentionally, and the tools with which we do it should be tools that people understand.  
(An aside: view-source for the world is simultaneously a good idea - yes, it would be good to understand the world - and a terrible one, because view-source is such a narrow way of presenting such information. Like Brett Victor, I want better ways of interrogating and understanding the world rather than ASCII text.)
3.0 Wearables
So I'm down in the Bay Area, at cloud city zero and I am talking to a lot of people at Wearables. We're talking about how I think they're terrible right now, a downright failure, how I'm not confident that Apple will have an iPod moment, and how still, nearly a week later, I am so excited about something like the Withings Activite.[1] 
Why am I excited? It's genuinely the first watch I'm excited about buying. And mainly because it *doesn't have a screen*. It's a smart object that has eschewed the lazy type of Valley and tech culture thinking of smart equals display. But smart also means sensing, computation and communication. Display is interface. A full-colour, not-completely-round is simply one way to show information and sure, it can also be a control surface. 
But on the Activite, the (non-display) glass acts as a control surface too. Double-tap it and the hands on the watch move to show you the time your alarm's set for. 
I love the idea of non-needy smartness. Smartness just in every day things, without the lure of a screen. And also, because screens are *lazy*. You put a screen in something and suddenly, hey, now you have 24 bit problems with an alpha channel at a 200dpi+ resolution. Congratulations.  
And gosh, it turns out I have so many opinions about what's *wrong* about wearables right now. About the distinction between sensing and interface. And the interface that exists after the sensing. And, in the end, how to make the damn things humane.  
I like the Culture's terminals. I like the idea of adornments, of things that are smart because they are connected or because they can sense. Or things that speak through other things, or communicate through other things. And I like being in conversations with people who can at least imagine a non-siloed world. At least, until the suits get into the room.  
So my hope for Apple is this: please, not a screen. You've sold us a thing with a screen and we love that already, perhaps too much. 
[1] Withings Activite 
--
Best,
Dan
 



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Twelve: Probationary Agents of S.H.I.E.L.D.; The Blog Unbundled; A World of Connected Objects
Date: June 27, 2014 at 9:03:26 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gbm9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm an hour out of getting back to Portland for the weekend before I inevitably end up going back down to the Bay Area on Monday. I miss my son dearly - he's taken to walking around and putting things in other things, just the mere concept of walking around while carrying something is so novel and amazing to him that at time it's hilarious and he just bursts out laughing. 
Ground speed: 476mph
Battery life: 20%
Diet Coke: in hand
1.0 Probationary Agents of S.H.I.E.L.D.
(This contains spoilers for the current state of the Marvel Cinematic Universe. If you care, but have not yet seen Captain America: The Winter Soldier *and* Marvel's Agents of S.H.I.E.L.D., then a) what are you doing, and b) skip to 2.0)
Well, technically, not S.H.I.E.L.D., but S.T.A.T.I.O.N., the Scientific Training and Tactical Intelligence Operative Network.[1]
I'm a late-developing comic book fan, but it'd be fair to say that I am *this* into the Marvel Cinematic Universe. In theory, something like Avengers S.T.A.T.I.O.N. (I'm not going to keep up with the full stops in the acronyms), an immersive exhibit that not only shows off props from the movies, but builds a narrative around it (enlist as a probationary agent, explore Dr. Banner and Stark's labs, learn about the SSR and so on, would be super exciting. 
And it was *kind of* super exciting. I mean, the music helped. Pulling the themes and motifs from each character (Captain America, The Avengers, Iron Man and Thor - not quite sure what they did about the Hulk) really helped set the scene. The set design was pretty good. Lots of displays everywhere that made you feel like you were on the set of a SHIELD installation. I mean you obviously *weren't* on a SHIELD installation, so we're talking like 85% of a Disney Parks effort, but, you know, the whole thing was dressed well. There were things that felt like the inside of shipping containers hastily dropped in admittedly prime real estate at Times Square and the requisite Goes-Nowhere-Does-Nothing conduits that make the place look and feel all militaristic. 
I was disappointed that when I peered up against the retina scanners at each entryway they didn't go red or green. 
But then there were the niggles, the remaining 15% that just made the whole thing feel more like a missed opportunity to achieve something truly special. 
Whilst there were large plasma screens everywhere showing whizzy motion graphics, the graphics hadn't been composed for the physical screen resolution - so they'd been interpolated and scaled up to the extent that you couldn't read the tiny text anymore, having been mushed into some sort of anti-aliased bicubic who is your Helvetica Neue god now slurry. 
What I'm saying is: if you're going to the extent of creating fake Hydra documents and showing the baseball cards that Coulson collected and letting people *read what's on them*, then you should pretty much make sure that you can read whether it's sensor A/11/98/B that's showing a gamma ray spike in Lahore or, well, any other sensor. 
It's interesting because STATION is like a commercial museum exhibit - like The Art Of The Brick, or Sherlock Holmes, and the temptation is to think of it as a ride, too. There are nice touches, but ultimately the whole package feels like it's ultimately let down by execution in technology rather than a failure of vision.  
So you walk up, at the beginning, to a kiosk and enter your details to get a provisional badge. The badge has a QR code and RFID so you can be identified at the various interactive stations through the exhibit - either through inserting it like a credit card, or touching to an RFID reader, or scanning the QR code. The information used from the badge ID can also be pulled in from Facebook, giving you the opportunity to allow a STATION application to post to your timeline. 
There's a nice bit at the beginning where you're spoken to by someone who's impersonating a training camp drill sergeant (all attendants are wearing STATION AGENT garb with requisite earpieces) who congratulates you on becoming a probationary STATION agent, reminds you of the top-secret nature of the place and that you'll be in big trouble if you take out your cellphone and photograph or record anything. Because, you know, it's not like you've been infiltrated by a terrorist organisation bent on remaking the world order or anything. But hey: I tried saying Hail Hydra to a few people and didn't get much of a reaction, so perhaps STATION is one of the non-bad-apples. 
All of this is inside something suspiciously similar to the dimensions of a shipping container (I'm so flirty with shipping containers it's a bit embarassing) which was exciting, and then we get a bit of cutscene video where someone tells us what the purpose of STATION is - that it was set up in the wake of the attack on Earth to provide scientific and tactical backup to Earth's Mightiest Heroes.  
I have to admit to feeling a bit of cognitive dissonance in the first room. It feels like a history exhibit (and, in a way, it is) because we're learning about World War 2, a real thing that happened, where bad things were done by a lot of people, and a lot of people died. Now, some of that was because of HYDRA and the Red Skull, you see, and at this point I'm thinking: this might not matter so much to me, the only adult in our group not being escorted by children, but, you know, HYDRA wasn't real.  
This'll crop up again later. 
But, part of me is screaming: this doesn't matter, because they're playing Captain America's theme and there's a photo of Howard and Peggy on the wall over there because we're learning about the founding of the Strategic Science Reserve and I'm all *swoon*.  
You get to see the costumes - I mean uniforms - of Black Widow, Hawkeye, Maria Hill, Nick Fury and Agent Coulson. You get to see Tony's armor, and you get to use a particle accelerator he's installed to discover a new element. You get to compare your physical attributes to Captain America - grip strength, reaction time, height and weight, galvanic skin response and all that sort of stuff. 
Most of the Captain America tests were fine - apart form the reaction time one, which was essentially a whack-a-mole test produced *incredibly poorly* on a touchscreen that didn't register touches, and you were left thinking: am I *supposed* to only score zero?  
There's a bit where you can stand in front of something that's probably hooked up to a Kinect and see how you'd do at piloting one of Tony's suits. And there's a Head-Up Display mockup, which uses (very bad) eye tracking and blink tracking using an EEG for you to move a cursor around a screen. 
It doesn't work.
By "it doesn't work," I mean: it goes through a calibration process where you look at the corners of the screen and then *stupidly*, positions the menu items in the farthest corners of the screen where it's actually possible that due to bad calibration, you can't actually move the cursor to them.
And then it doesn't recognise your blinks anyway.
Which, you know, is just irritating.
There's a replica suit hand that you're supposed to be able to control, but it had a piece of letter-sized paper and a laser-printed note on it saying that the station was being "recalibrated". 
One of the screens had a LogMeIn Hamachi prompt and an explorer window open showing stuff like IronManHandv3.exe and for a moment I wasn't *entirely* sure whether it was supposed to look like that. Then I realised duh, Tony doesn't use Windows, Stark Industries uses the Oracle Cloud. 
Another bit of cognitive dissonance was a giant display - an amazing one, really, with some touchscreens of Nasa's Kepler program, teaching kids about the planets we've found in the universe. Complete with live data and the most recent discoveries!
Around the back was an exhibit about the nine worlds of Yggdrasil.
Loki's sceptre was there, which poses important questions like: aren't HYDRA supposed to have it now? At least they didn't have the Tesseract. 
Item 47 there, as was a little card talking about Agent Sitwell's role in recovering it, and I shook my head, because Sitwell. 
(The whole thing appeared to run on Windows and Android/Windows Tablets). Touchscreens didn't feel particularly responsive, the interfaces weren't great (some scrolly text that you couldn't work out how to scroll). Basically, unsurprisingly and depressingly, most stuff on screens that was interactive was disappointing. 
Nick Fury's coat looks to be made out of some sort of carbon fiber weave which makes me desperately want one, and his trousers are so tactical as to practically require a DANGER CLOSE warning area around them.
The gift shop made it *really* hard for me to spend money. I mean, really hard. Most of the t-shirts were tat, apart from the fact that one of the attendants managed to persuade me that because this was specially licensed Marvel merchandise for the exhibit, I wouldn't be able to get a t-shirt with the SHIELD logo on it anywhere else.
I really wanted a t-shirt with the SHIELD logo on it, even though it only came in grey or white and I really wanted a black one. 
Anyway, that's my report of The Time I Tried Out To Be A Shield Agent And Decided To Not Buy The Badge I Got Because It Was Like Thirty Bucks.  
Oh, right, at the beginning there's an especially stupid bit where you stand in front of a green screen and have *no idea* what backdrop they're going to drop behind you (spoilers: it's not goatse) and it turns out the reason why they want you to strike a superhero pose is because you're surrounded to the left and right by striding-toward-the-camera Avengers and the Hulk behind you and it just looks terrible. Like, really terrible. 
7/10 if you're a regular person, 8/10 if you're a Marvel geek, 5/10 if you're a Marvel geek with high standards who's constantly disappointed with the world.  
[1] Marvel Avengers S.T.A.T.I.O.N. (this is a terrible website, I'm only linking you to it out of a sake of completeness) 
 
2.0 The Blog Unbundled
Tiny Letters to the Web We Miss by Joanne McNeill on Medium[1] is the latest look at an anecdotal resurgence of the newsletter personal publishing trend. McNeill does a good job of describing the trend to which I have to admit I feel like a latecomer when I started writing here in January earlier this year.  
McNeill says that she feels like she knew what a blog was in 2002 (I'm guessing the reverse-chronological collection of posts, generally run by an individual for individual expression), in 2008 (when more corporate entities starting doing them and a year after Tumblr's launch, two years after Twitter's launch), but now, she's not quite sure. It's not defined by the software that powers it, because blogging software, like most software, inevitably became a CMS and ended up, as she points out, becoming a significant proportion of the web. And also, as she notes,
"It isn’t a place for short links, because that is Twitter. Tumblr and Instagram took over for photoblogs. And those long personal essay/personal rant posts that people would write every once in a while — those are happening here on Medium instead of our own websites. Specific products are driving the content."
I think if McNeill had pulled on that thread a bit longer, she'd have come to the conclusion that the behaviour of blogging (which for the sake of argument we'll say originally meant personal self-expression through publishing mediated by the internet) has become unbundled from its original monolith providers. 
Twitter, again, has separated out the short-form quips and quotes that would've been short alongside a medium (you can see where this is going) or long-form blog post, and obviously done it better. Self-hosted Wordpress for such a type of content is a special form of overkill for the masochistic. 
Tumblr, likewise, has been able to focus on short-form text and image-based blogging, as well as offering a space for intense expression of personality, emotion and feeling, along with a built-in method of quickly spreading specific ideas in a way that never existed in Blogging Classic.  
We all know about Instagram, and, well, Medium pretty much explains itself. No matter how many problems Medium may have about how it's perceived, it does do two things very well: allow you a (marginally) better opportunity to attract attention, if not a recurring audience, than if you self published, and a stupendously good composing interface, combined with none of headache of keeping up with the latest Wordpress vulnerabilities or dealing with updating Akismet to make sure you're not inadvertently publishing spam comments.  
Secret, for what it's worth, and the other host of anonymous-ish publishing apps again unbundle the anonymous blog, without any perceived notions of having to deal with identity, as well as providing a platform and opportunity for the original publisher to receive a degree of positive feedback in the form of likes and comments.  
So, what have TinyLetter (and, by extension, MailChimp) found themselves with? What part of the blogging experience did they unbundle? 
I'd argue that they unbundled the audience connection. I've said it before, but here are the things that I like - whether *you* like them or not - about the newsletter/tinyletter format from a personal publishing point of view. 
 - it provides audience metrics (to the extent that one cares about audience metrics) in a qualitatively different way than RSS ever did. Unless you used a service like Feedburner, you never really knew how many people were reading your content (ugh, that word) over RSS. And what you *really* didn't know was who they were. Behind each and every single subscriber I get, there's an email address. There are real people behind those subscriptions, and, with a little Googling, I can find out who they are, should I wish. Used to be, the only way you'd know if someone was reading your blog was if they told you, either through linking, commenting, trackbacking (trackbacking!) or including you in their linkroll (linkroll!). Or, you know, you could be super anal about it and take a look through your webserver logs and look at breakdowns over domains, but that's a bit high-level. 
 - it's innately biased in favour of high outward, low inward traffic. By that, I mean that the newsletter is broadcast, and one doesn't have to worry about replies because: have you seen internet comments lately? In any event, the default nature of *not* publishing comments means that again, the nature of the publisher/reader/audience relationship is changed. I can choose to ask for replies - and they can be done very easily by just, you know, hitting reply, but also I don't have to publish them unless I want to. Commenters have a relationship with me, not with the rest of the internet as well. 
  - the reading experience is different. In theory, of course, if you're reading on mobile you're one click away from anything else through your home button. Or, if you're on a desktop/laptop, you're still one click away to anything else. But the nature of a newsletter is that it will be mainly experienced inside the context of email. And, I've found, for my longform newsletters, my audience have generally gotten the idea that the *point* is that they're long. And I make a point of not embedding links in the middle of the text, because to me, these act more like conversations that don't have branching off points. For me, I choose to put links in footnotes, because, hey, I'm talking: pay attention.  
Those are just some of the things that I like about the Tinyletter format. There's the minimalist composing interface, and there's the general lack of bells and whistles. It feels more like "write here, send there", rather than the monster that something like Wordpress has come into. The rest of what I like about it, though, is idiosyncratic to me, I feel: the fact that I've built a daily practice into writing and am using the medium as a way to explore my own thoughts and not *completely* just punditing from upon high.  
But McNeill has another point, which is that blogging in 2003, before social media, felt like it was "just us". The community was self-selecting, and I can talk at length about the early community and friendships that formed amongst bloggers in the UK in the late 90s early '00s, many of whom remain incredibly close. At the same time, though, McNeill's wrong: even by 2003 there were some of us who were worried about getting rape threats and getting abuse online from those who stumbled upon their online personae.  
Anyway, I don't think social media was the downfall of the era of close-group blogging. It was the fact that the internet finally did what it was supposed to, and started to hit a mass audience. 2003 was around the time that broadband really started taking off. 2007/8 was around the time that internet access through something that people wanted and were familiar with - their phones - became accessible both in usability and in cost. The reason why the internet felt like drinking with friends early on is that there just weren't that many people there. A sort of Fermi paradox of online community: we were early, we were alone, and then the universe grew up and the aliens came.  
So McNeill's right, in a way: "we subscribe to newsletters because we like someone and take interest in their unique point of view." And a relationship is able to form without it *having* to be in the open. Quite why it's taken this long to happen, is a bit strange - it's not like newsletters hadn't existed before. But perhaps we needed to get used to the idea of publishing out in the open, before we published out in the semi-open.  
McNeill talks, in the end, about missing the comments section, and missing, I think, the feel of discovery of like-minded people. For me, it feels like that part of the internet - finding like-minded people - was unbundled out of blogging a long time ago and moved elsewhere. Right now, it feels like it's more on Twitter than anywhere else. Unlike McNeill, I have a private Twitter account alongside my public account - a friends and family only account - for which some people feel like is a way of doing Twitter wrong; that anything I'm afraid of saying on the internet, or out loud in anyway, is perhaps something I shouldn't be saying. But, I'm only human and I can't help myself, and I have an instinctual need to connect on a closer level with people I trust.  
On the other hand, I've never felt like I would lose my job over something I did online. I know I'm lucky that way. I also know that I feel I'm not likely to do anything spectacularly stupid and that I've got a reasonable sense of judgment as to what spectacularly stupid things might be. But I've always, more or less, been able to speak my mind. And whilst this newsletter has been a way for *me* to find more likeminded people, it hasn't been a great way for those of my readers to find each other. At least, not yet. Perhaps that's something TinyLetter might look into: discussion forums for readers.  
[1] Tiny Letters to the Web We Miss by Joanne McNeill 
3.0 A World Of Connected Objects
Tom Coates, prompted by Matt Jones, has helpfully written up notes of his talk at this year's FOO camp on the subject of helping people see and understand the normal behaviour of objects in our new future: conversing and being controlled over the network[1].
Coates has been thinking about this for a while along with a bunch of others, Ben Cerveny, Matt Jones, Matt Biddulph to name a few. He starts by setting up the basic premise: a world not so soon from now where objects are not just made of physical materials, but also have the material of connectivity woven into them. There's a basic set of attributes that such objects have that one should be able to query, and manners in which one should be able to control and be notified by them. 
There's a lot that's interesting here. The anthropomorphism and animism of such objects, axes of verbosity and personality layered on top of that, and the realisation, of course, that a world full of incessantly chattering objects perhaps best illustrated by Douglas Adams' Genuine People Personalities, would in all likelihood be one that was unbearable.
Coates notices something that I think I touched on (although hadn't really expanded upon) when I talked about Google and its purchase of Nest and, again, user trust and empathy. Coates remarks that he hadn't anticipated how strongly people in the session felt about having to tend to their connected objects and how much time and maintenance they required, that they felt like a chore. The way I read his essay it almost feels like at times people resented the connected objects that they had in their homes. 
Part of me suspects that he's dealing with an incredibly smart audience who also know that things shouldn't have to be that way: he is in a way having a discussion with the people capable of building - and indeed, actually building - such objects, who have a technical, architectural and design understanding of both how these objects function and how they should function and can identify the gap. Being aware of a gap between expected/desired behaviour and actual behaviour as well as being powerless to do anything about it feels like a recipe for resentment. 
Quite whether people who *don't know* how the objects might or should act in an optimal way would react in the same way I'm not entirely sure about. It's not like regular, non-technical people get frustrated at things. But it might just be a difference of degree. 
There's an insightful bringing up of the context in which the devices are actually going to be used. They're not in the minimalist yet gorgeous house that Tom Cruise and Andrea Riseborough inhabit in Oblivion, for example. Technologists and designers would do better to imagine what smart objects would exist in the world of Friends circa 1998 (The One Where Joey Got A Smart Toaster, The One Where Monica Had To Do All The Firmware Updates, The One Where Phoebe Thought Her Thermostat Was Haunted[2]), or sitcoms like Married With Children that don't reflect a perfect middle-class utopia. This, at least, is one of the reasons why corporate vision videos rarely connect. 
It feels like a function of late-stage capitalism that we're going to end up, as Coates points out, with a whole bunch of silo'd objects. The hope for our future objects interacting and communicating with each other in a way that truly unlocks how powerful and expressive they might be seems not so much as distant as practically unobtainable given the sheer amount of capital it's going to take to implement an open, connected web of objects in the physical world, rather than the purely bits-based world. 
[1] Interacting with a World of Connected Objects by Tom Coates / Product Club
[2] @FriendsnObjects, "The TV show Friends, but with Smart, Connected Objects"
--
Okay! You people are seriously underperforming, audience-with-whom-I-have-a-relationship.
Heres what you should do. You should hit "reply" and you should type something like "Hi Dan, I am {insert name}" and introduce yourself and maybe say some things. Basically, it gets a lot easier once you hit reply and you've typed some words.
Have a good weekend, and see you on Monday, 
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eleven: If You Want To Make Products; Enterprise Driven Software Development; Odds
Date: June 26, 2014 at 8:07:57 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-gabh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm on a bus on the way to an undisclosed for NOSTROMO BLACK. 



1.0 If You Want To Make Products

Then hire product people. 

I was thinking about yesterday's episode[1] and the mini-rant in which I attacked Peter Levitan for suggesting that advertising agencies make hiring computer scientists and engineers a priority over, well, anyone else. Peter's thesis is that agencies need to get out of the business of making ads and chasing after the next Lion because they're the epitome of short-termism. The real value, the thinking goes, is to produce some sort of reusable IP in a product or service where you can increase your margin. 

It took me a while to figure out the root cause of why I felt uncomfortable about this, and I think it's an illustration of inaccurate thinking as to what it takes to make something that's not advertising. 

Let me first say this, though: making good advertising, like good anything-else, is hard, difficult, painful and necessarily involves a whole bunch of people and herding them in the right direction. You are, in essence, talking about a creative endeavour. What's interesting about advertising is that, from an outsider's perspective who spent four years in it, it can sometimes feel a little bit weird. I mean: the traditional setup is something like this - your client and your planners work on a brief, account management makes sure everyone's happy with it, the creative directors assign a team and the copywriter and the art director go and have a think. They come back with some ideas that then get turned into scripts, that may or may not be storyboarded, the client agrees that these are pretty good ideas and then you go out and production talks to lots of production companies and directors to see who might make the creative team's idea. The production company and the director then produce a treatment which is their vision of how they think they can bring the creative team's idea to life inside all of the constraints like budget and time and talent and all that kind of thing, then everyone goes to LA for a week and eats themselves silly on craft services and sits in the video village, which is where you have the folding chairs and watch what happens on a monitor while the director does their thing and directs the advert. Sometimes the director will come over, or the team will send a note to the director and there'll be a conversation about: perhaps we should try this, or, you know what, we really need a shot of the logo here, or, "I'm not really feeling it from that actress" and "could she try to open the app again, but smile this time". And then an editor gets all the film that's shot and starts assembling it into a rough cut and it's probably terrible, so you lock the copywriter and the art director and the producer in a small room for about another week and you don't let them out until they've massaged and edited the film into something that actually a) tells a story and b) does the job that the brief asked it to do. 

I write all this out longhand, because if you're not familiar with making software - products or services - and your entire experience has been with making film, then you're going to have a rude awakening. Or, rather, you're going to fail. Hard. And often. 

Because, unless you take the time to understand all the people who're involved in the process, you're relying on institutional osmosis through learning. The analogues are only analogues - they're not direct translations. 

Who's the director, for example, in software development? Ultimately, a creative team can tell a director what to do. The director is a hired gun, for example. Sure, the director has made films before. And obviously the best creative partnerships are those where they're a partnership and the creative team can see things that the director can't and vice versa and they push each other to make better work. 

I'm pretty sure I've written about this before, but the worst case scenario is that you get someone like the Winklevii saying "Hey, we've got an idea for an app" and before you know it someone's gone off and called up a production shop and, well. It gets a bit embarrassing. 

All of this is to say that there are skills that are valuable in making *advertising* that are not necessarily translatable to product design or service design. There are certainly skills at the soft front-end in terms of thinking creatively about solving a problem that will get peoples' attention. Or that might spread. You know: ideas for things. But, as they say, the devil is in the execution. 

When you're dealing with large teams, it's incredibly important to make sure that roles, responsibilities and respect are established. People need to know who's good at what, who's responsible for what. For good creative people - whether they're put in the "art director" or "copywriter" bucket, who are smart and able to come up with good insights and contributions, one of the biggest problems is a failure of communication. Because there hasn't been practice, it's hard to find common ground to express what it is that you actually mean because, more often than not, the tools that we have available to us (conference calls and email and Basecamp, for example) for giving useful feedback consistently fail us. At the worst case, for example, when you have a team who want to have input on how an object behaves in a simulated physical environment, how do you describe how you want it to act in feedback? Less bouncy? More bouncy? More springy? When you have to build-deploy-install-gather feedback, the loop is slow and irritating. 

And yet, part of this is why you lock the creative team in a small room with an editor for a week. In the filming process, you grab all the bits you think you're going to need, and in the editing room, you frantically assemble them into something that (hopefully) works. And you should get better at that process over time, having a good idea of the kind of shots that you might need, of the ways that you can assemble things. Non-linear editing is a great tool for helping that. 

Here are some of the areas that a creative team will or should have input on for a shoot, after writing the script:

 - the selection of a director, from the gathered treatments
 - casting
 - location scouting
 - wardrobe
 - props
 - lighting
 - camera angles
 - editing
 - music
 - voiceover casting
 - voiceover recording
 - sound design
 - colour correction and grading
 - title and card design

When traditional agencies are asked to provide interactive or digital solutions to briefs, they're commonly asking teams whose skillset is in the above areas because that's their experience. You're then asking a team that's used to that level of involvement - of being able to pass quite detailed notes to a director - to then, essentially, direct a software experience for a product or a service.

And then you're asking them to do it with no user testing period, most of the time - because who's got enough time for that? Typically testing and QA will cover the type of "does it have a bug" testing, not "does it do what it's supposed to do" testing, and you're lucky if you even have that amount of time for testing. (Conversely, you can be unlucky and have an overly corporate client who requires an unreasonable amount of testing and QA and then you have other problems).

So you have an environment that has fostered a certain level of control inviting teams to exert the same level of control on something they haven't done before that is *as complex, at least* as making a piece of film. Only I'm going to be honest and to say: making good software is potentially orders of magnitude *more* complex, because hey, you're talking about an interactive experience. It's non-linear. It has multiple states. 

When you're talking about building a great product or service that *does something*, there are analogues to each and every single one of those areas of responsibility or input that need a considered decision. And, obviously, they're areas for which there are established norms. Whilst software might not be as old as the language of film, it has its own conventions and expectations. And it's also an incredibly malleable medium. There are things that you can do in software that sometimes you *shouldn't* do, or you shouldn't even be able to do. Sometimes that's good, because it means you can make something surprising. Sometimes, not. 

So in the same way that making a great tv spot is a team effort, so is making software. And one of the first steps is making sure that you've got the right team. For a long time, knowledge of "interactive" in agencies was so bad that being an interactive person meant that you were expected to be able to deal with the entire domain. This would be like saying you were a "film" person and you were expected to be able to execute and have a professional opinion on *everything* to do with making a piece of film. But again, obviously, there are specialists and specialisms. It's why we have interaction designers, it's why we have frontend developers and backend developers and devops and so on. 

The gist of this is: if you want to make product, then you need leadership that understands how to make product and can teach teams how to make product. 

If you hire only software engineers, you'll only get the builders. And you absolutely need builders - to build the thing. But it doesn't mean you know people who know *what* to build, or how it should function or, even, how you can sell it to a client. Because selling an ad and selling a product or service are very different things, *especially* when your clients expect ads. 

Whether that's product strategy or design or research or whatever: product management simply isn't a discipline that exists at most traditional agencies. And product management isn't a thing that's at the top of a software engineer's skillset either. It's a completely different thing. But, it does rely on some of the core competencies that agencies pride themselves on: understanding how to make a connection with people. 

[1] Episode 110, 1.0: Stop Hitting Yourself

2.0 Enterprise Driven Software Development

After that, be forewarned: this bit is *really* dumb and silly. It's Yet Another Star Trek: The Next Generation bit. 

So here's a new model for software development that can become a cult and a whole bunch of people can follow. It's Enterprise Driven Software Development, and in it, everyone gets to pretend to be a castmember of Star Trek: The Next Generation and roleplays the kind of software that they're designing. 

Look, it's really easy:

Counsellor Troi obviously speaks for the user because she's the empath. She's super in-touch with user needs and will tell you whether your users are feeling distress because of the confusing modal dialog you've just implemented.

Lieutenant Commander Worf is all about Verbing Things and Doing Action Now. Mainly, your software should make pew-pew noises. 

Lieutenant Commander Data is the stakeholder who's going to point out that you literally said that the thing would do that thing and now it's not done that thing, you'll have to explain it to him like he's five, please. 

Commander La Forge will purse his lips and basically tell you some sort of dev ops story about how you really shouldn't be using this to do that, but I suppose you could do, and then it all turns out to be fine apart from that one time the ship's computer became sentient and then *we never spoke of it again*. 

Commander Riker just wants to know if you can a) hide porn in it, b) search for porn using it, c) turn it into some sort of subspace-range Tinder app or d) use it to play the trombone. He is essentially the troll, who will break your app. 

Wesley Crusher is a reminder that everyone on your team - even the precocious teenager - is able to contribute solutions to the problem. 

Doctor Crusher is there as a reminder that sexual tension is never a good idea on your team, and you should just keep it simmering for about seven years. 

Captain Picard has an unswerving faith in daily stand-up meetings in his ready room and basically is the good kind of product director who cajoles every team member when needed, plays the flute in his downtime and has an idiosyncratic way of responding to Jira tickets by requesting that there be a "Make it so" option in the dropdown.

3.0 Odds

Withings have a new smart watch out. It's a watch[1]. And JESUS CHRIST IF I HAVE TO VISIT ANOTHER FULL BLEED AUTO PLAYING BACKGROUND VIDEO THIN WHITE TYPE ON IMAGE SITE AGAIN I WILL KILL MYSELF SO HELP ME GOD. 

Anyway.

You should pay attention to the Activité because it's a watch that happens to be smart, instead of a watch that needs to scream to the entire world that it is smart and appears to have some sort of chip (ha) on its shoulder about never being taken seriously for being a smart thing. Because the Activité is a watch first that only just *happens* to have a three-axis accelerometer inside it that can measure your activity and wirelessly sync it with your phone. It doesn't have a display. It's just connected and smart. I mean that is fucking *brilliant* compared to the "Ok Google, Get Me A Car" stuff that we saw at I/O. 

Also, I don't think this is *entirely* because they're a French company, but there's basically a) lots of attractive people, and b) lots of exposed skin on that Withings site and it's almost feels like I accidentally opened a copy of Vogue instead of navigated to a Smart Things website. Well done, Withings, with the art direction and photography. Ten house points to you.

Next up, Whirlpool emailed me to tell me in breathless terms that their washing and drying machines now Work With Nest! Which is great because I've always wanted my thermostat to be able to talk to my washing machine behind my back. Anyway, minus several million house points to Whirlpool for the quite frankly stupid URL[2] for the smart washing machine, and then also minus several million house points for the following infractions:

 - detergent cartridges, because hey, you want your washing machine to be like your razor or your crap coffee machine that George Clooney likes
 - having a "built-in suite of Laundry Apps includes features like Stain Assist and Hints & Tips that give practical advice on stains and other everyday laundry questions." whereby it *sounds* like washing machine programs have now become Apps because Apps
 - a Smart Nudge, which must be better than just a Regular Nudge
 - some Smart Energy which likewise
 - Smart Stats via Sixth Sense Live (TM) which amongst other things, will let you look up how many days your washing machine's been online because, I don't know, you want to measure its uptime? You want it to cut back on its internet usage? 
 - a full colour widescreen LCD display that probably isn't a touchscreen.

Bad Whirlpool and your badly named washing machine. Watch the Berg Cloudwash video one hundred times before you come back tomorrow. 

Matt Jones wrote up notes from his session at Foo Camp[3] and we should all applaud him because he's been blogging again which is great but also makes the rest of us look bad because he's so smart. Anyway: the whole idea of all this (great?) ideas that were essentially unexecutable due to insufficient tech-tree advancement when the Civilization that discovered them was in play. In other words, technological advancements in computing, communications and materials science mean that we can (possibly) do all these things that were undoable before, never mind the fact that fusion is still a few decades away. Examples? Zeppelins. Balloons. The Memex. The Hitch-Hiker's Guide. Virtual Reality. Micro-economies. Micro-lending. Digital currencies. There's a whole bunch of this stuff. 

It's also interesting because it points to the suspicion that we're inherently lazy as a species. It's just so much work inventing *new* stuff when we can just dig up the recent(ish) history and then figure out how to do it properly. Is this different than Hollywood taking beloved old IP and then showing what can be done with an outsourced renderfarm and hundreds of match-move artists?

[1] The Withings Activité
[2] Laundry-dash-one-slash-Laundry-dash-two-slash-Washers-dash-three, really?
[3] All of this has happened before and will happen again

--

As ever, you should send me notes. Because I eat them and they sustain me.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Ten: Stop Hitting Yourself; Fire; Beyond Thinking Computationally; Snow Crashing (8)
Date: June 25, 2014 at 12:07:41 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g9rl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
NOSTROMO BLACK is calling me over to New York, so it's a 4:30am wakeup call, breakfast at the airport and a hop, skip and a sitting in the manufactured normalcy field of seat 1A for 5 hours until arriving in the chaos that's JFK and their taxi line. It's also Google I/O day, so, aside from the Verge fan fiction[1] and writing this, lots of pondering and thinking. And, hopefully not so much with the deep vein thrombosis, but hey, what've you got to do apart from have no legs and die of an embolism. 

Oh, in other news, James S.A. Corey's Cibola Burn[2] is out, and yay, more Space Opera. And there are some *very* good Jim Holden lines in it. 

And then on top of *that*, because I have a silly attention span, I haven't even finished my Snow Crashing series of picking apart Neal Stephenson's seminal work and now I'm thinking of doing a Pattern Recognising series to do the same to William Gibson's series[3].

And it looks like yesterday's episode was trapped inside Gmail's Promotions tab, in all likelihood because of all the Amazon affiliate reading list links I stuffed into it. So, I guess, Bad Dan, no college fund for Calvin, you should check the Promotions tab every now and then.

[1] Hey, Remember That Time Google Accidentally Made Skynet?
[2] Cibola Burn, by James S.A. Corey
[3] Pattern Recognition, by William Gibson

Altitude: 34,979 feet
Ground speed: 596mph

1.0 Stop Hitting Yourself

Look, just stop hitting yourself, advertising industry. I feel a bit like shooting fish in a barrel, but this "advice and wisdom" from Peter Levitan[1] perhaps one of the silliest posts that I've seen about how the agencies should be hiring "computer scientists and developers" before filling creative or account management positions. It's just so confused and smacks of someone who doesn't completely understand what's going on and instead wants to help agencies show that they "get digital". In other words: more suggestions for organisational change that don't, well, help to change an organisation. 

Levitan says that part of the reason for this is Because Apple, which is smacks a little of bandwagon jumping. The first bit just feels like a non-sequitur (Apple just had its developer conference, where it announced things for developers, just the same as it has *every single year*, and just the same as Microsoft and Google and everyone else who does developer outreach). 

The second is that Apple's MarCom division has recently expanded its agency roster by adding AKQA, Huge, Area 17 and Kettle. This is whilst Apple is really quite obviously staffing up and jump-balling creative assignments between its internal capability and MAL. So yeah, Apple's (read: Phil Schiller) has ideas about how marketing and advertising can change in the post-Steve era and the post-Todd Pendleton era of directing Samsung into a shock-and-awe campaign that bombed Apple into submission.

It is not clear, at the moment, what the new digital agencies are going to do for Apple. Certainly some of their web stuff has been impressive - everyone was wowed by the Mac Pro Snowfall-esque scrolling extravaganza. And similar efforts have shown up for the Mac anniversary mini-campaign. But it would be pretty inoffensive to say that Apple's good at knowing what it wants and directing its external partners. 

So Levitan says that agencies "need computer scientists and programmers" to "take advantage of iOS and deliver the programming to make it happen". But that says nothing of what the strategy of delivery would, or should, be, or what the briefs are that are being assigned to these agencies. What problems are they being asked to solve that *require computer scientists and programmers*?

Where it gets really funny for me is in the tone of Levitan's advice as to how agencies should attract computer scientists and engineers because, in his own words, "these guys are hard to interest, to hire and, well, afford." Let's leave aside the possibly sexism in "guys" because that would just be mean. Levitan says agencies should do this:
Really entice them by telling them you are going to build something really special. Really special.
This is quite simply some of the *silliest* advice and, if I were a computer scientist or an engineer who's relatively smart, I'd be asking: why are you just *telling* me you're going to build something really special? Where's the evidence that you're going to build something really special? And why would an agency be a better place than somewhere like a startup where *even* though it's a crapshoot, at least you have a crapshoot of a WhatsApp, rather than, you know, toiling away at an agency. 

And then, what's that special thing? Is this some kind of stupid bait and switch? Or, you know, is this advertising at its worst (and, funnily, *exactly* the kind of advertising that stereotypically turns off computer scientists and engineers) by more or less lying. You *said* you were going to build something really special. Where is it? And do you know how to build it?
Fire a couple of people and pay them the going rate.
If, you know, you're happy with disrupting the finely balanced pay scale of everyone else at the agency and suddenly hiring in a bunch of people who're being paid a lot more than everyone else.
Give them some equity.
And, as above, answer to everyone: why are the computer scientists and engineers getting equity if no-one else in the agency is? 

Levitan provides three bait-and-switch ways to get people *in the door* and there's no real advice as to how to effect real organisational change. Because, you know, that would be hard, and would require you to think about *why* and *what* sort of digital solutions to advertising briefs make sense, are the right thing to do for your client *and are sellable*. 

Because the deal with those computer scientists and engineers is this: they don't need you. They can make things and ship them on their own. So what do you possibly have to offer them?

Or, you know, you could go out to a monthly programmer, mobile or startup event and "look like an agency that 'gets it'". 

[1] Advertising Agencies: Your Next Hire Should Be A Nerd

2.0 Fire

Ben Thompson has written about Amazon's Fire phone[1]. Thompson's theory - or, at least, the one that he thinks best fits the evidence and is most indicative of Amazon doing something sane - that their new phone is for whales, a segment of their customers that we've seen before from social gaming, and before that, casinos and gambling. Whales are your outliers - the small percentage of customers who spend an outsized amount and are disproportionately profitable. 

In this fitting of the facts, Thompson's theory is that Amazon's going to super-serve their whales in the belief that they love Amazon so much that they'll buy the phone, too, and that a physical device will deepen their relationship with the retailer and the money will flow forth. The whales will get whalier.

I think Thompson's right in his thinking that the Fire phone is as compelling a phone as you can get without investing as much as Google and Apple have done into the entire system: no matter the technology that's been invented and integrated into the new device, features like Dynamic Perspective are wow bells-and-whistles that aren't big enough differentiators. High-end Android phones and iPhones are better and I'm not quite sure what position you're in if both the apps available on iOS *and* Android are better (or more visible, even) than the ones on your own platform. Whether that puts you ahead or behind of Windows Phone or Blackberry feels somewhat academic at this point. (There's also the issue of whether or not having a vibrant - or even viable - app ecosystem is important to the user of an Amazon Fire phone and how much work it takes to port an Android app over and support Amazon's store.)

But where I do think Thompson has missed a trick is that he doesn't go quite far enough in comparing the Fire Phone to Facebook's efforts with Home and the HTC First. I don't think it's an irrelevant segue into semantics to question whether people *love* Facebook or not in his statement "just because people love Facebook didn’t mean they wanted Facebook to dominate their phone, and by extension, their lives." Because it's not clear that people do love Facebook - indeed, that was a large part of our work in terms of user trust. 

The data show that people *use* Facebook a lot. It's an entirely different matter as to whether or not they *love* Facebook. And that, I feel, is an important difference. This is becoming a tired example, but I *use* Comcast and Verizon every day, but I'm not sure if I love them or not. In the particular market dynamics that they operate where the barrier to entry is high, I'm a captive customer from Comcast's point of view for wireline broadband services (at least, I am until Portland's city council completely submits and welcomes Google Fiber with open arms). 

Amazon is obviously not a company with a local, physical monopoly. There are clearly other retailers to buy from on the internet. But it's worth unpicking why customers choose to deal with you when you're expanding into another area where you don't have a pre-existing relationship. The goodwill, it feels, must be pretty significant. So the question is this: do Prime users *love* Amazon, or do they pay for Prime primarily because it is convenient? 

A familiar refrain by now from me is that it is easy to disguise love - and loyalty - for utility when you have service relationships conducted over the 'net. I think this explains the predilection people have for describing online audiences as fickle and jumping from one service to another: the canonical example is the Friendster to Myspace to Facebook train of social networking and communications. But I think saying the audience is fickle is an easy way out - each of these services did the job better than the previous, *and* there was not enough extant love or loyalty to act as a reason to stay. 

This isn't an either/or binary situation. These effects are additive. All I'm saying is that I don't think you can rely on just one or the other: clearly and ideally you want to offer more utility as well as goodwill that makes that transition to a new product or service easier. 

The biggest issue - and example of hubris that I see - is that Amazon have seen fit to emblazon the Fire Phone with the Amazon logo on the back. I'm really, really not sure that people are ready to be seen with a phone that shows their relationship with a retailer (even if that retailer's logotype has a smile and, well, does slightly more things than just sell things these days). I'm not that worried about a 45 minute keynote to introduce a phone - companies regularly have self-important moments, and in the grand scheme of things, they should figure out things like the logo rather than the event length.

Friends in the UK have quipped that it's a bit like flashing a phone that says Tesco Value on the back (or, I guess, Wal-Mart) and whilst I acknowledge that this probably sounds pretty snobby of me, people care about appearance. In other words, it doesn't just matter if *I* don't mind that my phone says Amazon on its back, it matters what I think *you* think that my phone says Amazon on its back. What does that say about me? You also have to wonder what including the logo on the back is intended to achieve.

Of course, perhaps this doesn't matter as much. Perhaps Amazon's famously unlabeled-on-the-y-axis graphs of tens of millions of Prime subscribers and Kindle/Fire-family devices really don't care. And I've certainly seen a number of Fire tablets on flights and airport waiting areas. But again, there's something that's still qualitatively different about a phone, than a tablet.  

[1] Amazon's Whale Strategy 

3.0 Beyond Thinking Computationally

I had a reader write back asking what I meant by "thinking computationally" as opposed to "learning to code". Part of the objection (or more accurately, clarification) that I have about the learning to code movement is that, at its worst it feels like yet more education-for-the-industrial-age of rote learning and of sending its students down to the code mills to learn how to make a website using a Javascript framework without particularly *understanding* what, why and how. 

But, I realise, there's something more than just "thinking computationally" and things like logic, identifying a goal and breaking that goal down into its constituent parts and conditions and so on. It's more about an understanding of the way a computer works and the components you have from which to build your solution. 

So when the email pinged onto my phone as I was halfway through the jetbridge, I realised: it's things like - this is what a web browser does *and how it works*. This is how computer vision works: it can look for high contrast things, it can key out background, it can look for edges and so on. This is how listening works: you filter out unwanted frequencies and you use Fast Fourier Transforms. This is how hardware works, you have a sensor that's a three-axis accelerometer, and you can read data from it quickly or slowly. This is how Bluetooth works. This is how natural language processing works, this is how you count the number of lines, this is how you look for statistically significant phrases, this is how you get an image, this is what you can do to an image and these are things you can do to an image on a device because they're easy, these are things you can to do an image on a server because they're harder. This is what a big thing is, this is what a small thing is. This is fast to do, this is slow to do. If you want to move this on a screen, how hard is it? I mean, you can *do* it, but we could do it with CoreAnimation (mostly easy), or we could do it five years ago using Javascript and Canvas and, well, a stupendously talented JS/HTML developer, or we could do it now using an off-the-shelf framework. If we want to listen to audio, can we do that in a web browser? Well, quickly, on a desktop browser, probably. On a mobile device? Probably want to do it native because it's faster. Why is it faster? How do I get this phone here to talk to that browser window there? What are web sockets? How fast does it take to make one, to use it, to tear it down? What if it doesn't work? Can I use the camera? Well, in a web browser, but it depends which one. Can I recognise a face? If we use this off-the-shelf thing. Where can we use the face-recognising thing? Well, we could use it here or there...

It takes a moment to step back and take a look at all the junk that's accumulated from twenty odd years of being interested in tech and reading stuff like Hacker News and Slashdot and god knows what else. There's so many tools. So many bits and pieces, loosely joined. And, at least, the way that I think about the *thing* that something does is as much assembling the bits together in a novel combination as it is the wrapping that goes around, inside and through that thing that's made, that dictates the why and also the how. 

So, some simple things. A story from one of my friends about how once someone asked if you could have a triangular web browser. Because, you know, advertising. And the answer isn't *no*. It's "well, you *can*" and things like Kai's Power Tools certainly don't help. So, you need to understand why the answer isn't no, and why the answer isn't an easy yes. It's because you read things like Neal Stephenson's In The Beginning Was The Command Line that talk about the almost Tower of Babel-like abstractions that sit on top of each other that let you get stuff done.

So you can't have a triangular browser for reasonable variables of time and money because: computers run operating systems and operating systems have application programming interfaces that are guidelines and foundations for how you put things on the screen because otherwise you just spend all day figuring out what pixel to put where and what colour and Jesus Christ is that tedious, so a lot of that stuff is done for you so it's *easy* to put a rectangular window (or a roundrect window) up, but *hard* to do a round window or a triangular window because the framework isn't there, but if you *wanted* to, if you really, really wanted to, you could do it yourself but, well, *sucks* that's a right job guvnor now I'm going outside for a fag. 

(And that's before you get into *really* silly stuff like, "well where do I put the scroll bars?" to which some smartass will invariably reply "where Apple put them").

So it's not so much learning to code. It's knowing - again - what the materials are. What the components are. Code is the material that you make components out of so that you can reuse them again or combine them in different ways. 

I'm not a materials scientist, but I imagine it's knowing what to use for what thing: (ugh, thing). You know. This has this tensile strength. This has that, uh, hardness. Flex. Shine. Conductivity. All of those properties. And it doesn't help that the whole field of software engineering is, to be honest, a big goddamn fucking mess. 

It's back to materials and systems, all over again.

[1] In The Beginning... Was The Command Line by Neal Stephenson

4.0 Snow Crashing (8)

Last episode of Snow Crashing we were pointing at the FQNEs and laughing until the world went all Free Trade Zone on us and people joked about Peter Thiel's island and seasteading and Google buying Detroit. 

So anyway, Y.T.'s on her way to jail and the MetaCops are trying to work out which sub-contracted private jail Y.T.'s having her ass remanded to, and Y.T. attempts to negotiate as one rational actor with another as to circumventing this whole sub-contracted law-enforcement business and we get a mini-lesson in hyperinflation. A trillion bucks and the MetaCops will take her to a Hoosegow, Y.T. bargains them down to seven hundred and fifty billion and - retro! - *swipes* her card in the slot on the back of the card because again, radio-wave and wireless transmission is something that was hard to predict, and the economy runs on magnetised credit cards. Well, we don't know for sure that they're magnetised, but we do know that the physical intent and motion is there. Stephenson is taking the familiar and pushing it, here. Remember, this is 1992, and credit cards only had been around for about a decade.

Funnily, the Hoosegaw's logo (lit up in brilliant light outside the franchise) sports a black cowboy hat resting at a jaunty angle, proving that media company or no, Yahoo!'s presence will live on in the future. Hoosegaw lives in a world of branded differentiation, so it's got a faux rustic feel - employees wear cowboy hats, five-pointed stars with names embossed on them. And Y.T. gets to use a coin-operated (coins!) TV (TV!) with a private phone (land!) line. 

We get another barcode scanner - another visible example of data in the real world, this one zaps the barcode on, well, Y.T. - the one that's embedded in her passport and identification documents (that are externally visible? Presumably because she's a thrasher and zipping about making deliveries the whole time and having them visible makes for expedited access), and "hundreds of pages about Y.T.'s personal life zoom up on a graphics screen". 

Again, there's this whole notion - even in Stephenson's world of an America where one of the few things it's good at is microcode - of delineated screens. It's a graphics screen here or a TV screen there - but in a world of bits, it doesn't and shouldn't matter without reason or the odd Supreme Court ruling notwithstanding. 

Y.T. doesn't get into the Hoosegaw, unfortunately. She blips up as female - an example of computer says no, the guy behind the desk at the franchise has to see it on a screen before he sees what's in front of him - and Y.T.'s disappointedly on her way to the Clink after having looked forward to a nice meal at the Hoosegaw, which was beginning to sound more and more like a themed hotel and not, as Stephenson says, the occasional place to habeas a stray corpus.

We get to see the thing closest to a gross QR code out in the wild - on the way to The Clink, they pass under "a square illuminated logo, a giant Universal Product Code in black-on-white with Buy'n'Fly underneath it". 

We play with the hyper-corporatised world a bit more - Y.T. accuses the MetaCop of credit card fraud for ultimately taking her to The Clink and we see how the justice system now acts with a mention of Judge Bob's Judicial System. Folksy, friendly names. Everybody knows a Bob! Bob will treat you fairly!

And then that's it - Y.T.'s in The Clink. And it's our first mention of the Dentata.

--

Phew, okay! Fun! Go team. Good job everyone, take a break, send me some notes and we'll see each other in meeting room A bright and early tomorrow morning. Denise will bring bagels and I'll bring the coffee.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Nine: What You Want; Messiahs; The List
Date: June 24, 2014 at 5:19:11 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g99l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident




So I'm camped out in Yet Another Coffee Shop in Portland, this time venturing out to the South East and relying on tethering rather than wifi this time. So I'm getting prepped for a NOSTROMO BLACK trip out at stupid o'clock tomorrow morning out to New York and then bunkering down for a couple of days, before re-emerging in time for the weekend in Portland. 

I woke up this morning to see that Warren Ellis has started publishing a morning writing practice at morning.computer[1] of which a) goddamn it that's a good URL, b) irritatingly good because Warren Elis. Anyway, he describes it like this:

"A system to be in the moment every morning, and a moment to get some things out of my system.  A way to think.  I’m a writer, and I’m also trained to process a thought by seeing it written in front of me.  Which is a ridiculous way to think, and live, but it’s all I have to work with."

of which - yes, exactly this. It doesn't work for everyone, but I definitely identify: my thinking happens as I type or as I speak and I frequently don't know what's going to come out of my mouth until it's actually come out. If I stop and take a moment, I can be surprised about how something just *appears* and it's not like it was a conscious observation when I utter a speech fragment. It's just there. And I probably shouldn't think too hard about it. My wife once remarked to me that she thought my newsletters were much better in the mornings than in the evenings - you could tell that I was tired, she said, and I wonder if you can, too. But I've always said, right from the beginning, that this is about practice for me: a daily habit, one that I'm inordinately proud of (one hundred and nine episodes! In a row! No breaks!) and one that pushes me but that I get a tremendous amount of - well, it would be wrong to say "value" but I get something important out of it that's good for me. 

I think more about what it's like to just speak and the words to just appear and there's a niggling bit at the back of my brain that's probably freaking out about what'll happen when I can't type anymore. I was playing with Type Racer[2] the other day and was pleased to see that I'm still hitting around 130 words a minute (amusingly, the last time I logged in was *five years ago*). I don't even know how fast I can speak. I do know that writing is (obviously, duh) different from speaking: I used dictation systems for about two years whilst I was training to be a lawyer and didn't really get on with them (they don't make that much sense when you can type quickly. Well, they make a lot *less* sense) *but* what they do do is enforce a sort of verbal discipline. And yes, you practice and you get better. Almost so that you internally edit *with* a conscious voice, cue up your thoughts in the right order and then hit play and then they spurt out of your mouth.

Heh. Spurt.

[1] http://morning.computer
[2] http://play.typeracer.com

Listening to: The Grid, Remixed By The Crystal Method; http://www.youtube.com/watch?v=myUAQvBCpYw
Drinking: 12oz moca
Eating: Almond croissant
At: http://www.wateravenuecoffee.com

1.0 What You Want

Marc Andreessen tweeted something this morning (at least, I think it was him - now I can't find the tweet) along the lines of all the people who wanted flying cars now being super annoyed about autonomous drones. Or, rather, bits of drones falling out of the sky on to them. It prompted a little bit of a thought:

We wanted: flying cars.
We got: self-driving, autonomous cars.

We wanted: jetpacks.
We got: autonomous drones.[1]

Scott Smith pointed out the gap[2], which is that we asked for mechanical and self-contained, and instead we got networked and digital. It's worth digging into that a bit because I think it illustrates part of how technology informs culture and how culture pushes back to inform what gets made in the present. Or even: what's possible to imagine. 

Jetpacks and flying cars are the prototypical 50s golden-era science fiction: gleaming and polished chrome from a post-war abundancy of America, full of newly empowered boomers exercising personal autonomy, zipping about the place. The 1950s didn't have networks and it didn't have digital computers. Computers were big, big things that could hardly take you to the moon, if anyone was ever going to get there. 

But I'd argue that this mechanical future is the one that was easiest for us to understand. I keep banging on about this: systems are hard to understand and even harder to visualise. I was encouraged the other day to see op/eds starting to emerge that it's not learning *code* that should be the goal, and not even learning *how* to code, but thinking programmatically and thinking in that critical way. What is it that I want to achieve, and what steps are involved in achieving it? Logic and flow control are important concepts in terms of understanding instructions and consequence. 

It is much easier to demand a future, or future objects, that have been visualised. That feel tangible. Jetpacks and flying cars were made tangible through fiction that captivated the young. 

We are in a liminal physical/digital state: some sort of boundary or phase change between code that's incredibly powerful and shapes our world in unseen ways, and code that is reaching out into our world and affecting it in ways that obey Newtonian mechanics. The feedback loop and understanding between code-that-does-this and reaction-in-the-world is so much shorter now that the network is starting to permeate everything. 

We are talking so much about an internet of things when things don't even need to be *smart* to be connected to or affected by the internet. You can think about the physical effects of the network in terms of points or a field - you could even say that it's quantum in nature: points of presence, binary states of connectivity: you can get an IP address and send and receive packets or not. But now, at this tipping point, connectivity has become a wave (literally) - carried on EM radiation that permeates the world, but quantised at the same time into packets. 

But at some point in the last ten years, the internet flipped, hit a phase change and *did* become a field. Commodities that aren't smart on their own, products that aren't smart on their own moved *because the field moved*. When the internet jiggles, the physical atoms embedded in it - although not made of the field or connected to it - jiggle too.

This is what we mean when talking about making things out of a new medium or material. Jetpacks and flying cars were about mechanical, materials science and engineering prowess: taming the physical world and putting it under our thumb. Man can't fly? We'll show physics: we'll put fucking nuclear reactors in everything.

It turned out that the physical world wasn't quite that easy to tame. At least, it wasn't at the time. 

But this new material is *magic*. It propagates information at close to the speed of light. In networks things together. It's a signaling fabric that can be smart because it means the *things* don't need to be smart and the smartness can live elsewhere, if it needs to. We're a young species, and we still expect things to behave in a classical, physical way. Hell, even abstract concepts like "money" confuse a great majority of us. 

We need to want new things to get new things. 

[1] https://twitter.com/hondanhon/status/481463884369248257
[2] https://twitter.com/changeist/status/481466209452707840

2.0 Messiahs
I was pointed in the direction of BBH's John Hegarty (I'm sorry, this is yet another bit about advertising) talking about this year's Cannes festival[1] which is a bit like SXSW but for advertising, only, I guess SXSW is for advertising too these days. 

Anyway. Hegarty's got a reasonable point that he wraps in attention-grabbing rhetoric (I know, right! Advertising!) which is that "good stuff" - namely things like the animated John Lewis Christmas ad[1] doing things like Moving The Needle and Numbers Numbers Numbers, Business for the brand (because brands are all about good storytelling) and the combination of a good media buy and a good, excellently produced script, pointing out that you could do all of those things 40 years ago.

Which yes, you could. I've got no time for people who're saying that things are dead because quite clearly quality is never going to be dead and will always have a place at the table. 

So Hegarty gets to say that the digital messiahs are like the Taliban because if you disagree with them, you're taken out and shot (as opposed to the fundamentalist Christians, who if you disagree with about, say, abortion, you get firebombed, but hey, who's counting). And he's not helped by digital messiahs who go around saying that TV is dead, but frankly, that's what startup challenger brands do all the time: say provocative things to get a reaction. 

What is interesting that I pick up on is a) that Hegarty talks about the value of brands that build relationships (and where my head goes from that is that relationships can be precipitated by a good ad, for example, but certainly not necessarily sustained by them) and b) that brands are all about storytelling. 

Part of where this starts to fall down - or at least be capital D disrupted is in the construction of brands in the first place. All that's happening is the shift in primacy of a medium: you want to tell a story - an emotionally arresting one - to lots of people at the same time? TV's not a bad bet. 

So fine, it's a balance. But all of this means that agencies need to work out what they're good at, and what media can do for them. If agencies are good at *brands* then they're good at brand *storytelling* in which case, Jesus Christ, are we not surprised that agencies don't "get" digital? Storytelling is about 1% of the promise of digital, and in terms of "storytelling", the best kind that agencies seem to achieve success with is the linear video kind. So, you know, why not just double down on that and not bother creating services and products? 

There are a whole bunch of other *business* problems that can be solved using digital delivery. Building a brand through storytelling is not the only one. Trying to do "brand storytelling" on digital - transplanting knowledge from one platform to the other - is the difficult part, because it's a different medium. And you can build brands a different way through a strategy based primarily on delivery, not on communication.

[1] http://www.theguardian.com/media/video/2014/jun/20/bbh-john-hegarty-digital-messiahs-video
[2] http://www.johnlewis.com/inspiration-and-advice/az-of-christmas/bear-and-hare

3.0 The List
I keep referencing certain books, so thought I'd pull together a reading list of Things That I Like And That Have Had A Pretty Formative Effect On Me. These are all Amazon Affiliate links too, so if you buy things, they go toward my son's nascent college fund, provided college doesn't get disrupted in the next fifteen years or so.

Basically, if you want a primer on how to be me, at a gross level, then you should probably read some of these.

On Pixar:
	•	Creativity, Inc by Ed Catmull
	•	The Pixar Touch by David A. Price
	•	Disneywar by James B. Stewart
On startups and management:
	•	Founders at Work by Jessica Livingstone
	•	Coders at Work by Peter Seibel
	•	Managing Humans: Biting and Humorous Tales of a Software Engineering Manager by Michael Lopp
Games and design:
	•	Jony Ive: The Genius Behind Apple's Greatest Products by Leander Kahney
	•	Theory of Fun for Game Design by Raph Koster
	•	The Art of Game Design: A Book of Lenses by Jesse Schell
	•	Talk To Me: Design and the Communication Between People and Objects by Paola Antonelli

Fiction:
	•	Microserfs by Douglas Coupland
	•	Global Frequency by Warren Ellis
	•	Excession by Iain M. Banks
	•	Halting State and Rule 34 by Charles Stross
	•	Red Men by Matthew De Abaitua 
	•	Rainbows End by Vernor Vinge
	•	Mr. Penumbra's 24-Hour Bookstore: A Novel and Annabel Scheme by Robin Sloan
	•	Little Brother by Cory Doctorow
	•	The Lifecycle of Software Objects by Ted Chiang
	•	Blindsight by Peter Watts
--

OK, that's it for today. Now off to pack.

Send me notes and also, you're all good recommendation engines. So some of those books probably sparked off "oh, Dan might like this, too". So send me your reckons about what I'd be interested in reading.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Nine: What You Want; Messiahs; The List
Date: June 24, 2014 at 5:16:49 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident




So I'm camped out in Yet Another Coffee Shop in Portland, this time venturing out to the South East and relying on tethering rather than wifi this time. So I'm getting prepped for a NOSTROMO BLACK trip out at stupid o'clock tomorrow morning out to New York and then bunkering down for a couple of days, before re-emerging in time for the weekend in Portland. 

I woke up this morning to see that Warren Ellis has started publishing a morning writing practice at morning.computer[1] of which a) goddamn it that's a good URL, b) irritatingly good because Warren Elis. Anyway, he describes it like this:

"A system to be in the moment every morning, and a moment to get some things out of my system.  A way to think.  I’m a writer, and I’m also trained to process a thought by seeing it written in front of me.  Which is a ridiculous way to think, and live, but it’s all I have to work with."

of which - yes, exactly this. It doesn't work for everyone, but I definitely identify: my thinking happens as I type or as I speak and I frequently don't know what's going to come out of my mouth until it's actually come out. If I stop and take a moment, I can be surprised about how something just *appears* and it's not like it was a conscious observation when I utter a speech fragment. It's just there. And I probably shouldn't think too hard about it. My wife once remarked to me that she thought my newsletters were much better in the mornings than in the evenings - you could tell that I was tired, she said, and I wonder if you can, too. But I've always said, right from the beginning, that this is about practice for me: a daily habit, one that I'm inordinately proud of (one hundred and nine episodes! In a row! No breaks!) and one that pushes me but that I get a tremendous amount of - well, it would be wrong to say "value" but I get something important out of it that's good for me. 

I think more about what it's like to just speak and the words to just appear and there's a niggling bit at the back of my brain that's probably freaking out about what'll happen when I can't type anymore. I was playing with Type Racer[2] the other day and was pleased to see that I'm still hitting around 130 words a minute (amusingly, the last time I logged in was *five years ago*). I don't even know how fast I can speak. I do know that writing is (obviously, duh) different from speaking: I used dictation systems for about two years whilst I was training to be a lawyer and didn't really get on with them (they don't make that much sense when you can type quickly. Well, they make a lot *less* sense) *but* what they do do is enforce a sort of verbal discipline. And yes, you practice and you get better. Almost so that you internally edit *with* a conscious voice, cue up your thoughts in the right order and then hit play and then they spurt out of your mouth.

Heh. Spurt.

[1] http://morning.computer
[2] http://play.typeracer.com

Listening to: The Grid, Remixed By The Crystal Method; http://www.youtube.com/watch?v=myUAQvBCpYw
Drinking: 12oz moca
Eating: Almond croissant
At: http://www.wateravenuecoffee.com

1.0 What You Want

Marc Andreessen tweeted something this morning (at least, I think it was him - now I can't find the tweet) along the lines of all the people who wanted flying cars now being super annoyed about autonomous drones. Or, rather, bits of drones falling out of the sky on to them. It prompted a little bit of a thought:

We wanted: flying cars.
We got: self-driving, autonomous cars.

We wanted: jetpacks.
We got: autonomous drones.[1]

Scott Smith pointed out the gap[2], which is that we asked for mechanical and self-contained, and instead we got networked and digital. It's worth digging into that a bit because I think it illustrates part of how technology informs culture and how culture pushes back to inform what gets made in the present. Or even: what's possible to imagine. 

Jetpacks and flying cars are the prototypical 50s golden-era science fiction: gleaming and polished chrome from a post-war abundancy of America, full of newly empowered boomers exercising personal autonomy, zipping about the place. The 1950s didn't have networks and it didn't have digital computers. Computers were big, big things that could hardly take you to the moon, if anyone was ever going to get there. 

But I'd argue that this mechanical future is the one that was easiest for us to understand. I keep banging on about this: systems are hard to understand and even harder to visualise. I was encouraged the other day to see op/eds starting to emerge that it's not learning *code* that should be the goal, and not even learning *how* to code, but thinking programmatically and thinking in that critical way. What is it that I want to achieve, and what steps are involved in achieving it? Logic and flow control are important concepts in terms of understanding instructions and consequence. 

It is much easier to demand a future, or future objects, that have been visualised. That feel tangible. Jetpacks and flying cars were made tangible through fiction that captivated the young. 

We are in a liminal physical/digital state: some sort of boundary or phase change between code that's incredibly powerful and shapes our world in unseen ways, and code that is reaching out into our world and affecting it in ways that obey Newtonian mechanics. The feedback loop and understanding between code-that-does-this and reaction-in-the-world is so much shorter now that the network is starting to permeate everything. 

We are talking so much about an internet of things when things don't even need to be *smart* to be connected to or affected by the internet. You can think about the physical effects of the network in terms of points or a field - you could even say that it's quantum in nature: points of presence, binary states of connectivity: you can get an IP address and send and receive packets or not. But now, at this tipping point, connectivity has become a wave (literally) - carried on EM radiation that permeates the world, but quantised at the same time into packets. 

But at some point in the last ten years, the internet flipped, hit a phase change and *did* become a field. Commodities that aren't smart on their own, products that aren't smart on their own moved *because the field moved*. When the internet jiggles, the physical atoms embedded in it - although not made of the field or connected to it - jiggle too.

This is what we mean when talking about making things out of a new medium or material. Jetpacks and flying cars were about mechanical, materials science and engineering prowess: taming the physical world and putting it under our thumb. Man can't fly? We'll show physics: we'll put fucking nuclear reactors in everything.

It turned out that the physical world wasn't quite that easy to tame. At least, it wasn't at the time. 

But this new material is *magic*. It propagates information at close to the speed of light. In networks things together. It's a signaling fabric that can be smart because it means the *things* don't need to be smart and the smartness can live elsewhere, if it needs to. We're a young species, and we still expect things to behave in a classical, physical way. Hell, even abstract concepts like "money" confuse a great majority of us. 

We need to want new things to get new things. 

[1] https://twitter.com/hondanhon/status/481463884369248257
[2] https://twitter.com/changeist/status/481466209452707840
2.0 Messiahs
I was pointed in the direction of BBH's John Hegarty (I'm sorry, this is yet another bit about advertising) talking about this year's Cannes festival[1] which is a bit like SXSW but for advertising, only, I guess SXSW is for advertising too these days. 

Anyway. Hegarty's got a reasonable point that he wraps in attention-grabbing rhetoric (I know, right! Advertising!) which is that "good stuff" - namely things like the animated John Lewis Christmas ad[1] doing things like Moving The Needle and Numbers Numbers Numbers, Business for the brand (because brands are all about good storytelling) and the combination of a good media buy and a good, excellently produced script, pointing out that you could do all of those things 40 years ago.

Which yes, you could. I've got no time for people who're saying that things are dead because quite clearly quality is never going to be dead and will always have a place at the table. 

So Hegarty gets to say that the digital messiahs are like the Taliban because if you disagree with them, you're taken out and shot (as opposed to the fundamentalist Christians, who if you disagree with about, say, abortion, you get firebombed, but hey, who's counting). And he's not helped by digital messiahs who go around saying that TV is dead, but frankly, that's what startup challenger brands do all the time: say provocative things to get a reaction. 

What is interesting that I pick up on is a) that Hegarty talks about the value of brands that build relationships (and where my head goes from that is that relationships can be precipitated by a good ad, for example, but certainly not necessarily sustained by them) and b) that brands are all about storytelling. 

Part of where this starts to fall down - or at least be capital D disrupted is in the construction of brands in the first place. All that's happening is the shift in primacy of a medium: you want to tell a story - an emotionally arresting one - to lots of people at the same time? TV's not a bad bet. 

So fine, it's a balance. But all of this means that agencies need to work out what they're good at, and what media can do for them. If agencies are good at *brands* then they're good at brand *storytelling* in which case, Jesus Christ, are we not surprised that agencies don't "get" digital? Storytelling is about 1% of the promise of digital, and in terms of "storytelling", the best kind that agencies seem to achieve success with is the linear video kind. So, you know, why not just double down on that and not bother creating services and products? 

There are a whole bunch of other *business* problems that can be solved using digital delivery. Building a brand through storytelling is not the only one. Trying to do "brand storytelling" on digital - transplanting knowledge from one platform to the other - is the difficult part, because it's a different medium. And you can build brands a different way through a strategy based primarily on delivery, not on communication.

[1] http://www.theguardian.com/media/video/2014/jun/20/bbh-john-hegarty-digital-messiahs-video
[2] http://www.johnlewis.com/inspiration-and-advice/az-of-christmas/bear-and-hare
3.0 The List
I keep referencing certain books, so thought I'd pull together a reading list of Things That I Like And That Have Had A Pretty Formative Effect On Me. These are all Amazon Affiliate links too, so if you buy things, they go toward my son's nascent college fund, provided college doesn't get disrupted in the next fifteen years or so.

Basically, if you want a primer on how to be me, at a gross level, then you should probably read some of these.

On Pixar:
	•	Creativity, Inc by Ed Catmull
	•	The Pixar Touch by David A. Price
	•	Disneywar by James B. Stewart
On startups and management:
	•	Founders at Work by Jessica Livingstone
	•	Coders at Work by Peter Seibel
	•	Managing Humans: Biting and Humorous Tales of a Software Engineering Manager by Michael Lopp
Games and design:
	•	Jony Ive: The Genius Behind Apple's Greatest Products by Leander Kahney
	•	Theory of Fun for Game Design by Raph Koster
	•	The Art of Game Design: A Book of Lenses by Jesse Schell
	•	Talk To Me: Design and the Communication Between People and Objects by Paola Antonelli

Fiction:
	•	Microserfs by Douglas Coupland
	•	Global Frequency by Warren Ellis
	•	Excession by Iain M. Banks
	•	Halting State and Rule 34 by Charles Stross
	•	Red Men by Matthew De Abaitua 
	•	Rainbows End by Vernor Vinge
	•	Mr. Penumbra's 24-Hour Bookstore: A Novel and Annabel Scheme by Robin Sloan
	•	Little Brother by Cory Doctorow
	•	The Lifecycle of Software Objects by Ted Chiang
	•	Blindsight by Peter Watts
--

OK, that's it for today. Now off to pack.

Send me notes and also, you're all good recommendation engines. So some of those books probably sparked off "oh, Dan might like this, too". So send me your reckons about what I'd be interested in reading.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eight: Clarity; The Customer
Date: June 23, 2014 at 10:25:40 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g8lt=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
NOSTROMO BLACK went so well last week that I'm off to New York this week for more. One can only hope that it's not a sort of bug hunt and that the aliens we're looking for are illegal aliens. Or, worse, that Carter's sent us on this mission because he thinks it's going to make him look good back at Gateway for the Company. 

This means I'm doing more miles - zipping over to New York and then back down to the Bay Area the following week for some new meetings. And then it's off back to England for TEDxLIVERPOOL. 

One of the things I'm still trying to figure out is all the self-directed projects. I have one that I've kicked off and found a collaborator for, but need to, you know, *sit down and do the work* on PROMETHEUS RED. And I should, because everyone I've spoken to about that particular project has said it's actually a good idea. 

Ideas, time, too many, not enough of.




1.0 Clarity

I think a lot about the organisations, companies and individuals that I admire and they all appear to have one thing in common: clarity. They know what it is that they want to do. For Pixar, that means knowing, right from the get-go for Ed Catmull, that he wanted to make computer-animated movies. For my former employer, that means knowing that they don't want to make advertising-that-looks-like-advertising. For Apple, they append it to the end of every press release (and it's interesting to note how they describe themselves has changed over time):

"Apple designs Macs, the best personal computers in the world, along with OS X, iLife, iWork and professional software. Apple leads the digital music revolution with its iPods and iTunes online store. Apple has reinvented the mobile phone with its revolutionary iPhone and App Store, and is defining the future of mobile media and computing devices with iPad."

This is sound-bite advice, of course. Knowing what you want to do feels like 90% of the battle, but of course, the "now you have two problems" - you know what you want to do and now you have to relentlessly execute upon it to do that the best. You have to focus and cut out everything else. 

This is clearly a problem for a bunch of people. I take a look at all the stuff that I'm interested in, and it's hard to quieten everything down and listen for some sort of wow signal[1] coming from my subconcious which indicates a sort of "concentrate on this now, because it is important." 

Some people might call this a calling - Catmull talks about how he was able to take some time out after university to figure out what, exactly, it was that he wanted to do. And then of course he had to figure out what he wanted to do *after* he had achieved his goal of creating a computer animated movie. Thus his book[2] talks about his next goal being building a sustainable, long-lived creative organisation that will last after he's moved on. So Catmull's got his personal goal and Pixar's got its own. 

I suppose some of this sounds like the 90s fad for Mission Statements[3], which ended up all over the place. I remember when my secondary school decided that it needed a mission statement, which is either an indictment of how bad education got in the 90s in England, or how invasive management techniques got in the 90s in England. 

I think what I'm interested in is how clarity of purpose relates to being flexible to change: I'm obviously super interested in how advertising agencies are navigating the environment that they find themselves in, and you can be sure that if you're outside the industry, for however complex you think it is, it's way more complex on the inside.

Or, bluntly, is it? One of the pieces of cognitive dissonance that I experienced at Wieden was reconciling an early part of agency history "We don't want to make advertising" that had turned into "We don't like advertising" with what it was that the agency actually *did* and made on a day-to-day basis. Because, when you get to the heart of it, 1980s era Wieden+Kennedy assuredly did make things that fit in holes made for advertising. They just didn't make them *look* like advertising. This feels like it opens up the opportunity for confusion: you're an ad agency that says you don't like advertising, but when you push, you mean: you don't like *bad* advertising. Advertising itself solves a problem. 

Against this, a background of change - especially and most obviously in the way that media and attention works. In Pixar's case, because the goal was to make *computer-animated* movies, provided they don't do anything stupid (and Catmull's book is basically a long list of ways and means to avoid doing stupid things, or things that they might otherwise be blind to), it's slightly more difficult for them to get disrupted or blindsided by technological advancements. Note that I didn't say that Pixar *couldn't* get disrupted - indeed Catmull explicitly talks about the business environment and pressures they found themselves under thanks to changes in digital distribution and the changing home video market, for example. Which is another reason why you should buy and read the book. 

In advertising (or, for example, any other purely atoms-based business) - and this is one of the things that Catmull's book hammers home - change isn't taken as a given and organisations ossify around practices to the extent that, cargo-cult-like, practices get worshipped rather than the goal. 

I suppose my point is this: if you're at risk of being eaten by software, it really, really helps if you have the utmost clarity about what it is that you're doing (and why you're doing it). Because the *how* of how you're doing it is inevitably going to change. And then you need to be bloody minded about the whole thing.

Advertising, as a way of communicating with people, obviously risks being disrupted. Media has already disrupted, been changed. All of this is to do with how Moore's law has unthinkingly crept over our world. But that clarity of purpose depends on what you're doing and how you're approaching that task. On one level, subsuming "advertising" into "solving our clients' business problems" is all fine and well - but agencies would do well to remember that often, their clients are asking them to solve their business problems *in the context of advertising*. And even though it may well be ill-defined these days with less of a clear-cut line and more of a gradient, more often than not, "solving a client's business problem" in the advertising context means solving a communication problem *as well as* getting the attention of someone in the first place.

That's a lot of problems to be solved. And in terms of navigating the transition from advertising to "digital", clarity is incredibly important both internally and externally, and less a tightrope that is managed than one that should be traversed with honesty. If, from an agency point of view, you genuinely believe or support the belief that digital is an opportunity to "solve clients' business problems", and if you're being tasked with approaching a brief from a fresh perspective, there's going to be (at best) a tendency to want to find the root cause a problem that's presented in a brief and then solve for *that*. The difference here is: are you solving business problems *in any way*, or are you solving business problems *using advertising*.

Because advertising doesn't, most of the time, mean a product. It doesn't mean a service. Those things throw up problems of their own regarding attention and take-up and rhythm of use. They may well be the answer to a *business* problem. They are not necessarily the answer to an advertising or communications brief. Which is why video will be alive and well answering some - not most, maybe not even all - communications briefs, because video turns out to be an effective communication tool. 

All too often, the problem is not even asking the right question, or knowing what the answer is. Agencies - traditional ones especially - and I'm including digital agencies, in a way, as traditional agencies, are built around presumptions and patterns and habits of working. The agency/client relationship in advertising has evolved and settled over decades for a certain provision of service in a certain way. That means that clients - ie CMOs - are as guilty of being stuck into an established way of solving problems instead of solving the problem itself. This isn't to lay blame necessarily, merely to recognise a fact: *advertising* is a way of solving a problem. An advertising agency being asked to solve a problem is already presumed to need to use advertising. That's why they generally don't get asked to concept other types of solutions for business problems. They're not in their wheelhouse or purvue, and furthermore, the people sitting in advertising and marketing roles aren't necessarily suited to buy solutions of those types. Because, again, advertising is a box or a tool.

I started this section talking about clarity of purpose. One of the reasons why is because I believe clarity of purpose is key to an organisation's ability to handle change, and that once you've got a tightly defined purpose, you need to be able to execute on it. Wieden+Kennedy, for example, says that it exists to create provocative relationships between good companies and their customers and to solve their clients' business problems. And one of my questions to their partners was: is there a big asterisk in there that says "with advertising"? This might seem like a facetious question. But in the context of *how problems get solved* and how we accomplish things, there's a lot of grey area. Saying that those goals are accomplished in the box of advertising only is very different from saying that they're just goals in general. What's left unsaid is as important as what's said - if I'm to borrow a leaf from Catmull, it would be to say that there would need to be a level of candor to say: these goals are solved with *advertising*. Advertising means x, y and z. It means a certain expectation of deliverable that, say, is slanted toward film or visual communication that our clients know how to buy. Or that there's a plan in place for educating clients and bringing them on a journey on how problems *could* be solved. 

But, ultimately, if an organisation's goal is to make *advertising*, then, advertising it is.

All of this thinking has been around what I want to do next. There's a clarity in the work of the Government Digital Service where they're able to tape a sign to the window and say "these are our users". That isn't a construct or a demographic: it's the delivery of state service. It's the football-obssessed-teens, it's not midwest moms who don't have enough time but want to cook a healthy dinner, it's not lapsed runners. 

Much of this has led me to think about the state of healthcare - not just in the states, but the 'states happens to be where I am right now. And kind of leads me on to the next section.

And yes, I realise the irony in me starting to write about clarity and then rambling on for several hundred worlds.

[1] http://en.wikipedia.org/wiki/Wow!_signal
[2] http://amzn.to/1j7VtTv (really, you should buy it and read it if only to stop me posting the link)
[3] http://en.wikipedia.org/wiki/Mission_statement

2.0 The Customer

There's a joke - well, less of a joke and more of an observation or an excuse or a slight - about the Microsoft some of us grew up with in the 1980s and 1990s. The general gist was that you and I - the end user who has been immortalised in the EULA - we were not Microsoft's customer. Microsoft's customers were Dell, HP, IBM, Gateway - the OEMs who bought Microsoft software en-masse and pre-installed it on the computers that we bought. We did not choose to buy Windows, the theory went - the OEMs did. The revenue that Microsoft derived from a direct personal customer was minuscule compared to the revenue from b2b sales. 

This, so went the joke, went a way toward explaining why Microsoft's software did so much and yet was still so difficult to use or impenetrable or plain unfriendly at times. I'm simplifying a lot, but Microsoft had to do the bare minimum of user research and testing to make sure that its customers' customers were happy. And yes, Microsoft took on the support burden in the form of people calling up to complain that Windows wasn't doing what it was supposed to be doing. But in the end, you followed the money, so the theory went, and the buck stopped at the OEMs and VARs.

I was talking with a friend about why there's so much bad *stuff* in the world, and a lot of the reasons came back to "because it's enterprise software, duh". It turns out that "because enterprise" is just shorthand for "the person making the purchasing decision is not the person using $thing". 

There's so much anecdata around this topic that you only have to sit down and *ask* someone who's using a piece of software in their day to day job. Timesheet software that's still being sold *to this day* that relies on you Java being turned on in the browser. Project management software. Hell, even *planes* are a problem. I was talking about how much I thought the new 737-900ERs were fantastic to my friend, and she remarked on a similar experience, but she actually asked an attendant if they liked flying the new planes. Turns out, the attendant didn't: they hated them, and quickly rattled off 14-15 different things about the plane that made their job more difficult or more annoying or just plain not-as-good as the previous generation. 

It's easy to construct a story that fills in the gaps. It's a convenient one, but I'm sure that it's not a complete picture of the truth. But it goes a little bit like this: Boeing's customers are airlines. The airlines' customers are passengers. But the way that service is delivered to the airlines' customers is a function of their staff (who use the planes - but in a different capacity to passengers) and of the physical infrastructure (the planes) and also of the other methods through which the airline delivers service (telephone, online or whatever medium). 

So, just like with Microsoft and its customers, you follow the money. The money leads you to the biggest stakeholder, the loudest voice, the one that needs to be satisfied, the one with the power in the relationship. The one with the power to make the sale, the purchasing decision. And at an airline, that's not necessarily the attendants. And also you have to ask yourself, in the position of the airline/passenger relationship: what's the service being sold? It's transport from one place to another. What will the market bear? Do people value comfort or cost? A simple look at Ryanair in Europe will show you that it turns out people really want to get to one place to another, and will bear quite a bit (nevermind whether or not you obfuscate the real cost of travelling and lead with a low headline rate). 

How would an airline or a manufacturer discover that its new planes were causing grievous problems for its staff? By a customer (passenger) service questionnaire? You'd be asking however-many-whys to get to the root cause, which might be that a surly or ill-tempered attendant had just completed however many shifts on a noticeably *worse* plane, and wasn't able to provide a great service to a passenger. But then would you ask the attendants why service had dipped, or would you even be able to discern the signal that service had dipped on the new planes? How would you tease that data out? (Using big data and new analytics tools, obviously - if you can hear my dripping sarcasm). 

Or, would you ask the attendants in the first place? Would you place their comfort and ability to do their job *well* - not just efficiently, but comfortably - as well as the ability to maximise against passenger revenue *and* passenger comfort? 

It is hard to see who advocates for the customer or the user. 

Leisa Reichelt tweeted at me, a while ago - back in episode sixty[1] - about the concept of exposure hours:

"which is such a blindingly simple idea that you're kind of surprised (and then when you think about, it understand why) more companies or organisations don't use it. It's just this: the more time your designers or product owners spend with end-users, the better designed those products or services tend to be: "There is a direct correlation between this exposure and the improvements we see in the designs that team produces." And this isn't just for design personnel - as soon as non-design personnel were included in the contact hours, the entire group would fall together. This is as much an argument for audience/customer contact across each functional unit or team across an organisation."

It's hard work to remember who the customers are. It's almost fractal in the same way that some people say that quality is fractal[2]. It's hard work to remember who the users are at all the times. But someone has to stand up for them, because *not* doing so is part of the reason why we have such shitty stuff everywhere. Because there's been a link broken between the thing, and the people who have to use it because they don't have a choice.

This is part of why I'm starting to feel angry about the state of healthcare, whether it's in the United States or in the UK. I've written about this before, I think, talking about the fact that most healthcare services *appear* like they're not delivered in any digital format whatsoever, and the ones that are, are delivered incredibly badly. 

Part of the reason, at a naive outside guess, again appears to be "because enterprise". Because it's easy to buy software that *says* it solves a particular problem, and in a way, it does solve that particular problem. In the same way that you *could* do surgery with a kitchen knife. But again, I wonder if you blow away all of the accreted cruft and you take a look at who the users are and you look at the best way to satisfy their needs. It goes without saying that even doing *that* and asking a simple question like "who is the user" opens up a political can of worms in the case of healthcare (The insurer? The hospital system? The patient? The doctor? The nurse? The billing administrator? All of the above?) that, almost Brazil-like threatens to expose the absurdity of the current situation. 

Where I despair, though, is in trying to figure out how you untangle the mess. Sure, there are efforts like Dr. Chrono[3] who appear to be going about the issue of better healthcare software bit by bit, like eating an elephant. But, you know: enterprise sales is enterprise sales. It's very salesy, and in a regulated area like healthcare, you don't necessarily get to "disrupt" the market in the same way that 37Signals goes in and ten years later, everyone's using Basecamp for project management (for which: oh my god, Basecamp doesn't mean better project management. It's just a tool.)

But just for once, I'd like to go see a doctor and not see them be befuddled about the EHR screen. I'd like for their to be better handoff between shifts of caregivers. I'd like a service that actually understood my life and reminded me at the right time that I had a fasting test to be done. You know, maybe the night before, before I actually ate anything. I'd like to know about my results. I'd like to get my bills in a format that I can read. I'd like to book my appointments by using my phone, or even, perish the thought, *change them*. 

These are base-level, bring-your-fucking-game, these things are *normal* now expectations. When I moved to Portland, Zoomcare, a local healthcare provider seemed *amazing because you could book an appointment over a desktop web interface. Three years later, there's still no mobile interface. And the Americans I talk to are somehow Stockholm-syndromed into saying "but at least I can book online!"

Well, sincerely, fuck that bullshit. 

We deserve better.

[1] http://newsletter.danhon.com/episode-sixty-we-have-always-been-at-war-our-independence-day-spimes-duh/
[2] http://ramenapp.net/post/53a4b26b35343800020a0000
[3] https://www.drchrono.com

--

It's Monday. You should start the week off right by sending me notes about today's episode and by forwarding it to people who'll get a kick out of it.

Love you all,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Eight: Clarity; The Customer
Date: June 23, 2014 at 10:23:30 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident
NOSTROMO BLACK went so well last week that I'm off to New York this week for more. One can only hope that it's not a sort of bug hunt and that the aliens we're looking for are illegal aliens. Or, worse, that Carter's sent us on this mission because he thinks it's going to make him look good back at Gateway for the Company. 

This means I'm doing more miles - zipping over to New York and then back down to the Bay Area the following week for some new meetings. And then it's off back to England for TEDxLIVERPOOL. 

One of the things I'm still trying to figure out is all the self-directed projects. I have one that I've kicked off and found a collaborator for, but need to, you know, *sit down and do the work* on PROMETHEUS RED. And I should, because everyone I've spoken to about that particular project has said it's actually a good idea. 

Ideas, time, too many, not enough of.




1.0 Clarity

I think a lot about the organisations, companies and individuals that I admire and they all appear to have one thing in common: clarity. They know what it is that they want to do. For Pixar, that means knowing, right from the get-go for Ed Catmull, that he wanted to make computer-animated movies. For my former employer, that means knowing that they don't want to make advertising-that-looks-like-advertising. For Apple, they append it to the end of every press release (and it's interesting to note how they describe themselves has changed over time):

"Apple designs Macs, the best personal computers in the world, along with OS X, iLife, iWork and professional software. Apple leads the digital music revolution with its iPods and iTunes online store. Apple has reinvented the mobile phone with its revolutionary iPhone and App Store, and is defining the future of mobile media and computing devices with iPad."

This is sound-bite advice, of course. Knowing what you want to do feels like 90% of the battle, but of course, the "now you have two problems" - you know what you want to do and now you have to relentlessly execute upon it to do that the best. You have to focus and cut out everything else. 

This is clearly a problem for a bunch of people. I take a look at all the stuff that I'm interested in, and it's hard to quieten everything down and listen for some sort of wow signal[1] coming from my subconcious which indicates a sort of "concentrate on this now, because it is important." 

Some people might call this a calling - Catmull talks about how he was able to take some time out after university to figure out what, exactly, it was that he wanted to do. And then of course he had to figure out what he wanted to do *after* he had achieved his goal of creating a computer animated movie. Thus his book[2] talks about his next goal being building a sustainable, long-lived creative organisation that will last after he's moved on. So Catmull's got his personal goal and Pixar's got its own. 

I suppose some of this sounds like the 90s fad for Mission Statements[3], which ended up all over the place. I remember when my secondary school decided that it needed a mission statement, which is either an indictment of how bad education got in the 90s in England, or how invasive management techniques got in the 90s in England. 

I think what I'm interested in is how clarity of purpose relates to being flexible to change: I'm obviously super interested in how advertising agencies are navigating the environment that they find themselves in, and you can be sure that if you're outside the industry, for however complex you think it is, it's way more complex on the inside.

Or, bluntly, is it? One of the pieces of cognitive dissonance that I experienced at Wieden was reconciling an early part of agency history "We don't want to make advertising" that had turned into "We don't like advertising" with what it was that the agency actually *did* and made on a day-to-day basis. Because, when you get to the heart of it, 1980s era Wieden+Kennedy assuredly did make things that fit in holes made for advertising. They just didn't make them *look* like advertising. This feels like it opens up the opportunity for confusion: you're an ad agency that says you don't like advertising, but when you push, you mean: you don't like *bad* advertising. Advertising itself solves a problem. 

Against this, a background of change - especially and most obviously in the way that media and attention works. In Pixar's case, because the goal was to make *computer-animated* movies, provided they don't do anything stupid (and Catmull's book is basically a long list of ways and means to avoid doing stupid things, or things that they might otherwise be blind to), it's slightly more difficult for them to get disrupted or blindsided by technological advancements. Note that I didn't say that Pixar *couldn't* get disrupted - indeed Catmull explicitly talks about the business environment and pressures they found themselves under thanks to changes in digital distribution and the changing home video market, for example. Which is another reason why you should buy and read the book. 

In advertising (or, for example, any other purely atoms-based business) - and this is one of the things that Catmull's book hammers home - change isn't taken as a given and organisations ossify around practices to the extent that, cargo-cult-like, practices get worshipped rather than the goal. 

I suppose my point is this: if you're at risk of being eaten by software, it really, really helps if you have the utmost clarity about what it is that you're doing (and why you're doing it). Because the *how* of how you're doing it is inevitably going to change. And then you need to be bloody minded about the whole thing.

Advertising, as a way of communicating with people, obviously risks being disrupted. Media has already disrupted, been changed. All of this is to do with how Moore's law has unthinkingly crept over our world. But that clarity of purpose depends on what you're doing and how you're approaching that task. On one level, subsuming "advertising" into "solving our clients' business problems" is all fine and well - but agencies would do well to remember that often, their clients are asking them to solve their business problems *in the context of advertising*. And even though it may well be ill-defined these days with less of a clear-cut line and more of a gradient, more often than not, "solving a client's business problem" in the advertising context means solving a communication problem *as well as* getting the attention of someone in the first place.

That's a lot of problems to be solved. And in terms of navigating the transition from advertising to "digital", clarity is incredibly important both internally and externally, and less a tightrope that is managed than one that should be traversed with honesty. If, from an agency point of view, you genuinely believe or support the belief that digital is an opportunity to "solve clients' business problems", and if you're being tasked with approaching a brief from a fresh perspective, there's going to be (at best) a tendency to want to find the root cause a problem that's presented in a brief and then solve for *that*. The difference here is: are you solving business problems *in any way*, or are you solving business problems *using advertising*.

Because advertising doesn't, most of the time, mean a product. It doesn't mean a service. Those things throw up problems of their own regarding attention and take-up and rhythm of use. They may well be the answer to a *business* problem. They are not necessarily the answer to an advertising or communications brief. Which is why video will be alive and well answering some - not most, maybe not even all - communications briefs, because video turns out to be an effective communication tool. 

All too often, the problem is not even asking the right question, or knowing what the answer is. Agencies - traditional ones especially - and I'm including digital agencies, in a way, as traditional agencies, are built around presumptions and patterns and habits of working. The agency/client relationship in advertising has evolved and settled over decades for a certain provision of service in a certain way. That means that clients - ie CMOs - are as guilty of being stuck into an established way of solving problems instead of solving the problem itself. This isn't to lay blame necessarily, merely to recognise a fact: *advertising* is a way of solving a problem. An advertising agency being asked to solve a problem is already presumed to need to use advertising. That's why they generally don't get asked to concept other types of solutions for business problems. They're not in their wheelhouse or purvue, and furthermore, the people sitting in advertising and marketing roles aren't necessarily suited to buy solutions of those types. Because, again, advertising is a box or a tool.

I started this section talking about clarity of purpose. One of the reasons why is because I believe clarity of purpose is key to an organisation's ability to handle change, and that once you've got a tightly defined purpose, you need to be able to execute on it. Wieden+Kennedy, for example, says that it exists to create provocative relationships between good companies and their customers and to solve their clients' business problems. And one of my questions to their partners was: is there a big asterisk in there that says "with advertising"? This might seem like a facetious question. But in the context of *how problems get solved* and how we accomplish things, there's a lot of grey area. Saying that those goals are accomplished in the box of advertising only is very different from saying that they're just goals in general. What's left unsaid is as important as what's said - if I'm to borrow a leaf from Catmull, it would be to say that there would need to be a level of candor to say: these goals are solved with *advertising*. Advertising means x, y and z. It means a certain expectation of deliverable that, say, is slanted toward film or visual communication that our clients know how to buy. Or that there's a plan in place for educating clients and bringing them on a journey on how problems *could* be solved. 

But, ultimately, if an organisation's goal is to make *advertising*, then, advertising it is.

All of this thinking has been around what I want to do next. There's a clarity in the work of the Government Digital Service where they're able to tape a sign to the window and say "these are our users". That isn't a construct or a demographic: it's the delivery of state service. It's the football-obssessed-teens, it's not midwest moms who don't have enough time but want to cook a healthy dinner, it's not lapsed runners. 

Much of this has led me to think about the state of healthcare - not just in the states, but the 'states happens to be where I am right now. And kind of leads me on to the next section.

And yes, I realise the irony in me starting to write about clarity and then rambling on for several hundred worlds.

[1] http://en.wikipedia.org/wiki/Wow!_signal
[2] http://amzn.to/1j7VtTv (really, you should buy it and read it if only to stop me posting the link)
[3] http://en.wikipedia.org/wiki/Mission_statement

2.0 The Customer

There's a joke - well, less of a joke and more of an observation or an excuse or a slight - about the Microsoft some of us grew up with in the 1980s and 1990s. The general gist was that you and I - the end user who has been immortalised in the EULA - we were not Microsoft's customer. Microsoft's customers were Dell, HP, IBM, Gateway - the OEMs who bought Microsoft software en-masse and pre-installed it on the computers that we bought. We did not choose to buy Windows, the theory went - the OEMs did. The revenue that Microsoft derived from a direct personal customer was minuscule compared to the revenue from b2b sales. 

This, so went the joke, went a way toward explaining why Microsoft's software did so much and yet was still so difficult to use or impenetrable or plain unfriendly at times. I'm simplifying a lot, but Microsoft had to do the bare minimum of user research and testing to make sure that its customers' customers were happy. And yes, Microsoft took on the support burden in the form of people calling up to complain that Windows wasn't doing what it was supposed to be doing. But in the end, you followed the money, so the theory went, and the buck stopped at the OEMs and VARs.

I was talking with a friend about why there's so much bad *stuff* in the world, and a lot of the reasons came back to "because it's enterprise software, duh". It turns out that "because enterprise" is just shorthand for "the person making the purchasing decision is not the person using $thing". 

There's so much anecdata around this topic that you only have to sit down and *ask* someone who's using a piece of software in their day to day job. Timesheet software that's still being sold *to this day* that relies on you Java being turned on in the browser. Project management software. Hell, even *planes* are a problem. I was talking about how much I thought the new 737-900ERs were fantastic to my friend, and she remarked on a similar experience, but she actually asked an attendant if they liked flying the new planes. Turns out, the attendant didn't: they hated them, and quickly rattled off 14-15 different things about the plane that made their job more difficult or more annoying or just plain not-as-good as the previous generation. 

It's easy to construct a story that fills in the gaps. It's a convenient one, but I'm sure that it's not a complete picture of the truth. But it goes a little bit like this: Boeing's customers are airlines. The airlines' customers are passengers. But the way that service is delivered to the airlines' customers is a function of their staff (who use the planes - but in a different capacity to passengers) and of the physical infrastructure (the planes) and also of the other methods through which the airline delivers service (telephone, online or whatever medium). 

So, just like with Microsoft and its customers, you follow the money. The money leads you to the biggest stakeholder, the loudest voice, the one that needs to be satisfied, the one with the power in the relationship. The one with the power to make the sale, the purchasing decision. And at an airline, that's not necessarily the attendants. And also you have to ask yourself, in the position of the airline/passenger relationship: what's the service being sold? It's transport from one place to another. What will the market bear? Do people value comfort or cost? A simple look at Ryanair in Europe will show you that it turns out people really want to get to one place to another, and will bear quite a bit (nevermind whether or not you obfuscate the real cost of travelling and lead with a low headline rate). 

How would an airline or a manufacturer discover that its new planes were causing grievous problems for its staff? By a customer (passenger) service questionnaire? You'd be asking however-many-whys to get to the root cause, which might be that a surly or ill-tempered attendant had just completed however many shifts on a noticeably *worse* plane, and wasn't able to provide a great service to a passenger. But then would you ask the attendants why service had dipped, or would you even be able to discern the signal that service had dipped on the new planes? How would you tease that data out? (Using big data and new analytics tools, obviously - if you can hear my dripping sarcasm). 

Or, would you ask the attendants in the first place? Would you place their comfort and ability to do their job *well* - not just efficiently, but comfortably - as well as the ability to maximise against passenger revenue *and* passenger comfort? 

It is hard to see who advocates for the customer or the user. 

Leisa Reichelt tweeted at me, a while ago - back in episode sixty[1] - about the concept of exposure hours:

"which is such a blindingly simple idea that you're kind of surprised (and then when you think about, it understand why) more companies or organisations don't use it. It's just this: the more time your designers or product owners spend with end-users, the better designed those products or services tend to be: "There is a direct correlation between this exposure and the improvements we see in the designs that team produces." And this isn't just for design personnel - as soon as non-design personnel were included in the contact hours, the entire group would fall together. This is as much an argument for audience/customer contact across each functional unit or team across an organisation."

It's hard work to remember who the customers are. It's almost fractal in the same way that some people say that quality is fractal[2]. It's hard work to remember who the users are at all the times. But someone has to stand up for them, because *not* doing so is part of the reason why we have such shitty stuff everywhere. Because there's been a link broken between the thing, and the people who have to use it because they don't have a choice.

This is part of why I'm starting to feel angry about the state of healthcare, whether it's in the United States or in the UK. I've written about this before, I think, talking about the fact that most healthcare services *appear* like they're not delivered in any digital format whatsoever, and the ones that are, are delivered incredibly badly. 

Part of the reason, at a naive outside guess, again appears to be "because enterprise". Because it's easy to buy software that *says* it solves a particular problem, and in a way, it does solve that particular problem. In the same way that you *could* do surgery with a kitchen knife. But again, I wonder if you blow away all of the accreted cruft and you take a look at who the users are and you look at the best way to satisfy their needs. It goes without saying that even doing *that* and asking a simple question like "who is the user" opens up a political can of worms in the case of healthcare (The insurer? The hospital system? The patient? The doctor? The nurse? The billing administrator? All of the above?) that, almost Brazil-like threatens to expose the absurdity of the current situation. 

Where I despair, though, is in trying to figure out how you untangle the mess. Sure, there are efforts like Dr. Chrono[3] who appear to be going about the issue of better healthcare software bit by bit, like eating an elephant. But, you know: enterprise sales is enterprise sales. It's very salesy, and in a regulated area like healthcare, you don't necessarily get to "disrupt" the market in the same way that 37Signals goes in and ten years later, everyone's using Basecamp for project management (for which: oh my god, Basecamp doesn't mean better project management. It's just a tool.)

But just for once, I'd like to go see a doctor and not see them be befuddled about the EHR screen. I'd like for their to be better handoff between shifts of caregivers. I'd like a service that actually understood my life and reminded me at the right time that I had a fasting test to be done. You know, maybe the night before, before I actually ate anything. I'd like to know about my results. I'd like to get my bills in a format that I can read. I'd like to book my appointments by using my phone, or even, perish the thought, *change them*. 

These are base-level, bring-your-fucking-game, these things are *normal* now expectations. When I moved to Portland, Zoomcare, a local healthcare provider seemed *amazing because you could book an appointment over a desktop web interface. Three years later, there's still no mobile interface. And the Americans I talk to are somehow Stockholm-syndromed into saying "but at least I can book online!"

Well, sincerely, fuck that bullshit. 

We deserve better.

[1] http://newsletter.danhon.com/episode-sixty-we-have-always-been-at-war-our-independence-day-spimes-duh/
[2] http://ramenapp.net/post/53a4b26b35343800020a0000
[3] https://www.drchrono.com

--

It's Monday. You should start the week off right by sending me notes about today's episode and by forwarding it to people who'll get a kick out of it.

Love you a
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seven: Allies; How Does This Even; Maximum Happy Imagination
Date: June 20, 2014 at 10:29:52 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g751=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident
I've been thinking a lot about the kind of problems that I want to solve and the ones that matter to me. And I think I'm honing in on one, but not only just the *kind* of problem, but the way that I want to solve it. A good friend gave me some advice recently that it wasn't so much about the work (which counts), but also the people. Surround yourself with a good team, he said, and you'll be surprised at what you can achieve. And that feels like it makes sense, rings true: that things don't just *happen* in our human universe (well, they do), but we change the universe by deciding to make it change. Agents of our own, self-determining wills. And that truly awe-inspiring things and works can be made by the right people, together, at the right time.

1.0 Allies
There's a sort of Turing-lite test these days in the creation of Twitter bots. The most famous example to date is probably the story of @horse_ebooks[1], the spammy Twitter account that verged on (and arguably crossed over) into the poetic, and then, once acquired and operated by another human, had to try to pretend to be bot-like. 

Some of my favourite bots are by Darius Kazemi[2], an individual with a quite frankly astonishing amount of output over the last few years, with @TwoHeadlines[3] being perhaps the best. 

So the other day, I learn about @OliviaTaters[4], another Twitter bot that does a bunch of elementary (and yet incredibly creative) language processing for, well, algorithmically generated poetry. The wonderful thing about this is that it's another kind of additive creativity: seeing what you can do with off-the-shelf natural language processing for identifying sentence fragments, and then letting the algorithm rip. You never know what's going to be created. 

One the one hand, gamers are used to the phrase "procedurally generated content" to mean maps or levels generated out of thin air, or universes or non-player characters. 

But it feels like there's something different going on when, instead of saying "procedurally generated content", we talk about procedurally generated poetry. Because, just as in more graphic-oriented endeavours, a procedure is being followed (identifying sentence phrases, picking from a giant corpus of all the utterances on Twitter that already exist) that creates something new. The thing about language, linguists will tell you, is how wonderfully combinatorial it is: that each utterance that we bring into the world has a very high probability of *never having existed before*. 

And so the utterances that the TwoHeadlines and OliviaTaters bots come up with feel magical because a) they exist in a space that is full of the gamut of social discourse, but also because b) they retain a feeling of uniqueness both *before* we discover they're bots and *after*. 

There's something about both of the bots - bots in general - where I wonder if the short-circuiting in terms of leaving out, say, the role of consciousness in constructing speech, results in phrases that, more often than not, stick out at us because they're speech-without-consciousness. They are simultaneously so close to one hundred percent organic free range human speech and yet also stuck in a sort of uncanny valley that, it feels like, triggers a sort of detector for the sublime. I mean, really, how else can you react to:

	what does it say about me that i won't play 2048 anymore, but i will love you[5]

I feel like I'm babbling here (and it may well be that I'm a receptive-to-babbling state, given that my son's speech development is at that stage and I'm probably more attuned to trying to find meaning in babbling than at other times), but there are a few things going on here: how much non-human "speech" is being generated these days? When speech-generating bots are being made for fun and the components are easily cloneable and off-the-shelfable, it's clear that there's less of an economic incentive. @OlivaTaters was made, in a way, for *fun*. Not in the way that spammers were the first to assemble weapons of mass markov-chaining to brute-force their way past our perception filters into our inboxes and trigger our click-finger-action-potential, but in that people are *playing* with markov-chaining and other techniques to produce new speech with human input as the seed. These utterances are still new, they're babbling and of course they're pre-sentient. There's no real feedback loop, for starters. 

It's against the background of all of this that I learn through a friend about #BotAlly[6] and Tully Hansen[7].

There's a growing discourse around bots and, well, the discourse that they themselves generate, no better summed up and explored than in a wonderful Medium article by Mark Sample[8], illustrated with painfully on-topic bots like @NRA_Tally[9].

There's an amazing new genre of literature emerging[10], and it already has its allies.

[1] http://bits.blogs.nytimes.com/2013/09/24/the-human-behind-a-favorite-spambot-horse_ebooks/
[2] http://tinysubversions.com
[3] https://twitter.com/twoheadlines
[4] https://twitter.com/oliviataters
[5] https://twitter.com/oliviataters/status/479836122236063745
[6] https://twitter.com/search?f=realtime&q=%23botally&src=typd
[7] http://tullyhansen.com
[8] https://medium.com/@samplereality/a-protest-bot-is-a-bot-so-specific-you-cant-mistake-it-for-bullshit-90fe10b7fbaa
[9] https://twitter.com/NRA_Tally
[10] http://iloveepoetry.com/?p=5427

2.0 How Does This Even
So, Washboard.co[1], a startup designed to solve that irritating problem of not having quarters when it's time to do laundry by shipping them to you at a cost of $15 for $10 worth of quarters, comes out at exactly the same time as renewed scrutiny for the term "disruption". 

There's a few things to note here.

The first, of course, takes a few minutes of getting used to, which is: how is this even a real thing? Are people these days (or, even, are *enough* people these days) so lazy as to pay a 50% premium to have some quarters lying around, or to not even, say, use a change machine? 

The quick answer is: well, only six people have signed up so far[2].

The second is that, it's easy to see imagine this in an ad agency creative pitch for a client like, say, Tide. The award submission video writes itself: "We set out to bring a new audience to Tide - hard to reach millenials whose only relationship to laundry detergents might be through their mothers. So we asked ourselves: how could we reach them at a relevant moment, when we could bring home to them how valuable Tide could be to them as a partner in their laundry endeavours? The answer was staring us in the face. We all remember that feeling of not having enough quarters for the laundromat: so we developed the world's first laundry quarter subscription service - brought to you by Tide. By showing that we understood the problems encountered by millenials, we could gain their trust - and bring home the real benefits of Tide in their lives."

I mean, this kind of stuff is award season *gold*. I fully expect Washboard to have been ripped off and to win big at Cannes this time next year.

The third is: holy crap, do we have any new formats for startup/product/service homepages yet? Large, full-bleed background images, vertical scrolling, thin type. You almost don't even need to read the stuff anymore. 

[1] http://washboard.co
[2] http://www.boston.com/news/local/massachusetts/2014/06/19/new-business-charges-for-quarters-can-work/stA5GE3E271nm6x6Bph1PM/story.html

3.0 Maximum Happy Imagination
I'm glad Matt Jones has started blogging again because his post about Maximum Happy Imagination[1] hit a chord. It's a short one, this, but Jones quite deftly points to the end-game of bending things in hockey-stick shaped lines toward divide-by-zero states that just don't make sense. Only, in the utopian post-scarcity world, for some reason, capitalism remains and we're still talking about "democratic capitalism to the Nth degree". 

It feels like an abrupt failure of the imagination. Almost like capitalism is a *law* that cannot be broken, that it's simply a fact. And yet here we are, quite happily imagining breaking the speed of light! Alcubierre drives, negative mass, exotic matter - all of these things, all in the service of not being happy with the status quo and wanting more out of the universe. We want 5nm manufacturing processes, we imagine matrioshka brains devouring entire stellar systems, *all of these things* and yet, and still: democratic capitalism to the Nth degree.

Now it may well be that it's impolitic to talk too loudly about replacing democracy with something else. Or replacing capitalism with something else. That might be a good reason.

But to assert (seemingly blindly) that *even in a post-scarcity world*, even in a world where we're able to do so much more than we are now, that democracy and capitalism are in effect finished projects, perfected, seems remarkably short sighted. 

The full extrapolation, in the way that Andreessen posits, of the traits and concepts of "money, competition, status-seeking or the will to power" almost sounds like it falls to the innovator's dilemma trap of assuming that all of those things are immune to disruption. Sure, you can imagine a future that has all of those things in it, assuming that all of things are inherent characteristics of our universe. And perhaps some of them are. But, in the same way that we assume that we can and might fight what we assume to be *physical* laws of the universe and find ways to change them, do we not imagine that we can change status-seeking or money or competition? 

Do we imagine that we, as hom. sap., are also immune to change and that our current predilection for status-seeking and the usage of competition to bring about forward momentum in ourselves as societies and species is immutable? 

[1] http://magicalnihilism.com/2014/06/20/maximum-happy-imagination/

-- 

Well on that note, I hope you have a good weekend. 

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Seven: Allies
Date: June 20, 2014 at 10:28:23 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident
I've been thinking a lot about the kind of problems that I want to solve and the ones that matter to me. And I think I'm honing in on one, but not only just the *kind* of problem, but the way that I want to solve it. A good friend gave me some advice recently that it wasn't so much about the work (which counts), but also the people. Surround yourself with a good team, he said, and you'll be surprised at what you can achieve. And that feels like it makes sense, rings true: that things don't just *happen* in our human universe (well, they do), but we change the universe by deciding to make it change. Agents of our own, self-determining wills. And that truly awe-inspiring things and works can be made by the right people, together, at the right time.
1.0 Allies
There's a sort of Turing-lite test these days in the creation of Twitter bots. The most famous example to date is probably the story of @horse_ebooks[1], the spammy Twitter account that verged on (and arguably crossed over) into the poetic, and then, once acquired and operated by another human, had to try to pretend to be bot-like. 

Some of my favourite bots are by Darius Kazemi[2], an individual with a quite frankly astonishing amount of output over the last few years, with @TwoHeadlines[3] being perhaps the best. 

So the other day, I learn about @OliviaTaters[4], another Twitter bot that does a bunch of elementary (and yet incredibly creative) language processing for, well, algorithmically generated poetry. The wonderful thing about this is that it's another kind of additive creativity: seeing what you can do with off-the-shelf natural language processing for identifying sentence fragments, and then letting the algorithm rip. You never know what's going to be created. 

One the one hand, gamers are used to the phrase "procedurally generated content" to mean maps or levels generated out of thin air, or universes or non-player characters. 

But it feels like there's something different going on when, instead of saying "procedurally generated content", we talk about procedurally generated poetry. Because, just as in more graphic-oriented endeavours, a procedure is being followed (identifying sentence phrases, picking from a giant corpus of all the utterances on Twitter that already exist) that creates something new. The thing about language, linguists will tell you, is how wonderfully combinatorial it is: that each utterance that we bring into the world has a very high probability of *never having existed before*. 

And so the utterances that the TwoHeadlines and OliviaTaters bots come up with feel magical because a) they exist in a space that is full of the gamut of social discourse, but also because b) they retain a feeling of uniqueness both *before* we discover they're bots and *after*. 

There's something about both of the bots - bots in general - where I wonder if the short-circuiting in terms of leaving out, say, the role of consciousness in constructing speech, results in phrases that, more often than not, stick out at us because they're speech-without-consciousness. They are simultaneously so close to one hundred percent organic free range human speech and yet also stuck in a sort of uncanny valley that, it feels like, triggers a sort of detector for the sublime. I mean, really, how else can you react to:

	what does it say about me that i won't play 2048 anymore, but i will love you[5]

I feel like I'm babbling here (and it may well be that I'm a receptive-to-babbling state, given that my son's speech development is at that stage and I'm probably more attuned to trying to find meaning in babbling than at other times), but there are a few things going on here: how much non-human "speech" is being generated these days? When speech-generating bots are being made for fun and the components are easily cloneable and off-the-shelfable, it's clear that there's less of an economic incentive. @OlivaTaters was made, in a way, for *fun*. Not in the way that spammers were the first to assemble weapons of mass markov-chaining to brute-force their way past our perception filters into our inboxes and trigger our click-finger-action-potential, but in that people are *playing* with markov-chaining and other techniques to produce new speech with human input as the seed. These utterances are still new, they're babbling and of course they're pre-sentient. There's no real feedback loop, for starters. 

It's against the background of all of this that I learn through a friend about #BotAlly[6] and Tully Hansen[7].

There's a growing discourse around bots and, well, the discourse that they themselves generate, no better summed up and explored than in a wonderful Medium article by Mark Sample[8], illustrated with painfully on-topic bots like @NRA_Tally[9].

There's an amazing new genre of literature emerging[10], and it already has its allies.

[1] http://bits.blogs.nytimes.com/2013/09/24/the-human-behind-a-favorite-spambot-horse_ebooks/
[2] http://tinysubversions.com
[3] https://twitter.com/twoheadlines
[4] https://twitter.com/oliviataters
[5] https://twitter.com/oliviataters/status/479836122236063745
[6] https://twitter.com/search?f=realtime&q=%23botally&src=typd
[7] http://tullyhansen.com
[8] https://medium.com/@samplereality/a-protest-bot-is-a-bot-so-specific-you-cant-mistake-it-for-bullshit-90fe10b7fbaa
[9] https://twitter.com/NRA_Tally
[10] http://iloveepoetry.com/?p=5427
2.0 How Does This Even
So, Washboard.co[1], a startup designed to solve that irritating problem of not having quarters when it's time to do laundry by shipping them to you at a cost of $15 for $10 worth of quarters, comes out at exactly the same time as renewed scrutiny for the term "disruption". 

There's a few things to note here.

The first, of course, takes a few minutes of getting used to, which is: how is this even a real thing? Are people these days (or, even, are *enough* people these days) so lazy as to pay a 50% premium to have some quarters lying around, or to not even, say, use a change machine? 

The quick answer is: well, only six people have signed up so far[2].

The second is that, it's easy to see imagine this in an ad agency creative pitch for a client like, say, Tide. The award submission video writes itself: "We set out to bring a new audience to Tide - hard to reach millenials whose only relationship to laundry detergents might be through their mothers. So we asked ourselves: how could we reach them at a relevant moment, when we could bring home to them how valuable Tide could be to them as a partner in their laundry endeavours? The answer was staring us in the face. We all remember that feeling of not having enough quarters for the laundromat: so we developed the world's first laundry quarter subscription service - brought to you by Tide. By showing that we understood the problems encountered by millenials, we could gain their trust - and bring home the real benefits of Tide in their lives."

I mean, this kind of stuff is award season *gold*. I fully expect Washboard to have been ripped off and to win big at Cannes this time next year.

The third is: holy crap, do we have any new formats for startup/product/service homepages yet? Large, full-bleed background images, vertical scrolling, thin type. You almost don't even need to read the stuff anymore. 

[1] http://washboard.co
[2] http://www.boston.com/news/local/massachusetts/2014/06/19/new-business-charges-for-quarters-can-work/stA5GE3E271nm6x6Bph1PM/story.html
3.0 Maximum Happy Imagination
I'm glad Matt Jones has started blogging again because his post about Maximum Happy Imagination[1] hit a chord. It's a short one, this, but Jones quite deftly points to the end-game of bending things in hockey-stick shaped lines toward divide-by-zero states that just don't make sense. Only, in the utopian post-scarcity world, for some reason, capitalism remains and we're still talking about "democratic capitalism to the Nth degree". 

It feels like an abrupt failure of the imagination. Almost like capitalism is a *law* that cannot be broken, that it's simply a fact. And yet here we are, quite happily imagining breaking the speed of light! Alcubierre drives, negative mass, exotic matter - all of these things, all in the service of not being happy with the status quo and wanting more out of the universe. We want 5nm manufacturing processes, we imagine matrioshka brains devouring entire stellar systems, *all of these things* and yet, and still: democratic capitalism to the Nth degree.

Now it may well be that it's impolitic to talk too loudly about replacing democracy with something else. Or replacing capitalism with something else. That might be a good reason.

But to assert (seemingly blindly) that *even in a post-scarcity world*, even in a world where we're able to do so much more than we are now, that democracy and capitalism are in effect finished projects, perfected, seems remarkably short sighted. 

The full extrapolation, in the way that Andreessen posits, of the traits and concepts of "money, competition, status-seeking or the will to power" almost sounds like it falls to the innovator's dilemma trap of assuming that all of those things are immune to disruption. Sure, you can imagine a future that has all of those things in it, assuming that all of things are inherent characteristics of our universe. And perhaps some of them are. But, in the same way that we assume that we can and might fight what we assume to be *physical* laws of the universe and find ways to change them, do we not imagine that we can change status-seeking or money or competition? 

Do we imagine that we, as hom. sap., are also immune to change and that our current predilection for status-seeking and the usage of competition to bring about forward momentum in ourselves as societies and species is immutable? 

[1] http://magicalnihilism.com/2014/06/20/maximum-happy-imagination/

-- 

Well on that note, I hope you have a good weekend. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Six: Meat Puppets; The Circuit
Date: June 20, 2014 at 12:24:20 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g689=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>





0.0 Station Ident
It was eighty-ish and sunny today in Portland, which, as I explained to a friend, makes sense because I use fahrenheit when it's hot and celsius when it's cold to get a good spread of numbers. This also probably explains why I'm not very good at baking. I keep meeting people who're reading Creativity, Inc. who look like they're emerging from some sort of horrible nightmarish fugue state and they're frantically pawing at the glass and brick and steel of Pixar's Steve Jobs building like a zombie horde wanting to be saved from bad management.

It turns out there's a lot of bad management out there.

It also turns out that one of the most consistent antidotes to bad management is a) hard work and b) giving a shit.
1.0 Meat Puppets
Okay, so as far as I can tell, this is a real thing[1], and not, as pointed out on Twitter[2] some sort of artistic intervention. What meat puppets, I hear you ask? In this instantiation, it's nothing more (more or less) than the remote control of other humans. Sure, in this version it's all opt-in: "actors" (the remote controlled humans) are directed by "directors", who tell them what to do and see what they see and experience what they experience through an outward facing 4G/LTE phone running an app. Basically, camgirls, but out in the real world.

Meat Puppets has always been a pretty derogatory term: humans being made of meat[3], after all, and puppetry implying the slack, non-conscious remote appendage controlled by something else at a distance. Of course, you have a mouth and you must scream if you're made of meat and you're being controlled by something else.

One of the signs that this is real and not, say, a piece of performance art or a scam is that it's on Kickstarter and not, say, Indiegogo, which shall we say is less thorough with the kind of stuff it allows on its site. But what's also interesting is the way that Karl Lautman, the project instigator (and, for those keeping score, someone with 20 years of experience in sales and marketing) talks about the *risks* of the project, which is something you're encouraged to do on Kickstarter. The risks are entirely project-based in terms of risks for the backers, so of course, the first (and most important risk) is that the site might not respond well to the crushing demand it will be under when it launches! Sure, it's running on the cloud ("everything that doesn't happen on the phone takes place on Amazon Web Services and is designed for scaleability"). The second risk is again, of user experience for backers and people who might be using the service in terms of *quality* of service - latency. You don't want there to be a crucial delay when you're getting your meat puppet to do something, for example. Whether that's checking out new office space (their example) or um, anything slightly less salubrious. I mean, I have *no idea* what this could possibly be used for that might be morally questionable or might take advantage of at-risk people. Oh no. Not at all. In the geek way, of course, the only real negative example that's talked about is "[assembling] an army of Actors and [making] a bid for world domination."

The following isn't intended to be a slight to Kickstarter - a service I love and respect and have used a lot as a backer (man, if that sentence doesn't sound like a "some of my best friends are on Kickstarter!" defence), but when a project like this says: "one of the reasons we're using Kickstarter is to find out how others might use Zabosu", one of the first things that comes into my mind is: you either don't have a good imagination, or you're willfully *not* imagining things and foisting them upon the "community" to say that you couldn't possibly have anticipated them.

Spoiler: humans are pretty predictable when it comes to their baser instincts.

I mean, if, for example, you wanted to harass someone at a distance in a plausibly deniable way: well, this just makes it much easier, right? So I wonder what Zabosu might be doing to counteract that. Because that's a pretty easy use-case that you'd want to design around to prevent, right? 

So, it has come to this. The meat puppets that we'd imagined in the past, and this is *yet another* way for me to point to Bruce Sterling's short story Maneki Neko[4] (Haughey, this one's for you. Again) are coming about, unsurprisingly, whether we like it or not, and it appears that they're also most likely going to come about naively and without due consideration.

Note that I'm not saying that meat puppets shouldn't come about at all. But that there are a bunch of fairly obvious, close-to-the-surface failure modes and *risks to actors, directors and the public at large* with technology like this, and it would be nice, just-for-fucking-once for someone who's proposing something like this to actually have sat down and gotten past the shit-eating "I've just had my first wank" grin of discovering/inventing something and *actually give some due care and attention* as to how technology like this will inevitably be used, abused and subverted in the wild. Because, hey, humans: it's what we do. 

So yes, it fucking grates, it *grates* when there's this irrational exuberance and copy on the project page that reads "[Blah, blah, blah. Quit slacking and back us already. You know you want to!]" because hey, I'm not saying that this project is like someone deciding to go off and do a Manhattan project, but JESUS CHRIST, I would've punched Oppenheimer in the face if, after Trinity went off, he mugged to the camera with a thumbs-up and went "PRETTY FUCKING AWESOME, AMIRITE? FUCK YEAH!" 

Because that's what this reads like. It reads like: you know what? We've managed to dehumanise people *again* and turn them into database records and not people who're trying to make a buck or who are at risk or need the extra cash so they get listed in a dumb NOSQL instance somewhere in us-east, and some dick with a credit card gets to play god. Whoopde-fucking-do. 

Oh, and what else? Yes, this week, we got the inevitable re-brand from TaskRabbit[5] which has, honestly, done wonders to debunk the stereotype that YES ALL WOMEN are sensitive, caring souls possessing empathy for their fellow human because after ages of calling *their* meat puppets "rabbits" in that goddamn stupid plinky-plonky folk music Innocent Smoothies-esque juvenileification of language, they're finally trying to grow the fuck up and instead are now calling them "Taskers" (which, you know, just sounds a bit CIA). 

The reason for this? Because they "received some feedback on [their] brand terminology."

Well, yes. When you say that the people performing tasks are like small white fluffy rabbits, then yeah, you probably are going to get some "feedback on [our] brand terminology." 

Also: stop using words like "brand terminology" because it makes you look like sociopathic idiots. No one talks like that other than c-suite hugging people who think they're too important to speak like "normal" people. 

The TaskRabbit blog post is also notable because it gives us some hard numbers. Given that they've received feedback on their brand terminology, I'm going to apply mine and say that they now have "over 25,000 meat puppets earning an income on their site" with "10 percent (2,500) running meat-puppet tasks as full-time meat-puppet jobs."

Funny how at times it was 25,000 *people* earning an income but at other times it was "Rabbits", right?

And again, nice positioning to say that 25,000 meat puppets are earning an *income*, but not, you know "contributing to their income" and then to say "full-time jobs". It's fair to say that TaskRabbit is just another way for *most* meat puppets to take up the slack from lost income, because hey, "we now provide employment to 2,500 people" isn't, well, the best number to be trumpeting. But hey, 10%, so go TaskRabbit!

Another thing that I couldn't find many details about was this, in the part of the blogpost about a New! Improved! Algorithm! that would match meat-puppets with their fractional owners:

"We present the Client with a variety of suitable Tasker candidates – some tenured, some new – so the Client is able to make their selection on the grounds they see fit (e.g. experience, ratings/ reviews or price)."

What, exactly, does "tenure" mean in the context of a zero-hours contract worker? Does it mean that they're a "permanent taskrabbit" with, oh, I don't know, benefits? Because it doesn't say anywhere in the help files. 

But anyway. Who am I to talk: I haven't used TaskRabbit either as a puppet or as a fractional owner. 

What galls me is this: that thing about what armies do in war, about dehumanising the enemy, so that you can do Bad Things to do them to override any residual sense of morality in your fighting force? Why are we dehumanising employees? Oh, it's a rhetorical question, all right: but what I'm getting at is this: is this a zero-sum race to the bottom where the entity that provides the best, basest API-to-humans wins? Or at some point is someone going to turn round and figure out a way to sustainably provide a route to work that's actually respectful? 

I say this because you've undoubtedly got Manpower, Randstad and Kelly all looking at this type of stuff and going: when do we get our cut? Or is it because they feel like they have to comply with too much red tape? There's all this paperwork that you have to fill out when you become a temp with Manpower and there's probably all these rules about the things that the companies these staffing providers provide service to about the things you're *not* allowed to ask supplied personnel to do. Presumably Zabosu is going to cover all that, right? It's not going to be some sort of disrupting free-for-all? 

[1] https://www.kickstarter.com/projects/780943604/remote-controlled-humans
[2] https://twitter.com/thejaymo/status/479739629495926787
[3] http://www.terrybisson.com/page6/page6.html
[4] http://www.lightspeedmagazine.com/fiction/maneki-neko/
[5] http://blog.taskrabbit.com/2014/06/17/unveiling-the-new-taskrabbit/
2.0 The Circuit
I have a fun-filled few months coming up full of a bunch of speaking engagements. For mostly all of them, I'm going to be exploring what I've been writing about for the past few months on the subject of empathy in product and service design. So far, if you're interested in hearing what I've got to say in a significantly more polished format, you can catch me at:

 - TEDxLiverpool, Liverpool England, 20 July 
 - Cascadia Ruby, Portland OR, 11-12 August
 - HOW Interactive, Washington D.C., 3-5 September
 - HOW Interactive, Chicago, 19-21 October

and the one I'm most excited about, a keynote at

 - Web Directions South, Sydney, Australia, 30-31 October. 

Specifically, I'll be talking about the concept of an empathy gap: the gap of understanding between an organisation and its audience. You might point to the botched introduction of Google Glass as an example of an empathy gap - the benefit of having a constant connection to the internet (and all that that entails) in your peripheral vision, combined with the decision to include a camera that can take stills and video, without understanding the social norms that such a product and display would violate (and yes, even taking into account the fact that the same *practical* effect) can easily be achieved through using a conventional smartphone surreptitiously. But this failure to understand and anticipate (or, even acknowledge, until far too late) the visceral reaction that Glass received is merely evidence of a gap int he first place. 

What I want to make clear, though, is that I don't think this idea of an empathy gap applies to just Silicon Valley and stereotypical (and untrue) accusations of autism spectrum disorder engineers releasing new technology into the world. It turns out that, rightly or wrongly, this gap is experienced everywhere from the world of travel, where an airline’s customer service can frequently feel indifferent to the needs of those on a long journey; in government when theoretical legislative policy reaches implementation; and in finance, where the world over is struggling with dealing with income equality.

So. Empathy. (Or, more accurately, having been pointed in the direction of more of Stephen Pinker's stuff that I need to read, sympathy and reason). I'm super excited.

If you're interested in having me speak at your conference, drop me a line at dan@danhon.com. I give good talk.

--

Thursday! You know what I love about Thursdays? Especially when they finish? Waking up to notes from people I've never heard from before. They're always awesome. Oh, and notes from people I have heard from before, too.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Five: This Incredible Journey; What Comes First; Who Owns The Robots
Date: June 18, 2014 at 10:26:26 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g55t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


1.0 This Incredible Journey

A good (I hope!) friend of mine runs the Tumblr Our Incredible Journey[1] and has recently found that they've needed to explain[2] what, exactly an Incredible Journey is. You should go read that explanation, but the gist of it is this:
The "Incredible Journey" construct is drawing attention to the now-cliche of a startup exiting through acquisition and closing down its service, shuttering everything and essentially deleting data. It's a bait-and-switch. Founders are typically *very excited* and honored to become part of the acquiring company and they write effusively about the new opportunities afforded to them. 
But, all of this comes at a cost: the time, data and effort expended by that now closed service is now lost. It's a model that's repeating because the Valley has a particular model of emphasising growth over (profitable) revenue, where the big plan is an exit and other forms of less hard cash value. 
This is also, it feels like, a protuberance of the Californian Ideology again. In the world that practically worships a utilitarian view of ethics, it doesn't matter if a small number of users lose out if the acquisition and closure of service is to deliver a bigger vision to more people. It's always the next thing, the big thing, the growth thing. 
And I get to bang my empathy/sympathy drum a bit more and perhaps revisit the whole value exchange again. User data generates value. That value can be captured in lots of different ways - from advertising revenue against present or future value, or in terms of demonstrating the capability of a team to execute against a product definition to show their value to a potential acquirer. 
It's almost like a mating dance - I used to love the description of the language that Stephen Baxter used in his Phase Space/Time/Space/Origin collection of books of Sheena 5 and the uplifted squids: "Court me. Court me. See my weapons! I am strong and fierce."[3] 
"Look at the users we attracted! See their data! Admire the way we execute onboarding processes!"
All of that to preen and to position for talent acquisition - in the worst cases, of course - where users are but collateral damage. So Incredible Journey, in that TRON way, fights for the user, stands to remind that they exist, that there *was* a value exchange and no, it wasn't explicit, and that what was poured into that startup's mating attractor was human endeavour that's now gone, forever. And for what.
[1] http://ourincrediblejourney.tumblr.com/
[2] http://ourincrediblejourney.tumblr.com/post/89180616013/what-is-an-incredible-journey
[3] http://www.vondanmcintyre.com/squids/baxter-sheena5.html
2.0 What Comes First
I'm reading Ed Catmull and Amy Wallace's book, Creativity, Inc.[1] (You should buy it - click that link!) at the moment. Anyone who's followed this newsletter for a while, or knows me well enough, knows that I'm a stupendous Pixar fan - not just because of the movies that they've produced, but because of *how* they've produced them and the creativity and culture that they foster in their production. I'm also lucky enough to know a friend at Pixar who's been gracious enough to show me around a couple of times, both of which have been nigh-on religious experiences. 
I used to think that my former employer, Wieden+Kennedy, was close to Pixar in terms of culture, and after reading Catmull's book, I'm not as sure. I realise that all of this is now also through the lens of layoffs, but there were a couple of clarifications and areas that I've seen in Catmull's telling of how he's tried to nurture a constantly changing, evolving, adaptive and curious culture at Pixar.
W+K has this motto that "the work comes first" and it's frequently used to justify things like pushing off client meetings because the work isn't ready yet. That's one of the good qualities about the place: that it's willing to wait and perfect the work and when it's ready to share with a client - when it's good enough - *then* it will be presented. We were reminded, of course, that it also cut the other way: we might be persuaded that the work we had conceived of was to be protected and to fight tooth and nail for it against the client, persuading them of its value and ability to solve the particular communications problem. But at the same time, we had to recognise that creating *better* work, that *better* solved the problem was also a way out. 
While both organisations share a commitment to quality and craft, I do see something unique in the way that Catmull describes what he considers to be more important - people or ideas. In Catmull's mind, the answer, hands down, is: people. Ideas aren't out there, waiting to be discovered. The new has to be painfully created, wrought out of not necessarily nothingness, but synthesised and birthed. And I think birthed is the right kind of metaphor: to start from a tiny seed and to be grown in fits and starts - but then the metaphor falls down, because (and I agree with Catmull here) - we don't know where we're going. We might know we're going *forward* - or more accurately, we might know that we're *moving* - but we might not know where we're going to end up, and it's continual acts of course correction that make sure that we make land. 
But ultimately, those ideas come from people. They aren't there to be discovered by just anyone. And people are thus the most important resource of any creative organisation. There are numerous other factors involved - the way Catmull talks about creating an atmosphere that's receptive to and able to produce candor is fantastic. I highly recommend reading the book if you're involved in any creative endeavour whatsoever. 
So no, I no longer believe the work comes first. I believe the people do, and Catmull does a good job of showing how hard it is to actually *act* in a way that demonstrates that people come first. And not just some people, but all people, in a way that requiring everyone who's contributing to producing a feature film needs to feel like a team to work like a perfectly oiled machine. And, perfectly oiled machines still make noises. 
One of the other things that stuck with me was a saying that Catmull attributed to Lasseter: "Art challenges Technology, Technology Inspires Art". It's the kind of quote that, like "Standing at the intersection of the liberal arts and technology" feels like it speaks tremendously to me. 
One of the things that I loved about being at Wieden was working with storytellers who would get inspired by technology and wanted to do things with it. It was interesting because at the time, like most other agencies, we were figuring out what our role was in "digital" and "interactive". I had come from a non-advertising background, a startup background, and had never really intended to end up in advertising. And yet, the chance to work with some of the best storytellers in the world and *inspire* them with technology and then produce *new kinds of storytelling* that pushed technology, created new kinds of story, new ways of telling story - that was the promise that brought me to the agency. I would love to be able to say: look at what we can do now. Look at these things. And look how you could bring them alive! And for us to make them live, to make them sing, to make them *move* people, we can only do it with storytelling *and* technology. That was the promise, and it extended through not just storytelling but through services and products that used the best of storytelling to solve problems. That was what got me excited.
I've gone through the startup mill twice - once at Mind Candy, as second to my founding CEO, building up a team with him, and the second time with my brother at Six to Start. Both times, some of the most rewarding experiences I've had have been when I've brought teams together, inspired them and led them to make fantastic things. Sometimes those things were too early, sometimes they weren't fantastic enough. And almost embarrassingly,  one of the times I knew that I'd succeeded in helping to build a close-knit team was when we were running close to the wind, again, at Six to Start (it's never a good idea to start a company in a down economy) and it was time to have The Talk about the cashflow problems we were facing. As a manager and owner having gone through the process of making sure that everyone else is paid before you are, having people say that they would work for you *for free* through this difficult period was incredibly moving. And we would say: that isn't the point. You're supposed to get paid. We're all supposed to get paid. 
There are times when I know that I'm doing the best I could be though, and all I can do is try and remember for next time. So one of the hardest things for me to learn when I arrived at W+K Portland was that I was a director now, and that I wasn't necessarily *doing the work*. It wasn't my job to solve the problem, because I had incredibly talented, smart, more than competent people on my team who were more than capable of solving them problem themselves. As someone who loves solving problems, that was one of the hardest things to give up - I love being at the whiteboard and sketching out how things might work. But over time, I learned that as a director, my role had changed and that it was now different: that it was giving guidance and not doing the work. 
But part of me still wants to do that: still wants to build a team from the ground up, to solve big problems, to make a big difference. And part of it is because again, some of the best and most personally rewarding experiences (and, to be honest, shit-bricking experiences) have been the "how do we react in a crisis moments" of pulling a team together and showing clarity, direction and that there's a way out of the situation that we're in. That we might feel like we're stuck, but we're still a team and if we all start moving, it's all going to be OK and we're going to make land. 
And then there are things like realising: valuing the people at an organisation is as much as knowing who's a good fit and that what's good for *them* might be for them not to remain. It may well be that my former employer has decided that their core is advertising, and while the things that I wanted to do there were indeed great ways of solving client problems, they were a step to far in terms of reach of what they wanted to do. They are, and perhaps always will be, an advertising agency, not the kind of company that makes products or services because that office is, at its heart, passionate and exists to make storytelling. 
That's something that I did get from Catmull's book - Pixar didn't suffer from an existential crisis. It's not so much about navigating change in a changing business environment in the way that ad agencies are still having to do. Pixar always knew what it wanted to do: it wanted to make the best computer animated movies. The challenge for an advertising agency like Wieden is: it used to be clear what advertising was. It still is, in a way, clear what advertising is. But the advent of "digital" and "interactive" has meant that that line has blurred, and the agency has to decide where it wants to hang its hat. Its competitors are all trying to build products and services and it has to preserve what is core and true to itself. 
For me, it's clear now that that's *advertising*. And advertising doesn't at its core have products and services. Advertising is a communication business, and brand advertising doubly so. To say that communication can occur inside of services and products is of course true, but they're not easy forms of communication to buy from the outside. They are big, hard problems to solve. Especially when those channels might already exist. 
I wouldn't be surprised if I do a startup again. I know my wife wouldn't be. I feel like I'm quietly waiting, like a seed, for the right conditions. For the right time to take that step again. And then I'll bloom.
[1] Amazon: http://amzn.to/1lB5X3w
3.0 Who Owns The Robots
That's the sting of Alex Payne's well-written critique[1] of Marc Andreessen's optimistic position on the big-picture success of capitalism in pulling *humanity's* (note: not different states) standard of living up over the past hundred years or so. 
The question that I've always been asking is this: what sort of society do we want to create? Because (surprise) we have the power (in theory) to create the sort of society we want (if, I guess, you ignore the somewhat worrying studies that show that in late-stage capitalist democracies like the US, an individual's vote is somewhat... less than effective). 
I do think that there are some issues that aren't covered in Payne's essay. Namely that yes: labor wants self-determination, but one of the things that labor *doesn't* get, is to choose the environment that it finds itself in. None of us do. And yes, while the pushback may be on exploitative business models, the issues around a company like Uber are complex. Because Uber is playing a long game, a longer game than, I would venture, the average taxi driver would be expected to play. What I mean by that is: Uber's appetite is big, obviously and demonstrably so. It is also being *encouraged* to have a big appetite. What a lot of people see is the prototypical "disruption" in a market that hasn't had software eat it yet. But again, software that driving taxis does it in a bunch of different ways. It does it in the long-term where Uber's CEO, Travis Kalanick, admits that of course Uber's future is in self-driving cars. 
The kind of self-determination that labor is talking about in Payne's case needs to necessarily encompass: what sort of labor does a self-determining individual want to do when taxi-driving is something that has become automated? 
And to remember this: Uber's goal isn't to provide a great working environment for drivers. It isn't even to ensure that drivers have a job. Taxicab companies have that requirement, but again, Uber's appetite is bigger.
Payne, I think, has identified the problem with the whole "technological gains will increase productivity that will pay for the future safety net". That's the post-scarcity argument: that at some magical point in the future, someone flicks a switch and everything becomes free. Not that we live through an incredibly painful period of transition that's within our power to smooth out. Not that those types of technological change happen everywhere at the same time. There's a reason why everyone keeps quoting Gibson's "the future is here, it's just not evenly distributed." 
It's that in the *entire history of mankind* we've never been good at distributing. There is no reason to believe, in the same way that Payne puts forward, that the magical robot future will lead to even distribution of technological advancements. Sure, capitalism and the market might be a way to achieve *faster* distribution than ever before given that we live in a more interconnected infrastructural world, but that's only an improvement *inside the framework of capitalism*. 
What happens if you want to distribute that change *faster* than the way that capitalism can allow? Or can we only think inside of the market (sorry, share) economy box?
And, of course, there was the whole notion of the sharing economy lurking in the background. There's a reason, I believe, that we're calling it the sharing economy and not the peer economy as some used to. It's because it sounds better. It sounds nicer. It sounds warmer. It ticks off all the right *brand values*. 
But the peer economy - well, we would have to explain what peers are, right? That peers are equal? Oh, they're not equal? Some are more equal than others? That's the reality that the Bitcoin community are coming to face with the news that there's a mining bloc that had the majority of blockchain processing: that's not distributed peer-to-peer based cryptocurrency. It's the start of centralised control. A single point of failure. 
So no, we don't have peer economies anymore. We have sharing markets. And we don't have the concept of a peer. 
You want more disruption? You start closing the loop and allowing microloans to enable people to buy their own airbnb property to rent out, right? And not doing it through mortgage providers. Maybe that's closer to a peer economy. Or you allow microloans to enable people to pull together community resources to build Ubers. Or, you build an open-source Uber clone (because hey, you could do that, right?) and let the drivers compete against Uber. Because we're sharing, right?
[1] https://al3x.net/2014/06/17/dear-marc-andreessen.html
--
Send me notes. They power me. Like little midichlorians.
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Four: The New Jobs; Disrupting Bitcoin; Protect Us; The Full Stack Is Better?; Dumb Screens
Date: June 17, 2014 at 10:18:11 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g4bp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm writing this at the weekly 30,000 feet, perilously typing into a textarea that's on the end of a flaky Gogo Wifi connection to the ground. Today and tomorrow are NOSTROMO BLACK days, the last bit of typing for coins and client presentation before potentially a new project opens up. NOSTROMO BLACK also means travelling (duh) a bit further down the west coast to Las Vegas, for my very first visit. Bets open as to what I could possibly be doing in Vegas and why will be accepted via return note.

1.0 The New Jobs

Last episode[1], I asked, more-or-less, when (thought-experiment "when", not literal "when") Uber transitions its cars to driverless and we all live in some sort of cartopia where we never have to drive and on-demand automobiles seamlessly shuttle us from one location to another at just the tiniest waggle of our smartphone-wielding hands, what are the best Uber drivers going to be? 

It's kind of related to thinking about: what are the new jobs going to be, what with all this disruption going on? There are the short-term new jobs - the Ubers and TaskRabbits and mainly three-to-five-year arbitrage where there's people who need something that hasn't been automated away yet (extreme example: teens who are good at making glitter-makers for other teens' MySpace profiles to the more up-to-date "good Wordpress themes" version) but that's a bit of a treadmill. Is there something else, something that's uniquely human that could sustain you for say five to ten years, almost approaching something like a mini-career?

So the thinking is like this: what are the transport jobs in a society with *completely* commoditised on-demand transport? Are drivers in that world the archetypal "driver" who's discreet and will transport you places off-the-books, no questions asked, never shows up on the household transport account, Madam?

And then, what are the other jobs? The fictional Dr. Susan Calvin[2] was a cyberneticist who ended up specialising in robopsychology. The film and game that got me into all of this mess (in a way) featured a sentient machine therapist. But *right now* in the same way that there are people who make a living sorting out the *physical* plumbing of your house, will there be people who sort out the *software* plumbing of your house? Or your life? In a way (he says, handwavingly, rather like a Church of England clergyman who's being reminded of Our Lord Jesus), isn't physical plumbing a sort of integration job in the same way that you might call the local sysadmin around to sort out your hodgepodge of software and hardware services at your apartment? 

"Yeah, you've had some right cowboys in here. See, you've got a Netgear NAS, yeah, that's one of the five-thousand-series, they recalled those back in the the twenties because the SSDs suffered from a MTBF that was way out of whack *sucks in deeply* so we're gonna have to replace that, you've been backing up to the cloud, yeah? Oh, iCloud? Yeah, we'll need to have a look at that iCloud setup, see they've been failing silently with bit rot, depends - we'll have to check to see if you're backing up to Ireland or to Telehouse - oh, and you said something about the toaster's Dropcam not working? Probably a compatibility issue with it and the new codec - you've got a late teens Dropcam, so it's firmware... *pauses* oh, I've not seen one of these for a while. That's an original firmware! With the Bobby Tables backdoor! The boys back at the office'll love to see that, I'll take an image of that one! And this? What's this? A SkyPlus DVR with WatchAnywhere? Not seen one of those in years! With HDMI 4.0! Yeah, we'll have to rip all of this out."

And then you get an invoice for about three hundred quid and all she did was slag off your home network for about half an hour and then nothing worked for a week while everything was being reconfigured. 

Already we're seeing jobs like curators - and I hate using the term - proliferate. A business like Consumer Reports is being bought kicking and screaming into the networked age through highly defined and regularly updated sites that make money from affiliate fees, not gated access with the likes of new entrants like The Wirecutter[3] and its siblings The Sweethome[4] and The Nightlight[5], now being aped by Vox media with This Is My Next[6]. These jobs necessarily rely on network effect, attention and audience gathering. You can *run* one of these as a platform, which is less of a job and more of an entrepreneurial business, or you can contribute to one. In which case, we're talking about specialised communicators, writers[7]. 

There are also the elements where people *like* having tasks done by a human, even if they could get equivalent or better or safer service from a computerised system. My former employer is working with Turbotax trying to persuade people to switch from using meat-puppet accountants (who, at the low-end, are reasonably-paid meat puppets performing some sort of Chinese-room equivalent of financial and tax jiggery-pokery behind the veil of a limited liability corporation) to rule-based software systems that are good-as-low-end-human. In the same way that there are some of us who think that the "car thing" will never go away because, at least in America, *driving* is as much a God-given right as owning a gun is (and I'm not going to pull the pin on that particular hand-grenade save to note that I wouldn't be *entirely* surprised if there were a hot-button self-determination issue to get "the right to drive" as a new constitutional amendment). Again, my former employer put this to great effect in their campaign for Dodge, positioning the All-American car manufacturer as for lots of things, apart from letting computers drive our cars for us[8].

The stack of cards that's the advertising business continues to reach for the moon. The fact that it's entirely reasonable for a tweet to take 45 days from brief to deployment is by-the-by[9]. The other side of the narrative is that when a company has the potential for a persistent connection with its customers (sorry, audience) that's a big gap that needs to be filled with, well, "stuff" (if, indeed you're the kind of company that likes filling gaps with stuff, whether they should be filled or not. Certain companies would make great donut manufacturers), and the stuff is invariably being filled with "people". Digital media has meant that we're faced with a glut of inventory, and while every application might expand until it's available to read email, every online service or product apparently also has to expand until it's able to serve targeted advertising, at which point that advertising needs to exist as inventory and inventory needs to be dealt with, programatically or no. Whither the days of teams of people crafting beautiful full-page newspaper spreads, these days, it's filling social content calendars and planning out strategy. It's about as opaque as it ever was, with new metrics replacing old metrics and questions still not entirely being answered the whole time.

Goldfarming wasn't even a thing until persistent net connectivity reached a threshold audience, and even then, goldfarming was something that happened in developing countries (or, in another way, the "differently enfranchised" - ie teens and children who wouldn't otherwise be able to earn money, but for whom the internet, as a giant communications network, wouldn't particularly care whether they were of age or not). Is that something people will pay to get better at? Will there be enough disposable income such that you'll hire the equivalent of a personal trainer for Bungie's Destiny, or for Respawn's Titanfall? Or, even, what sort of added-value infrastructure will next-generation clans need? 

This all sounds rather idealistic but, from a government's point of view (or, I guess, from an entrepreneur's point of view), what do you get all the meat-puppets to do? How jobs are genuine meat-puppet jobs where the meat just provides a presence and a legally safe way to transact or operate machinery? The whole spiel about the "knowledge economy" turns out to be pretty thin when a lot of the knowledge economy appears to be having useless meetings about things and deciding what to do with all the unread emails in your Outlook inbox about needing to clear your food out of the fridge. 

I suppose the real question is this: what things are humans *best* at? 

As an aside, is the Uber argument even zero-sum? Is there only room for one Uber? (Lyft feels like an also-ran, but then I don't live in the Bay Area and I'm not a witness to the white-hot heat of disruption and how it feels on the ground) Where's the brand differentiation? Is there even room for differentiation? If all you're doing is satisfying a need to get from one place to another, does it matter *how* you arrive? (Sure it does: anyone who wants to make an impression wants to arrive in the right kind of car, right? There's arriving at your date's house and trying to impress him with the Google kawaii car and arriving in a Tesla S).

[1] http://newsletter.danhon.com/episode-one-hundred-and-three-recurring-better-but-not-best/
[2] http://en.wikipedia.org/wiki/Susan_Calvin
[3] http://thewirecutter.com
[4] http://thesweethome.com
[5] http://thenightlight.com
[6] http://www.theverge.com/2014/6/11/5798884/welcome-to-this-is-my-next-your-buying-guide-for-the-future
[7] http://thewirecutter.com/jobs/
[8] https://www.youtube.com/watch?v=ajZm6Ew4ODI
[9] http://www.businessinsider.com/huge-social-media-manager-does-all-day-2014-5
2.0 Disrupting Bitcoin
A reader pointed me toward this article[1] about a disturbance (ha) in the bitcoin mining space.

The gist - from what I can make out - is that one particular entity has achieved a majority of network mining power for a significant period of time, in this case, about 24 hours. Majority control of network mining power appears to equate to certain denial of service attacks, but perhaps more central to this is the idea that Bitcoin was supposed to be a decentralised service where trust was distributed. When you end up having to trust one large entity, one of the founding ideologies of Bitcoin ends up evaporating. 

From my naive point of view, this feels like what happens when idealistic technology encounters run-of-the-mill humans who're incentivised by hard cash (albeit one in a different financial system). It's interesting to look at whether this constitutes some sort of panic regarding bitcoin - that the currency and infrastructural system around it suffers (or adheres to) the same kind of confidence requirement that any monetary system does. There's now talk, I bet, of "faith in Bitcoin" which would spur protocol and algorithm development of an even more decentralised protocol and web of trust and verification that, one imagines, would lead to another Red Queen sort of race to game the system. 

[1] http://hackingdistributed.com/2014/06/16/how-a-mining-monopoly-can-attack-bitcoin/

3.0 Protect Us
In a not altogether unsurprising move, data crunched from Nest Protect sensors[1, 2] have revealed that you're more likely to suffer from carbon monoxide poisoning than previously thought, so you'd better go get a carbon monoxide alarm. 

Now, this sort of aggregate data is great - from 400,000 homes, so not an insignificant amount, I suppose - and hey, we always knew that replacing reckons with data was going to be a good thing, too. 

I don't have a Nest Protect. I don't know how mnuch data you get access to, but at some point, you imagine a sort of "data in the public interest" legislation that would be inefficient for the government to collect. Regulatory authorities aren't (or are they?) going to require every homeowner (or a majority of homeowners) to include public health sensors in their homes, and you could argue that they'd be hard pressed to in the US with issues of self-determination, privacy and overreach. So when it falls to the private sector to instrument the world that we live in, and that data could be useful to public policy, what happens? 

[1] http://gizmodo.com/how-nest-is-already-using-all-that-data-from-its-army-o-1591811364
[2] https://nest.com/downloads/press/documents/co-white-paper.pdf
4.0 The Full Stack Is Better?
I'm sitting here trying to figure out a way of talking about this particular issue without necessarily finger-pointing or doing the usual "ooh, Google" dance. Let me give you personal example. Portland, Oregon, is a step closer to getting Google Fiber now that its council has voted through granting a local broadband franchise to our favourite mathematically inspired conglomerate.

My wife, in her usual insightful way (all of my best ideas are, naturally, hers and I just take credit for them) pointed out that we could either deal with the devil we knew, Comcast, in which case we knew them to be pretty institutionally incompetent and gouging, or we could potentially deal with Google, with whom we could guess to be almost unnaturally efficient in trying to not be evil. Trading one titan for another, without any real choice doesn't feel like any real choice. 

I've already done some things that at times feel more like tilting at windmills and mere acts indicating defiance rather than something that actually *matters* - my emails are signed now, so I suppose you know if they come from me or not - and my email moved a while ago from Gmail to Fastmail.

I suppose the frustration is in this, something that also came out over lunch today. I was complaining about how terrible EHR software was and how you'd get something like Epic's MyChart as an add-on as a hospital system in that Epic would, I presume, sell you an add-on "oh look, your patients get an app! You get an app! You get an app too! Everyone gets apps!" when you buy into their more-or-less vendor-locked-in "solution". I would say something like: MyChart is terrible, to which my stockholm syndrome lunch meet would protest "yes, but it's better than nothing!"

Screw nothing! Screw better than nothing! Just because it's better than nothing doesn't mean it's *good*. (ZoomCare, another Portland-based primary healthcare provider, felt like it was 

And I guess the deal is this: Google is certainly better than what we had before. I hope that we can get *even better than Google* and I wonder how much of that will be able to deal with the capriciousness of human beings. By that, I mean this: Google is the product of not only hundreds of thousands of servers toiling away in farms, but it's also the product of tens of thousands of *people*. And people are, well - I'm going to jump on the bandwagon and say you just have to read Franz Kafka's The Trial, not Orwell's 1984 to get an idea of what people can be like - people. The technology is a human construct that, which algorithms reflect the biases of humans. They don't *have* to, it's just that if you're not constantly on the look-out for how they *might* be doing that, you just won't spot it. 

So the deal with the Full Stack is: yes. Fine. We get a search platform. We get a stupendous world-spanning video platform. We get real-time translation. We get mobile phones. We get maps. We get near real-time satellite data. We get super-fast internet access. We get self-driving cars. We get, gosh, so many things. We get it all! In one place!

I wish I had something more constructive to say than "I have a bad feeling about this," but I don't, really. Centralisation just doesn't feel good. And a really, really, really tall integrated stack feels like it just also might be good at tottering over.

[1] http://www.theverge.com/2014/6/16/5814380/google-fiber-is-cleared-to-land-in-portland
5.0 Dumb Screens
My friends at Berg have done a lot of thinking about this, and I know there's a lot of other thinking out there too. Experiments with e-ink screens persistently showing ambient information, and the idea of living *with* screens instead of them just being black mirrors that tempt us in infinitely configurable ways. 

One thing that's struck me about screens - and it looks like the idea might be coming back with Apple's iOS 8 and Yosemite through something they're calling Handoff - is that they're so *dumb* in some ways. I'll give you an example: I long thought that if you had to choose between a network-connected screen or a 3D screen, you'd choose the network-connected one. Sure, the choice is a false one because you'd get the network connection with a 3D TV anyway, but the fact remained that connecting to the network made something that much more powerful and flexible.

Or so I thought. 

The internet connections in smart TVs (never mind displays) these days feel more like they're about content delivery than the fact that holy shit you've got in best-case a gigabit ethernet connection plugged into that thing over there. And it goes both ways! So whilst we have input screens and output screens (and the TV still has a big role as, well, the biggest output screen), it's also something where it feels like it's a piece of - well - functionality and furniture. The big TV is the centerpiece of a room, it's something that so many other things are still arranged *around*. 

So the idea of a TV that is aware of all the other screens in the house in a way that's smarter than just AirPlay or Chromecast, that acknowledges that there are all these other screens, or that knows for argument's sake what *room* it's in and acts accordingly is super interesting. 

And that's just TVs. Screens that are aware of each other in terms of close proximity - if you haven't played Spaceteam[1], you should - that take advantage of physical presence and the fact that we have a supercomputer in our pocket that's got local two-way communication to people who're in the same room as you. Because people are often in the same room as you. 

It feels like there's been a fair amount of work done in this area - Bump is a boring one - but at the same time it feels like most of the work is the *boring* kind - the problem solving utility, hey, let's try and build something in the Valley that's going to scale, that isn't necessarily really creative and, well, fun. 

So I'm going to think about that. Fun things to do with people near you. Not in a Tinder-way. But in a fun way. 

[1] http://www.sleepingbeastgames.com/spaceteam/

--

That's it for today. Have you never sent me a note before? Do you know how easy it is? It's easy: you hit reply, and then you start typing and then an amount of time later, you stop typing and you hit send. There. Easy.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Four: The New Jobs; Disrupting Bitcoin; Protect Us; The Full Stack Is Better?; Dumb Screens
Date: June 17, 2014 at 10:12:20 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident
I'm writing this at the weekly 30,000 feet, perilously typing into a textarea that's on the end of a flaky Gogo Wifi connection to the ground. Today and tomorrow are NOSTROMO BLACK days, the last bit of typing for coins and client presentation before potentially a new project opens up. NOSTROMO BLACK also means travelling (duh) a bit further down the west coast to Las Vegas, for my very first visit. Bets open as to what I could possibly be doing in Vegas and why will be accepted via return note.

1.0 The New Jobs

Last episode[1], I asked, more-or-less, when (thought-experiment "when", not literal "when") Uber transitions its cars to driverless and we all live in some sort of cartopia where we never have to drive and on-demand automobiles seamlessly shuttle us from one location to another at just the tiniest waggle of our smartphone-wielding hands, what are the best Uber drivers going to be? 

It's kind of related to thinking about: what are the new jobs going to be, what with all this disruption going on? There are the short-term new jobs - the Ubers and TaskRabbits and mainly three-to-five-year arbitrage where there's people who need something that hasn't been automated away yet (extreme example: teens who are good at making glitter-makers for other teens' MySpace profiles to the more up-to-date "good Wordpress themes" version) but that's a bit of a treadmill. Is there something else, something that's uniquely human that could sustain you for say five to ten years, almost approaching something like a mini-career?

So the thinking is like this: what are the transport jobs in a society with *completely* commoditised on-demand transport? Are drivers in that world the archetypal "driver" who's discreet and will transport you places off-the-books, no questions asked, never shows up on the household transport account, Madam?

And then, what are the other jobs? The fictional Dr. Susan Calvin[2] was a cyberneticist who ended up specialising in robopsychology. The film and game that got me into all of this mess (in a way) featured a sentient machine therapist. But *right now* in the same way that there are people who make a living sorting out the *physical* plumbing of your house, will there be people who sort out the *software* plumbing of your house? Or your life? In a way (he says, handwavingly, rather like a Church of England clergyman who's being reminded of Our Lord Jesus), isn't physical plumbing a sort of integration job in the same way that you might call the local sysadmin around to sort out your hodgepodge of software and hardware services at your apartment? 

"Yeah, you've had some right cowboys in here. See, you've got a Netgear NAS, yeah, that's one of the five-thousand-series, they recalled those back in the the twenties because the SSDs suffered from a MTBF that was way out of whack *sucks in deeply* so we're gonna have to replace that, you've been backing up to the cloud, yeah? Oh, iCloud? Yeah, we'll need to have a look at that iCloud setup, see they've been failing silently with bit rot, depends - we'll have to check to see if you're backing up to Ireland or to Telehouse - oh, and you said something about the toaster's Dropcam not working? Probably a compatibility issue with it and the new codec - you've got a late teens Dropcam, so it's firmware... *pauses* oh, I've not seen one of these for a while. That's an original firmware! With the Bobby Tables backdoor! The boys back at the office'll love to see that, I'll take an image of that one! And this? What's this? A SkyPlus DVR with WatchAnywhere? Not seen one of those in years! With HDMI 4.0! Yeah, we'll have to rip all of this out."

And then you get an invoice for about three hundred quid and all she did was slag off your home network for about half an hour and then nothing worked for a week while everything was being reconfigured. 

Already we're seeing jobs like curators - and I hate using the term - proliferate. A business like Consumer Reports is being bought kicking and screaming into the networked age through highly defined and regularly updated sites that make money from affiliate fees, not gated access with the likes of new entrants like The Wirecutter[3] and its siblings The Sweethome[4] and The Nightlight[5], now being aped by Vox media with This Is My Next[6]. These jobs necessarily rely on network effect, attention and audience gathering. You can *run* one of these as a platform, which is less of a job and more of an entrepreneurial business, or you can contribute to one. In which case, we're talking about specialised communicators, writers[7]. 

There are also the elements where people *like* having tasks done by a human, even if they could get equivalent or better or safer service from a computerised system. My former employer is working with Turbotax trying to persuade people to switch from using meat-puppet accountants (who, at the low-end, are reasonably-paid meat puppets performing some sort of Chinese-room equivalent of financial and tax jiggery-pokery behind the veil of a limited liability corporation) to rule-based software systems that are good-as-low-end-human. In the same way that there are some of us who think that the "car thing" will never go away because, at least in America, *driving* is as much a God-given right as owning a gun is (and I'm not going to pull the pin on that particular hand-grenade save to note that I wouldn't be *entirely* surprised if there were a hot-button self-determination issue to get "the right to drive" as a new constitutional amendment). Again, my former employer put this to great effect in their campaign for Dodge, positioning the All-American car manufacturer as for lots of things, apart from letting computers drive our cars for us[8].

The stack of cards that's the advertising business continues to reach for the moon. The fact that it's entirely reasonable for a tweet to take 45 days from brief to deployment is by-the-by[9]. The other side of the narrative is that when a company has the potential for a persistent connection with its customers (sorry, audience) that's a big gap that needs to be filled with, well, "stuff" (if, indeed you're the kind of company that likes filling gaps with stuff, whether they should be filled or not. Certain companies would make great donut manufacturers), and the stuff is invariably being filled with "people". Digital media has meant that we're faced with a glut of inventory, and while every application might expand until it's available to read email, every online service or product apparently also has to expand until it's able to serve targeted advertising, at which point that advertising needs to exist as inventory and inventory needs to be dealt with, programatically or no. Whither the days of teams of people crafting beautiful full-page newspaper spreads, these days, it's filling social content calendars and planning out strategy. It's about as opaque as it ever was, with new metrics replacing old metrics and questions still not entirely being answered the whole time.

Goldfarming wasn't even a thing until persistent net connectivity reached a threshold audience, and even then, goldfarming was something that happened in developing countries (or, in another way, the "differently enfranchised" - ie teens and children who wouldn't otherwise be able to earn money, but for whom the internet, as a giant communications network, wouldn't particularly care whether they were of age or not). Is that something people will pay to get better at? Will there be enough disposable income such that you'll hire the equivalent of a personal trainer for Bungie's Destiny, or for Respawn's Titanfall? Or, even, what sort of added-value infrastructure will next-generation clans need? 

This all sounds rather idealistic but, from a government's point of view (or, I guess, from an entrepreneur's point of view), what do you get all the meat-puppets to do? How jobs are genuine meat-puppet jobs where the meat just provides a presence and a legally safe way to transact or operate machinery? The whole spiel about the "knowledge economy" turns out to be pretty thin when a lot of the knowledge economy appears to be having useless meetings about things and deciding what to do with all the unread emails in your Outlook inbox about needing to clear your food out of the fridge. 

I suppose the real question is this: what things are humans *best* at? 

As an aside, is the Uber argument even zero-sum? Is there only room for one Uber? (Lyft feels like an also-ran, but then I don't live in the Bay Area and I'm not a witness to the white-hot heat of disruption and how it feels on the ground) Where's the brand differentiation? Is there even room for differentiation? If all you're doing is satisfying a need to get from one place to another, does it matter *how* you arrive? (Sure it does: anyone who wants to make an impression wants to arrive in the right kind of car, right? There's arriving at your date's house and trying to impress him with the Google kawaii car and arriving in a Tesla S).

[1] http://newsletter.danhon.com/episode-one-hundred-and-three-recurring-better-but-not-best/
[2] http://en.wikipedia.org/wiki/Susan_Calvin
[3] http://thewirecutter.com
[4] http://thesweethome.com
[5] http://thenightlight.com
[6] http://www.theverge.com/2014/6/11/5798884/welcome-to-this-is-my-next-your-buying-guide-for-the-future
[7] http://thewirecutter.com/jobs/
[8] https://www.youtube.com/watch?v=ajZm6Ew4ODI
[9] http://www.businessinsider.com/huge-social-media-manager-does-all-day-2014-5
2.0 Disrupting Bitcoin
A reader pointed me toward this article[1] about a disturbance (ha) in the bitcoin mining space.

The gist - from what I can make out - is that one particular entity has achieved a majority of network mining power for a significant period of time, in this case, about 24 hours. Majority control of network mining power appears to equate to certain denial of service attacks, but perhaps more central to this is the idea that Bitcoin was supposed to be a decentralised service where trust was distributed. When you end up having to trust one large entity, one of the founding ideologies of Bitcoin ends up evaporating. 

From my naive point of view, this feels like what happens when idealistic technology encounters run-of-the-mill humans who're incentivised by hard cash (albeit one in a different financial system). It's interesting to look at whether this constitutes some sort of panic regarding bitcoin - that the currency and infrastructural system around it suffers (or adheres to) the same kind of confidence requirement that any monetary system does. There's now talk, I bet, of "faith in Bitcoin" which would spur protocol and algorithm development of an even more decentralised protocol and web of trust and verification that, one imagines, would lead to another Red Queen sort of race to game the system. 

[1] http://hackingdistributed.com/2014/06/16/how-a-mining-monopoly-can-attack-bitcoin/
3.0 Protect Us
In a not altogether unsurprising move, data crunched from Nest Protect sensors[1, 2] have revealed that you're more likely to suffer from carbon monoxide poisoning than previously thought, so you'd better go get a carbon monoxide alarm. 

Now, this sort of aggregate data is great - from 400,000 homes, so not an insignificant amount, I suppose - and hey, we always knew that replacing reckons with data was going to be a good thing, too. 

I don't have a Nest Protect. I don't know how mnuch data you get access to, but at some point, you imagine a sort of "data in the public interest" legislation that would be inefficient for the government to collect. Regulatory authorities aren't (or are they?) going to require every homeowner (or a majority of homeowners) to include public health sensors in their homes, and you could argue that they'd be hard pressed to in the US with issues of self-determination, privacy and overreach. So when it falls to the private sector to instrument the world that we live in, and that data could be useful to public policy, what happens? 

[1] http://gizmodo.com/how-nest-is-already-using-all-that-data-from-its-army-o-1591811364
[2] https://nest.com/downloads/press/documents/co-white-paper.pdf
4.0 The Full Stack Is Better?
I'm sitting here trying to figure out a way of talking about this particular issue without necessarily finger-pointing or doing the usual "ooh, Google" dance. Let me give you personal example. Portland, Oregon, is a step closer to getting Google Fiber now that its council has voted through granting a local broadband franchise to our favourite mathematically inspired conglomerate.

My wife, in her usual insightful way (all of my best ideas are, naturally, hers and I just take credit for them) pointed out that we could either deal with the devil we knew, Comcast, in which case we knew them to be pretty institutionally incompetent and gouging, or we could potentially deal with Google, with whom we could guess to be almost unnaturally efficient in trying to not be evil. Trading one titan for another, without any real choice doesn't feel like any real choice. 

I've already done some things that at times feel more like tilting at windmills and mere acts indicating defiance rather than something that actually *matters* - my emails are signed now, so I suppose you know if they come from me or not - and my email moved a while ago from Gmail to Fastmail.

I suppose the frustration is in this, something that also came out over lunch today. I was complaining about how terrible EHR software was and how you'd get something like Epic's MyChart as an add-on as a hospital system in that Epic would, I presume, sell you an add-on "oh look, your patients get an app! You get an app! You get an app too! Everyone gets apps!" when you buy into their more-or-less vendor-locked-in "solution". I would say something like: MyChart is terrible, to which my stockholm syndrome lunch meet would protest "yes, but it's better than nothing!"

Screw nothing! Screw better than nothing! Just because it's better than nothing doesn't mean it's *good*. (ZoomCare, another Portland-based primary healthcare provider, felt like it was 

And I guess the deal is this: Google is certainly better than what we had before. I hope that we can get *even better than Google* and I wonder how much of that will be able to deal with the capriciousness of human beings. By that, I mean this: Google is the product of not only hundreds of thousands of servers toiling away in farms, but it's also the product of tens of thousands of *people*. And people are, well - I'm going to jump on the bandwagon and say you just have to read Franz Kafka's The Trial, not Orwell's 1984 to get an idea of what people can be like - people. The technology is a human construct that, which algorithms reflect the biases of humans. They don't *have* to, it's just that if you're not constantly on the look-out for how they *might* be doing that, you just won't spot it. 

So the deal with the Full Stack is: yes. Fine. We get a search platform. We get a stupendous world-spanning video platform. We get real-time translation. We get mobile phones. We get maps. We get near real-time satellite data. We get super-fast internet access. We get self-driving cars. We get, gosh, so many things. We get it all! In one place!

I wish I had something more constructive to say than "I have a bad feeling about this," but I don't, really. Centralisation just doesn't feel good. And a really, really, really tall integrated stack feels like it just also might be good at tottering over.

[1] http://www.theverge.com/2014/6/16/5814380/google-fiber-is-cleared-to-land-in-portland
5.0 Dumb Screens
My friends at Berg have done a lot of thinking about this, and I know there's a lot of other thinking out there too. Experiments with e-ink screens persistently showing ambient information, and the idea of living *with* screens instead of them just being black mirrors that tempt us in infinitely configurable ways. 

One thing that's struck me about screens - and it looks like the idea might be coming back with Apple's iOS 8 and Yosemite through something they're calling Handoff - is that they're so *dumb* in some ways. I'll give you an example: I long thought that if you had to choose between a network-connected screen or a 3D screen, you'd choose the network-connected one. Sure, the choice is a false one because you'd get the network connection with a 3D TV anyway, but the fact remained that connecting to the network made something that much more powerful and flexible.

Or so I thought. 

The internet connections in smart TVs (never mind displays) these days feel more like they're about content delivery than the fact that holy shit you've got in best-case a gigabit ethernet connection plugged into that thing over there. And it goes both ways! So whilst we have input screens and output screens (and the TV still has a big role as, well, the biggest output screen), it's also something where it feels like it's a piece of - well - functionality and furniture. The big TV is the centerpiece of a room, it's something that so many other things are still arranged *around*. 

So the idea of a TV that is aware of all the other screens in the house in a way that's smarter than just AirPlay or Chromecast, that acknowledges that there are all these other screens, or that knows for argument's sake what *room* it's in and acts accordingly is super interesting. 

And that's just TVs. Screens that are aware of each other in terms of close proximity - if you haven't played Spaceteam[1], you should - that take advantage of physical presence and the fact that we have a supercomputer in our pocket that's got local two-way communication to people who're in the same room as you. Because people are often in the same room as you. 

It feels like there's been a fair amount of work done in this area - Bump is a boring one - but at the same time it feels like most of the work is the *boring* kind - the problem solving utility, hey, let's try and build something in the Valley that's going to scale, that isn't necessarily really creative and, well, fun. 

So I'm going to think about that. Fun things to do with people near you. Not in a Tinder-way. But in a fun way. 

[1] http://www.sleepingbeastgames.com/spaceteam/

--

That's it for today. Have you never sent me a note before? Do you know how easy it is? It's easy: you hit reply, and then you start typing and then an amount of time later, you stop typing and you hit send. There. Easy.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Three: Recurring; Better, But Not Best
Date: June 17, 2014 at 12:19:53 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g3k1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
It rained today in Portland. Really, really hard. I'm the kind of person (don't judge) who dresses for the previous day's weather, which must reveal some sort of bizarre insight into my foresight and planning capability. At least, it only reveals it in the sense of how I choose what to wear. So whilst I was smart enough to grab a rain jacket (this is Portland after all), that didn't really help when the streets were rivers of water and my dinky car2go was a couple of blocks away. So I got *soaked*. 
1.0 Recurring
There are so many more recurring services that I pay for now that I never would have paid for (or, indeed, would never have existed just a few years ago). I don't count DNS or hosting among these - they seem somewhat esoteric even now - but instead things like Flickr, Amazon Prime, Xbox Live, PlayStation Network, Dropbox, Netflix, Hulu, Backblaze and so on. 

A couple of things happened recently that prompted this reassessment of the things that I pay for on a monthly basis and an examination of where all the money's going. 

Amazon Prime used to be a bit of a no-brainer, but recently hit the psychologically sensitive price of $99 a year (up $20 from $79). They sent me an email about it back in mid-March, but it was only now, in June, that my subscription re-billed. And, let's be clear: it re-billed silently, in a somewhat dark (muddy?) pattern. From their point of view they *had* told me that the price was going up, it's just that it would've been nice to have been reminded, say, the day before, by Amazon, instead of being told after the fact by American Express about a card-not-present transaction. That's sneaky, Jeff. Very sneaky.

Flickr on the other hand *also* used to be a no-brainer but recently I let my old-style Pro membership lapse because, and I hate to say this, I no longer really understood the difference between any of the accounts, despite the help page[1]. Also, it wasn't clear exactly what I was missing and, how should I say, in a world of Instagram and Facebook and iCloud Photo Streams and now Kidpost[2] my photo-sharing needs were kind-of taken care of. (By kind-of taken care of, I mean: not really, not in the sense of canonical URLs for things and, well, photo *sharing* and community, but hey, apparently the world moves on.)

So Amazon gets a re-up through a passive-aggressive price raise and because I *didn't* do anything it re-upped, Flickr *didn't* get a re-up because I've been a member since 2004(!) and the last credit card to be used on the account expired. So Yahoo! lost out in part through sheer bloody-minded apathy and procrastination on my part. 

Amazon, though. The original announcement[3] of the price increase (also: "hike") was met with predictable comments given the Internet's status of Customer Service Medium and Why Wasn't I Consulted reckons. Ostensibly, the reason for the $20 price increase was fuel and transportation costs, for which, fair enough, really. But you can't help but wonder what's funding the media licensing acquisition for Amazon Prime TV and Movies and now Music. For someone who's already happy with a Spotify account and iTunes radio and well, any other free streaming service, I'm not that particularly interested in a brand new 1 million song streaming offering[4].

But, I'm a bit off-topic. The original point was this: there are few network services that I'm happy to pay for, that genuinely fall over the line into must-haves. Dropbox has finally gotten there, and I'm paying for it myself instead of the old corporate account that I used to have. I pay for extra iCloud storage because I'm really annoyed at Apple that something that *should* be free for their devices (and arguably would increase lock-in) is instead an added-value extra. Quite how you're supposed to back up your iPhone with 5GB of free storage when the average iPhone is pretty much already full of photos and video is beyond me. 

Media is media, of course. Our household cut the cord a while ago: we got over-the-air HD and rely on Hulu and Netflix, both of which we pay for, and the occasional iTunes TV purchase. 

So, a question is this: what would Uber charge for unlimited monthly transport?

[1] https://www.flickr.com/help/limits/
[2] http://www.kidpost.net
[3] http://www.nytimes.com/2014/03/14/technology/amazon-is-raising-prime-membership-fee.html
[4] http://www.amazon.com/gp/feature.html?ie=UTF8&docId=1002557791
2.0 Better, But Not Best
There was a debate on Twitter the other day - I have to admit, I can't remember who and let's just say that search on Twitter isn't *great* - about the fact that London taxicab drivers - black cab drivers - still have to learn "the knowledge"[1]. Wikipedia reckons that the test takes about three years to pass, and if you've ever been to London, it's the process by which you *should* be able to get into any black cab, say an address and the driver will know how to get you there. Learning the streets of London is even supposed to be enough of a large-scale task that it alters structures of the brain[2] which, even if only in a folklore sense, would seem to make sense as having a map of London inside your brain in a way that enabled you to grok the connections between different areas seems like a pretty fundamental piece of structural information.

The argument goes that, these days, a $99 GPS device (or, again, Uber) is the kind of disruption that's waiting to happen to the London black cab drivers in the same way that the Spanish were waiting to happen to the Incas, ie a sort of brutal no-hands barred competition that results in a fairly complete massacre and the end of the black cab as we know it. 

So, we wonder, what are the cabbies to do in the face of disruption? Should they, for example, learn to code? Arguably some cabbies have, because the London answer to Uber is Hailo[3] apparently developed or conceived in part by the same cabbies. But less facetiously, part of the differentiation is in the level of service. Sure, you'd have to allow for the element of romanticisation, but a large proportion of the number of times I've taken a cab where the driver's been reliant on GPS (warning: anecdata and probably confirmation bias) the service hasn't been that great. It *feels* like the driver literally has no knowledge of the city they're driving in whatsoever, and the case isn't of GPS as a sort of augmentation rather than a *replacement* of navigation ability. The navigation ability is the somewhat tenuous ability to operate a car (albeit not entirely safely, by appearances, and most times, not exactly according to the posted speed limits) and not a sort of contextual awareness. I can say "I live at this street, near this hospital" and will be met with a blank look and a request for an address to be input into Google Maps. 

To be fair, this happens fairly often with any of the Uber levels of service lower than the Black Car service - essentially drivers are meat puppets who are paid because legally, you need humans to operate cars right now. As soon as we don't need those pesky humans to operate transportation infrastructure, you can be sure they'll be done away with. 

No, best is someone who already knows how to get to my destination and uses tools to get there even better. Better than someone who doesn't know how to get there at all is someone with GPS, but have you ever encountered the experience of feeling like saying: "Here, just give me that," keying the address in and wondering: "wouldn't it just be easier if I drove, at this point?" 

Unless, of course, you've taken out your laptop in the back and you're busy writing newsletter episodes. 

I guess part of the point I'm making is this: human meat puppets, Uber-style, aren't that great. They don't use what's good about humans, and they rely on what's acceptable about software. Nowhere do they feel like they're making the best of both ends of the spectrum. *Maybe* something like TaskRabbit or Airbnb will do that because either of those two services will let you select for individual, non-replicable traits of human beings. But Uber, man. For the talk of its valuation for its recent round because it has the promise to become the de-facto infrastucture and transport company is all well and good, but it feels like they shouldn't simultaneously be talking about how they're a great employment opportunity for people. Because they're a zero-hours employer, who also prefers that you yourself structure as a business. Also, ask yourself this: in the long-term, what's the upside of being the best Uber driver you can possibly be? Or is it just a stopgap? 

[1] http://en.wikipedia.org/wiki/Taxicabs_of_the_United_Kingdom#The_Knowledge
[2] http://www.wired.com/2011/12/london-taxi-driver-memory/
[3] http://en.wikipedia.org/wiki/Hailo

--

Another week, another opportunity for you to send me a barrage of notes. Which I welcome. So you should send them.

Best,

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode One Hundred and Two: Structure; The Thing About People
Date: June 13, 2014 at 11:45:16 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g1tl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I have to admit, I started this one not knowing what I was going to write about. But I'm pretty happy with it.
1.0 Structure
NOSTROMO BLACK is the name I've given to a project that I'm consulting on at the moment - putting together a technical feasibility study for something that's quite exciting if it all comes together. It touches on a whole bunch of things I'm interested in: a kind of top-to-bottom strategic view of a nice, meaty problem that's required at times putting together a shopping list of technology that's already out there, but just hasn't been used in this particular domain yet.

I'm lucky to be working with two good friends on this project, one of whom is based in Portland with me. So we're doing that thing where we're meeting up every so often and camping out in coffee shops, when I realised that one of the things that I miss about full time employment is a sense of structure, and I'm thinking about how I can replicate it. 

By structure, I mean this sense of being able to wrap myself in organisational infrastructure - whether I'm fully integrated into it or not - but at least the feeling of being surrounded by it or nestled within it. At the agency I worked at, it was a sense of having the photocopiers and meeting rooms and phone systems and all of this *stuff* - as well as people and teams and other sorts of resource. But it feels like there were intangibles as well, a sort of psychogeography on an architectural scale that comes with working inside an organisation of around 600 people. Day-to-day, at Wieden, you might never really interact with people outside of your account group; certainly when I started and found myself immersed in the Nike team I could've never really needed to interact with anyone else in the building who wasn't working on the same account. 

Some of my friends, I think, had this same thought and ran a mailing list for a while called Pretend Office. It's not a secret, I don't think - it's got a website[1] and the mailing list was for a while designed to give that sort of feel of an all-staff mailing list for freelancers who weren't employed by an organisation but still, I think, wanted to feel like they belonged to one. In the end it turned out to be pretty hilarious as it was mainly populated by the kind of insanely creative people who were good writers and ended up being email improv comedy neatly parodying and skewering the sort of all-office email about reminding everyone that the fridges were going to be emptied this Friday and you really should remove your leftovers from them. Or that a new meeting room was about to be christened and could people submit suggestions. 

At this point I wanted to reach for a word a bit like *mouthfeel*[2] to describe that sort of internet sense of belonging to an organisation. There was a feeling I had when I removed my work Exchange accounts from all of my devices and unsubscribed myself from various Facebook groups that felt like the cutting of an umbilical (in a way, I suppose, it was), but there was a rhythm to the messages, notifications and impulses that directed my life for the last three years that is gone now. 

A different set of friends I have - also freelancers, mostly - have a ritual where they get together once a week, roughly, and do a group Skype call where they each talk through what they've been doing. Ritual is an important thing here, I think. I've been thinking about space and how camping out in coffee shops is good for some things, but not for others. So this afternoon was spent doing some ridiculously satisfying work down in the basement, getting it ready for a corner for me to call the place where I do work, so I'm not colonising the den (you can tell how American I've become by adopting that name for "the room with the television in it"). 

But the/an office can be like a city but on a smaller scale. It has the same infrastructural requirements writ smaller, design for spaces, open and closed areas, high and low traffic areas and, bluntly, "bad" areas that people just plain don't like. And being a freelancer that *isn't* in an office - something I've only really done for the last four weeks - feels a bit like a hermit, rather than something with lots of freedom.

[1] http://www.pretendoffice.co.uk
[2] http://en.wikipedia.org/wiki/Mouthfeel
2.0 The Thing About People



A long time ago, I thought about dating websites because one of my jobs was to think about, well, I'm not sure exactly. But, I had a thought about dating websites and it meant that for a while I was maintaining multiple accounts on everything from J-Date to Christian Mingle, Guardian Soulmates and OKCupid. 

I had a whole bunch of thoughts at the time - this was around 2010 - and, now that for some reason it's popped back into my head I thought I'd revisit them to see if my intuition was accurate or not. 

The basic insight was that 2010-era online dating services had done a pretty terrible job - OKCupid included - of representing people. And by that, I mean we were still in the era of online services essentially being "here's a view of a database record", albeit that record might be JOINED across however many other records you wanted. But essentially, the way of describing a person on a dating website was here's your primary key UID of your person, and here's a bunch of VARCHAR fields that you can write answers to, like "what's your favourite movie". In essence, trying to describe a human being through a whole bunch of text strings. 

Turns out, people don't really like reading that much - no, that's not true: people read a lot and bad Dan for supporting the misapprehension that people don't read - they do, they just also like looking at pictures. Reading is a complicated thing that takes concentration.

2010 was around the time that Pinterest was launched and fairly early on it was pretty clear that the founders were on to something. It might have been a number of factors like internet access *finally* being fast and pervasive enough, but it turns out that, hey, people are pretty visual people. And they like looking at pictures. And they like to keep them.

So my dumb-as-a-sack-of-nails thought was to wonder if you could do dating "right" by forgetting about all the text fields and instead doing everything visually. Profile photos, interests - everything. 

Of course, now you can look at stuff like Tinder that combines a highly visual interface (hardly any text! Lots of pictures!) with a nice fast mechanism to browse through a large set and act on it quickly, and hey, I get to feel like I should've just gone and actually executed that dating idea back in 2010. Because, as we all know, ideas are ten a penny and it's all in the execution. But hey: free idea.

The other thing that strikes me about the whole people-are-visual thing is this: pictures, images, photographs - they can all convey subtlety in a very easy to understand and parse way. That sort of subtlety either requires someone who's very good at writing, or someone who's very good at understanding and picking apart hidden meaning from multiple textual sources. But a photograph? A photograph can do that *instantly*. 

What I'm getting at is this: databases are terrible things for telling us about humans when we're reduced to *fields*. We're vague things that don't operate on a binary continuum - we can hardly keep our minds or opinions straight from one moment to the next. So to reduce us to n (whether n is small or very large) fields in a database that are boolean or VARCHARs or whatever, doesn't really do us service and, my gut tells me, insufficient in terms of modeling us on a personal level. 

All this is to say is this: perhaps it was something like the cheap availability of easily scaleable storage, where you could just keep provisioning s3 buckets to store all of those images and you didn't have to worry about buying all of those giant 3U disk servers, but when you're dealing with *people* and *people things*, photographs convey a lot of nuance that is hard to render in Unicode or ASCII and that is still hard for computers to understand. I can say, for example, that I'm a fan of Star Trek: The Next Generation and I could write a whole screeds about what I like and don't like about it, but if you want to understand me as a *person*, this is a pretty efficient way of going about it: 

 


(originally at https://twitter.com/hondanhon/status/469553163440111616)

And that type of array of images - lots of them - especially when they're picked by me and curated by me to show off different aspects of my personality (just like, say, on Tinder) communicates a lot more about me, a lot more quickly, than a lot of words.

--

It's Friday the 13th, so you should send me notes unless you want an axe murderer to come and visit you. Unless it's not Friday the 13th where you are, in which case it's too late and you should send me a note to tell me how you survived.

Have a good weekend,

Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred and One: Dangerous; Not Trying Is A Signal (2); What's Mine; Laundry
Date: June 12, 2014 at 8:47:08 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g0zl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
It's 6:30pm on Thursday night and my nose is streaming and my eyes are itching because I don't know, allergies. YouTube didn't stream In The Night Garden to the Apple TV because I don't know, spinning wheel of buffering. But hey, none of that really matters because I get to write about one of my favourite video games today.



1.0 Dangerous
Like a great many other Brits growing up in the 80s, one of my first experiences of a computer game was playing ELITE on a BBC micro. I'd come back to it a few years later buying an MS-DOS copy (having convinced my parents to let me spend hard earned pocket money on it - I can't remember if we ordered it from Special Reserve or managed to pick up a retail box copy - either way, I remember seeing the old British Telecom logo on it, the T with the two dots) and as much of what was interesting about it was the manual and short story set in the universe, never mind the procedurally generated universe and the feeling of freedom. 

I wouldn't be able to get over never seeing the Thargoids[1], though. To this day - because I haven't seen them with my own eyes - I still regard them as one might a myth or superstition - the kind of ghost that you might encounter one day in hyperspace.

So there was a genuine, tangible tingly feeling when I watched the Elite: Dangerous E3 trailer[3] and seeing such a realised version of what must've been in David Braben and Ian Bell's minds when they first conceived of the docking sequence in the original game. 

Stuff like this makes me excited. It feels like in so many ways, our grasp is catching up to our reach. In my mind, the other sequels - the Frontier series[4] - don't really count because they felt like intermediate mud-stick-scratchings, attempts to build the platonic Elite that still had to make do with relatively crude technology. But this Elite at least in terms of visual depth (if you'll excuse the Oculus pun) feels like it brings the universe to life.

For whatever reason, I never got around to backing the Kickstarter, and I'm not going to put down $150 for the early-access premium beta (yet another way in which gaming has changed since the 1980s) not least of which because it's going to require me to set up a Windows install somewhere. But, damn. I have friends who have, who've gushed about how amazing it is. Elite is one of those rare examples, I think, where the original version was in as much a low-fidelity prototype: it was, visually, a sketch: rendered in stupendously bare and ambitious vector graphics, with a seed of a universe pre-computed and thrown in. So while it's another example of a retro game receiving a reboot and a re-imagining, I don't really see it as such: it's not so much a *re*-imagining as, genuinely, feeling like what the original game was supposed to be. Certainly it looked that way in my imagination when I remember it.

[1] http://en.wikipedia.org/wiki/Elite_(video_game)
[2] http://wiki.alioth.net/index.php/Thargoids
[3] https://www.youtube.com/watch?v=ISR4ebdGlOk
[4] http://en.wikipedia.org/wiki/Frontier:_Elite_II and http://en.wikipedia.org/wiki/Frontier:_First_Encounters
2.0 Not Trying Is A Signal: Double The Animations Edition
So, if you hadn't heard (and it's entirely possible that you haven't), Ubisoft, the videogame publisher and developer found itself suffering from an entirely self-inflicted wound when staff working on its forthcoming game Assassin's Creed: Unity let slip that there would be no female playable characters in its multiplayer mode because it would, essentially "take too much time", time that they didn't have due to the restrictions and constraints of shipping a major triple-A game. 

Some of the best reporting on this has been over at Rock Paper Shotgun[1], but in a rare moment of, well, unity, it feels like most of the "mainstream" videogame press are not only taking Ubisoft to account, but explaining to their audiences why this is a big deal and shouldn't be tolerated. 

The deal, as Rock Paper Shotgun accurately points out is that the initial reasons as to why there wouldn't be any female playable characters in multiplayer mode - because of the animation would that would be required compared to all the other things that needed to be done, like finishing the game - was a weaselly one. And so what we have now is a company that prefaced the original Assassin's Creed game with the text "Assassin’s Creed is developed by a multicultural team of various faiths and beliefs" in 2014 needing to explain why having a female playable characters was a low priority in one of their titles. 

Now, this isn't to say that Ubisoft are a misogynistic company. They aren't: many of their games have had female playable characters. Some of them have even been good. 

But the response here betrays a shift - one in which it was business as usual for development teams on triple-A game franchises to be (mostly) directed by men and made for other people like them. Games have always (mostly) had male protagonists. In its best and least offensive form, this is simply blindness: doing things the way they have always been done and not noticing that there hadn't been a choice. Perhaps this is one of the most innocuous forms of sexism. Now, for whatever reason (but thankfully there is one), the very reasonable question of "hang on, why I can't I play as a woman" is being raised of game developers. 

This isn't to say either that *all* games must have male and female playable options. But again (if I were to get on my empathy/sympathy hobby horse again), it illustrates the gap in understanding between people who're used to the rhythm of making triple-A games and the changing marketplace. It turns out that women like playing them. It turns out that men who have reasonable (humane, even) attitudes towards gender relations like playing them too. And they see a distinct lopsidedness. 

Whether Ubisoft (or any other organisation in the media space) likes it or not, whether their intentions were good or simply ignorance, at least this week in games, not trying has become a signal. Not having a good reason why half the world's population isn't represented in your game has become a signal that *you don't care*, whether you care or not.  

[1] http://www.rockpapershotgun.com/2014/06/11/assassins-creed-unity-no-women/
3.0 What's Mine
Can now also be yours if we're talking (maybe?) about fair, reasonable and non-descriminatory licensing terms[1] now that Elon Musk has announced Tesla will not litigate against those using its patents "in good faith"[2]. 

Seeing as the devil is always in the details, I'm not quite sure what to read of Musk's announcement. 

Generally, the deal with patents (and apologies here for a lapsed lawyer intellectualpropertysplaining) is: the government wants you to invent stuff, so grants you a monopoly on that invention, provided you write it down so that *after* your monopoly expires, everyone else gets to {build on, copy} your invention. 

The key here is that, if you want to, you're always able to *license* the patent to someone else, which in this case means: hey, you can take advantage of this invention in this patent that's protected for 20 years, and I promise not to sue you if you do things like a) pay me lots of money, b) or pay me just a little money, or c) even no money at all. You might throw extra things in like quality control because you don't want someone saying they're using your invention and then them misusing it and lots of small children dying. Because that would be bad. 

So. It's always been open to Tesla to licence their technology to other car companies (and indeed, they've done so). They could even licence that technology for free. Presumably now, they're saying: hey, we promise not to sue you on the basis of a vague promise that if you use it for good things, ie. "in good faith" (nb: "good faith" to be defined by our lawyers at our discretion) and for good purposes. Presumably using Tesla tech to build giant battery powered hippy shooting lasers would not be a use in good faith. 

We've seen this kind of thing before. Part of the whole mess that's going on with Samsung and Apple was to do with whether Samsung had certain patents that went into specifications that should, because they were part of a specification that defined interoperability, have been licensed on a fair and non-discriminatory basis. You shouldn't be able to use patents that are part of a shared specification to stop others from implementing that specification. That's the whole point of interoperable specifications. 

So. Who does Tesla want using these patents, and what do they want them to use them for? 

[1] http://en.wikipedia.org/wiki/Reasonable_and_non-discriminatory_licensing
[2] http://www.teslamotors.com/blog/all-our-patent-are-belong-you
4.0 Laundry
Our washing machine broke, so of course I found myself at Spin Laundry Lounge[1] on the receiving end of text messages[2] from washing machines telling me that our loads of laundry and diapers had been done (we cloth diaper and live in Portland. Deal with it). Laundry remains one of those things that I think, *by and large*, if you're male, you don't have to deal with a lot of the time because the traditional division of domestic labour has meant that it's been seen as a woman's job. There's nothing particularly *hard* about doing laundry: but as with any task, if you're not familiar with it, then it can seem difficult and frightening and suddenly you're writing inappropriate and mildly verging on strongly sexist posts about garment care labels and taking your clothes home so that your mum can clean them. 

So Spin Laundry Lounge: that particular Portland-ish combination of a {laundrette, laundromat, washateria} that has new shiny machines, eco-detergent that they make themselves, a bar with food and a rotating draft, fast wi-fi and ample plug sockets. You know, laundry, but *disrupted*. If it sounds like I'm being mean, I'm really not: they're all very nice people there who seem focussed on providing a good, high quality service that's comfortable and easy to use. What I am interested in is deconstructing it a bit. 

I'm lucky (privileged) enough that I've never really used laundry spaces before, so this is all going to sound a bit like White Man Discovers Africa, Writes Back A Postcard, and if it *does* really sound like that then I'm terribly sorry (again with the White Colonial Man thing). But hey: you've got a comfortable, well-lit communal space that's designed with lots of *space* in the aisles for you to have room for the inevitable IKEA blue bags and white plastic baskets, you have pinball machines upstairs, sofas for lounging on, change machines and attendants roaming the aisles to make sure you're being helped if you need help. 

The particular texting functionality was on the washing machines. They'd be hooked up to a payment system that would take credit card payments (equipped with paywave/RFID readers, too) as well as the traditional slot for quarters. Electrolux TMIS[3] would display on the washing machine during the beginning of the cycle that you could text a code to a phone number and it would let you know when the load was done. 

Some things to note here:

	•	there wasn't a short code - it was just a regular phone number, but displayed in a user hostile way (ie a string of 10 digits, not grouped to aid memory) 
	•	you got a code that identified the washing machine. The ones that I saw were all variants of {F, K, N}01[1-9] and displayed in a font that meant you had to squint to see if it was a zero or a letter o-for-oscar 
	•	there was no confirmation to let you know your opting in for notifications had succeeded. ie you'd text F019 to the requisite number and you wouldn't get a reply until 10 minutes before your load was done.
	•	all of the communications from the washing machine was in ALL CAPS because washing machines are ROBOTS that talk in ALL CAPS. ie: ELECTROLUX TMIS: YOUR LAUNDRY WILL BE FINISHED IN: 10 MIN and ELECTROLUX TMIS: YOUR LAUNDRY IS NOW READY; PLEASE UNLOAD MACHINE which, you know, is a bit like a polite laundry Dalek. 
And that was it, really. 

Electrolux TMIS[3] is interesting because it's at least three years old and it's geared primarily toward professional laundry services. The language in the brochure is a bit clumsy, not knowing whether customers are the people operating self-service laundry outfits or the people using the machines. In any event, there are some use-cases like "check machine availability" but that's countered by other slightly more opaque benefits to an end-user customer, like "error condition notification". 

All of this is against the backdrop, obviously, of stuff like Berg's Cloudwash[4] and the idea that these machines have state that can be communicated in a bunch of different ways, to different people. 

But, I suppose, this is the thing: we shouldn't be surprised that TMIS exists, it's only depressing that it exists in a b2b context, and not in a consumer, user-focussed way. Because you could arguably say that the interface borders on masochistic for laundry operators as well.

[1] http://www.spinlaundrylounge.com
[2] https://twitter.com/hondanhon/status/476911548393594880
[3] Electrolux TMIS and TMIS brochure (PDF) and https://www.youtube.com/watch?v=HD8xK5g5TN4
[4] http://bergcloud.com/case-studies/cloudwash/

--

It's nearly Friday! That means you should send me notes!

Best,

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode One Hundred: Taking Stock; And The New
Date: June 11, 2014 at 4:50:03 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-g019=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
It's a nice sunny day back in Portland, Oregon and I'm sat in Kenny and Zuke's about to devour an meatball sub. I took my son out to the library for storytime and we had a funtimes sticking things to the window and generally walking around (he walks now! It happened a mere half hour after getting home fro my trip) spinning spinning things. And then one of those drives home where you kind of have to drive aimlessly, but with the purpose of trying to get him to sleep, all the while having your movements be a) narrated by Google Maps and b) tracked by Automatic and Moves and everything else that is watching my location data, squiggling all around Portland like a haphazard toddler with a bottle of ketchup. 



1.0 Taking Stock
So. 

Ninety-nine episodes. One hundred and eight seven thousand, three hundred and fifty five words. One of the side effects about this particular project (and if any of you are nervous that hitting this milestone is an opportunity for me to stop: it isn't, I'm going to keep going, so you can calm down) was that because it was a stream-of-conciousness just-sit-down-and-write deal, I've got the opportunity to go back and interrogate it to find out, well, what I'm interested in. Because the things that I find interesting enough to write a couple thousand a words about a day are, presumably, the things I'm actually interested in and have an opinion about. 

With that in mind, here are some themes (and some archive links) to the things I've been writing about, as well as a pseudo writer's commentary. It's not necessarily a best-of, more of a "hmmm".
1.1 The Californian Ideology
It took a while, but one of the early themes that emerged was that of the Californian Ideology. That phrase has become a sort of short-hand for me to take a critical look at what's coming out of the west coast of the USA (and what that west coast is inspiring in the rest of the world). It's a conflicting experience for me, because I genuinely believe in the power of technology to enhance the human experience and to pull everyone, not just some people, up to a humane standard of living. But there's a particular heady mix that goes into the Ideology: one of libertarianism, of the power of the algorithm and an almost-blind belief in a purity of an algorithm, of the maths that goes into it, of the fact that it's executed in and on a machine substrate that renders the algorithm untouchable. But the algorithms we design reflect our intentions, our beliefs and our predispositions. We're learning so much about how our cognitive architecture functions - how our brains work, the hacks that evolution "installed" in us that are essentially zero-day back-door unpatched vulnerabilties - that I feel like someone does need to be critical about all the ways software is going to eat the world. Because software is undeniably eating the world, and it doesn't need to eat it in a particular way. It can disrupt and obsolete the world, and most certainly will, but one of the questions we should be asking is: to what end? 

This isn't to say that we should ask these questions to impede progress just as a matter of course: just that if we're doing these things anyway, we should also (because we *do* have the ability to) feel able to examine the long term consequences and ask: is this what we want? 

The first mention of the Californian Ideology was way back in episode twenty eight. 

On humane technology, and whether the jobs are really going away, in episode thirty five. And later on, I'd have tremendous fun coming up with the phrase "terraforming for capitalism". 

I'd go on to explore the idea of the jobs going away when thinking more about what's called the sharing economy in "A Symptom Masquerading As Disruption" and its followup.
1.2 Empathy
Which kind of led to another obsession of mine, that of empathy in technology. This particular thread developed out of watching pretty much all of my friends in the UK get sucked into the Government Digital Service and its excellent work in rebuilding government services for a digital age. There's a lot to unpack in there, but essentially one of the things that struck me was a friend saying that they weren't necessarily doing new things, they just finally had the permission and the ability to do the things that they knew had to be done, but that were hard and difficult. 

What's hard and difficult, of course, is understanding your audience and delivering what they need. In the case of government, this is clearer cut: you have ministers that set policies that need to be enacted and delivered. Quite unsurprisingly, there's a disconnect at the delivery level, and the fact that there's such a disconnect between stating a policy and delivering it is part of the reason why there's a problem with governance in the first place (from my ex-agency hat side, I can clearly see the difference between just *saying* something and not *doing* that thing, and that's one of the places where it doesn't matter a jot what kind of communications you've got or how many Lions it's won, because if that's not backed up by action and fulfillment, then in the long term, what's the point? Other than winning a bunch of Lions, I suppose, and if that's all you're in it for then, er, maybe find something else to do?) 

This act of looking at empathy would turn out to cut across pretty much everything I'd write about.

There was the idea that, in this day and age, and the hands-down *ease* of putting together a web service, that *not doing one* (ie requiring people to opt out of a policy decision through writing a letter and mailing/posting it to a PO box somewhere and not receiving a response instead of a simple web-based opt-out) smacked of selfishness and pure *lack* of empathy for the userbase/audience in "Not Trying Is A Signal".

There was the tone-of-voice and the way that the Heartbleed vulnerability was communicated by various services to their users. And the counter-example, of those organisations (banks and so on) that *didn't* say anything about Heartbleed, despite it being a security issue that had hit mainstream understanding, in "Sharing Heartbleed".

And then there was the duo of posts about the role of empathy in organisations, first with "Chief Empathy Officer" and then the subsequent clarification that I didn't mean anyone should actually create the office of Chief Empathy Officer because, of course, such a responsibility should be devolved to *everyone* and be everyone's responsibility, in "We Have Always Been At War".

The issue of empathy would come back again in a series of posts about the internet of things. First in "I Sense Feelings, Captain" where I worried about the prospect of sociopathic corporations extended physical tendrils into our homes through internet connected objects, and then in my first and second episodes from the O'Reilly Solid conference. 
1.3 Me
I've written a fair bit, about my depression. I'm not going to re-link to it: it's more for me than it is for you, and it's more there for historial record. What I will link to, though, are the episodes that I wrote in response to a prompt from Robin Sloan: he wanted me to write about something that had nothing to do with technology or its effect on culture or the economy. In his words, he described it (before the fact, rather flatteringly) as “one of those runs in X-Men comics where Professor X is in a coma or something, so someone else has to lead the team for a while, and it was always interesting to see what happened ;-)”.

And in response to those, I wrote three episodes of which I remain inordinately proud of.

The first, "Different", was about my experience growing up as a first generation British-born immigrant to Hong Kong Chinese parents. It's not something that I really talk about, and my ethnicity and cultural background aren't really things that rear their heads until, well, they kind of stick out like a sore thumb. I get my fair share of "Where are you from?" questions to which various answers don't satisfy until I finally relent and say "My parents are Chinese and they moved to Britain in the 70s, where I was born". But it was the response to the episode that was the most emotional to me, that showed that there were others who undoubtedly went through that same experience, but also where I could start to understand that whilst for me it may have felt like I never fit in, for others, they could be jealous of my otherness. 

The second, "This is a story about a brain and its hands" was, I suppose, again a thinly veiled piece of writing that took a fairly plain speaking look at what it felt like when I looked inside my head. And again, I was struck by the people who wrote back to say that it was something that had resonated strongly with them and that they didn't know there were other people out there like that.

The third, and last, "Zero" was of course about my experiences in becoming a father for the first time. 
1.4 The Quantified Self
And not just the quantified self, really, but mainly armchair quarterbacking about product and service design, and taking pot-shots at the more-or-less abysmal state of affairs in the quantified self space. 

I've written before about wearables: there's the piece I originally published on my blog, "Myself, Quantified", and the much better version over at Domus, "Fitness by Design". 

One of the early episodes about wearables, though, was "Wearable Reckons", but one of the other episodes that I liked was "I Miss Dopplr", where I would rip into the also abysmal state of information visualization and the preoccupation with the activity trackers and wearable manufacturers to assume that everyone would like to see a dashboard. I'd come back to that in episode ninety three in the "Dubya Dubya Dee Cee" section:

"The other way around is: man, you know how I feel about dashboards. Too much information that I don’t care about, that I don’t need to see. Honestly, if the quantified self people went and designed a car you’d never get around to driving it because you’d spend the whole time looking at graphs of data over time like, ooh, isn’t piston number one doing well, see how its performance has been doing over the last six months when: I DON’T CARE, I JUST WANT THE ENGINE TO START."
1.5 A Failure To Organize
Obviously what I should do is spend the time to properly categorise all of my previous episodes and then write the rest of this section with a greater sense of organisation than what you're about to experience. But I'm not going to, because this is my letter and I'm just going to list some of my favourite bits instead.

I have an on-going project where I'm re-reading Neal Stephenson's Snow Crash and taking it apart. You can get all of those at:
	•	Episode Forty Four: Snow Crashing; danah boyd; Facebook and Oculus Rift 
	•	Episode Forty Five – Station Ident; Snow Crashing 2; Computers, AMIRITE?; A Book on your Face 
	•	Episode Forty Six – Snow Crashing 3; Video is a Content-Type; Blame Your Tools 
	•	Episode Forty Nine: Living In An Immaterial World; Snow Crashing 4; Odds 
	•	Episode Fifty: Cities; Snow Crashing 5; More Television 
	•	Episode Sixty Four: Computer Says No, Snow Crashing 
	•	Episode Ninety Two: Continued Disruption; Snow Crashing (7); Edge of Tomorrow 
I was very pleased with the idea of Maslow's hierarchy of needs and technology moving down the pyramid, starting at the top in the 70s and then finally getting nearer to the base of the stack in the present in the Internet of Safety.
	•	Episode Seventy Nine: The Internet of Safety; Invisible Technology; Like A Dog Whistle; Odds 
And also the idea of a sustainable web, and not a boom-bust web, given the web of obligations and issues of disposal (and retention) of user data:
	•	Episode Seventy Five: The Sustainable Web; TaskRabbit; Airbnb; Cities 
Then there's the fact that every now and then I'd fixate on Star Trek: The Next Generation and pick apart its universe based on the dominant mobile computing and app-distribution method of the day:
	•	Episode Twelve: Attention, Star Trek and Cars 
	•	Episode Twenty Two: Infrastructure, The LCARS App Store
2.0 And The New
Enough of looking back. Here's some of what's new:

Avery Edison also wrote a piece about Her's Samantha[1] and how her love is a literally unimaginable on the human scale tragedy.

Mat Honan wrote about how notifications are about to rule the smartphone interface[2] which merely seems to be the latest move in the Red-Queen-Race to capture and act upon our limited capacity for attention. In other words: the notification area is a free-for-all space (ish, of course) for the display of (ostensibly) timely and relevant information to the user. I've no doubt that this is going to be very useful and that notifications are about to rule the smartphone interface *for the next period* but this strikes me as another hurdle that we're going to have to deal with in terms of: what's relevant, what's timely and what's actionable. The promise of course is that we're now able to anticipate and accurately model what's relevant, timely and actionable and the proof will be in those applications that are able to "best" (for certain values of best, obviously) deal with what should be there.

Again, this should be a differentiating moment for Apple and Google: I would expect (but given the recent WWDC, am prepared to be proven wrong) that Apple are going to have a strong point of view in terms of what a "good" notification extension is going to be and the kind that they will approve and thus curate. It's not in Apple's interest (or Google's, arguably) for people to associate their device with something that is incessantly *annoying*.

[1] http://bygonebureau.com/2014/02/03/were-leaving/
[2] http://www.wired.com/2014/06/smartphone-notifications/

--

So that's it. One hundred. 

A bit of a look back and a bit of a regular look at now. 

And now I'm going to go and get ready for a phone call.

Best, and do send those lovely notes,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Nine: Building Together; Beautiful Shooty Things; Software For Eating; The New Toys On The Web; Take It Seriously; And Finally
Date: June 10, 2014 at 3:13:55 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fz9t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
There's been a bunch of things that I've bookmarked over the past few days that I've been wanting to share, so I'm going to use this episode to kind of splurge them a bit, and probably insert some wildly unsubstantiated opinions here and there.
1.0 Building Together
Melissa Santos and Rafe Colburn wrote an excellent piece[1] in the excellent Model View Culture that shows how, upon a little examination, perks that startups provide its employees even when coming from the best intentions to foster good culture, can unintentionally divide and alienate people. Part of the point here is that I suppose it's entirely OK for you to *not* aspire to have a diverse and engaged workforce - you can run your business however you want provided you're not breaking the law - but one of the side-effects of doing things more out in the open and having more connected societies means that, whether you like it or not, how you act ends up standing much more of a chance of being communicated than it did a few years ago. And people will judge you by how you act. And the tide in terms of treating *all* people respectfully and with equal opportunity means, whether you like it or not, these things need thinking about and responding to. 

One could argue that this is a tax and that it gets in the way of doing the job. Well, you know what: if you're saying that having to override built-in biases or assumptions in favour of a more beneficial long-term goal (and let's just agree that this *is* a more beneficial long-term goal) is a tax and that you'd prefer to rely on slightly more base assumptions, then essentially you're saying: I'm smart and I've got this giant old brain and capacity for self-reflection and planning and you know what: I'm not going to use it and Locke is very upset with you. 

It's not a tax. It's progress, which requires us to do work.

[1] http://modelviewculture.com/pieces/how-perks-can-divide-us
2.0 Beautiful Shooty Things
For all that this year's E3 was yet another reminder that at least part of the videogaming industry is preoccupied with ways of moving around and shooting things, we did get to see the latest installment[1] of Hello Games' No Man's Sky, for which: well, yes, it does involve running around and (as far as we can see) shooting at things. But it looks gorgeous and the colour palette is at least different, eschewing the brown and grey corridors that define the majority of mass console videogame experiences these days. That Hello Games are able to achieve something as beautiful and ambitious as No Man's Sky with such a tiny team (I think they're only around four people) and that Sony were willing to recognise it and give it space at such a big industry event is the kind of thing that keeps jaded fans of the form sticking around. 

That and new Nintendo stuff, of course. 
 
[1] http://blog.eu.playstation.com/2014/06/10/mans-sky-coming-ps4/

3.0 Software For Eating
Via Jason Kottke, an epic post from Nick Kokonos[1] on the last three years of his restaurants designing and implementing a ticketing system for reservations. I'm not really up on the restaurant scene, so I'm grateful for Jason pointing this out, but this is just another data point slash nail in the proverbial coffin for "good" software eating the world, and I think I'm able to look at this type of software eating as the kind that produces the good jobs. 

Here's my chain of thought: Kokonos does an incredibly good job of not just persuading, but showing, through hard data, how beneficial implementing a ticketing system has been for his business. As an aside, he also shows how hard it is for entrenched businesses to change their ways and innovate, and we see another example of what can happen when someone who "gets' software applies it to their business, which otherwise wouldn't have anything to do with software. I'm going to temporarily fork and follow this thread a little bit, because I think it requires a little more examination. When I say software here, I mean software the material, as opposed to finished software, the product. Kokonos understands what he needs and that computers/software can do that. He's confident enough to just map out the process and go to a contractor and get what he needs built. I'm going to go out on a limb of reckon here and say that he had to pull together a disparate bunch of skills in order to map out that process and to be able to communicate it in a way that resulted in a successful project. But, note: I don't think it mattered whether or if Kokonos knew "how to code". He merely knew that he had a problem that could be solved with software and the types of things that software could do to help his business. He might even have known *how* to implement it, but in terms of tradeoff of spending his time to do it versus his money, he clearly came down on the side of money - and why not, he has a business to run.

There's a point that I'm trying to make here, and it's that there are untold billions of problem domains that could be obsoleted or solved or just plain made better by the good application of software now that Moore's law has pushed the stack both down in terms of what it does for us in terms of needs, and wide in terms of availability. Again, sure, we're not at one hundred percent availability, but there's definitely been a significant enough shift. 

The good news, I think, is this. Kokonos had to employ people to do drudge work that wasn't even that good for his business. He had to employ people to answer the phone to tell potential customers - who had already engaged in a significant signal of purchasing intent - that he could not take their business. And then they would have to do it again. Kokonos said he was employing three full time people answering the phone, and that was a cost for his business. 

The good version of the story is where the software means Nick is able to hire more high-value, specialised and actualised employees more directly related to his business venture. This isn't job creation at the Uber level, which I would argue makes room for substitutable jobs that are pretty much low-end skills and drudge work. Software in this case, for Kokonos, has created more room for high value work. 

Sure, I get that he won't be employing people to answer phones. Those three full-time jobs are gone. But I would hope that he's able to replace them with higher-value jobs or open a new restaurant.

I do think there's a distinction here, a subtle one, at that. But I'm perfectly happy to be proven wrong or argued with.

[1] http://website.alinearestaurant.com/site/2014/06/tickets-for-restaurants/
4.0 The New Toys On The Web
Boris Smus, an emerging user interface researcher at Google, dropped one of his latest projects on Monday, a full-screen in-browser live-input spectrogram[1] that runs on Chrome or Firefox through the web audio API. This is the kind of thing that makes me incredibly excited for my son for the world that he's growing up in (other things make me incredibly sad for my son for the world he's growing up in, so I guess it all balances out). To have a toy spectroscope to play with as a tool to explore the world is fantastic. That it's done in open source software and deployed on the web where so many people can play with it, that it's done in a format that he will be able to play with is one of the wonderful things about what we've built with the internet and the entire stack. 

[1] http://smus.com/spectrogram-and-oscillator/
5.0 Take It Seriously
I have friends, whom I love dearly, who I think like to take seriously the concepts exposed in fiction and poke holes in the universe. I give them a break because, generally speaking, they're also able to revel in the drama and the story (apart from some instances, like where Thor takes the tube and the London tube map is, shall we say, topographically challenged).

But you get a couple of instances which are funny, too. One of my friends tumblred this piece[1] by Avery Edison on what kind of movie Iron Man would've been if everyone had instead just shat their pants at Tony having essentially booted up a Strong, Turing Test passing AI (that wasn't a Ukranian thirteen year old, natch) and were just nonplussed by the existence of a simple exosuit of armour. 

One thing out of the way first: Avery Edison is fucking hilarious. I had a bit of a noodle around the rest of her site, and you should too. Last episode I talked a little about a new generation of Adams-esque role-models and inspirational figures, ones who were excited about technology and could communicate about it to a large, mass audience and I sincerely hope that Edison is one of them. You should check out her work[2] because she deserves encouragement and success. 

I mean, we get a few pages of well-written funny ha-ha script about people generally losing their shit that Tony's just advanced the state of computer science (on the Oracle Cloud, no less![3]. 

But that was part of what was disappointing about Transcendence[4] which not only was a *bad movie* (no biscuit, Johnny Depp) but also a tired one that didn't tell a particularly new or interesting story either. Boring. Waste of money. 

Her was a lot better in that the transcendence and implied subliming (oops, spoiler, but you probably should've seen it by now so I'm not *that* sorry) were just background. 

With neither movie though, you never really got a vision of societies in transition: of stupendously powerful computing and an idea of how we get from here to there. We get enough visions of here to dystopia or here to 'you know, maybe we shouldn't trust the machines' and I suppose there's a reason for that and it's mostly the dramatic and emotional arc which is why something like Foundation is a bit hard to film, but really: we could stand to see a filmic story of the eventual promise but difficult transition phase of technology. Or even a goddamn good documentary. 

[1] http://blog.averyedison.com/post/88204553167
[2] https://twitter.com/aedison and http://www.averyedison.com
[3] http://www.oracle.com/us/ironman3/omag-mj13-ironman-1936895.pdf (warning: PDF, but also because it is literal fan fiction written by Oracle about them and Stark Industries)
[4] http://newsletter.danhon.com/episode-sixty-nine-transcendence-broom-shaped-objects-odds/
6.0 And Finally
Here's Aleks Krotoski on serendipity[1], saying it much better than I did.

[1] http://www.theguardian.com/technology/2011/aug/21/google-serendipity-profiling-aleks-krotoski 
 
-- 

That's it for today. Hope you've had a good one. And America, please sort out your deal with guns. It's breaking my heart.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Eight: Engineering Serendipity; Genuinely Useful People Personalities; Hubris
Date: June 9, 2014 at 9:43:46 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fytd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

First: hello new subscribers. There's around thirty of you today, so if you manage to make it to the end of today's episode, then you should also check out my archives at http://newsletter.danhon.com/archive/.
I'm in South Carolina for NOSTROMO BLACK which amongst other things means driving a Mustang around little roads at quite unreasonable speed and looking at giant CNC machines and various kinds of 3D printers and laser scanners. I fly back to Portland tomorrow, where there are things like reasonable weather and not ninety-five degree heat and eighty-odd-percent humidity. In that respect, Myrtle Beach is better than Washington, DC, where it's ninety-five degree heat and ninety-five percent humidity. 
The plane ride over on Sunday was also room to do some more thinking around SULACO BLUE, which I'm pretty excited about because I've found new ways in to getting it started, but also to start putting some structure into place for PROMETHEUS RED, for which I had a kickoff meeting last Friday. 
1.0 Engineering Serendipity
Or: "The right thing, at the right time, for the right price."
For the past few years, there's been a bunch of talk of serendipity in the building of services and products. One of the earliest incarnations of this was the Explore page on Flickr - for which Yahoo! even has a patent[1] on an algorithm to determine the *interestingness* of a photograph.  
It feels awfully high school to do the whole "let's look up what serendipity means in a dictionary" thing, but this is what we mean something is serendipitous: a development of a fortuitous chain of events by happy coincidence.  
It's telling that serendipity was coined in a fairy tale[2] - one where an author is in charge of narrative events. What I think we do when we encounter serendipity in real life is apply it as a sort of post-processing filter: we're causal beings that experience life in terms of narrative, so we find the happy coincidence, or the beneficial outcome and then work backwards to construct a reason for it occurring. And when one isn't apparent, or when we're unable to assess the probability or the probability that we assess is judged to be quite low, then we label the sequence of events as something serendipitous. 
When we talk about engineering serendipity, we're second guessing: inferring in some way the sorts of things that we're interested in, that will provide us with pleasure or that "happy or beneficial way" and deciding to surface those things. Serendipity prompts, as it were. This strikes me as an inherently fuzzy thing (such reckon, of course, that I'm entirely happen to be proven depressingly wrong). So instead imagine something like this: there's a set of things in my head, the contents of which can be (to a greater or lesser degree) duplicated externally through inference via my behaviour or explicitly, because I state: I like these things. We can simplify this by removing any sort of time component: at all times, I would be happy if any of these things happened. 
Does it make any difference if these things are then placed in front of me by something with agency? Does it matter if I tell some sort of system: I want to increase the amount of things that I perceive as happening serendipitously in my life?  
This is essentially what I'm doing with the promise of an invisible application like Swarm: I like to see my friends. I would like to know when my friends are nearby. If my friends are nearby, let me know, so I can spend time with them.  
That feels like a kind of high-level serendipity. No movements have strictly been engineered by accident, everything's been explicitly asked for.  
The other kind of serendipity, though, is the ones are invisible apps don't do yet. Part of the question, apart from whether they should or not, is whether you'd be able to notice. If there were something nudging you, would you be able to tell? Would you want to know about it afterwards? 
You could imagine a sort of integration with Google Maps, then: an *interestingness* option for route calculation. I want to get from point A to point B, and here's a selection of routes: the fatest route, the shortest route and another one: the most interesting one.  
Because part of the joy of serendipity is the hiding of information and the belief that a low-probability series of events occurred, regardless of their actual probability. You might think it was a happy coincidence that you bumped into Hannah at the cafe and then Arthur around the corner, who both happen to be working on the same thing, but it turns out that Hannah and Arthur both follow a routine that brings them to the cafe, or on a walk, at roughly the same time each week. It was bound to happen.  
What's different is the story that you tell yourself. Do you want interesting stories to tell?  
In this way, asking for serendipity in terms of a "most interesting route" from Google is giving up a bit of agency, a bit of control. I don't know *exactly* why this route's been chosen: it might be because the routing engine knows that I probably haven't seen Sarah in a while, and there's a high chance I'll bump into her. It might be because I don't know about a book tour that one of my favourite authors is doing in town tomorrow night, and that I might hear about it on the way.  
I don't know any of those things. All I know is that the route will deliver something interesting. And the great thing about human brains being pattern matching machines, looking for stories in everything, is that if something *did* happen that wasn't anticipated, then I'd chalk that success up to the machine as well. 
At that point, *real* serendipity, the non-engineered kind becomes the glitch in the algorithm. When you see something you weren't supposed to. When something happens that was unplanned - by you, by anything.  
I'd say a challenge would be: how spooky could you engineer someone's life? How much you would you need to know about them and how many nudges would you be able to insert into their daily routine for them to have a palpable feel that something were different? And could you do so algorithmically? In a productised fashion? 
I wonder what kind of access you would need. I wonder how privileged it would need to be. Is there some suite of genie rights and permissions that you could give to a Simmons (not a Donna, not a [female named assistant] from your phone that would be good enough? We'd be talking about: contacts, major and minor social network read history plus graph data, purchase history, geolocation and notable places. At what point do we bundle that type of information together so that services and applications can ask for it in one go? And what sort of name would we give that bundle? 
I started this off writing about serendipity, and that was a route in to looking at how our lives are mediated through the three-to-five inch screens we have with us. I used to joke at work that I would be endlessly shuttled by my assistant and project managers from meeting to meeting, that they would be waiting for you outside the bathroom to move you on to the next task, papers held in hand for you to examine or sign or walk-and-talk with you before the next review. It would get to the point where I could do national travel and not necessarily know *where* I was going, because I'd trusted someone else to figure it all out for me. I would trust in the instructions and that following them would lead to the accomplishment of my tasks.  
Of course, this would work great for my professional life. I would get a lot done.  
But now I have a spreadsheet full of todo items. And it's not even really full of todo items, it's full of did-this-last, doing-this-next and dates.  
So what strikes me is that I would love a to-do list that told me what to do and when. I mean, sure, I'd set priorities. But I kind of liked being shuffled around. Decisions had been made and I had to make decisions during the time allotted. And sure, I'd be able to say: this decision needs more time, and then the diary would reconfigure itself, be a shifting morass of priorities and decision-making spaces.  
If you're looking for the answer to the question: what does a creative director do all day, the answer is: directs things. If you want to know what that means in a slightly less facetious way, it meant making decision after decision after decision.  
Sitting in a meeting: is this brief ready or not? What would make it ready? 
In another meeting: is this idea ready or not? What would make it ready?
In yet another meeting: is the plan for this presentation ready or not? What would make it ready?
There wasn't much time for reflection, a lot of the time, because of the volume of the work to be done. Occasionally, there would be things like: 
Sitting in a meeting: because the work is ready, so: help present it. 
Also, to be brutally honest, there were also things like: 
Having a long lunch: because clients are here: you should talk to them 
What it meant though, was that there was always a succinct answer to the question "what am I doing right now?".  
My Outlook calendar was a finely-tuned Jenga puzzle work of art. 
How would you go about engineering that kind of workflow? Like everyone else, I've got at least two copies of Allen's Getting Things Done. But hey, didn't we invent computers for this sort of thing? 
Where's my to-do list that requires me to break tasks down into subtasks, organises my projects for me but also *has access to my calendar* and inserts those tasks? Because one way of answering the question "what am I doing right now?" is to take a look at that task list and say: looking at the task list. The task list may well have been sorted and prioritised. And you could say that it's my responsibility, as a human being with executive control and time-management skills - both features that apparently come as standard in modern adult h. sap - to work out what I want to do and when.  
But it's nice not having to decide sometimes. Because we also know that deciding things  takes up non-renewable mental energy. It engages that System 2 of Daniel Kahneman's and that requires *effort* and hey, Kahneman said that evolution designed me to be cognitively lazy and look for the easy way out, so I'm doing that.  
I want a todo app that has access to my calendar and says: hey, you could be doing this right now. And then it would be done. And just fills up as much time as I want it to. That's not a reminder. It's a: this is what you're doing now. 
In a way, it's removing agency (heh). But I like to get things done.  
[1] http://appft1.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&d=PG01&p=1&u=%2Fnetahtml%2FPTO%2Fsrchnum.html&r=1&f=G&l=50&s1=%2220060242139%22.PGNR.&OS=DN/20060242139&RS=DN/20060242139
[2] http://en.wikipedia.org/wiki/The_Three_Princes_of_Serendip
2.0 Genuinely Useful People Personalities
One of my friends I follow on Twitter[1] called out the intensifying of some sort of local Douglas Adams field. References to the tall one had been cropping up more frequently, lately, and they wondered, rightly, was this sort of thing alienating to younger people, who hadn't grown up with him? Who hadn't been around when he was alive, or hadn't really been a fan when he had died? 
I said: I'd keep referring to Adams until I died. Not so much because of his ideas - but because of his enthusiasm and passion for them, and because of that enthusiasm and passion, he was a great explainer. One who would take a woolly concept that might not have been instantiated in the world yet, which presence might just be a ghostly outline of a possible future, and then, like a showman or an entertainer, almost will it into being through sheer force of exuberance. What I like about Adams was that he was an unabashed optimist, and an infectious one at that. 
I wish there were more people like him, but I think that's why he had a singularly disproportionate effect upon people. He was unique. And his knack for doing both things like Hyperland, where he got the platform to be curious in front of millions of people, and things like his insight into technology invented after you turn thirty (against the natural order of things, wrong, etc.) illustrated his ability to inspire, educate and simplify (though in the latter case, perhaps overly so). 
He was, in short, a passionate communicator who bridged the arts and the sciences. Like I said, I wish there were more people like him, and I think it's a tragedy that we enforce an artificial divide between the liberal arts and the sciences. The two play off each other. Perhaps the cult of Jobs will, if anything, inspire a new generation of parents that perhaps there's something to be said for encouraging kids who sit in the middle, and don't feel comfortable completely in either camp. I know I don't, and it's taken a long time (and is an ongoing process) for me to comfortable with sitting in between the two. 
That said: do you know any people like Adams? I mean, not freakishly tall and afraid of deadlines, but instead people who are curious about the world and can spread that curiosity with infectious verve and are genuinely *excited and optimistic* about our future, and not instead preoccupied with the grimdark. 
[1] https://twitter.com/finalbullet/status/475288420592656384 
3.0 Hubris
Or: SUSAN SHOPS AT TARGET BUT PUTS HER STUFF IN NORDSTROM BAGS
I finally deleted Secret from my phone the other day. I'd been checking it less and less and it never really graduated into a habit. I had a peak usage where I was kind of obsessively checking it and making up stuff and getting comments and then there was the whole thing with the leak about Nike shutting down its Fuelband hardware engineering team that sucked me in a bit. 
But today, looks like the Secret team finally decided to double down on - in my humble opinion - showing that they're stupendously optimistic about the nature of human beings despite a whole bunch of evidence to the contrary with the launch of Secret Dens[1].
(If, like me, you heard "Secret dens" and you thought: what does Secret have to do with the founder of Dodgeball and Foursquare? then you should take a drink and think very carefully about your life)
So what is Secret Dens? It's basically Secret for different networks: like your workplace. Because having an anonymous-ish gossip network has always worked out really well when large groups of human beings have been involved.
But don't worry! Everything will be fine! How do we know? Because Valley:
"Our invite-only pilot of Dens follows an experiment at Secret HQ, where the 16 of us can share anything and everything we want — just with our team. After enjoying our inside jokes, updates and secrets in our Den over the last month, we’re confident that any company will love having one of its own." 
Right.
Admittedly, it's invite-only. So you know, you kind of have to apply for it, which kind of makes sense because hey, you didn't want to *accidentally* deploy a secret gossip network to your organisation, did you? And presumably they want to make sure that the individuals in charge of said organisation know that a secret gossip network has just been deployed to their organisation. 
Look, I know it's exciting to be in a startup and thinking that you're doing something that's going to disrupt the world. I get it. Well done, lots of golf claps all around, perhaps you can get daddy a membership to the country club if you go public. 
But I feel like I know how this went down. People got excited about phrases like "radical transparency" and "disrupting the organisation". Someone probably read Ed Catmull's new book and said that Secret was the "killer app for candor" and that it would "unlock more efficient, organic transfers of information and knowledge" leading to "more efficient, happier employees".
For which: bullshit. We know how this goes down. We know what people are like. 
I'm going to go and tie this a bit to some of the bad implementations of Holocracy, or the accusations of the kind of culture that Github is alleged to have. The whole startup culture of "we don't need no management!", which is perfectly fine when you're, say, sixteen people and you all more-or-less know each other and there are a lot of implied social conventions that you're all okay with until someone from outside the group joins and they, oh, I don't know, reasonable expectations and then it turns out that your implied social conventions weren't as well-tuned as you thought and then: drama!
There are a whole bunch of eminently reasonably ethnographers, anthropologists, historians, community managers and so on who would be able to look at Dens and say, pretty quickly, I reckon: this isn't going to end well. 
But I guess the promise of the Californian Ideology is this time, things can be different, and that if you deploy the right code in the right place, you really can change the world. So why not try?
And so I end today's episode with grumpy Dan: I predict bad things and the quiet closure of Secret Dens.
[1] https://medium.com/secret-den/introducing-secret-dens-633647edaf4
--
As ever, I love receiving your notes. So you should send me some. And if you've liked today's episode, please consider forwarding it to someone else who would like it too.
Also: congratulations! You got to the end of today's episode. If you feel like reading more rambling missives, then check out my archives at http://newsletter.danhon.com/archive/.
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Ninety Seven: That Most Killer Of Deals; Need To Know
Date: June 6, 2014 at 10:46:47 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fxgl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I got a bunch of notes back about what I wrote the other day about my depression. I don't really mind writing about it, and I think it's a tragedy that more people don't understand how someone can look fine on the outside but really not be on the inside. And in every single job where I've been in a managerial position, I've made it a point to make sure that everyone I work with knows it's OK - in the right way - to be able to talk to someone about what they're going through. 

It was still there when I woke up today. I was supposed to go out with my son to a music class, and I just couldn't do it. I collapsed on a sofa and practically passed out. I *should* have been able to go (there's that should voice again), in fact, I'd done perfectly fine getting up in the morning and getting him dressed and fed and cleaned up and then cleaning up after him, but... I just couldn't take that next step. And I had an incredibly understanding wife who told me that if I needed to hide from the world from a bit, then that was OK. 

I think it's a question of balance. I know that one of the problems I have is in dealing with things like they're absolutes: that if I take some time to slow down and recuperate by staying at home and away from people, essentially retreating a bit, then that's bad or a failure when I should be out getting stimulation. It doesn't matter if I might actually *need* to retreat for a bit, because that signal gets overridden by the guilt of essentially wanting to hide from the world and not deal with it. But today, I didn't take him to music class and instead looked after him at the park and we had a fun time on the swings and the roundabout and looking for planes. And whilst there's a little bit of it lingering, I can feel it receding. So that's good. 




1.0 That Most Killer Of Deals
One of the things that stuck in my head from Mary Meeker's 2014 report[1] was her description of the invisible app. Meeker uses Matthew Panzarino's description of what an invisible app is:

"Now, we’re entering the age of apps as service layers. These are apps you have on your phone but only open when you know they explicitly have something to say to you. They aren’t for ‘idle browsing’, they’re purpose built and informed by contextual signals like hardware sensors, location, history of use and predictive computation.

"These ‘invisible apps’ are less about the way they look or how many features they cram in and more about maximizing their usefulness to you without monopolizing your attention."[2]

There's a bunch of ways you could describe this. One might be just-in-time-apps: software that surfaces just when you need it, and not at any other time; it's this kind of "without monopolizing attention" that Panzarino's talking about. Another way of looking at it is that this is the dream of "do-what-I-mean" contextual computing: that finally, a computer will be smart enough to only tell me relevant information when I need it, and not before, certainly not after, and definitely never, not ever, irrelevant information. 

I have a feeling that the dominant way of looking at a problem like this was one of smarts: someone like Kurzweil would say something like: well, when we finally have enough processing power we'll be able to use *smarts* to predict what you might like, or want, and when. 

The horror, of course, is that something like this doesn't require smarts at all, it requires simple brute force. That's the thesis in Beau Cronin's O'Reilly Radar article about untapped opportunities in AI[3], and it points to a confluence of a number of trends that some of us might not be too comfortable about. Briefly, while the strong AI academics were busy not fulfilling the promises they'd dangled in front of us for the last forty-odd years, Google quite quietly amassed an unreasonable amount of data, an unreasonable amount of computing power, and than ran somewhat-reasonable machine-learning algorithms over them and came up with something (paraphrasing Douglas Adams) that was almost, but not entirely unlike artificial intelligence in narrow domains. Perhaps the best example of this is Google's success in machine translation. 

The dream behind the invisible app is one that's always been with us, ever since we've gathered around a fire and had an argument with the next hom. sap. because, damnit, why couldn't you just do what I *meant*, not what I *said*? Why do I have to bother with all of this communication nonsense, when you could just implicitly *understand what I want* and just do it? So Panzarino describes them as:

"[A] social network [that] knows exactly what posts you’ll want to read and tells you when you can see them, and not before? What about a shopping app that ignores everything that you’re unlikely to buy and taps you on the shoulder for only the most killer of deals? What about a location aware app that knows where you and all of your friends are at all times but is smart enough to know when you want people to know and when you don’t?"[2]

There is, as ever, a bit of Californian Ideology seeping through here. This is pure utility-by-algorithm, if only we let the algorithm peer into our whole lives, unobstructed, will it be able to anticipate our every need, at our side, in our pockets, on our faces, in our field of view. There's also a belief here: if *only* we had enough data, if only we had more context, if only we put more sensors in phones, if only we collected it all: and not just yours, we need everyone's - then we could iterate over it and map/reduce and hadoop it into just this one thing, that will forever and ever, tell you what you need, just when you need it. And then life will be so much easier. 

It's worth looking at this the opposite way: this anticipatory or context-sensitive computing utility is now being pitched as a way to save us from information overload. We can't possibly be expected to deal with the storm of notifications out there, so these new apps, in exchange for *more information about us* promise to keep quiet until there's something they think is relevant to us. 

But isn't the problem that all of these applications are *also* the ones contributing to the storm in the first place? This is somewhat of a devil's bargain: create an environment (whether by design or not) so noisy that the solution is to hand over *more information* and instead accept the quietness and the judgment of the algorithm.

So you ask: what do they make us give? What's the cost that we're paying? It's hard for us to calculate as punters, because it doesn't have a currency amount attributed to it: all of this is "free" at the point of consumption. As ever, the bargain is information about our lives, and that information is delivered (and stored) in an opaque way. I'm going to point to Maciej Ceglowski's talk again[4], because *right now*, with Google, the bargain is: have a bunch of implicit data collected about you, and then when you go and ask what Google says it knows about you, it's incredibly coarse and, well, wrong. 

Part of the argument here would be: well, you wouldn't be able to make sense of all that implicit data we have about you. And anyway, it might be useful, you never know! You never know when we'll surface - in Panzarino's words - 'that most killer of deals'.

I should be clear: I *want* context-sensitive applications. I want that magic future. But I've also grown up enough and changed from my 14-year old self to understand the consequences of that magic future and what you need to exchange for it. Because as Ceglowski points out, right now the value exchange feels tipped in the wrong direction and at least not entirely equally balanced. 

I would also *kill* for an example, any example, of this type of context-sensitive computing that is something other than the fabled "hey, here's that most killer of deals!" I mean, you don't see Picard pootling about in his Ready Room and then suddenly Main Computer says "Hey, Jean-Luc, but it turns out that someone just listed an original Shakespeare folio or whatever on FedBay, how much non-existent Federation money do you want to bid for it, oh, nm, I already sorted that out and it's in Transporter Room 2, Miles O'Brien is bringing it over now."

No (and I realise this is as lazy as the 'hey, here's a Starbucks coupon' perennial example that's merely been upgraded from its location-based incarnation), where's all my serendipity? Where's the genuine just-in-time *surprise*? Because all these examples are things that you know I'm interested in *when someone's got something to sell*. Where are the non-transactional examples? Where are the fun ones? Where are the even scarier ones? Where are the ones that are just goddamn frivolous? 

And all of this is without the real horror: that with all of that context that's being harvested, with all of that implicit data, we'll find out how predictable we really are. 

(Spoiler: very)

[1] http://www.kpcb.com/internet-trends
[2] http://techcrunch.com/2014/05/15/foursquares-swarm-and-the-rise-of-the-invisible-app/
[3] http://radar.oreilly.com/2014/06/untapped-opportunities-in-ai.html
[4] http://idlewords.com/bt14.htm
2.0 Need To Know
One of the notes I received in relation to one of my (many) rants about the quantified self was that there was one particular domain where it did indeed make sense, and it was one that I found myself in quite strong agreement with. Parents will understand this one, non-parents won't so much. 

So it turns out, when you have a baby, people (qualified professionals like nurses, paediatricians and doctors) keep asking questions like: how much are they sleeping, how many times did they poop, what was the poop like, how often are they feeding, which breast, for how long, how often did they wake up. 

Honestly, it's like they're obsessed with babies or something. The questions make a lot more sense when you understand that evolution has basically done a number on us - or women, at least - and attempted to perform some sort of optimisation tradeoff between how big our brains are and how big babies can be before they can't actually fit through the birth canal anymore. So the first three months *outside* the womb are pretty much a fourth trimester when, all things considered, it'd probably be best if baby stayed inside, but then baby wouldn't have a good way of exiting without doing an impression of that scene from Alien.

Anyway.

You want quantified self? That's quantified self. At the advice of good friends, we (or more accurately, my wife) used an app[1] to pretty much track *everything* about our newborn. And that meant that whenever a midwife or doctor or whoever asked a question about how well our baby was doing, we knew. To the minute. And then the awesome/creepy thing happened where it'd be able to predict his feeds down to the minute. 

So, yes. Babies. Totally need to be quantified.

[1] https://itunes.apple.com/us/app/ibaby-feed-timer-breastfeeding/id395357581?mt=8&uo=4&at=11ly9m

--

Some housekeeping:

For my new(er) readers, the long-term archive of newletter episodes is at http://newsletter.danhon.com/archive/ in case Tinyletter ever disappears (I hope it doesn't). Also, you should drop me a note and introduce yourself and say hi!

For everyone, consider forwarding this to someone who'd find it interesting. Or useful. Or funny. Or anything, really. Just don't waste their time. And if you think of something I should do to celebrate my upcoming one hundredth episode, do let me know. 

For some people who know *exactly* who they are, please put all of these in a corpus and run a Markov generator over them and set up a parallel tinyletter please so I can go on holiday sometime.

Have a good weekend,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Six: And Then It Came Back; Meek, Meeker, Meekest
Date: June 5, 2014 at 11:39:18 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fwrh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

A difficult day, as you'll see below. And the baby monitor app isn't working, so I'm upstairs, typing quietly and quickly whilst watching my son sleep. But, tomorrow's Friday, and my one meeting is about a fun project.



1.0 And Then It Came Back
I don't know how or why, but today was - is - one of the bad days again. I think the kind of depression that I get these days is different than the kind I used to get: the old kind would linger for weeks and would be incredibly hard to shrug off. It would be a sort of black listlessness that would leave me feeling like I was just going through the motions, every single day. 

But this morning was just started with a feeling - no, more than a feeling, a belief, a strong *conviction* that all of the typing for coins that I'd been doing wouldn't actually result in any coins. That everyone I'd been talking to wouldn't ever get back to me, and why would they? I mean, I'd look inside myself, do that bit of introspection where you try and list the things that you're good at and that people might be interested and it's like you're not even coming up empty handed, you're coming up just: empty. 

And it's a hard feeling to shake, and I think for people who've never encountered depression, *belief* is a better description than feeling. Because you *feel* low, or bad, but that feeling is grounded in a strongly held, conviction-welded *belief*. It's almost like you're a devout follower of how terrible, useless or worthless you are as a person. And nothing can shake that *belief*. The feeling almost just describes the physiological symptoms: the listlessness and the lowness, but there's a different sort of quality when you have an almost religious understanding and unshakeable belief - against all rational evidence - that you really are that useless. 

So in that respect, it's more like brainwashing, more like being a member of a cult of one, a sort of solipsistic downer in that of course no one can do anything to convince you otherwise, because it's just like when we discovered that we could zap brains in the right area and induce religious feelings and visions. It's a self-reinforcing, Gödelian strange loop that twists back in on itself and says: you're useless, and you thinking you're useless is even more evidence that you're useless. In an abstract way, I find it interesting because, at least in my case, I *can* step back and try to examine the system and say: yep, looks like you're depressed, you've had some right cowboys in messing around with your brain chemistry and neurological programming, definitely looks like you've got that thing where you're convinced you're worthless - and my exoself can understand that but can't *do* anything about because it's just got viewing rights, not admin rights to my neurological infrastructure. That's part of what makes the feeling part of depression feel quite so terrible: because in some cases you can absolutely know and understand from a rational point of view what you should be doing about it. But you can't. Because you have an irrational part of you that's busy one-true-believing that you really are that worthless. 

So I took the afternoon off. I got myself a replacement car2go card, authenticated myself into some German-produced metal-womb-like minimum viable transport device and self-drove myself home, ineffectually sat in front of WATCH_DOGS for about half an hour lobbing grenades at criminal convoys and watching them blow up, then headed upstairs to pass out. 

And it even kind of persisted when I woke up and looked after my son for a few hours whilst his mum got to have a stupendously relaxing massage, it persisted through when he learned how to blow through a recorder for the first time to make a sound, and it didn't even lift when I fed him dinner and gave him his bath. It didn't even go away when incredibly kind strangers who I've never met not only offered to introduce me to people, but followed through, and it still didn't go away when I got yet another holding note from the people running this year's Presidential Innovation Fellowships saying that they were still working on sifting through applications. 

Because it's depression. I have no idea when it will go away. But I know that it will go away. The thing is, I know that it will come back, too.
2.0 Meek, Meeker, Meekest
Here, I'll earn my keep. Here's some reckons on Mary Meeker's infamous internet trends report[1].

I'm not sure if it's possible to say it any more bluntly, but basically: people want the internet and they want it wherever they are. They will keep wanting it. It is too good. I'm not quite sure what mobile telcos are going to do about that, but hey, I'm glad I'm not a mobile telco. 

One of the things that's interesting about the headroom for growth for internet-connected consumer electronics with screens (Ie mobile and smartphones, PCs and tablets) is that mobile phones have only really been around from a consumer's point of view for about fifteen years and they're just about catching up to TV penetration at 72 vs 73% of world population. One of the things that I remember finding interesting is the effective-screen-size when you take into account physical screen size versus distance from face. People will hold mobile phones and tablets at the requisite distance to achieve a sort of comfortable viewing angle and size, so you don't ever really get the postage-stamp effect when the screen is big-enough for certain values of big-enough. Which means, at least for me: smartphone video is going to be a thing, because hey, TV is a thing. 

Also, I really hope at some point we can put to bed the concept of mobile web/internet usage being some sort of second-class citizen to desktop/laptop based access. The point of the matter is: the job-to-be-done requires the internet, and the internet is in your pocket. Of course it's going to be the first thing you reach for, because you're reaching for *access*. We shouldn't be surprised because it's kind of like asking someone: hey, do you prefer pizza at the restaurant a ten minute drive away (which, practically speaking, is what the laptop on the other side of the room is), or pizza *in your lap right now*. I'm always going for pizza in my lap.

There's an interesting implication that I don't think is covered elsewhere in Meeker's presentation which is the supposition that each new computing cycle leads to a 10x increase in the install base over the previous cycle. Meeker illustrates this by showing the progression from mainframes (1mm units) to minicomputers (10mm) to PCs (100mm) to Desktop Internet (1bn) to Mobile Internet (10bn). Current best bets, then, would be for 100bn internet-connected devices thanks to Moore's law transformatively pushing down connectivity into pretty much everything that doesn't have a screens. 

One last note - and this is only probably about midway through Meeker's report - is the statistic that 84% of hospital-esque healthcare systems are now using "fully functioning EHRs", when, from my point of view, a fully functioning EHR appears to be something that *says* it does all the things it's supposed to do, but doesn't necessarily do them in a way that conforms to the way that people work. 

While I'm here: it's notable that Maeda's slide on the death of bad user interfaces includes someone like Nike, but Nike aren't mentioned *at all* in the context of user interfaces or product or service design by Meeker, instead their only mention is in the production of the best ad on YouTube. Instead we get Fitbits, Runkeepers and MyFitnessPals in more evidence that it's the new challengers that are making the most headway, not the established brands. 

[1] http://www.kpcb.com/internet-trends

-- 

As ever, send me notes. I read all of them. And I'm even trying to reply to most of them.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Five: Health; Smart Cars; Odds
Date: June 5, 2014 at 2:20:14 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fw3t=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

It's 11:45pm here on the west coast, so I'm cutting it fine. This is probably the latest and closest to midnight I've written one of these weekdaily episodes and I don't think I've quite yet found a post-employment rhythm to them yet. It's been a one-and-a-half episode of In the Night Garden night, along with a oh-look-the-cat-brought-in-a-quarter-of-a-mouse night along with a it-was-quite-nice-whilst-you-were-sleeping nights with my son. And so: it's late. And I want to go to bed. And I'm tired. But, I'll still write. 



1.0 Health

So I'm still thinking about Health-the-app and HealthKit and the use-cases and the things that we can't talk about from the WWDC session videos and I'm kind of relaxing my stance a little and trying to be a little bit less grumpy and less reactionary. I suppose the thing is this: if you take a somewhat more reasonable attitude than the utopian quantified-selfers, then sure, having *access* to more information about your health to allow you to take more informed decisions is probably a good thing.

But then ask yourself this: when was the last time we were able to build something that gave you reasonable access to information so you had a sort of awareness, but didn't feel intruded upon or overloaded? Or, do you necessarily trust for-profit models to not try to monopolise your attention? I think what I'm getting at is this: it's not clear what Google was going to do with Google Health. It's kind of clear what Microsoft were - are - trying to do with HealthVault, because it's a typically Gates/Ballmer-era move: some sort of enterprise-the-business-is-actually-our-customer solution that in principle gives you access to your health record. Apple - whether through dint of great positioning or not - seem to have a take on Health and managing your medical information that they just want to help you out. Sure, it happens to be on their device, locked into their platform, but they're just kind of sucking everything out of existing data sources and then plumbing it together with a much more usable interface. 

On the one hand I've seen claims that if Apple saves even one life thanks to an emergency health record that's carried inside the Health app (much like the trend for having an address book contact named ICE - In Case Of Emergency - in UK phones), then they'll have achieved something tangible and worthwhile. Leaving aside the issue that for someone to access that information it would need to be easily accessed *whilst you were unconscious, and your phone was locked* and figuring out how to maintain access controls that would restrict and safeguard any sensitive information contained therein. 

On the other hand is the more specific example - which makes sense when you listen to it, but not in some other reports - of the Health app being able to notify your primary care provider (or whomever needs to know) when you record a blood pressure reading that is *outside of a defined range*. Again, leaving aside the whole issue of "well, what doctor is able to respond to such constant notifications" (part of the answer being: well, nurse practitioners, obviously). 

This might seem really obvious, but I suppose the point is: what can we build now that someone's decided to fix this problem of not knowing about the stuff your body's up to. It's not a particularly pressing problem (at least, we don't know how pressing it is and what the implications will be), but at least there's an option for better access to medical information that isn't precluded on the model of you checking it all the time to see if you're hitting your daily goal.

2.0 Smart Cars

I had my first ride in a Smart Car - actually, the car2go variant - when a friend I'm working with got us one to pop down town for lunch. They're pretty, well, smart: a bit minimum viable car: you turn round in the passenger seat and realise: holy crap, there's no rest of car there, it just *stops* like some sort of horror movie. The integration is nice, and I suppose it's what you get when you have Mercedes doing the whole thing end-to-end rather than what Zipcar's doing with retrofitting remote access to whatever cars they can get their hands on (side note: Zipcar's car's are significantly less fun in the Portland area now that they've been acquired by Avis Budget and instead of sporty zoomy things are now boring Ford Focuses), so when we entered the car the central display said something along the lines of "Hello Evan" and invited my friend to enter his PIN. 

We agreed, though, that there was a significant lack of personalization pushed through to the car. The mapping system that's built in looks kind of in-house (but I couldn't really tell) - again, it was kind of minimum viable mapping, but what you'd at least like would be some sort of "hey, we linked this with your Google/Foursquare/Swarm/whatever account and here are the top five places you normally go, if you'd like directions." We didn't really get a chance to use the nav system because I'm a human who knows how to get from a small number of places to another small number of places, but it would've been interesting to see if search history persists across car-sharing sessions. 

3.0 Odds

It looks like there's a small number of you who already read this who'd be interested in buying, or supporting, a best-of collection. And I realise that perhaps I was looking at this the wrong way because you're all obviously reading this in the first place. So the best-of isn't really for you, it's for everyone who hasn't read my newsletters yet. There were some good suggestions along the lines of "don't just collate them, edit them and do the easy thing", pointing out that what some people like about these episodes are that they are a bit stream of consciousness and what I should instead do is to try to replicate that experience or at least go a little bit deeper into it. I have to admit that the thought of doing a podcast is alternately a bit terrifying and a bit thrilling, partly because some of the most fun times I've had have been conference panel sessions with a bunch of friends where we're essentially chatting (and, from what I can tell, the audience enjoyed them too), and terrifying because hey all public speaking is terrifying even if you end up enjoying it in the end. 

I have a big spreadsheet at the moment. I caught myself, in a slightly weird moment, saying to my wife that I missed Salesforce. We used to use Salesforce (and also used Highrise) a little bit at Six to Start, the company I co-founded with my brother Adrian to track all the leads that we were getting and to try to model our revenue and sales pipeline. What I learned from that was that modelling that kind of of pipeline was stupendously infuriating because in reality, it didn't really feel like a pipeline at all. It felt like a really badly written progress bar indicator that would move really quickly for a bit and then get stuck at 98% for like three weeks and then either sprint across to completion or just hang and you'd have to force-quit the process. 

So anyway: I have a spreadsheet and it has a list of all the people I'm talking to and all the people I want to talk to and what I last did and what I have to do next and how much it might be worth to me and when I should hustle or hassle them again and I think: man. Someone should make this better. Email is so broken in so many ways. I shouldn't have to use a spreadsheet for this. Or perhaps it's just that I'm being overly anal and instead regular people are able to keep track of all of this in their heads. Or regular people really love using Salesforce. 

All of that is, I suppose, a roundabout way of saying: I'm still interested in, and looking to have, conversations with interesting people who are interested in working with me. I'm looking for consultancy/freelance contracting at the moment, and preferably a retainer relationship where I can do some thinking and doing for you. If you need someone who's super good at product strategy, or need to bridge the gap between traditional communications and product/service design, or you're thinking about (or doing) something in mHealth or wearables or the quantified self and want to talk to someone who has, I think, a lot of smart opinions about where things should be going, drop me a line. Or check out my LinkedIn profile at https://www.linkedin.com/in/danhon. Or if you know someone, point them in my direction. 

Gosh, that felt really dirty. 

--

Now send me notes saying how it shouldn't have felt dirty. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Four: Eating The World; And A Question
Date: June 3, 2014 at 11:36:57 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fva9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm settling into a sort of post-employment routine now where the family gets up at around 7am and I dress and feed our son then play with him a bit while my wife gets ready. Today, my first bit of "work" was at 10am when I had a call scheduled - and instead of doing it at the house, I decided to go downtown and take the call at a cafe, seeing as I had a lunch meeting, too. And it's at that point that, I think, I made my first mistake. 

See, I might have that part of a routine, but I don't have the "work" part of a routine quite yet. So today I decided to take my call at Tilt, which is just kitty-corner from the agency where I used to work, and I told my wife, "oh, it's not problem, just drop me off where you used to drop me off". And so we stopped at the usual place and I paused before getting out of the car and said, "We can't do this again. It's too weird." 

Because, no disrespect to my former colleagues, but it *was* too weird. It was as if I still had some sort of employment umbilicus that I hadn't quite cut yet that was still tethering me to a specific place. Perhaps it was clinging on to some sort of familiarity and routine of the coffee shops and places I used to go for lunch that I got drawn back to that place. But, stepping out of the car and seeing people I used to work with, everything felt wrong.

So, I think, I won't be going back. At least, not regularly. 
1.0 Eating The World
Marc Andreessen of a16z kicked off one of his tweetstorms the other day looking at the macro picture of automation and computing and their effect on the economy and labour market[1]. A gross simplification of Andreessen's argument is that robots won't "eat all the jobs" because they will free us up to do other things, creating new markets and new jobs. I should add, first, that where I think Andreessen and I differ is mainly just an element of degree rather than outright disagreement and also in terms of timescale. 

So, first: Andreessen says that we don't know how to automate, or know how to apply the computing power that's now available to us, towards goals like "creativity, innovation, exploration, art, science, entertainment [and] caring for others". His argument follows that when automation is abundant, human experiences become rare and valuable (because they focus on what it is that is unique and non-replicable about the human experience), and says that as the price of recorded music has tended to zero (or that access to recorded to music has tended to zero), the live touring business has exploded. Alongside that, he points out that as the price of drip coffee dropped, the demand for handmade gourmet coffee grew. 

Let's take a pause there. The last time I talked about this, I was mainly concerned about the loss of jobs in the transportation business. Having never worked in haulage, I'm fully prepared to admit that I'm probably talking out of my ass, but I can't necessarily say that long-distance haulage and transport of goods is a fulfilling career. It is, I would say, an example of the mindless drudgery, a job that could be done better through automation and probably should be done through automation. 

The thing is, at the macro level, eliminating those jobs is a good thing. People are capable of doing so much more than helping to move dumb arrangements of atoms from one physical location to another. Let the machines do that work at our bidding. But at the micro level, that's about three million livelihoods that are about to be disrupted. And this is, I suppose, where conservatism or paternalism or the idea that people are lazy layabouts who need to get off their asses comes from: the writing is on the wall. So what are you, as one of those three million, going to do about it? 

The narrative that we had been sold culturally - at least where I grew up - was a simplistic one: get a job, turn it into a career, settle down, buy a house, pay it off, live your life, retire, collect a pension, die.

Turns out the world is a lot more complicated than that. These days, more than it ever was, life is a hustle. The days of a job-for-life are obviously over, but what might also become true is that a career-for-life ends, too. *Within your own lifetime* you might find that the track that you had thought you were on becomes thoroughly disrupted. And without a framework for something like continuing education, or without a societal/governmental way of looking at how people transition from one career that *literally disappears* to one that *literally appears*, it's hard to see how, at the micro, individual, community, people level, we aren't in for anything other than a world of hurt. 

Of course the argument is that this has always happened. Well, it's always happened for a couple hundred years. But I think we can agree that the rate of change is increasing just as our institutions are incapable of keeping up with it. 

Okay, so the argument goes that you should change "education" and make it fit for the twenty first century purpose. There's been lots of back and forth in this space - the parts I've been exposed to have pointed out that the education system *as it exists - the classroom system and so on* happens to coincide quite neatly with industrialisation, factories, mechanisation and the need for a workforce that's able to do things. Sure, again, a gross oversimplification, but the question remains: what is education for, and what are people supposed to do with it? 

Because right now, the world *still needs* a bunch of people to do things that we can imagine will be eaten by software and automated away within their lifetime. You can imagine a sort of time horizon in that there are jobs-to-be-done that are the bottom of the pyramid, easily automated, most easily disrupted that *right now*, for at least the next five to ten years, need to be done. But, if you're considering things from the point of view of an individual who's working out how to maximise their income and contribution to society (ie their expected lifetime value of earnings), then they've got to take into account the following: should they anticipate automation? Or should they be prepared to work a series of short (five to ten year, say) term arbitrations where they "do the work" that machines will later do and then move on to the next piece of labour?

The problem there of course - and you have to realise that I'm thinking all of this out loud, as it were - is that if *everyone* were to do that, there'd be no one left to do the jobs that needed to be done (which, I guess, is why we have a labour market), but also this question: *why* are these people doing those jobs that machines are doing. The quick answer, of course, is: it's the market, stupid: they need the money, and someone's going to pay them for it. You don't get everyone educating themselves to be smart problem solvers with transferrable skills and no-one willing to do plumbing. 

Which brings us to the second part of Andreessen's argument: that you have to accept that, on a certain level, increased automation is going to bring the cost of *the goods and services affected by automation* down to zero or near-zero. Let's leave aside the fact that there's a massive difference in reality between zero and near-zero and instead focus on the point that automation increases the standard of living. Yes, it does: but does the cost of living stay fixed, and instead *for the same amount of money* do you get a higher standard? The point being that I would've paid a certain amount for "communications" a couple decades ago which would cover things like "stamps" and a "landline", but instead I probably pay roughly the same amount - so in real terms the money that I'm spending is the same - but I'm getting value that I couldn't have gotten a couple decades ago. I still need to spend the money though. 

So: better, higher standard of living. Still need to spend money for it. Some jobs going away, entire new fields being invented. Likelihood of government being able to act fast enough, or to develop a framework that will help ease the transition? Practically nil. *OR IS IT?*

[1] https://twitter.com/pmarca/status/473627894392958976
2.0 And A Question
It's been suggested to me by a few people, so I'm thinking of pulling together a Best Of edited collection of bits of this newsletter and making it available as an ebook or Kindle Single. Or, even, printing the damn thing out as a newspaper via Newspaper Club. 

So, let me ask you this: if I were to run a Kickstarter to get that all pulled together (which would cover getting an editor in to help me massage everything into the right kind of shape, and then spending the time to make sure everything was typeset right, or even hiring someone who actually knew how to do that):

a) would you back it; and 
b) how much would you pay for the ebook or Kindle Single;
c) how many of your friends would you tell to buy it.

It's super simple - just hit reply and say "yes" (or "no", I suppose, but I'm only really going to count "yes"es) with how much you might be willing to pay. 

--

That's it for today. As ever, send me notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Three: Email Is Still A Killer App; Dubya Dubya Dee Cee
Date: June 3, 2014 at 12:14:24 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fun9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
It's 10pm on a Monday night, and I've been typing for coins. And I thought it would be *easy* to type for coins today but I completely forgot about nerd Christmas.
1.0 Email Is Still A Killer App
Occasionally, I meet people who read this, or people who know that I write a newsletter and then we all have this weird conversation which is all funny ha-ha and goes a bit like "so, newsletters! Aren't they a bit artisanal 90s! And you live in Portland!" to which I have to say something like, "well, funny you say that, but..."

So here's the thing. I now have <checks> 1,093 subscribers to this. I've been doing it every weekday since 23 January this year. My "record" is 5,229 words. I am astounded, *literally astounded as in you would not believe the astounded look I have on my face*, by the people who subscribe to it, because I do not understand why they do, and yet (whispers) they're still here. 

Let me back up a bit. 

I started blogging back in 1999. It wasn't even called blogging then. It wasn't even called web logging. It was just... a thing that people did on the internet. And, for a few years, I blogged a lot. And by "blogged", I mean: wrote on the internet. About pretty much anything. And then I stopped. Funnily enough, most of the friends I made during that period (mainly people I met in 1999/2000, when you could make a list of "all the people in the UK who were web logging" and the length of that list would be countable using the digits a relatively average person would have on their hands) also stopped blogging. 

One of the reasons - and I hear this concern from others, who have similarly stopped writing online - is that: man, is there so much writing online these days. Oodles of it. It's almost as if we were at risk of using the internet to commune with each other and then some supreme being like Ev Williams decided: No! You shall not speak person unto person! Instead I will give publishing tools to each and every one of you so that you may all speak and never listen to each other! And then we will invent *comments*, which were like a proto-form of YouTube comments only they weren't quite as nonsensical and not quite as mean (apart from some of them), and then, just to confuse you, we will invent *trackbacks* and then someone will have to come up with rel=nofollow and then we will all use Blogger for a bit and then it will be bought by Google and then we'll use Movable Type for a bit and then some of us will use Blosxom and then some of us will use Wordpress and then some of us will just give up and use Tumblr and then just when we think we have it all sorted out Ev will go and invent Twitter and then we'll all truly be fucked because who has the time to write medium/long-form content on the internet anymore when you have to spend the whole day being witty in 140 characters and pretending you're in an episode of the West Wing. 

So, this: there's a lot of writing on the internet these days. Anyone can do it. Anyone does do it. So, if you're a reasonable person, why bother doing it unless you've got something interesting to say? And that chap Moore, with his law, only went and made it cheaper and easier and faster for *everyone* to get on the internet, not just the somewhat reclusive people in the mid to late 90s who were looking for other somewhat reclusive people. 

But no, when *everyone* could get on the internet (for certain values of "everyone"), then it wasn't just enough to have an opinion or a reckon, because it might turn out that someone who actually knew what they were talking about could *also* post their opinion. And then what would yours be worth?

So one thing that stopped me from blogging was performance anxiety and no longer feeling like a big fish in a small pond, or even just a fish in a pond, as opposed to the reality, which was being plankton in an ocean the volume of Jupiter.

That part was easily dealt with by, honestly, drugs and a whole bunch of therapy. Now I don't care. I just write. 

But, email. 

See, the thing about email is this. Even though you could just click or tap or home-button away at any moment, you don't. Because email is in a different context, even though it's just the same binary bits rendered through HTML (apart from if you read this in Gmail for iOS on an iPhone in which case the formatting is really terrible. Sorry about that.) 

But there's something about email where I can capture your attention. Where you won't go away. Where I don't embed links throughout the text so you can just leave. And maybe there's also something about the way and the tone and the manner in which I'm writing where, honestly, it's all a bit stream-of-consciousness and verbal as opposed to written. 

And yes, there's the argument that Google killed RSS when it killed Reader and that newsletters are where blogs are going but that's not really true, because yes, RSS is pretty much dead now apart from the RSS aficionados who trade tips on working readers and feeds like people who're into vinyl excitedly discovering a new store. 

But email and this newsletter gives me a different sense of relationship because I get identity data from my subscribers. I know, in a way, who these people are, in a way that I never did with RSS. All I ever got was a number of times my feed was hit, or maybe a number of RSS subscribers through a service like Feedburner. But with a mailing list, I get personal subscribers. Unless I assume you all have assistants who print this out for you and leave it on your desk, in which case, I have relationships with all of your assistants.

And it's not just about the editing interface: because the editing interface for Medium is so much better. But this mailing list, this newsletter is a bit dark web - it's on the web, but you have to kind of look for it. It won't really show up unless you know it's there. It's a bit Platform 9 3/4 that way. And comments, too: whilst I publish archives of this newsletter on a subdomain at my site, the only real way I invite people to reply is through email. Which isn't visible, and doesn't get published so, bluntly, I don't get crazy people leaving comments all over the place. Or comment spam. And I don't need to worry about Wordpress being vulnerable. (Apart from the archives, of course. Hey, Tinyletter: you should provide archive export and archive publishing for $).

So, this is the thing. Don't write off email. It does things the web doesn't do. And because of that, it's a unique, viable platform. 



2.0 Dubya Dubya Dee Cee
Apple kicked off their WorldWide Developer's Conference today, in case you hadn't noticed. I've got two short reckons here, about Health/HealthKit and HomeKit. 

First off: the keynote didn't actually give much meaty information about either Health{Kit} or HomeKit. But it wouldn't do: it's a keynote, and that's not the place to divulge all the awesome stuff. Because what both Health and HomeKit are, are under-the-hood things that will take a few years to get ready, rather than something that's more quickly grokkable, like the fancy Swift demo with a playground.

First, Health. I haven't spent much time thinking about this yet, but I'm curious as to how this is going to play out and in what direction. By that, I mean: will doctors trust self-reported, self-recorded data? I mean, they trust it when I use a medical device they give me, that's regulated by the FDA, and then they pull the data off themselves. They even trust it when I use a regulated device and write down the numbers (which I could be lying about) and then fax them back over. 

The other way around is: man, you know how I feel about dashboards. Too much information that I don't care about, that I don't need to see. Honestly, if the quantified self people went and designed a car you'd never get around to driving it because you'd spend the whole time looking at graphs of data over time like, ooh, isn't piston number one doing well, see how its performance has been doing over the last six months when: I DON'T CARE, I JUST WANT THE ENGINE TO START.

So I'm not convinced that we *need* to see all the data that's presented in Health all the time, but the nice thing about Health, the app, I suppose, is that you don't *need* to look at it all the time. And as a system application, Apple has no incentive for you to keep checking out your blood pressure every thirty seconds. Or for you to constantly be looking at your sleep patterns.

HomeKit, then. Again, not much about this in the keynote. And, frankly, not much more other than the promise of being able to control a cluster of things using some sort of *automation* that enables spooky action at a distance like turning on lights and so on. Again, I'm not entirely sure what the value of this is, and whether it's a thing that will totally catch on like people setting up whole scripts of actions to be accomplished when they leave the office geofence on their way home from work. Like, I don't know, tell the Roomba to hide its embarrassed ass. Or tell the microwave to, I don't know, microwave something empty because it can't put a frozen dinner for one inside itself without human assistance.

Anyway. More as I noodle on it.

--

Send notes. I eat them. I haven't had many lately, so you should all feel bad.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety Two: Continued Disruption; Snow Crashing (7); Edge of Tomorrow
Date: May 30, 2014 at 10:59:30 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ft1p=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I spent a pretty good morning with the internet's Evan Cordes working on a secret project that I think I used to have a code-name for, but have probably forgotten. Which means it's really secure. The afternoon was taken up with playing with my son in the water and finding out that today was the day that the plants decided to have sex and attack my nasal passages with all of their junk. Not cool, plants. And then lastly, some belated celebrating with the internet's Andy Baio, because he won. I'm pretty sure I'll do a reckon about Upcoming's second coming (ha) next week. 
1.0 Continued Disruption

Following on from yesterday's episode on disruption[1], this isn't a weak signal, it's a klaxon. One of my readers linked me to a CNN report that Amazon plans to deploy an additional 9,000 warehouse floor robots[2], for a total of 10,000 deployed, by the end of the year. There's more colour in this Motley Fool report[3]. Now, the Motley Fool report says that Amazon says the robot deployment won't impact the size of its human workforce (if true, this is Amazon catching up to required capacity, or deployments being used in new areas, for example). But the colour in the Fool report (complaints of Amazon's warehouses at or nearing sweatshop conditions, onerous overtime requirements, high temperatures) bring to mind something not so much as the concept of terraforming-for-capitalism[4], but terraforming-for-automation. 

The counter-reckon against this sort of SlowFast disruption is that for all those in transport-related employment, there's a big bunch of entrenched interests that will collectively lobby against, and try to resist, any sort of structural change in their industry. That sort of resistance only works in the sense that it slows structural change - name me one industry where change has actually been resisted or rolled back in a meaningful way. The MPAA and RIAA fought tooth and nail against the onslaught of digitization and what the net meant as a pipe to fulfilling consumer desires and arguably lost out as a result: the future of music and movie distribution could've been in their hands and yet it took technologists to implement a good-enough, usable solution that actually moved significant numbers of bits. And yet digitisation happened anway.

The question isn't if software's eating the world. It is. The question is what software is eating the world *for*. Is the world just an optimisation problem that needs some algorithms applied to it? This is why there's a clash of ideology between the stereotypical socialist European contingent and the Californian Ideology - both sides can see the promise of software, but both have different (if not vaguely articulated) visions of what software will leave once it *has* eaten the world. The fears of the left, in opposition to the Californian Ideology, are that software will eat the world in service of its capitalist masters, that it will promise to disrupt existing power structures but just end up reinforcing them, the same way it has always done. The fears of the right (I'm assuming) are that software will eat the world and will not reinforce the sort of power structures that are inherent to free-market capitalism. 

What sort of world do we want left over, once it's been eaten by software? Because the software is indifferent to you, me or anything else. We're just bits that can be digitised. 

[1] http://newsletter.danhon.com/episode-ninety-one-disruption-supply-chains-the-good-bit/
[2] http://money.cnn.com/2014/05/22/technology/amazon-robots/
[3] http://www.fool.com/investing/general/2014/05/29/will-amazons-10000-robot-workers-turn-it-into-the.aspx
[4] http://newsletter.danhon.com/episode-forty-seven-building-better-worlds-mobile-more-video/



2.0 Snow Crashing (7)
It's been a while since I've done a Snow Crashing. The last one was back in episode 64[1], where we covered the hypercard stack given to Hiro by the Snow Crash pusher outside the Black Sun. Now we're at the start of chapter six, and YT is about to introduce us to the metacops and the end-game of privatised security and policing. 

In Stephenson's vision of corporatised America, everything that can be done by a corporation instead of government is done by a corporation. It's obvious that he's satirising; Snow Crash, written in 1992, is a whole five years later in our universe's timeline than Robocop, which was released in 1987. MetaCops Unlimited are simply the latest expression of the horror that is privatised security in America's future. 

When Stephenson describes the MetaCops Unlimited cruiser and the badge on its door, he calls out the copy that's emblazoned on it: "DIAL 1-800-THE COPS / All Major Credit Cards", for which we're able to ascertain: in the future, there are no short codes, voice calls are still primacy, and credit cards are still the preferred method of moving bits of money around. 

Of course, the *real* end-game here is the Libertarian Police Department, neatly skewered in the New Yorker[2].

This is our opportunity to learn a little bit about FOQNEs again - Franchise-Organized Quasi-National Entities; the geo-political makeup of the Snow Crash universe includes Burbclaves (of which The Mews At Windsor Heights is one), FOQNEs like Caymans Plus, The Alps and Mr. Lee's Greater Hong Kong, and then of those, the very-special FOQNEs, like Metazania and New South Africa which are Stephenson's shorthand for violent, aggressive strongholds where white men like to shoot things. These days, I suspect that FOQNEs would include Alex Jones' INFOWARSLAND, Glenn Beck's Independence, Peter Thiel's Seasteading Institute and Reddit's Mens Rightslandia. I wonder if Mr. Lee's Greater Hong Kong (it's nice to see the reminders that, when Snow Crash was written, Asia was in its ascendancy in consumer electronics, and it would be Hong Kong, not the Valley, that would inspire a robotically defended sovereign nation). 

There's a nice line when Y.T. approaches the gates at White Columns and doesn't get scanned and Stephenson takes to its logical conclusion what it means to have a quasi-national entity operating on a smaller-than-city level. The security of the city state, reminds Stephenson, means that "just about everything, like not mowing your lawn, or playing your stereo too loud, becomes a national security issue."

We get a demo of non-violent takedown weapons - in this case, a kind of goo gun that is able to stick Y.T. to the gate with a football-sized set of super-sticky fibers. Such weapons are needed because city states are so small in this future; they're abutted next to each other such that "innocent thrashers [are] always a three-second ride away from asylum in a neighboring franchulate." And so we learn that the FOQNEs, like all good quasi-national entities, have treaties and extradition agreements with each other 

[1] http://newsletter.danhon.com/episode-sixty-four-computer-says-no-snow-crashing/
[2] http://www.newyorker.com/online/blogs/shouts/2014/03/libertarian-police-department.html

3.0 Edge of Tomorrow

I know some of you are going to find this hard to believe, but I actually got a Klout Perk that I didn't mind receiving (ie it wasn't a preview of a tv show on Hulu, and it wasn't something from McDonalds.) - a preview screening of Edge of Tomorrow, the Groundhog Day-meets-Aliens-meets-Pacific Rim action-SF film starring action-SF mainstay Tom Cruise. 

Edge of Tomorrow is based on the Japanese short story All You Need Is Kill[1], and all you need to know is that you should either watch the movie or read the story, right now. In a spoiler-free sense, no, this doesn't feel like your typical Tom Cruise movie. He feels relatable. And it's nice to see some aliens that actually look and behave pretty alien. I have to admit, I was a little weirded out by the actual BBC News 24 presenters being in actual BBC News 24 fake broadcasts, and the fact that most of the movie takes place in the UK (and at Heathrow, transport infrastructure fans) only gives it more nerd points. 

I place this movie near the top of the List Of Movies Matt Jones Should See.

[1] Amazon: http://amzn.to/1kROiCC

--

Okay, that's it. Have a great weekend and remember to send me notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety One: Disruption; Supply Chains; The Good Bit
Date: May 30, 2014 at 12:20:46 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fscl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I'm readjusting to life with family. And on top of that I'm finally getting back into videogames. But anyway, on with the show.
1.0 Disruption

Bear with me on this one, it's really thinking out loud and thoroughly unresearched. First, some data points:

 - Uber obviously wants to replace all of its drivers with self-driving cars[1] 
 - Google is designing self driving cars / autonomous transport units[2]
 - US 2012 Census Statistical Abstract; Labor Force By Industry[3]

I've written before about EasyHard[4] problems and now I want to think about SlowFast problems. Because disruption doesn't happen quickly, it happens like an iceberg hitting the Titanic: slowly, inexorably, somewhat inevitably and then quickly. By the time you notice it, it's too late. 

I wonder how governments get faster. They've always (see: there's a reckon) been pilloried by industry for reacting not only badly but with delayed reflexes, or quickly and badly. At least in good governments there's a principle of quick legislation always being bad legislation and normally upper houses are a good check on this, at least being able to send back bad or badly ambiguous legislation to lower houses for them to take, sit down in the corner and think carefully about what they've just done.

But it feels like there are things that will happen - or are happening - SlowFast and they'll have a shocking impact to how our nation states work. 

The reckon is this: when driverless cars come - and they will - they'll come quickly. They'll *feel* like they're coming slowly, but they'll come quickly. They will not come in the way that computerisation happened to the back-offices of the 70s through 90s, they're going to come like an ultrasonic shaped shockwave rippling through glass, smashing it to bits. And then those jobs will be gone. 

They won't be somewhat gone - they'll be gone. Because this isn't low-hanging fruit disruption anymore, this is capital D disruption, and I get that people are kind of salivating at their mouths at it, but point me to one time, one time *ever* in the history of humanity when Big Change has happened and it's gone down relatively well. 

Right.

The insensitive SFnal geek in me is looking at this stuff - driverless cars, autonomous transport systems, whatever you want to call them, the moment that Kiva and Baxter robots suddenly become slowly, quickly viable in pick-and-pack warehouses - *something* is going to happen and wondering (this is the insensitive bit): where's the Foundation[5]? Who's going to pick up the pieces? Around three million people work in haulage/transport jobs in America and, bluntly: those jobs won't be coming back. They will be done faster, better, cheaper through automation. 

But the world that they'll disappear from isn't the world of Usborne Utopia[6]. It's this one.

This is not a new thing. This is what happening when mining disappeared or when merchant shipping disappeared or any number of other industrial shifts.

So what's being done to make our population and economy resilient? Oh, I get that the *economy* in a way will be resilient. But I'm not sure what that means when x million of jobs get displaced and there's no safety net.

Software will eat the world. It will not care how.

[1] http://www.theverge.com/2014/5/28/5758734/uber-will-eventually-replace-all-its-drivers-with-self-driving-cars
[2] http://googleblog.blogspot.com/2014/05/just-press-go-designing-self-driving.html
[3] https://www.census.gov/compendia/statab/2012/tables/12s0620.pdf
[4] http://newsletter.danhon.com/episode-nineteen-not-trying-is-a-signal-peak-game-easyhard-snapchat/
[5] http://amzn.to/1pCMpdF
[6] http://life.enhasa.org/wp-content/uploads/2010/01/The%20Usborne%20Book%20of%20the%20Future.pdf



2.0 Supply Chains
Some more thoughts about supply chains, following on from yesterday's episode[1]. 

The first, prompted by a note from a reader is that yes: the Guardianista sandal-wearing among us fret every time we use Amazon because ohmygosh it's so convenient but did you hear how they treat their workers[2]? But what's the alternative? Do you have an option for slightly-more-expensive products with such a stupendously long tail that can also be delivered either next day, or in two working days? No, you don't. 

So it's unclear whether Amazon's Amazing Prices (and its supply chain and logistics) can only be delivered thanks to its uncompromising approach to labour (there's a euphemism for you) or if Bezos is just playing a long con and instead will pull some sort of bait-and-switch and go "surprise!" emancipate all of his workers and then replace them all with faster, cheaper, better Kiva/Baxter pick/pack automation. And anway, Amazon is only one of your worries, you Guardianista lot, Walmart is the other one. And Tesco. And basically all of the giant grocery superstore companies. 

Anyway. 

The other thing about domestic supply chains is that - for me, at least - getting the stuff to the door isn't the problem. I can do that. Tesco or Safeway or whoever can deliver stuff to my front door. They could get more regular about it, they could predict better, they could even just make the user experience of ordering the stuff easier. No, the big problem is The Last Few Meters. It's getting the stuff out of the bag and into cupboards and put away. It's like how people don't have laundry problems, they have folding and hanging and putting away problems. Solve that, and you'll have disrupted something.

[1] http://newsletter.danhon.com/episode-ninety-supply-chain-management-for-seven-billion-too-early-watch_dogs/
[2] http://www.theguardian.com/technology/2013/dec/01/week-amazon-insider-feature-treatment-employees-work

3.0 The Good Bit

Some good news, though. Space is happening.

 - SpaceX unveiled Dragon2, their man-rated spacecraft. It looks like a genuine outbreak of the future, only a few decades too late. http://new.livestream.com/spacex/DragonV2

 - Citizen scientists have assumed command and control of ISEE-3 in a quite-frankly Apollo 13-esque herculean effort of ingenuity and crowdfunding. http://spacecollege.org/isee3/we-are-now-in-command-of-the-isee-3-spacecraft.html

--

That's it for today. As ever, send me notes, because I devour them.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Ninety: Supply Chain Management For Seven Billion; Too Early; WATCH_DOGS
Date: May 28, 2014 at 3:48:21 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-frbx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Wife and son get home tonight, plus I have a man date to go see an early screening of All You Need Is Kill, er, I mean, TOM CRUISE'S EDGE OF TOMORROW, which by all accounts should be fun. 

One of the things I talked about with my therapist today was the anxious feeling of waiting for the other shoe to drop. By that, I mean I feel like I haven't - for whatever reason - fallen apart or collapsed given what's happened over the last few weeks. Sure, I've had wobbles, but it feels like stupendous progress to be able to stumble and keep going rather than to fall down and not be able to get up. That's what it feels like. I *think* that's resilience: to know that I can keep going and actually have it in me to keep going, to not get trapped into that place I'm familiar with where it's impossible to do anything. And I really do think that part of it is about the network of support that I've fashioned for myself. You might have read the story about toast, the latest artisanal food craze in San Francisco[1] and yes, you Won't Believe How It Ends, but really, you should read it. I feel like, through writing this newsletter, and building a quite remarkable network of relationships through it, I've made myself a lot stronger. So whether you've been reading these from day one, or whether you're one of the fifteen who've subscribed so far today, thank you.

[1] http://www.psmag.com/navigation/health-and-behavior/toast-story-latest-artisanal-food-craze-72676/

1.0 Supply Chain Management For Seven Billion
One provocative reply[1] to my thought about smart things from episode eighty eight[2] was the idea of the frictionless domestic supply chain. If you're talking about one thing that would help the stereotypical and somewhat gag-inducing "typical working parents" who have a household to manage, anything that saves time is a Good Thing. Anything that saves time without any further expenditure of cash money is an even gooder thing. 

There was a talk at one of the few advertising conferences that I went to - AdAge Digital 2013[3], I think, by Lisa Utzschneider, VP of Global Advertising Sales at Amazon. Utzschneider's talk was interesting not because of the advertising bits (blah blah opportunites for brands to connect with consumers) but because it illuminated Amazon's goal of working for the consumer (let's just say: the regular person) through efforts like subscribe and save. Utzschneider was a fairly vocal advocate of doing all your shopping from your phone, via Amazon, and not having to do that dreaded weekly shop (which, I think, is slightly more of a British phenomenon than an American one?) where you drag your kids out to a giant box store and cart everything around. Instead, imagine a much more civilized future where you just say "Oh, don't we need some more toilet paper" and then toilet paper magically appears.

But even that isn't frictionless enough. It's where things like Berg's Cloudwash[4] come in that do the mythical task of automatically ordering consumable supplies for you in the background. Of course, it'd be great if we could simultaneously envisage a future where those consumables didn't come locked, HP DRM printer-cartridge style to a particular service provider and there's nothing necessarily preventing an open consumable washing machine future (yes, we really type those sentences now) other than sheer bloody headed obstinance on the part of a manufacturer, retailer or FMCG brand. 

Anyway: it seems that you can divide home automation by looking at spooky-action-at-a-distance tasks (is my sump about to overrun, can I turn the lights on) and recurring supply-chain type tasks. I'm going to preface *all* of this by saying that Jesus Christ I don't want to sound like some sort of Mansplainer who's going to come in and tell you all about domestic maintenance, so if at any point I *do* sound like that, know that it's not my intention and these are just wildly inaccurate, possibly sexist, probably insensitive reckonings from someone who still is struggling to live in non-traditional domestic harmony. 

(An aside: there's a difference, for example, between *cleaning* your clothes and *caring* for your clothes - and in the extensive conversations my wife and I have had about the subject it's clear that my interest in the matter extends only so far as cleaning, whereas hers is much more in-depth and concerned with caring. Which is why we have a gazillion piles for different clothes, programs and washing detergents.)

So it strikes me that, *as a general principle*, if someone actually went and asked the people who by default end up performing the vast majority of domestic maintenance what would make their lives easier, you could probably free up a bunch of time. This idea of using technology to reduce friction is a common one, and one where it intuitively feels like there's a whole tonne of friction that can be disrupted out, as it were. America has its own problems that make nationwide scaleable delivery services difficult, but things like Amazon Fresh are making inroads whereas in the UK, grocery chains like Tesco, Sainsbury's and Ocado/Waitrose have been busy making hay with the increased population density. The idea of taking a look at what it takes to keep a house - for individuals, couples, cohabiters and families - and working to make that as easy and as pleasurable as possible feels like something that, opportunistically speaking, opens up a whole market that the valley doesn't traditionally take notice of. 

It's hard to think about this *without* Amazon coming to mind. When you say things like "how do you develop a supply chain for the mundane tasks and requirements of the next seven billion", you instinctively reach for one of the private companies that's already doing it: with their distribution centres and their Kiva robots and their zero-hour contract workers picking, packing and sending, what we have when we peel back the veneer of the gloss of the Amazon user interface is the underbelly of what it takes to move all that materiel, every single day, and make sure it gets to the right person on time. I refuse - in a bit of an obstinate way - to believe that this is a winner-takes-all market in terms of the "getting stuff to people" problem, but Amazon have a bit of a head start. Competition is always good, right?

[1] Thanks, Rachel Coldicutt: http://fabricofthings.wordpress.com and I write this deliberately provoking Ms. Plowright
[2] episode 88
[3] http://events.adage.com/digital2013/agenda/
[4] http://bergcloud.com/case-studies/cloudwash/



2.0 Too Early
Hanging out in San Francisco with friends I've had for nearly fifteen years now - through the first dotcom boom, through web 2.0 and now through this fourth internet - whatever that is - there was a lot of nostalgia. Many of us who started blogging in the late nineties met up for the first time in a pub in London and remained close friends ever since, and it's been interesting to see where we've all ended up. Some of us even nearly became rich, even nearly made it, even nearly came up with that one killer app.

What mostly happened, though, was that a fair few of us were early. I ended up looking today at a friends-only wiki page that had advice for choosing a mobile phone in the pre-iPhone era, lots of talk about people having Nokia N95 devices that were generally frustrating. And from there it was only a short hop skip and a jump to the Wikipedia entry for another thing I remember: Nokia Sports Tracker[1], something that was hacked together at Nokia that mainly used the built-in GPS of some of their devices to rudimentarily track your running or cycling activity, and that had later been hacked together to use accelerometer data too. (It turns out that the N95 had an accelerometer but used it more for device orientation when taking photographs than anything else). 

So it turns out that so many of those ideas people had, like Upcoming, like Dopplr, like Flickr, turned out to be too early. They could see what technology could do and bring but the tools, materials and critical mass just weren't all there at the same time. And sometimes, people forget that what happened was that simply something was too early, as opposed to completely the wrong thing.

[1] http://en.wikipedia.org/wiki/Nokia_Sports_Tracker

3.0 WATCH_DOGS

So I spent some time yesterday playing Ubisoft's WATCH_DOGS, a so-on-the-nose-zeitgeist new aesthetic open world game all about resistance and surveillance and hacking and all that jazz. The visual direction is so bleeding edge it hurts: there's glitch art all over the main menus, cutscenes themselves dissolve into broken MPEG blocks slip-sliding across the screen like those puzzle games with the missing square, ASCII art fades in through the background, interstitials are not rendered environments but instead 3D LIDAR pointclouds of a fictitious Chicago, and the protagonist character I swear spends his *entire* time staring at his phone. 

So far, it's your standard open world game. Ezio - I mean, Aiden - wanders around in his Assassin's - I mean, vigilante's outfit - and hides - I mean "uses cover" - and then trails people to surveil them and then picks their pockets - I mean hacks - them. 

There was a bit of a weird moment where I think I did a mission by accident and ended up stranded in a new area of the map where I hadn't unlocked any ctOS (hah! Get it? It's a smart city operating system that when pronounced, sounds like ceetee oh ess!) and ended up running around wondering why I couldn't hack anything (in this world, you simply aim yourself at a thing and if it's hackable, you press square to hack, which, I guess, is sort of how real life works). 

The only depressing thing so far (because otherwise it's open world as usual) is that hacking minigames *still* can't help presenting themselves as anything but slightly funkier and cyber-ier Pipe Mania minigames in that there are electrical circuits with cyber juice flowing through them and you need to redirect them from the start of the cyber juice, where it goes into the circuit, to where it needs to go, because all cyber juice misses its mum and wants to go home to finish the circuit. 

But otherwise: yummy. And yes. There was an update I needed to download to my PS4, but I could play it without it. And there's some in-game advertising, too! Nice one, Diesel.

[1] WatchDogs 
PS4: http://amzn.to/1lRHfqg 
PS3: http://amzn.to/RCm96V
Xbox One: http://amzn.to/1lRHphh
Xbox 360: http://amzn.to/1ouQwe4 

--

Okay, that's it. Notes please! Send them!

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Eighty Nine: Yet More Smarts; The Continued Tyranny; A Different Kind Of Overload
Date: May 28, 2014 at 12:39:09 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fqvx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
I've been back in Portland for about 24 hours and the panic has only just set in a little bit. First is that there are a whole bunch of threads that I need to pull on and constantly manage in terms of what I'm going to do next, and all I know is that I should have them organised in some way. And instead it was difficult to pull myself out of bed this morning just because of the sheer *weight* of things to do. 

And again, the big problem has always been being trapped in my head and having the fear of doing the things that need to be done. It doesn't quite matter that, once I start doing those things (like writing today's episode, for example, which I was terrified about writing until I started writing it, upon which all the words kind of just fell out of my fingertips onto the keyboard) they become exponentially easier to do until they just get done. For example: last Friday I had a good meeting that I promised to write up, and ultimately ended up being half-consumed by the terror that what I had been told was a good, interesting conversation would instead be exposed as a whole mound of stuff-I-made-up when I wrote it down. Which might still be the case. You never know. 

But anyway. I got through the day. And tomorrow, my wife and son get back. And it's another day.

1.0 Yet More Smarts
I got a bunch of good notes from people in response to my posts about Solid and one of the more provocative ones was about notification overload. One way of thinking about this is that as we move to an attention economy (or, at least, as some people *think* we're moving to an attention economy), the default is to try to grab as much attention as possible, at any given time, modulo some semblance of reasonableness. 

It's interesting that we've seen some sort of convention for dealing with notifications when we *don't* want to see them: the example of people putting their phones face down on a table when sitting down for a meeting or eating is one of them (and one that was quite nice to see Nokia highlighting, I think, in one of their product videos). Notification overload isn't a new problem: it was information overload a few years ago when people like Linda Stone coined the term continuous partial attention and its associated email apnea on the knowledge that people genuinely hold their breath - and get stressed - when they're doing keyboard tasks like checking and writing email. (Check it: I bet as you're reading this, or as you've got an Outlook window open, you're subconciously *not* breathing regularly). 

Continuous partial attention didn't really catch on - or it did, it's just that the mobile internet came along at the same time and we all kind of collectively shrugged our shoulders and got on with playing Clash of Clans as well as checking our email and hey did you see that Twitter push notification that just came in.

I know it's a disingenuous argument, but we've even got a terminology thing going on here: *push* notifications talk about the back-end technology that rely on a server passing on information to an end-point, but at the same time isn't it such a wonderful coincidence that they also push themselves to the foreground of our consciousness...

One of the things that I've noticed in the last three years of my experimenting with advertising was the value of the relationship, and how the inexorable push of social media has caused the nature of that ethereal brand relationship to change. My ex-employer likes to say that it creates 'provocative relationships between good companies and their customers', and what company doesn't want a relationship with its customer? And in a world of mobile computing and communications, the new relationship is mediated not just by broadcast push messaging (ie: television adverts) but by in-stream messaging (Tweets and Facebook posts) and also some sort of holy grail of interruptive push messaging (an exhortation to win the hour, for example).

The end-game of this, then, is: what happens when everything has its own IP address, its own route onto the internet and can talk not only to us, but to its sibling devices? You think the Professor had it bad when he could hear all the voices, you should think yourself glad that you won't be able to hear or sense the cacophony of IP packets coursing around you in the next few years. 

Perhaps one way of thinking about this is this: given we're all thinking about conversational interfaces now and everyone's busy trying to anthropomorphise their devices and services so that they can back-door hack empathy into our relationships with them, whatever happened to "if you don't have anything {good, interesting} to say, then don't say anything". 

I don't have a Nest, so I don't know how chatty it is. But right now, the mediation that we have between ourselves and chatty devices is pretty thin. One of the things I did lately when I reset my iPhone in a valiant attempt to fix its battery life was to go into Background App Refresh and have a long hard think about the apps that I *genuinely* needed to be updating in the background and then take a look at Notification Center and have a long hard think about the things that I *genuinely* needed to know about, as they happened. 

It turns out that there aren't that many. Sure, I don't find out, second by second, if someone has faved or retweeted one of my tweets or if someone has hearted one of my instagrams or even if someone has liked one of my Facebook posts. But all of those notifications are aggregated and pooled together when I decide to check. In fact, one nice change to my life was when I accidentally left on do-not-disturb mode and found out that it led to a considerable reduction in my anxiety that day. 

When we talk about doing good by the user and satisfying user need, this is one of those difficult questions: does the user *need* to receive those messages instantaneously? Should the default be on, or off? Should we always ask for push messaging notifications, and what sort of notifications should they be? I'm reminded of one of the exhortations of Steve Jobs when he pushed to get the bootup time of an Apple computer just that little bit quicker, and he persuaded his engineers using the argument of the aggregate: of all the millions of hours that would be saved just by shaving a couple seconds off. 

One of the dreams, of course, is to model some sort of executive assistant or agent who would know what was important to you and effortlessly perform some sort of do-what-I-mean-not-what-I-say prioritisation of incoming messages and notifications. But hey, that's kind of relying on hard AI or at least significantly better bayesian filtering not for spam, but for *useful* stuff. If anything, I hope Apple figures out what the "missed" part of Notification Centre means, because it's pretty much a joke. 

Anway. The corollary of attention being the most valuable thing to a company or a brand is that it's also the most valuable thing to a person. A brand might do well to respect that knowledge in order to gain trust. 

2.0 The Continued Tyranny

For various reasons, I've been looking at the Medium essay I published nearly a year ago now; The Tyranny of Digital Advertising[1].

One thing that didn't quite come across in that essay was exactly what was meant by native advertising, which pretty much every publisher has jumped on in the meantime. Nevermind the fact that there's already way more than enough display advertising inventory on the internet in the first place (the marginal cost of putting up another possible location for display advertising is zero, for example), one of the things that I got confused about upon rereading my essay was that there are clearly two things that native advertising could be. The first one is the boring one: advertorial content. The kind that we'd get at my ex-employer where we'd work with Buzzfeed and they'd pitch us a listicle that would kind-of go with our campaign and we'd kind-of be okay with it, but it was kind of obvious that everyone would rather be doing something else rather than a space-filling listicle. 

The other kind is the more interesting kind, and where I wasn't quite specific enough in my terminology. That is, native-meaning-native-to-the-web, the kind of non-scaleable, one-off, make-it-like-you-mean-it advertising that I don't think exists quite yet *because* there isn't a toolkit. 

Again all this comes down to a simple question: what does it mean to be native to the web? To which I'd say the answer is the unassailable link. The uniform resource locator. The anchor from one place to another. That's the web. Sure, you can say it's lots of other things too, but I think they all fall down without the humble URL. 

So the real question is this: if the link is what makes the web the web, then how can you use the link to make advertising that is built for the web, and could only be built for the web? That, I think, is native online advertising. 

[1] https://medium.com/i-m-h-o/2bfa73373a9a

3.0 A different kind of overload

A friend pointed me on Twitter to Perception's latest motion graphics work, this time for Captain America: The Winter Soldier[1], this time with the observation that it was high time Hollywood was able to move past 45 degree angle vir2l style designs and that they should embrace flat design already (never mind the teal and orange palette). 

A separate problem, though, is that of dashboard design. Sure, we all take cues from Hollywood, mainly because Hollywood gets the excuse to make things all shiny and, bluntly, not quite well thought-through for everyday use, but the thing about Nick Fury's car and the amusing slide-to-unlock aim and fire interface that Maria Hill uses at SHIELD is the sheer complexity of it. I get it: we need to understand that these are Serious Systems and that Lots of Important Things Are Going On, but the end result of it is that people think, when they're designing *consumer* systems, that regular people need to understand that things are Very Complicated too, instead of doing the hard work and simplifying where and when possible.

There's a storytelling reason for all this information overload. We, unlike Nick Fury, are not being ambushed in our Awesome Car, and we're quite happy to sit back in a plush seat with an unreasonably sized Diet Coke in our hand and sip whilst the scary fake police dudes try to break the window with their hydraulic battering ram. Nick Fury has serious shit to be getting on with, so from his point of view, he doesn't really need to understand that his car is trying to read the licence plate of the car that just obstructed him.

We, the audience, need to see these things for storytelling reasons. We need to understand that the Awesome Car is doing lots of things, is investigating a lot of things and is Working Hard. And I wonder if this is just a side-effect of that peculiarly American sensibility to not just work hard, but be seen to be working hard. Computer car is, of course, computing. 

Sometimes it's interesting to see internals for us to understand fundamentals. Many of us speak of a sort of golden age when you could take things apart and they weren't quite so appliances. I certainly remember a time when I was in my teens and I spent an, in retrospect, entirely unrealistic amount of time reading about Intel reference motherboard designs and ATX cases and building my first few PCs. It was a powerful feeling: to know that I knew what components went where, how they worked together, despite the fact that a lot of the esoteric knowledge I was gathering wasn't *entirely* useful in the long run. But it did mean that I understood concepts like busses and clock frequency multipliers and power supplies and cooling and disk interfaces. That said, I'm willing to bet that everyone who remembers what it was like to have to resolve IRQ conflicts would quite happily never go through that ever again. 

Anyway, that's a long roundabout way of saying this: Nick Fury's car, through its user interface, is explaining what's going on. We frequently don't get that in the user interfaces we deal with every single day. They don't, as it were, do a director's commentary on what's going on. Some of us intuit what's going on and recreate that director's commentary ("Well, it looks like what's going on here is that the local Wifi network is fine because I can ping the router here, see, but DNS lookups aren't working and traceroutes are timing out, and if I try this other device over there...") to try to understand what's going on on the inside. 

We see some of these things at the other end of the stack when we run things like stack traces when things go *really* wrong so we can step through and figure out what's going on. But there's a middle ground where we just get gobs of information thrown at us, smart-city-dashboard style, and we don't quite know what to do with it. It doesn't serve a storytelling goal, because the information isn't *going* anywhere - no one has written a beginning, middle or end - in fact, it's just an endless series of iterating beginnings as the dashboard silently refreshes.

I know there are certain of you out there that are going to eyeroll at this, because it's just me banging my drum and repeating ad infinitum the value of storytelling. But dashboards frequently don't tell stories in the way that Nick Fury's car does. They don't say: I'm doing this, to find out that, which means this. They just show you the number of faces they've seen at a busy intersection. That isn't to say that there always is, or must be, a narrative, just that one way of dealign with information overload is by putting it into a sort of temporal context that makes it relatable to us other than just a time-series slice of data. 

[1] http://perceptionnyc.com/content/captain-america-winter-soldier

--

As ever, I appreciate your notes. And you'll appreciate that I have a backlog of about 227 to reply to, which shouldn't discourage you from sending more. Because really, I like getting them.

See you tomorrow,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Eighty Eight: Smarts; The Real Internet
Date: May 26, 2014 at 8:49:01 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fq91=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm writing this again at about 20k feet on the way back home to Portland from San Francisco. It's been a long, crazy week, one capped off with meetings that feel like they've been interesting and productive. So fingers crossed there. 
1.0 Smarts
I woke up this morning to the news - or rumour, rather - that Apple was preparing an entrance into the internet of things, namely that there's evidence that they have some activity in the smart home area of things. The easiest course here would be to just sit tight and wait a couple of weeks: their WorldWide Developer Conference. 
After sitting through O'Reilly's Solid last week, there's one thing that feels quite clear to me: the consumer benefit for an internet of things is still really opaque. 
All of these benefits of smart homes: turning on lights when you get home, setting your security system, and so on - they all seem so abstract and so, well, the opposite of what we're probably going to end up using smart objects for.  
What I mean to say is this: *even* with the Nest, which I think is probably the best or most developed smart-home-object that we've seen, it's still hard to see (from a consumer's point of view) what clear benefits result from internet-connected things. This isn't to say that the internet of things is a solution looking for a problem, more that the right problem hasn't been found yet, or that the particular problem that can be solved by a network of things that can communicate with one-another hasn't yet been extruded into reality.  
In other words, it feels like we're in the Palm Pilot era of smart things. Generally a good idea that a bunch of early adopters can see the value of, but for the vast majority, the use-case and benefit isn't tangible enough yet. Sure, it's not as bad as having to learn how to handwrite in a completely different manner just so a slow microprocessor has a chance of understanding our scrawl, but it's clear that we're not in the "just stick it in front of someone and play a video" and everyone wants one era that something like the iPhone ushered in.  
So part of the question is this: what are the missing pieces? On one level it's the articulation, the selling of the benefit that's missing: why do I need this in my life and what problem (whether it's one I knew I had or not) does it solve? On another level there's a genuine question as to whether we're simply seeing the effects of a bunch of people sniffing opportunity and desperately jockeying for position for something that *is* coming but hasn't quite rezzed in yet. What do we need? What needs disrupting? How do you persuade people to buy new toasters or microwaves or televisions or thermostats or door locks or lightbulbs? These are not traditionally things (obviously) that have a frequent replacement cycle because Moore's law just hasn't collided into them yet.  
One particular aspect that I've been thinking about has been the wearable market. I suspect that the combined sales of activity trackers remain pretty (relatively) low. I find it telling that, having started wearing a Nike Fuelband again (an SE in volt, if you're asking), my Nike+ leaderboard, that used to be populated by up to twenty or thirty of my friends, is now practically *empty* on both the daily and seven-day slices of activity. Put it this way: no one wants to see their doctor every day, even when they're feeling well. So it's clear that, for whatever reason, the cadence of usage hasn't been properly considered for a general audience. I mean, really: who *wants* to see a dashboard of their personal fitness *every single day*?  
The converse is my relationship with something like Moves, which just sends me a push/on-device notification every day to let me know how much I moved the other day. I now have a new awareness, a sort of long-term proprioception of how much my body moves and here's the thing: I don't need to look at it every day. The long-term implication of this, for example in terms of lifetime healthcare and preventative diagnostics, haven't been touched upon at all. I would rather talk with my doctor, for example, or have that data available to *someone* I trust who can say: well, let's see - since our last well visit about six months ago your daily exercise has declined a bit. How are you feeling?  
Our relationship with the internet and with the devices we carry in our pockets that mediate our access to it are based on short cadences (maybe necessarily due to business imperatives?) and shown in our usage of terms like daily active user or monthly active user. But what of a yearly active user? What of that long-term relationship?  
2.0 The Real Internet
Maciej Ceglowski[1] wrote an absolute barnstormer of a talk[2] for Beyond Tellerand. It's long, yes, but you should go away and read it, and if it helps, I'll describe it as the sort of thing that I wish I could write in this newsletter. 
Ceglowski's talk is basically a depressing (and yet accurate) talk about the implications of the design of infrastructure and the things that that infrastructure enables. He draws an analogy with the types of second-order applications that the United States' interstate highway system enabled, and the types of behaviours that then arose from such pervasive infrastructure. A way of thinking about the interstate highway system - or, at least, the American implementation of it, is a sort of forcing function that makes certain artefacts and behaviours not only possible, but more likely.
Now that we have had a few decades of internet and a couple-and-a-half decades of web, now that there are adults who have grown up with it, now that we are in late-stage capitalism, it's time to take a good critical look at the sort of world the internet enabled, purely because of some early architectural and design decisions that were made in its birth. As much of Ceglowski's criticism is based upon the *computer* part of computer networking, because the first issue he brings up is a computer's inability to forget. I think what Ceglowski's getting at is that in the physical world, the act of remembering is an act that requires intention and effort: one of his particular examples is how taking photographs involves a combination of physical, gestural acts that evolved from mechanical/chemical through to electronic. And yet taking a photograph, until recently, has involved at least some sort of physical signalling system. And when that signalling system started to disappear - say, in Japan, with the acts of certain people being offensively enthusiastic as to how they treated women - the physical world tries to push back a little in order to remind us that remembering is an intentional act that should have some sort of physical feedback or consequence for those around us. 
Computers don't do that. By design, computers just *remember*. It is trivial to have computers remember everything they do, everything that passes through them, everything they touch, see, process. It is easier, now, to simply have a computer store everything than to work out what to discard. 
There are stories of what happens when humans remember too much. That our species needs to be able to forget things, that we need to file the edges off otherwise there is simply *too much*. Otherwise it is simply too hard to move on or to progress. Or that, essentially, as a species we have evolved *with* the capacity to forget, as opposed to without. And Ceglowski brings this to the fore, because with the capacity to never forget is the twin of never forgetting, to knowing everything, to caching and storing everything about us: not because it could be useful, but because we can. And that that ability is simply, unassailably, toxic.
I've had people say that I'm on a sort of empathy crusade, and I suppose this is one of those times when I'm going to be on that crusade again. It strikes me that as services strike to be 'friendly' or anthropomorphise themselves because it turns out we have a zero-day backdoor in our brains that allows some sort of short-circuting, the greater delta between how these services talk and how they act is going to be nothing short of an uncanny chasm, never mind a valley. In other words; it doesn't matter that Flickr can say that you know how to say hi in Swahili now and you think that's pretty cute, the fact of the matter is that *somewhere else in Yahoo!* there's a bit of that company that says: Hey, I know you said don't track me bro, but we're going to track you anyway. Sorry about that. But hey, you know how to say hi in Swahili!
I'm not sure at what point this becomes intolerable. I'm not sure at what point the cognitive dissonance becomes too great, but it feels like parts of it are pushing through into the cultural consciousness such that *some* people are aware and somewhat nervous about it. It comes through in there being more talk of people moving their email hosting from Google to a service like Fastmail, not just because it's (potentially) more secure, but also as a sort of statement. Never mind that, in practice, thanks to increasing centralisation, such a move may in the end, unfortunately, be more symbolic than active. 
But the point is this: in seeking to make services more approachable and a more ingrained part of our lives, in making them conversational, we may be exposing that which they absolutely aren't. You may well put an accessible face on an algorithm, but it isn't, and never has been, human.
[1] http://idlewords.com/about.htm
[2] http://idlewords.com/bt14.htm
--

That was a bit of a downer. We should still be super-excited though. The internet is one of the things that has brought so many people together. It can still do that. It works for us. Not us for them.

Best,

Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Eighty Seven: Robots; Smart Things; College; Wintermute
Date: May 24, 2014 at 2:11:23 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fp0d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

It's been a long day. It started early, checking out of the Sheraton at which I'd been staying for Solid, and headed straight into a whole bunch of back-to-back meetings, followed by a short period of decompression and X-Men: Days of Future Past and now this, writing today's episode at the late time of 11:45pm whilst crashed at a friend's house. It's been difficult. I've been lucky to have a good friend do the mental equivalent of smacking me with a wet fish in the morning and, in a way, telling me to get a hold of myself. Or to put it another way, try to get me to understand that I'm probably not best equipped to interrogate my mental state at the moment. 

It doesn't help that at the same time, I have to try and turn myself on and be interesting for all the meetings that I'm having and that I kind of collapse after them due to the effort of having to expend so much mental energy. On top of that, it doesn't help either that being able to turn on and off that kind of mental energy makes me feel like I'm a fraud, or pretending, or some sort of imposter because it can be switched on or off. The alternative explanation, of course, is that it takes energy and that I'm actually tired. People are trying to persuade me of the veracity  of the latter, with a kind of Occam's razor argument.

1.0 Robots

I mentioned in yesterday's episode that I didn't think we quite had an internet of things brand yet, or at the very least, we didn't have an umbrella cultural understanding of smart things. One of the things I'm trying to work out, for example, is why there aren't a hell of a lot more Roombas in houses. Cleaning - vacuuming in particular - being something that I'm pretty sure most people would prefer not to do, you'd think that a relatively inexpensive robotic solution would be a bit of a no-brainer. And the iRobot Roombas start at around $350 - about as much as a sexy Dyson vacuum cleaner. And yet I suspect that more Dysons are sold than Roombas. Why is this? If iRobot really wanted to go after the home cleaning market, then they could find a way: for starters, I suspect that awareness of Roombas is practically nil compared to other vacuum brands. Why is this? Is there a reason why iRobot *don't* want to sell lots of Roombas? Is it because they're like a hobby to iRobot (who have a perfectly serviceable line in military-esque robots) in the same way that the Apple TV is a hobby to Apple? This might just be me with my consumer marketing hat on, but throw a substantial marketing campaign at Roombas and I bet you could shift a lot more.

Or - and you'll have worked out that I'm essentially thinking out loud here - perhaps the deal is that what people want to buy is a clean house, and that it's much easier to buy a cleaning service - cleaners - than it is to buy an expensive vacuum cleaner. But I don't think that's the full story, either. 

This doesn't apply to just iRobot either. They might be the example that springs to mind first, but they're certainly not the only home cleaning robot. And yet the market still doesn't seem that big when we're ultimately talking about a middle-class labour saving device, which have historically done pretty well in the home. Is it because they're just not good enough? Because persistent, fire-and-forget cleaning is, in my lazy mind, still better than cleaning I have to pay someone for or cleaning that I have to do myself. 

2.0 Smart Things

I'm also not entirely sure that we're quite ready for smart things, or the internet of things, in terms of a consumer audience yet. By that, I mean that I'm not sure the consumer benefits are clearly articulated. Even something like the Nest, right now, feels like a luxury, and the sharp, easily understandable story about why it's better than any other thermostat - especially one that's a lot cheaper - doesn't feel like it's being understood by the wider market. I suppose it's difficult if you're making a monetary play - people discount future cost savings, for example, when compared to present-day cost savings, so even though a Nest might save money in the long run due to increased energy efficiency, people still look at present-day sticker price. So perhaps there's another story? 

The counterpoint to all of that of course is the uncovering of a Google SEC filing that only recently became public[1] of the possibility of the search conglomerate serving ads on “refrigerators, car dashboards, thermostats, glasses, and watches, to name just a few possibilities.” Now, such filings have to be parsed in the right way because they're legal documents and they're intended to be as wide as possible to make sure that any sort of liability is limited. What's depressing about this is the sheer mundanity of the filing: refrigerators, car dashboards, thermostats, glasses and watches are all screen-based devices, and Google's covering both their bases and their asses by saying that hey, in theory, anything that's got a screen on it that's connectable to the Google ecosystem may well end up as inventory in their ad network. 

The original Wall Street Journal article was clarified with two points from Google - one of which pointed out that the language in the filing was out of date and did not 'reflect the Google product roadmap', and the latter of which was an impassioned defence from Tony Fadell reiterating that Nest was not built on and is not predicated upon Google's ad network. Fadell is keen to remind us not only that Nest's business model is different from Google's, but it is also a separate corporate entity. 

This is all well and good - and anyway, it's not like we're able to hold corporations to their promises in any way other than the manner in which we use our wallets - but of course leaves open the rather wide loophole of the refrigerators and the car dashboards, for starters. 

There's the compelling argument that once cars do become autonomous and self driving (which might seem a little further away than we think, now we see that a lot of the smarts in Google's self-driving cars reside in the network - which makes sense - rather than in the car) the environment that they offer instantly changes into a new sort of space with different affordances for entertainment at the very least. Suddenly the time - and attention - that was sucked up by cars and driving can be reconfigured into something different, and another landgrab for attention can be made. 

There was one particularly good talk from Solid from Simone Rebaudengo[2], of which one part that struck me was our almost childish obsession with the first generation of smart things being simply very long fingers - that is, the idea of long-range remote control, of being able to reach out and touch or affect something in our home from a distance. That distance might be from the couch to the TV or it might be further, and the if we take the promise of smart things literally, there's really not that much smart in a lot of them other than the ability to affect action or sensing at a distance. Which sure, is interesting, but I'm not exactly sure if there's a latent user need that they would be satisfying. I'm entirely willing and happy to be proven wrong, of course, and am prepared to admit that there may well be incredibly interesting things that can happen when we all have very long fingers capable of spookily pushing buttons at a distance. 

[1] http://blogs.wsj.com/digits/2014/05/21/google-predicts-ads-in-odd-spots-like-thermostats/
[2] http://solidcon.com/solid2014/public/schedule/detail/33299

3.0 College
I did a fair bit of driving when I was in Missouri a couple weeks ago, mainly around the Kansas City area. One thing that I started to notice after a while was the billboards advertising college. It's always interesting for me to go back to the family farm because there are simply places of america that I haven't been in, and the middle part of America, being someone who's lived on the west coast - and the crunchy Portlandia part of the west coast, too - is incredibly interesting. The part that I picked up on this time was that there were billboard ads exhorting high schoolers to go to college and to pick a particular college based upon its sports team or their mascot. No mention of academics or anything, merely the question: Aren't You A Bearcat? for example. And it wasn't just one college: it was a few. So you wonder about the role that college plays in those types of communities and the hole that it's filling. 

4.0 Wintermute

On this, the last day of my old corporate email account working, news came of Portland having to issue a city-wide boil-water notice due to e.coli being found in the water supply. The practice of issuing a city-wide boil-water notice is in part carried out by robo-dialing every single phone number in the Portland area and playing a pre-recorded message. Which had the effect, from what I could make out from the IT department email, of crashing the VOIP based PBX and not only ringing everyone's phone (and leaving voicemail) but also disrupting extant calls and dropping them. Wintermute, it seems, is good at telling us when we might have an issue with our other infrastructure.

--

Okay, that's it. I'm spent and it's late. I hope you've had a good week, or one that's been better than mine. See you on the other side.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Eighty Six: Solid 2 of 2; Requests - GOV.UK 2018; Next
Date: May 23, 2014 at 1:38:23 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fogl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Today, reading LinkedIn recommendations as they came in felt like reading eulogies. Apart from me not quite being dead. Not yet, at least. Or, I was dead and I hadn't realised it yet. It doesn't matter, anyway: all the recommendations from people I've enjoyed working with over the past three years just feel, unfortunately, like double-edged knives - ultimately good but only really readable with a twist.
Right now is a bad time, one of those terrible times when it doesn't even really matter that one of my good friends has pulled me aside, insisted that I have something to eat and sat patiently with me in a pizza joint while I stare off into space and mumble. It doesn't matter that he's great and doing these things for me and telling me that this too will pass: I am hearing all of the words that he's saying, the sounds he's making as that make all the little bits of air vibrate and hit my ear and undergo some sort of magic transformation as they get understood in my brain. But they don't connect. Understanding is different from feeling. And right now, I'm feeling useless and broken and disconnected and above all, sad. But I can't feel those things. I have meetings to go to. Hustle to hust. Against what felt at times like the relentless optimism of an O'Reilly conference I had to finally hide away for a while, behind a Diet Coke and a slice of cheesecake, because dealing with that much social interaction was just far too draining. 
And so I'm hiding again tonight, instead of out with friends, because it's just too hard to smile and pretend that everything's OK when it's demonstrably not.
1.0 Solid 2 of 2
Carl Bass's opening keynote[1] this morning was fantastic, a great example of what a good keynote should be. Bass delivered it pretty effortlessly, and something that could easily have felt or sounded like a sponsored slot didn't feel like it at all. It's not like Autodesk have a vested interest in the Internet of Things - they did come out with their own 3D printer, after all - and like every expensive piece of professional software (I'm looking at you, Adobe) they're looking to make sure they remain relevant and useful in a post-PC, fluffy cloud world. 
Bass did a good job guiding us through four categories of hardware/manufacture: additive, subtractive, robotic assembly and nano/bio. The first two are pretty much mainstays of the new methods of making, but something that Bass was careful to emphasise was what you got for free with 3D printing methods and what the problems were. Bass's point was that the big value isn't necessarily in consumer 3D printing but in large-scale industrial 3D printing. Or, rather, what it means when we retool our manufacturing processes with these new capabilities. Because what we do get with 3D printing is things like shape complexity for free - the idea that we can generate arbitrarily complicated 3D shapes and that the manufacturing process doesn't care that their, I don't know, Sierpinski fractal triangles or a solid cube: they're both as easy to make as the other. 
What we get on the downside of these new manufacturing methods are problems like scaleability, where the time increase of increasing volume grows as a cube power, so it just takes *a very long time* to make big things. Almost unacceptable amounts of time. And it's not necessarily something we can throw parallelism at. Bass's point here is that although 3D printing and the ecosystem surrounding it makes use of Moore's law, the problems that are being faced aren't necessarily ones that are *solved* by Moore's law. They're different ones, and we're not going to get advances in build time for free, for example.  
The two most interesting parts of Bass's keynote where when he talked about bio/nano manufacturing, in particular Cambrian Genomics and the Wyss Institute and what they're doing with DNA printing (which is exactly what it sounds like: printing with adenine, cytosine, guanine and thymine) to create stochastically self-assembling structures that do useful things, like encapsulate chemical payloads and automatically deliver them upon encountering the right kind of cellular environment. Bass tells a compelling story of how tantalisingly close we are to bioforming materials and objects: that it won't be that long until we're building things the same way nature does, out of seeds and biological processes that only need the sun, carbon dioxide, water and dirt.  
Alongside that was Bass's submission that Autodesk really gets the cloud. I'm not entirely sure how persuaded I am about this because I don't know enough about the computational complexity involved and whether it really does require leveraging compute infrastructure like 'the cloud' or instead you could probably do the same thing if you had one of those fancy new Mac Pros. In essence, what it sound slike is that AUtodesk were able to approach the problem of how to help designers from a different angle: in the case of cad/cam engineering there are a whole bunch of multivariate problems where there is a solution space that needs to be explored. Previously, Bass submits, it had been too time intensive to explore the entire solution space. You would pick a coarse, low-resolution grid of the solution space and ask those questions, and you'd try and get a good-enough solution for the variables you were solving for. With cloud compute, Bass was saying it was in principle easy (and cheap, and fast) to instead search the entire solution space. But searching the solution space in that way is simply asking a million questions and getting a million answers and picking the right one: in a way, it's the going the wrong way around. Another way, that's breathlessly reported in publications like Fast Company, is instead to provide a design system with a goal (say, designing a chair, because it turns out that computers, just like human designers, can't get enough of designing chairs. Just wait til they start on boarding passes) and for the system to iterate over finding solutions for the goal *that can then be edited by a human*. Ultimately what Bass was able to show, pretty persuasively and entertainingly, was that Autodesk was still pretty relevant.  
Neil Gershenfeld from the Centre for Bits and Atoms at MIT delivered another well-received keynote[2] that I interpreted as a sort of smart materials science. It isn't often that you get someone opening with a sort of uber-combo move of Claude Shannon, John von Neumann *and* Vannevar Bush, but hey, if you're setting tone I guess there aren't that many less intimidating routes. But anyway: the crux of what Gershenfeld was saying, I think, was that hey: digitisation was a great conceptual advance in terms of stuff that humans have come up with, and it's high time that we applied the concepts of digitisation *as advanced by people like Shannon, von Neumann and Bush* to materials themselves, and not just made digitising/digitised *machines* out of materials.  
And so his four step roadmap to a genuine Star Trek replicator starts with computers that can make machines, to machines that can make more machines, to codes that can be applied to materials all the way through to programs that can be applied to materials. And at the very end of the line, you have smart matter. It's when someone on stage points out something like Superstorm Sandy causing $20bn worth of damage and our only real defence against it being wet bags of sand that you realise how smart people are and how dumb you are for not realising it sooner. So the idea of trying to print mountains (and hey, you don't have to print a *mountain*, you want to achieve the effect of a mountain only more efficiently, so you can *cheat*) is just a) literally awesome and b) audacious in a way that can only really command respect.  
It goes a little sideways when getting excited about a $20bn destruction of cost int erms of printing out airplanes instead of having to make all the little bits individually and then assemble them because you're suddenly wondering: where's that $20bn going to go? But, to be fair, it's not the job of people pushing forward the state of the art in materials science to be concerned with the economy, right? 
Instead, what we get are things like the frankly offensive session Wearables at Work that, well, let me just quote:  
"The real power of wearables comes from the behavioral data they generate and the environmental interfaces that they enable. Pairing data from these wearables with micro-level outcome data enables online-style behavioral analysis and A/B testing in the real world at an unprecedented scale. Physical changes in the workplace, from autonomous augmented cubicles to shifting walls will push the boundaries of what organizations can accomplish. This will not just change how people are managed, but will fundamentally alter the world economy." 
Warber is, for example, deeply and genuinely excited about measuring your posture, your cortisol, and all manner of implicit datapoints about your physiology in order to manage you better in the workplace. And, let's be clear here: we're not all on the same page when we use the phrase "manage you better".  
One of the themes that has been running for a long time in my newsletters has been how important empathy is because it turns out that when we're talking about an internet of things, one of the things is people, and people don't like to be things. Indeed, when we dehumanise people, generally speaking, bad things happen. So instinctively - whether Warber's intentions are good or no - any discussion of people where instrumenting them for the benefit of others, as opposed to the benefit of those being instrumented feels like a Bad Thing.   
See, it's all very well when Ishii talks of doing things because we can and because they're art and they just *are*, but the problem with rhetoric like Warber's is that it shows our tendency (or at least some members of our species' tendency) to want to treat other humans like they aren't humans. To reduce or abstract them into individual units. At the same time when other speakers are talking of an aberration in the 20th century of the mechanical and industrial that seeked to treat everything the same way, at the same time that Baxter is proven to be interesting precisely because it does not do everything the same way each time, there's something counter when we talk about measuring humans in the workplace and instrumenting them. Because, if there's anything management could blame, I hoped it wasn't a lack of instrumentation. 
[1] http://solidcon.com/solid2014/public/schedule/detail/33744 
[2] http://solidcon.com/solid2014/public/schedule/detail/35425
[3] http://solidcon.com/solid2014/public/schedule/detail/33559
2.0 Requests - GOV.UK in 2018
Roo Reynolds was the one who asked me to have a think about what GOV.UK might look like in 4 years time. Or, rather, what I'd like to see in GOV.UK in 4 years time. At a high-level reckon, I'd like to assume that a lot of the easyhard stuff - the transactional stuff and the meat and potatoes of government - would be taken care of by then. So all the things like better tax returns, notifications, licensing, would all be done and that the GDS team will have produced a base level of government services that are better-delivered-by-digital. 
It's what's next that I'm interested in, and government's role in that. Because those bottom-of-the-pyramid services are the most important ones that need to be implemented and improved first. When we move higher up the stack (or, as I'm happy to devolve to Mr. Heathcote, to different phases of life or to different priorities) I'm interested in government's ability to help us achieve what we *want* to achieve as opposed to what we *need* to achieve. I mean: what are aspirational government services? Are there any? What might they be? How easy should government make starting a new company? How easy should government make working out what sort of company to start?  
These feel like difficult questions because they kind of cut to the heart of what sort of role government should (or even could) play in citizens' lives. And they're less about survival and more about enablement.  
3.0 Next
Over the past couple of days at Solid it's become almost painfully apparent that the Valley, in broad terms, is suffering from a chronic lack of empathy in terms of how it both sees and deals with the rest of the world, not just in communicating what it's doing and what it's excited about, but also in its acts. Sometimes these are genuine gaffes - mistakes that do not betray a deeper level of consideration, thinking or strategy. Other times, they *are* genuine, and they betray at the very least a naivety as to consequence or second-order impact (and I'm prepared to accept that without at least a certain level of naivety or lack of consideration for impact we'd find it pretty hard as a species to ever take advantage of any technological advance), but let me instead perhaps point to a potential parallel.  
There are a bunch of people worried about what might happen if, or when, we finally get around to a sort of singularity event and we have to deal with a genuine superhuman artificial intelligence that can think (and act) rings around us, never mind improving its ability at a rate greater than O(n).  
One of the reasons to be afraid of such a strong AI was explained by Elizer Yudkowsky: 
"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else." 
And here's how the rest of the world, I think, can unfairly perceive Silicon Valley: Silicon Valley doesn't care about humans, really. Silicon Valley loves solving problems. It doesn't hate you and it doesn't love you, but you do things that it can use for something else. Right now, those things include things-that-humans-are-good-at, like content generation and pointing at things. Right now, those things include things like getting together and making things. But solving problems is more fun than looking after people, and sometimes solving problems can be rationalised away as looking after people because hey, now that $20bn worth of manufacturing involved in making planes has gone away, people can go do stuff that they want to do, instead of having to make planes! 
Would that it were that easy. 
So anyway. I'm thinking about the Internet of Things and how no one's done a good job of branding it or explaining it or communicating it to Everyone Else. Because that needs doing. 
-- 
As ever, thanks for the notes. Keep them coming in. If you haven't said hi already, please do and let me know where you heard about my newsletter. And if you like the newsletter, please consider telling some friends about it.
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Eighty Five: Solid 1 of 2; Requests: Cities and Technology
Date: May 22, 2014 at 1:37:14 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fnpl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

It's 11:33pm and I've just finished Day One of O'Reilly's Solid conference. At the same time, I've been fielding email - the people who're interested in having conversations with me continue to want to have conversations, and there's a bit of juggling around with availability and time. And at the same time, thank you so much for the notes that continue to come in about my news from last week. I'm incredibly fortunate in that I've been able to come down to San Francisco this week and be surrounded by good friends from around the world, as well as meet super interesting new people. 

At the same time, waking up this morning was a bitch. Since Friday, I haven't had a good night's sleep and last night wasn't an exception. I pretty much woke up every couple of hours, and needed to get up at 7:30 anyway in order to hit a meeting in the morning at the conference location. And no matter how many emails I get from interesting people, I'm clearly still super stressed out with everything that's been going on. So tonight's an experiment and I'm going to see if taking some of my lorazepam is going to help. Because hey, pharmaceuticals. 



1.0 Solid 1/2

There's been a certain buzz around O'Reilly's Solid[1] conference. It's twelve years since the first O'Reilly Emerging Technology conference - a gathering as much of interesting people and the things that they were doing, organised around some sort of ineffable future-ness. Part of the rhetoric around Etech - that I think I only managed to attend once, in 2004 - was that it was concerned with genuine outbreaks of the future. Back then, of course, the future was in bits, not bits-and-atoms, and the palpable excitement of connecting people pre-Wikipedia, pre-YouTube, pre-Facebook and essentially pre- the consumer internet that practically everyone (okay, fine, only one billion people) is on. 

But here we are at Solid and it is a weird thing. Like Etech, it doesn't know who it's for, I don't think - we have marketing-style keynotes from the CMO of General Electric and at the same time beautiful art and the seeing the nascent introduction of new materials - radical atoms - from Hiroshi Ishii. So - and as friends at the conference pointed out - you have Cisco's Cisco Live internet-of-things style conference down in the city proper, and out here at some sort of O'Reilly outpost, you have a semi-fringe - albeit one with Carbon Fiber(TM) level corporate sponsors. 

Because you see, in the years since 2002, the internet grew up and reached out and touched practically everyone. You couldn't do an ETech now without a corporate influence. We can't ever go back.

But (there's always a but) there's a sort of weird undertone: there were the throwaway references that Nick Negroponte had led us geeks astray by preoccupying us with the pure digital, by entrancing us with magical programmable pixels when, all along, pure digital was a distracting rabbit hole that meant we hadn't engaged with the world. So what the rallying calls sound like from people like Astro Teller of Google[x] when he proclaims that to solve physical problems, we need to make physical things, is that the geeks have emerged blinking into the Bay Area sunlight, discovered or remembered that they're embodied and have decided to take charge. And that to change the world they have to interact with it, and sometimes off-colour affectations like questions on slides in giant 72 point Helvetica asking the rhetorical question:

"How do you interact with the world?"

to which us pseudo-humanists who can also bridge the technological divide rather facetiously answer: well, you managed to make it here. 

This is, in a way, a language thing, of course. California - especially the part that comes to conferences like this - has its own particular ideolect, its own way of talking, and what we really mean when we say "interact with the world" is this: with built systems. But we have already built systems, we already interact with the world. The design question is: how do we *want* to interact with the world? Under what terms? How should the world respond to our needs and our desires and our preferences, because it has always done so, and you don't even need to be conscious to affect the world so because you exist in it. 

All of the advances and research I've seen have been amazing. They are all happening, whether I like them or not. And, in general, like most "neutral" technology, I like them. Apart from maybe the Boston Dynamics guys with their BigDog safely powered off in the corner. 

It's always been the way that we talk about this technology, how we harness it and the lens through which we apply it that's been interesting. When we talk about Baxter as a robot that can do what a six year old human can do, and mention that six year olds can do what the human workers in China can do, then that reflects upon how we view the world. When we talk about APIs for humans and reducing ourselves to systems we're not necessarily talking about augmenting our selves. And yes, I guess it is a step forward for us to talk not of user-interfaces but instead Human APIs, but then you unpack that word and you have a Human Application Programming Interface, and I don't know about you or 

There are so many interesting things here. Baxter (2012), a robot that's designed to be teachable and trainable in the same way that a human worker can be, sports an anthropomorphic face, GERTY from Moon (2009) style, but a face that from my point of view is somewhat unsettling and shifty, which could've been an easy thing to fix in terms of making robots more accomodating to the foibles of humans. And when Rodney Brooks, Baxter's father, talks about the fact that humans find robots like Baxter disconcerting when they are *unable* to precisely reproduce motion and tasks instead acting more reactively (like a human), and instead prefer them to be predictable in terms of their interactions. This, of course, can strike as strange given that humans aren't particularly predictable in the first place and that one of the major problems in interpersonal relationships is that oh for god's sake if only I knew what you were actually thinking and why you did that thing you just did. In a way, this want or need for robots to be predictable is almost as if the theory of mind model was some sort of computationally intesnive task and that it's much easier to interact with things in the world if they have no animus of their own. Until, of course, everything goes Sorcerer's Apprentice on you and your Roombas really fuck up cleaning your house. 

It's not a surprise, then, that when someone like Teller talks excitedly about being able to program cells with DNA and the cells being the runtime environment and it turns out that cells know how to copy-and-paste themselves, if you try and distance yourself from the excitement, you worry about a naive view of the world. "It's great," says Teller, when you've got an ex-marine who can take down your experiment when it escapes from you and can bring it back under control with a Bowie knife, and the inverse reaction is, of course: holy shit, you needed an ex-marine with a Bowie knife on hand to make sure your balloon didn't escape. 

What's refreshing is when someone like Ishii is able to step back and say: this part, this is just art. This doesn't have to be something massively disruptive, and what we've done with this programmable matter that, admittedly, is at a stupendously low resolution right now (we're at the 320x240 CGA era of programmable matter) albeit still fascinating. 

The rest of the conference has been slightly more predictable: yes, there's a palpable excitement in terms of how big this field is going to get, and there are starting to be good conversations around what's been learned over the last couple of years. A good session on cadence, for example, and timing, brought a high-level overview of the types of behaviours and the frequency and duration of interaction and messaging that make sense when the internet and digital interactions aren't just something that's over there, but instead something that's persistent and pervasive. In fact, when they're like something that's part of the environment. 

I think that's the general gist when, at a high level, Negroponte is accused - in a way - of having misled us. The focus on the promise of pure digital, of the power of only the pixels, as opposed to the atoms that the pixels are necessarily laid upon as a substrate, was an ideological charge: a thrust to pay attention to the promise of digital. But extremes never win out, and in the end, as we're seeing, the digital was always part of the physical. We are embodied, always have been, and will be - at least for the foreseeable future. The physical world is something that we don't have a choice about, in a way. 

Sure, there have been parts of today that have been, in a little way, perplexing or irritating. There have been panels or sessions that have felt like little more than advertorial, and it feels like there's much more commercialism rather than academic theory this time round instead of in 2002 or 2004. But that's the nature of the world, and the world changed in the last ten years. On the one hand, it's easy to look at the art that Bot&Dolly are able to produce, but the in-person demo was unsurprisingly underwhelming. It turns out that it's pretty easy to create a compelling piece of film, much harder to make that experience hang together in real life with a mirrorball on the end of a robot arm. Consensual reality is harder to edit than non-linear film. 

[1] http://solidcon.com/solid2014
[2] http://en.wikipedia.org/wiki/Emerging_Technology_Conference

2.0 Requests: Cities and Technology
So, roughly, the requests that I got in response to episode eighty four were:

 - (My) job search
 - Cities and technology
 - Communities
 - Higher education and early education
 - Gov.UK in 2018
 - Industrial design retrofits

and I'm going to pick cities and technology to write about a little bit, just because it ties in nicely with some of what I was immersed in today at Solid. 

There is a bit of debate, I think, as to whether we're actually going to achieve the sort of end-goal of a smart city in which sensors genuinely are everywhere. I think it's difficult to see at the moment: while we can see (or hope) that Moore's law is going to help us achieve the prototypical sensing motes that are pretty much cheap or effectively free to throw around and dispose of, what we do find difficulty with in a way right now is seeing the commercial incentive for doing so. In other words: what are the incentives for pervasiveness of sensing across the material (note: not the infrastructure) of a city that will result in the wholesale integration of that sensing capability. Or to put it another way: who's going to care enough to want to put all that sensing capability in, never mind making sure that it can all be aggregated in a useful and actionable way. 

A way to think about this is instead to not think of sensing as an add-on to an object. For example, it's easy to think of vision as an additional sensing capability that you can add to advertising hoardings. This means that you start considering the vision sense as an added cost that needs to come with a concurrent benefit otherwise it's not worth doing. In which case it's not worth adding vision to *all* billboards until the cost is practically negligible so that it all evens out in the end. You'll get a few high-value billboards that make significantly more money because of their sensing capability, and you'll get a usual long-tail relationship with every other billboard. But that betrays what I think Teller and Ishii would say would be a mechanical, 20th century civil-engineering mentality of looking at the world.

Instead, it's perhaps better to think of what happens when sensing is an integral attribute of the materials that you're using to construct the objects of a city. That's why I talked about material and not infrastructure above, in that if we reach a point where *all glass senses*, then you don't really get a choice. This is, I think, the demarcation between dumb material and smart matter: smart matter at least is able to sense its environment. I saw this today with wearable prototypes from Georgia Tech and in penumatic robotics from Otherlab: the piezoelectric pressure sensors used in prototype gloves from Georgia Tech and the pneumatically powered exoskeleton from Otherlab have as *inherent properties of their materials* sensing and reactivity built-in. You don't need to do anything to the piezoelectric material - it's an inherent characteristic of itself that it senses pressure. 

We don't have that right now. We have to augment the objects that we create with sensing capability, which necessarily leads, I think, to this sort of cost/benefit analysis as to whether or not to proceed with augmentation. It's a different matter entirely if instead of augmenting we are building out of smarter materials. In a way, this makes me feel like the current iteration of smarter cities when talking about augmenting existing structures is the first tiny baby step: you'd much rather build something that can sense natively, rather than retrofit on, right? 

There's a wonderful demo of work done out of Disney's Pitsburgh research lab that is a halfway house: adding sensing capabilities to existing materials in a slightly-less-than-built-augmented way. In that there's no obvious sensor package, but by using what they call swept frequency capacitive sensing[1], they're able to add touch and gesture sensitivity to everyday objects without needing some sort of sensor blister. The analogy that I have in my head right now is of something organic: skin is necessarily a sensor as well as an organ that's got other important jobs to do. I wrote before about a certain sense of proprioception and what that might mean for a city: it seems that when we're talking in terms of infrastructure - the wet, messy organs of a city - I would much rather that they natively sense rather than have sensing be something that's added to them. 

[1] http://www.disneyresearch.com/project/touche-touch-and-gesture-sensing-for-the-real-world/

--

Okay. That's it for tonight. It's been a long day. As ever, please send me notes. I'm working through a not inconsiderable backlog at the moment, but rest assured, I do read them all and I do try to reply to them all.

Best, 

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Eighty Four: Day One; Google Everything
Date: May 20, 2014 at 3:11:20 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fmm1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I write this at n thousand feet at x speed, on my way down to San Francisco for interesting meetings and O'Reilly Solid, of which there seems to be enough palpable excitement around for it to feel just a little bit like the O'Reilly ETech when it was good, which was the first one, which I wasn't at, not the second or third ones which I can't remember which one I went to. But anyway. Lots of interesting people in San Francisco at the moment, and I'm looking forward to meeting them and getting a little bit (or a lot) of friend time and gentle ego massaging. 
1.0 Day One
Things I haven't done: 
 - broken down and cried (though I've felt like it)
 - broken down and ordered delivery pizza (though I've felt like it) 
 - replied to all the incredibly kind emails I've received
 - had a good night's sleep
 - had too much pride to ask people for LinkedIn recommendations
 - not participated in drunken karaoke
 - given up
It already feels different. I dropped off the severance agreement today, signed, sealed and delivered. I have some interesting meetings coming up, for which I thank you all, but it never hurts to have more, so if you've been wavering because you think it's going to be super-easy for me to pick myself up and get out there, then don't waver: send me those introductions or get in touch. It all helps.  
One thing that hit me this morning as I was busy doing things like filing for unemployment, finishing a load of laundry, packing up for this trip down to SF, feeding the cat, picking up a new trike for my son from Craigslist, was: my self feels remarkably functional for what feels like has been thrown at it. (It probably isn't a good sign, though, that I'm able to disassociate from my self though, right?) 
I know - I mean I *know* know - that only a few months ago, if I'd been in this situation, alone, with the past few weeks that I've had, I'd be a pretty dysfunctional wreck. And yes, I have new drugs. And bonus drugs on top of those. So thanks, pharmaceutical industrial complex, for tweaking my neurochemistry in the required direction.
But I think one of the other things is that I've been writing this every day. 
I knew - and remember talking to my therapist about it - that the time would come when my mother-in-law would pass away. And I was worried that I wouldn't be able to or couldn't write, and that what's happened with that before has been the feeling of all-or-nothing, of having gone up eighty-odd steps, every single day, and each day accomplishing more and then having to lose it all with one mis-step. Because the way my brain works, one failure is - or maybe was - good as total failure. And that one mis-step would be so demotivating, so crippling, that it would turn into another mis-step the next day. And the day after.
But when I sat down to do it, every week day, all I have to do is just write. I just open up a text editor and start typing. And I don't care if it's good and I don't care that it's bad and I don't even necessarily care that you're on the other end of the SMTP connection.  
But whatever the writing's doing, I think it's doing a good thing. So I'm going to keep doing it. 
2.0 Google Everything
If you've been on the internet for a while, then it's likely that you'll have spent at least some time on Metafilter. One of the prototypical community sites, Metafilter is of a web 1.0 era: I remember when it updated to include fancy AJAXy features like having new comments append to the page instead of you having to reload the entire thing.  
I'm lucky enough to know Matt Haughey, Metafilter's founder, and to have spent a fair amount of time with him since I've moved to Portland. Generally, we go on geek dates like when he DM'd me and asked if I'd be up for going to the auto show and laughing at bad car user interfaces.  
Anyway. The thing about Metafilter is that it's a community site. And it's a community site done the hard way, in the way you used to read about in books like Powazek's Design for Community[1]. The hard way, of course, is by almost excessive use of humans. And not just any old humans, but freakishly empathetic humans: ones who are able to magically discern just through TCP/IP packets and their understanding of human behaviour, what it is that people on the other side of a screen and keyboard actually mean, as opposed to what they typed.  
Google's AdSense and its counterpart, the search algorithms and pagerank that power their search service for inbound and organic traffic, proved (notice the use of past-tense) an excellent way to fund the more idiosyncratic (and less, I supppose) parts of the web. Especially the useful parts. But now it looks like that's changing, and in the same way that the newspaper industry has its own church and state divide, Google has its own with the search product team and the AdSense product team.  
The crux of the matter is this: that Google ad revenue peaked, and - in the conversations that I've had with Matt - part of the issue is that the church/state wall is that it isn't a wall - it's a permeable business membrane, one that is algorithmically defined in a way that, I suspect, cannot be predicted or modelled in terms of its real life impact. And at the heart of the crux is something even simpler: what type of content does Google's pagerank algorithm favour, because the truth is that we have a content ecosystem that *in some pockets* (cue: Not All Googles) has a bona-fide monopsonist.  
You could look at this another way and say: well, Metafilter got fat on the teat of Google and should have made sure that its revenue came from diverse sources. Whatever. We're here now, and the question for Matt and Metafilter is: what now, and what other sources?  
To say that Metafilter was a great experiment is to miss the point, I feel. I don't think it was a great experiment: it was calculatedly tended. You get parks and you get gardens and then you get obsessively tended gardens that are intended to be something of a shelter in amongst all of the noise. In the continuum of community - we can drop the online prefix now, I feel - we've had Metafilter and sites like it that acted as our backstop, our hardly-any-algorithmic aids and pure, human brute force. And at the other end, we have our Reddits and Hacker Newses which show us what's possible when algorithms take a little more control.  
This isn't just curation. Curation's, I don't know, level one of  community - just picking the thing that your community has surrounded itself with and making sure it stays on track. No, what Metafilter did - does - with its moderators was *direction*.  
I feel like I speak with a little authority on this because of the time I spent, a long time ago now, helping to moderate the Cloudmakers mailing list for the A.I. alternate reality game, The Beast. Between the seven of us, we read and, if necessary, responded to *every single message*. And we were strong, and firm and when something happened that needed a light touch we gave one and if it needed a harder response, we gave that too. Because there's something to be said for leadership, and that's what Metafilter has: strong human leadership. And good humans cost money. 
Without a doubt there's a lot we can achieve with humans volunteering their time. But that type of involvement requires as much leadership and as much direction because the things we make are opinionated: they reflect the choices we make, and Metafilter in its usage of continual human contact *is a choice*.  
If we're interested in a diverse internet, then we should be thinking about what the evolution of the Metafilter is that preserves what makes good human involvement good, as well as making the best use of automation.  
So it's rather unsettling that news has leaked that Google's looking at providing a unified CMS publishing and advertising serving platform. With this component, you don't really need anything else: it's a one-click company town where you can just tap a card and start your publishing empire. It is, almost, a kind of pro-Blogger, the true democratisation of publishing, but this time a porous church/state divide that allows for content monetisation from the get-go.  
At this point, you start wondering (and if you haven't been wondering, know this: you should *always* be wondering) - how does this fit with the rest of the ecosystem out there? This isn't just a knee-jerk anti-valley reaction, it's a genuine question as to how all of this stuff fits together. Is a certain type of content being optimised for? In other words, as people like Anil Dash have pointed out, this is what happens when you try to build heuristics that aren't flexible enough and you get second-order effects. Sure, linkfarms are a bad, but they make a lot of money for people, and in the race, it's easier to make linkfarms than it is to detect them. And in wars there will always be collateral damage. In this war, it looks like Metafilter might be wounded, and we'll know in the next year or so whether mortally so.  
[1] Design for Community - Amazon: http://amzn.to/1lD959B
[2] http://www.adexchanger.com/publishers/google-explores-a-unified-cms-and-publisher-ad-platform/
3.0 Requests
I'm going to try an experiment this week: I'm going to take requests. I'm going to have a lot to write about, I expect, what with Solid going on, so this is just my masochistic self peeking through, but let's have a go at this. Send a suggestion for something you'd like me to have a think and a write about. Some of you have done that already; I'll add those into the hat. I'll take a look and pick some to write about on Wednesday, Thursday and Friday this week. 
--
That's it for today. See you on the other side. 
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Eighty Three: This Is My Next; And How It Felt
Date: May 20, 2014 at 12:16:56 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fm5x=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>





0.0 Station Ident

For reasons that will become apparent in the next section, I spent most of the weekend trying to not be alone. Saturday was spent having brunch and then running errands before failing at not being alone, playing an inordinate amount of Resogun and then watching a double-bill of The Incredibles and The Fifth Element. 

Anyway. On to the big news.
1.0 This Is My Next
The short version is this: I'm available and looking for freelance work. What am I interested in? 

Here's a short list:

 - net-native games and storytelling for the non-core-gamer audience 
 - wearables done right
 - consumer VR and poking holes in Snowcrash-as-a-business-model
 - fixing healthcare
 - the Internet and how it can be applied to Things
 - how genuinely-nearly-ubiquitous access to the 'net is pushing what the internet delivers further down Maslow's pyramid
 - better government
 - better banking
 - product-as-service-as-marketing
 - products or services and how they can be used to solve communications problems
 - products or services and how they can be used to solve consumer problems
 - helping interesting startups understand their customers and how to develop and demonstrate empathy through product and communications

The even shorter version is this: I like solving problems. And I think I solve them well.

The long list is here: http://newsletter.danhon.com/archive/

Drop me a line at dan@danhon.com, or reply to this episode. 

(If you're in San Francisco and you'd like to meet, drop me a line: I'll be at O'Reilly Solid this Wednesday and Thursday.)
2.0 And How It Felt
I've written before about how it was never one of my life's goals to end up in advertising. It was one of my life's goals to be an astronaut or to be a scientist or to be a writer, but, I have to admit, not someone at an advertising agency. And yet, about four years ago, I started on an adventure at W+K London, and then nine months later, moved out to Portland to work at the mothership, W+K's founding office. 

It as always a big experiment: when I had first interviewed at the agency, I dug into its history and saw that the craft in what they made. That they'd made some of the most memorable ads in the last thirty or so years and that, like any good - no, great - agency, they'd genuinely influenced culture. There were so many of them! The thing that really attracted me to them, though, was that here was a chance to see if I could work with some of the best storytellers in the world to make something amazing in the interactive space. 

And, honestly, it was really, really hard. Advertising is hard. Most things are hard. Over the past four years, I've learned *so* much about the problems companies face and the ways in which they can solve those problems through communication. I've had the privilege on working on and being a part of directing some absolutely amazing campaigns over the last four years, and I'd be the first one to say that the power of filmic storytelling is, well, literally awesome. Across every single account I've worked on - Nike, Coca-Cola, Sony, Kraft, Lurpak and Facebook - I've worked with fantastic, smart people and been a part of work I've been proud of.  And against all of this was the changing landscape of advertising being disrupted like every other traditional pre-internet industry and agencies as well as their clients needing to deal with the change. 

I came in and loved the challenge. Of building teams and helping to define new roles. One of my favourite experiences - and actually, one of the things that I love doing - was of helping a new team get together who hadn't worked with design or UX before and collaborating in a new way to come up with a new way of solving a client brief. And, ultimately, I loved learning through at the very least sheer force of osmosis, how to craft great stories that form a connection with people. 

But that's not what it felt like on Friday. 

Because Friday was the day I got laid off. 

I've been on the other end of layoffs. I dealt with them and managed them at the first startup I joined, Mind Candy, at the company I co-founded, Six to Start and at W+K. And I can tell you now: they're horrible (but obviously differently so) on both ends. 

It doesn't matter that I'd clearly been considering what sort of future I had in an agency environment. Because what happened when I was being laid off, in that meeting - and I appreciate, genuinely, that it was done in the one of the most respectful ways possible, by just ripping off the band-aid as quickly as could be - was something that I just didn't expect. And, at the end of it, it doesn't matter if you were even slightly thinking of moving on - because the choice was made for you and the decision was taken out of your hands. And, ultimately, the decision was made that, out of the pool, you were one of the ones deemed to not be needed in the future. 

And it's just shitty for everyone. And yeah, I did spend the rest of the day - and the weekend - in a bit of a daze. And I was lucky enough to realise that I shouldn't have to deal with it on my own, and that I had people to be with. And then oscillating between being a bit angry and being a bit resigned and being a bit excited and being a bit scared. But, mostly, scared - because my paycheck's disappeared, and I don't know where the next one is going to come from yet. From a personal point of view, I'm pretty sure this has been one of the shittiest Mays I've ever had.

On the plus side, more time for writing newsletters!

--

As ever, I like getting notes from all of you. So, send me notes. Even if it's just a "hi". 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Eighty Two: The Next Big Thing In Drugs; As If You Needed Another NYT Opinion; Experience This; The Value Of The Thing
Date: May 17, 2014 at 2:55:33 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fkhx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I write later than usual today, for reasons that will probably become clear next week. I didn't do too well yesterday: in the house, on my own, kind of passively-aggressively playing Resogun and shooting all the things with the cat beside me. It's one of the things that I've learned - and it's only taken 34 years, so I encourage you to try and do it faster than that if you're able - that if I'm on my own and I'm not engaged in some sort of speech act, then my brain kind of eats itself in a recursive way and before I know it I'm in a genuinely depressive funk that is incredibly hard to get out of. 

In a conversation with my therapist today, I said that it felt rather like I couldn't stop my brain moving - that it was always at the very least idling, and if I didn't find a way to turn it outward, onto and into the world, then it would look inward and not be particularly merciful about what it consumed. Now that I think about it, that's not a particularly nice metaphor or way to think about such an integral part of yourself, but I guess that's the relationship I have with the bit of my self that's reflexive enough to consider itself. When it works and I can point it outside, it's great. But when it's pointed into itself, it's a terrible thing.

It is going to rain this weekend in Portland. 



1.0 The Next Big Thing In Drugs

This morning via Quartz, news that Samsung the conglomerate (they make a lot of things - from electronics to ships to white goods to medical equipment and sell a lot of services from construction to advertising to financial services) is making a USD $2bn investment into biopharmaceuticals[1] (things like vaccines and viral therapies, instead of chemical-based treatments). Two things. 

One: the article is hilarious because it states that "The company will start by copying Enbrel (an arthritis therapy by Amgen Inc.) and Remicade (Johnson & Johnson’s autoimmune disease treatment) in the next couple of years." of which: wow, Samsung, way to go to retain your image of innovation and not merely copying things and bringing them to market slightly more cheaply.

Two: analysts are excited that because Samsung has wearables (or, rather, is trying to make them and failing spectacularly) it has a "health ecosystem" (see: S Health[2]) it will be able to do an end-run around the existing pharma companies that conversely do not have a "health ecosystem" - ie apps and internet connected things. Never mind that the first-mover advantage in this case appears, in my mind, to be virtually nought because it's not actually bringing any benefit to people and the utility being delivered is practically zero, the idea that Samsung will be able to produce a clear, consistent user experience in the realm of health is amusing. We're not talking about TVs or even smart TVs here. We're talking about medical diagnostic information (the examples are *always* of diabetics taking their blood glucose levels) for which regulation is going to clamp down on like a lead balloon. I get that the pharma/medical device companies are conservative in what they produce and what they think the market will bear in terms of complexity and functionality, and that there's also a *very* different go-to-market strategy, but to think that the company that *thinks* it has won the smartphone war because of innovative functionality and not, say, extremely well-executed marketing and price sensitivity, will do so in the medical devices arena is... well, I am not literally snorting things out of my nose. 

[1] http://qz.com/209603/samsung-is-becoming-a-drug-firm-and-the-drug-firms-should-watch-out/
[2] http://www.samsung.com/global/microsite/galaxys4/lifecare.html#page=shealth

2.0 As If You Needed Another New York Times Opinion

Nick Sweeney did a good job, I think, of summing up[1] the New York Times' leaked digital innovation report in a pithy statement as to the paper of record's future being "like that of a collapsed star: a small dense core of journalism with a large gravitational field of kittens." 

If I have learned anything, it's that the only organisations that really change are the ones that want to change. Sure, there are tea-leaf readings that indicate that the involvement of the current publisher's son and heir to the throne are positive portents for the future, but I suspect one of the best things about the report is that a whole bunch of us would just like to get our hands on it and kind of do a search-and-replace and hand it off to our collective management and leadership teams.

Full disclosure: I haven't read all ninety pages of the report (spoilers: I haven't even read *any* pages of the report) but it turns out that you can't fucking click on *anything* on the internet today without some sort of reckon about it. So this isn't really my reaction the report as such as it is these types of reports in general.

By all accounts, what's in it is eminently sensible and, depressingly, really obvious. Some of it is, inversely, obviously depressing: for example, the paucity of useful and relevant metadata as to their treasure trove of genuinely useful content that an easily-conceived audience would care about. No, what's depressing is that a lot of what needs to be done is clear, and would have been clear, quite a while ago. That it hasn't been done is a tragedy and exactly the sort of thing that leads people to hang their heads in exasperation and, ultimately, quit their jobs. 

Because the New York Times is that example of something more than an organisation and more of an institution. My brother's been writing up a set of notes on the BBC and its approach to digital commissioning[3]. One of the things to understand about the BBC if you're not British is exactly how much of an institution it is, and, for a certain set of people, the sort of civic values and kind-of patriotism that it inspires. And, I think, there is a stage in an organisation's evolution where it does sort of ossify into an institution that is designed to do certain things well and without, how shall I put it, *disruptive* change, it will continue to do those things. Unless there's a stupendously abrasive almost Jobsian petulance in place at the top, it doesn't matter if you have Reithian values of Nation Speaking Unto Nation or Entertain, Inform and Educate, or The Paper Of Record that speak to a medium-agnostic mission, you end up with an institution that warps *around* the medium instead of the content. 

I would say that perhaps Disney were one of the organisations that, in a way, got close to medium agnosticism, because clearly what they perceive as their value is, on some level, the IP in their characters and settings (Mickey, for example) and not necessarily just in a particular medium's expression (Fantasia, for example). You can kind of see this in their current strategy of buying up universes capable of multiple forms of expression like Star Wars and the Marvel universe, and no, I'm not going to get distracted and fall down the transmedia rabbit hole. 

But even Disney can't handle it quite right because arguably they haven't really figured out good interactivity yet, either. Of all of the                 entertainment or media companies, they are the most agnostic in all media *apart* from the binary. Theme parks, toys, movies, tv shows, music, you all know what I mean. But has one ever moved from digital to the other? Not yet. 

This is what perhaps has been disappointing and depressing to me about the state of the art of interactive entertainment. It's that we are *still* so early on in the stages of networked interactive media that one of our best examples is instead Angry Birds, something that appeared from nowhere and may well disappear to nowhere in about as much time as it exploded. We've seen what happened to Farmville and how quickly things can grow, but what we haven't seen is an example of a sustainable, digital-first/medium-agnostic entertainment property. I'd argue that we *could* have, had our media conglomerates looked at what was working online and moved it, but I look at stuff like the acquisition of Maker Studios and that's just TV-but-different, not something that's net or binary native.   

In a way, that's what I was interested in with what Vox Media have been doing: that they went net native first and they appear to be doing okay by it in terms of most of their verticals, but I'm still not entirely persuaded by Vox-the-news-publication as it feels like it hasn't quite hit home yet. 

I have never, ever, really been persuaded by change-from-within because the examples always seem to be outliers. Or, rather, they rely disproportionately upon mercurial leadership who are quite happy to hold what are called strong-yet-weak opinions. Ones that are hard and fast until they require changing at which point *everything changes*. I mean, maybe Nokia, who famously went from rubber to telecoms and then squandered that with some quite impressive hubris might have another wind with its internet-of-things strategy. Or maybe not. But this is the paradox: how do you build a framework that can create great work and is disciplined and strict in that way, but also flexible enough to spin at a moment's notice?   

Part of the trick, of course, is that you don't need to spin at a moment's notice. It's easy to say with the benefit of hindsight, but if you know the right things at the right time, these changes don't sneak up on you. You can act upon them: you can ditch the floppy drives and go USB before the floppy drives are ditched. Everyone else will be left scrambling - sometimes quickly, sometimes with less urgency - but it's not like it's impossible to get ahead of the curve. Why, then, does it feel so hard and so difficult to slaughter just a few sacred cows?

There's one irritating thing that I wanted to get off my chest and that was about the whole misunderstanding around Snow Fall. You know what? There *are* Snowfall Builders. They're called people, and they use tools like their heads to make New Things out of a unique combination of the technologies of the web and journalism. I hate for this to be an issue of terminology, but the thing is if you're going to have a conversation about Snow Fall you kind of need some sort of agreement as to what we *mean* by Snow Fall. Do we mean the particular format of vertical scrolling somewhat parallax storytellingwith progressively loading and rendering text and video? Or do we mean "unique thing on the internet" where content and presentation inform each other in a stupendously fluid medium? 

Because to ask for a Snowfall Builder is to misunderstand one of the central properties of the web and digital media. Certainly there are *properties* of digital media, but some of those properties are more aligned the axis of flexibility as opposed to constraints. The thing about a web page is that there are *so many* things you can do with it purely *because* of the interactivity, as opposed to a passive medium like newsprint. You know what a Snowfall Builder is? Something that can understand a Turing Complete environment and emit instructions for that environment. That's what a Snowfall Builder is. 

But, I suspect, those asking for a Snowfall Builder want a templatised system that is a sort of Fancypants Microsoft Publisher for the Web where we can drag-and-drop content and you don't need those weird developer and design type people and can we just go back to having journalism please. 

No, you can't have a Snowfall Builder because it's like asking for a Golden Globes Award Winning TV Show Builder or a Best Movie Oscar Builder - it betrays a fundamental not-grokking-it of what made Snow Fall Snow Fall. 

[1] http://www.niemanlab.org/2014/05/the-leaked-new-york-times-innovation-report-is-one-of-the-key-documents-of-this-media-age/
[2] http://nicksweeney.com/2014/05/16/tldr-horizon/
[3] http://mssv.net/2014/05/02/setting-the-scene-bbc-digital-commissioning-pt-1/

3.0 Experience This

So The Verge via Techcrunch reported that Airbnb have been testing offering experiences[1] of which I have a whole number of reckons! I'm not entirely sure how this fits into the sharing economy narrative. Techcrunch's position is that this helps Airbnb expand into the wider service area of a hospitality brand and blah blah a new revenue stream from experience providers. The flipside of this all of course is that this just another way to monetise the hosts with whom Airbnb has a relationship with. For the min-maxxers who are working out where to buy property to extract optimum short rents this isn't going to be interesting, but for the body of people for whom Airbnb is replacing lost salary or is becoming a supplement or alternative to employment that has disappeared or is disappearing, this is just another sign of the increasing corporatisation of the individual. I wonder how far this goes: does or will Airbnb encourage all of its hosts to have an interesting, valuable and unique service on offer in order to attract guests? Are you going to have to learn the local landmarks or a trick, in other words, for your rating to become high enough so that Airbnb has a chance to upsell a guest on a value-add that they can take a revenue mark out of? Or, are we destined in some sort of Douglas Adams-esque dystopian future to only ever travel to Airbnb managed properties and endure somewhat listless, lackadasical local tours in an exercise to just move more money around. 

Finally, there's a slip-up in the quote from the Airbnb spokesperson who said “We are always experimenting with new ways to create meaningful experiences on Airbnb, we currently don’t have any updates to share.” - and it's that usage of the phrase "meaningful experiences on Airbnb". To what does an Airbnb apply? The website? The guest experience? I mean, this kind of feels a bit like Airbnb mixed with an entertain me-please TaskRabbit...

[1] http://techcrunch.com/2014/05/16/airbnb-experiences//

4.0 The Value Of The Thing

I caught a tweet from Verizon about their device trade-in program that I thought was a neat interaction. It's a simple one, really: you can dial **VALUE from any phone, on any carrier, and Verizon will do some network magic to try to autodetect (presumably via something like IMEI) the manufacturer and model of your phone to give you a pseudo-realtime estimate of its tradein value. No messing around with dropdown menus to select Samsung and then another dropdown menu to pick which Samsung model phone you've got, just a simple phone interaction. 

The logical conclusion of this, of course - and I'm not sure if something like Amazon Flow[2] does anything like this, but the idea of being able to point a camera at anything and being able to find out its current worth via a simple lookup on Amazon Marketplace or eBay is a bit... well, they don't call it late-stage capitalism for no reason...

[1] http://www.verizonwireless.com/news/article/2014/04/smartphone-recycling-device-trade-in.html
[2] https://itunes.apple.com/us/app/flow-powered-by-amazon/id474664425?mt=8

--

It's been a long week. I'm planning to be at O'Reilly Solid next week in San Francisco, so if you're going to be around too, drop me a line. And thank you for all the notes - they're much appreciated. Again, if you're new, please do drop a line introducing yourself if you feel like it. I'm kind of intrigued as to where all my new subscribers are coming from...

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Eighty One: Board-Level Algorithms; You Speak GIF, Right?; Intent; Odds
Date: May 15, 2014 at 4:36:19 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fjnp=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident

I'm back in Portland, where for some bizarre reason it's hotter than Dearborn, Missouri. I've left my wife, son and mother behind with my father-in-law. Now I have a week or so of bachelorhood before wife and son come back. And there's only one episode left of Agents of SHIELD left to watch. 

1.0 Board-Level Algorithms

Aging Analytics Agency[1], whose website look like the kind of thing a production office would cook up for a movie or an ARG, issued a press release on Tuesday stating that "A Venture Capital Firm Just Named An Algorithm To Its Board Of Directors"[2], which press release is about as full of hyperbole as you could expect.

As an aside, the press release cites as a source a Business Insider article[3], which cites a Beta Beat article[4], which cites the press release, in a somewhat suspicious circle-jerk of attribution.

In any event, anyone who knows anything about VCs will know that there's a significant difference in terms of making investment decisions and *being named to the board of directors*, the latter of which opens up all sorts of legal issues around what would qualify as a Director that would make Ray Kurzweil super excited. 

Only Deep Knowledge Ventures[5], the Hong Kong-based VC company, knows in detail how Aging Analytics' algorithm will influence their decisions in practice. Their website says that they partner with "the top analytical companies utilizing machine learning and [a] large panel of experts" to "construct complex decision trees showing risk and return at every stage of company evolution."

All of which is, you know, blah blah big data blah blah deep learning blah blah investment decisions which is all fine and well until you find out Microsoft have incorporated a Deep Learning Wizard into the next version of Excel and all of your modeling spreadsheets are out of date. 

Absent substantive information from the press releases or public interviews, what we have here is a sort of expert system that the VC firm and its partner supplying the algorithm have seen fit to *let the rest of the world know* that it's helping them make investment decisions. Deep Knowledge Ventures is already an interesting company because of its investments in In Silico Medicine[6], and if you know what *that* means, you're wondering why a Gibson-esque science-fiction novel has again busted out into the real world perhaps a couple of years early. 

In Silico Medicine - apart from being the name of something you'd expect from a Michael Crichton novel and the phrase cropping up as the title of a good book from Jim Munroe[7]  - is the practice of Moore's law encroaching further into the medical process. Faster processors and more sophisticated software means higher fidelity simulations which means faster scientific iteration. At least, so the theory goes, if you're a singulatarian. But, of course, whilst those systems are more complicated to simulate than generally thought, it's never wise to bet against Moore's Law. 

So no. An algorithm has not just become a legally defined person capable of holding corporate office. It is merely "voting" in an advisory capacity to assist a board of directors in making investment decisions. The real story here is yet another mark in the book showing how intertwined we are becoming with the technology we create (which has always been the case), and the gradual prising of open of the Overton window for *real* algorithmic representation in corporate law.


[1] http://aginganalytics.com
[2] http://aginganalytics.com/a-venture-capital-firm-just-named-an-algorithm-to-its-board-of-directors/#more-178
[3] http://www.businessinsider.com/vital-named-to-board-2014-5#ixzz31dVwrSEo
[4] http://betabeat.com/2014/05/v-c-firm-names-robot-to-board-of-directors/
[5] http://deepknowledgeventures.com
[6] http://www.insilicomedicine.com/#!/
[7] Everyone In Silico:
Amazon: http://amzn.to/RFQMJ1
Powell's: http://www.powells.com/biblio/9781568582405

2.0 You Speak GIF, Right?

Balaji S. Srinivasan posted a provocative multi-tweet-essay in the style of his a16z colleague Marc Andreessen yesterday on the evolution of our species communication technology[1], from the written word through to animated GIFs. Srinivasan's got an interesting point - written laws were a breakthrough, he contends, because they allowed "lossless digital replay over distance" - and we'll just leave aside the inaccurate usage of the word 'digital'. They won out of oral laws because oral communication was limited not only in travel radius and memory, but also in a temporal sense, because human memory necessarily decays over time. So yes, written language allowed scaling a culture to much larger areas than ever before. 

The tweak that Srinivasan adds is looking at communication through the lens of the current trend of photo and image sharing. Language, he says, began with hieroglyphs and pictograms, then became ideograms and then became abstracted into alphabets. So, you can expect language-forming behaviour around photo/video and image sharing, thus leading inexorably to the memes that we have on the internet. And then we get to a sort of not-quite-Dawkinesque memeplex - that is, conglomerations of memes that convey complex concepts. 

What we have with photo-sharing and the culture of meme/photo/video sharing is, Srinivasan says, the "ability to communicate what we see/hear digitally, losslessly over great distance" without using just characters. So it's not that we're entering a post-literate society because memes are incorporating written language - you still need to understand English to grok the full nature of the meme. But memes again are built upon a shared understanding of culture - they're built on the stump of literacy, or cultural literacy, as a base. 

I think the point that I take issue is this idea of lossless communication. Human communication is necessarily lossy - because there's that part in our heads where we interpret what's going on and integrate it into our own understanding. True digital lossless communication would be along the SFnal lines of transferring mind states, and whilst the literality of what Srinivasan says is true: ie communicating what we *see* and what we *hear* losslessly, what is lossily transmitted is the *intent* or the meaning behind those images. 

Weirdly, this is a part that animated gifs are, in part, fixing. In terms of animated gifs ripped from popular culture, what's interesting about them is that they appropriate the entire context of the surrounding material. So a shakes-my-head animated gif from Doctor Who is communicating a very different shakes-my-head animated gif from The Good Wife, for example - and both only work if both the sender *and* the recipient share a similar cultural reference frame: or, we've both watched that episode, or understand those characters and their motivations and their personalities and their settings. 

So whilst image and photo sharing is undeniably a leap in terms of literally being able to *see what I see*, it's not the same as *understanding what I see*. There's still lossy communication there.

[1] https://twitter.com/balajis/status/466762126934016001

3.0 Intent

Via Gruber, John Moran wrote about what makes Apple unique[1] (because in our world, we will never be short of opinions about what makes or made Apple unique - and yours truly is as guilty of this as anyone else), and takes a look at what it is that makes Apple's particular application of that woolly word "design" special as opposed to any other company's. Morgan's point is that design is about intent - and that it's not just "how it works as well as how it looks" but that the intent covers "why it does what it does" or "how should this be". With this, Morgan pulls out quotes like Steve Jobs potentially being at his most frustrating in his home life, with the story of him taking forever to choose some furniture (or, if you've read the Isaacson biography, a washing machine) because he first had to work out what the *point* of a sofa was in the first place before he could choose the right one. 

Morgan contends that no other company makes intentional design decisions like Apple, and it should be clear that Apple only occasionally holds itself up to that particular high standard, otherwise we wouldn't get things like iCloud or iPod socks. Instead, Apple's competitors and other companies make what Morgan categorises as Design Evasions that fall under the category of preservation (see: Microsoft), copying (see: Android) and delegating (see: Samsung and Project Ara). 

I wrote in a previous episode[2] that Astro Teller's designs for Google X - a sort of sufficiently advanced technology indistinguishable from a do-what-I-mean magic - was a bit ambitious and perhaps misrepresented when he spoke at TechCrunch Disrupt. But in case it was ever not obvious, that lack of editing seems to be a weakness for Google. Sure, Apple appear - from the outside - to lack the technical chops these days, but at least you can rely upon them to be ruthless (ish) on the what and the why of the utility that they're providing. What I do find interesting is how this philosophy of what-a-thing-does and curation/editing means in terms of smart objects that are comfortable being connected with a network. Sure, they'll be good at what they do, but how do you curate/edit how they talk to the rest of the network? 


[1] http://rampantinnovation.com/2014/05/13/design-is-about-intent/
[2] http://newsletter.danhon.com/episode-seventy-nine-the-internet-of-safety-invisible-technology-like-a-dog-whistle-odds/

4.0 Odds

 - It's Siggraph technical paper preview time. Here's 2014's, full of more jaw-dropping algorithmic awesomeness: https://www.youtube.com/watch?v=u3Z1hDwGEmM

 - Stross on Pikettty: http://www.antipope.org/charlie/blog-static/2014/04/the-prospects-of-the-space-and.html

 - Amazing Military Infographics: https://medium.com/message/1ba60bdc32e7 - this one I think I might write a bit more about tomorrow.
 
 --
 
 Seriously, you lot are underperforming with notes. I can only assume that all the new people are far too embarrassed to introduce themselves, to which I say: it's just an email. Just say hi. Also: only nineteen episodes to go til I hit one hundred!
 
 Best,
 
 Dan




Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Eighty: Motion, Controlled; The Childish Myth; Odds
Date: May 14, 2014 at 8:50:14 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fj3x=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Over one thousand subscribers! And it only took me 80 episodes! It's late on Wednesday night, and I'm heading back to Portland tomorrow, sans wife and son. We had a stupid amount of good barbecue today. I can't eat anymore, ever.

1.0 Motion, Controlled



So Microsoft caved and Kinect 2 is no longer a pack-in for the Xbox One[1]. The upgraded motion/3D/depth/high-definition camera that had the unfortunate timing of being announced at roughly the same time as the Snowden revelations, capitalising upon the evil-red-all-seeing-eye of, well, both Sauron *and* HAL 9000, isn't a requirement anymore, and you can now bask in a slightly-less-powerful than PS4 gaming experience, or, if you prefer a slightly-better-than-PS4 on-demand video experience that integrates with your cable box. That you won't be able to talk to. 

Ian Bogost had a good post in Edge Online (not edge.org) earlier this month, calling the death of "physical interfaces for active play"[1]. Whilst Bogost does have a reputation for being a bit of a crochety bastard, he's certainly a *smart* crotchety bastard, and he presents a compelling case for the history of physical user interfaces for gaming as being nothing more than a Groundhog day cycle of faddish repeats. 

I think Bogost's most compelling point was that, aside party games like Just Dance/Dance Central and Kinect Adventures for kids, motion-control just really wasn't an interesting or sticky enough behaviour inside the house. I remember the moment pretty early on when we figured we could play Wii Tennis just as easily by sitting on the couch and flicking our wrist, with minimal movement, and that appears to define the moment for Bogost when the dream of the original Wii died. His other point, that Kinect's other big point is voice control, is that it's hardly an active interface at all, and, at worst, one that makes the user experience ever so slightly more tedious. 

Perhaps what's needed with motion sensing is for the motion to be pervasive, unintrusive and supplemental to the main mode. I have to admit that one of the games that I was most taken with for Kinect was Child of Eden[3], the spiritual successor to Tetsuya Mizuguchi's Rez[4], the classic Dreamcast synesthesia on-rails trance shooter. Child of Eden, with its magic/sorcery-like control system for targeting and firing made me appreciate exactly how buff Tom Cruise's upper-body was, and despite the literally awe-some music and visuals, I never got that into it because the damn thing was tiring. 

And that was one of the criticisms of motion-controlled gaming: we already have motion control that enough people are familiar with, and that's touch direct manipulation on every touch screen. There's physical resistance against the screen, and a metaphor of direct manipulation in that the frame-rate is high enough and the latency low enough to make it feel like you're manipulating the thing, unlike the CGI that we're used to when Tony Stark manipulates the design for his latest suit. I'm quite happy to go back to the well and quote Douglas Adams on motion control here:

"For years radios had been operated by means of pressing buttons and turning dials; then as the technology became more sophistated the controls were made touch sensitive - you merely had to brush the panels with your fingers; now all you had to do was wave your hand in the general direction of the components and hope. It saved a lot of muscular expenditure, of course, but meant that you had to sit infuriatingly still if you wanted to keep listening to the same program."

Whilst I haven't tried Kinect 2 yet, the experience with Kinect One was just slightly emerging out of the trench of disappointment. Motion control, Kinect-style, was tantalisingly close, but also infuriatingly imprecise. Anyone who's tried the original Kinect will be familiar with the irritating jitter that the faux hand cursor would display on the screen as you held your hand up to manipulate menus (once you had been impressed by the way the hand switched orientation to display your corresponding right, or left, hand as you switched). Perhaps motion control is rather like the capactive touchscreen Symbian era of smartphones: the technology is kind of there, but no one's quite combined all the rights bits together yet. 

[1] http://www.polygon.com/2014/5/13/5714120/no-kinect-xbox-one
[2] http://www.edge-online.com/features/with-kinect-2-the-era-of-physical-interfaces-for-active-play-has-come-to-a-definitive-close/
[3] http://en.wikipedia.org/wiki/Child_of_Eden
[4] http://en.wikipedia.org/wiki/Rez

2.0 The Childish Myth

Timo Arnall has produced a new multi-screen film titled Internet Machine[1], about the invisible infrastructure of the internet. You might remember Arnall as helping to put together the Immaterials Project[2], a beautiful bringing to life of the intangible infrastructure that now envelops us and is outside of our realm of perception. 

There was a particular phrase of Arnall's that struck me in his description of his latest project:

"In this film I wanted to look beyond the childish myth of ‘the cloud’, to investigate what the infrastructures of the internet actually look like."

It's his characterisation of the current understanding of what 'the cloud' is as childish that's interesting. Way back when we used to scribble network and architecture diagrams, there'd be a kind of zagged line that would end in a fluffy cloud shape, and that cloud or internet would exist as a kind of off-the-cuff marginalia - something that we didn't have to worry about, that would fulfill a certain function, because what we were concerned with was the meat of the diagram - look over here, not over there. 

Arnall's point is that you can't really ignore and abstract away as a fluffy object that's 'over there' when it's the infrastructure that powers, well, most of the world. And that it's worth understanding: in geography lessons at school we grew up learning about transport hubs, what made cities cities, the different types of industry that would make up a town or indeed a country. Are kids being taught about what data centers are? How critical they are to the mundanity of daily life? I mean, it's one thing to start thinking: hey, shipping containers are pretty interesting, ever think about how much the world shrunk when we standardised on shipping containers? And it's another to think about the humble TCP/IP packet, but spare a thought for the physical substrate that all of this stuff runs on. The electricity requirements. The square footage. The geographical location. The fact that states and cities compete by offering tax incentives to house buildings that, while they generate employment in the short term in terms of erecting their sheer size, once they become operational, actually require minimal human involvement as a ratio to their volume. As Arnall's film makes visually clear, this isn't a *cloud*. It's noise and heat and light and cold and cabling and corridors and not just blinking lights with overhanging flat-panel monitors that display Johnny Depp's uploaded visage. The cloud is *heavy*. It's made of concrete and chillers and fans. This isn't to say that it's a wrong thing to have the cloud in the first place, but that's the point of the "childish" description. It's like saying: hey, did you know that trade lines were ploughed by dragons? Yeah, dragons. I mean boats. Giant container ships. But we call them dragons. Yeah, I don't know why. Aren't dragons awesome?![3]

[1] http://www.elasticspace.com/2014/05/internet-machine
[2] http://www.elasticspace.com/2013/09/the-immaterials-project
[3] http://shorttermmemoryloss.com/portfolio/project/dragons/

3.0 Odds

 - I helped edit Tom Coates' In Praise of Boring Objects (https://medium.com/product-club/379216903543) which you should read, even though it's long, because it explains how the internet connected objects can just be plain *better*, and not just stick extraneous interface in the way that shows off that they're connected. Coates explains, plainly and persuasively, what it means for objects to use the network as a material.

 - In the continued quest to put Bluetooth 4.0 LE connected three-axis accelerometers in *everything*, you can now (well, when the Kickstarter's done) put them on skateboards. http://syrmo.com

--

Okay, that was disappointing. I didn't get any notes. I was all excited for notes, and then you all didn't send any. Either that or I should check my email again. Or maybe you're all reeling from yesterday's episode? Or maybe it was just obvious. In any event, if you're new, you should say hi and introduce yourself and let me know where you heard about this little newsletter.

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Seventy Nine: The Internet of Safety; Invisible Technology; Like A Dog Whistle; Odds
Date: May 13, 2014 at 10:04:18 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fihh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>




0.0 Station Ident
The sky was tuned to the colour of a violent heatmap, or, DarkSky was telling me that there was some pretty hardcore precipitation coming down. I'm still at the farm in Missouri. It's still not quite quiet. We saw two turkeys in a field today. Calvin has taken to climbing onto what honestly looks like a 1980s era plasticised death trap on wheels and whizzing around, so we've had to MacGyver a harness to stop him from faceplanting, which he's already done once.


I am very, very tired. But I did manage to get on the phone with Centurylink to try and talk some sense into a technical support agent and persuade them that our DSL link was dropping every so often (and tried my best to be patient as I was asked to power cycle the modem and say when the "internet" light was green and then do a speedtest.net diagnostic) and swap out the DSL modem for a new one. *And* I took the father-in-law down to a Verizon store and patiently waited while he was upgraded from a Samsung flip-phone to colour-tastic iPhone 5C and  inducted into the Apple ecosystem. 
1.0 The Internet of Safety
Ben Evans had a good post the other day[1] bringing more attention to his "Unfair but relevant"[2] post, where he justified the usage of comparing unlike-with-unlike. For example, he'd compare iOS device shipments against Windows PC shipments and have to explain that, whilst they were *unfair* in terms of iOS devices being a completely different market segment than Windows PCs (and the products being on a different replacement cycle and go-to-market strategy), they were *relevant* because of the time and attention that they were cannibalising in terms of their audience. 
Evans makes the throwaway point that "customers don't care if a company's advantage is unfair", and I want to unpack that a little. A good example is in terms of the first example (not shown in a chart) where Evans compared would compare customers per employee at fixed versus mobile networks. From the fixed network point of view, that would be unfair, but like Evans says, and more bluntly: the customer doesn't give a shit. The customer gives a shit about *the job to be done*. 
I suppose this is the *really obvious by now* point about Maslow's hierarchy of needs and Moore's Law. By dint of manufacturing process, the first computers were necessarily large, slow and expensive: and because they were *expensive*, they had to justify their price and weren't trivial. So they started actualising at the very *top* of Maslow's pyramid. But here we are, thirty to forty years of Moore's Law later, and the inexorable progress of silicon in computing and communications has meant that per-FLOP cost has dropped so much, and the corresponding energy bill has dropped so much, that computing and communication has now penetrated down to near the bottom of the pyramid. 
At the root of it, perhaps that's one of the reasons why Apple ended up in the ascendant, not Microsoft. Microsoft, always attacking things from the productivity point of view, was always going to be placed at the top of Maslow's pyramid in terms of satisfying user need (and there's that crusade again: the empathy with a user necessary to determine, discern and *act upon* genuine user need as opposed to imposed user need). Microsoft's vast revenues were in the office and b2b side of things: the oft-quoted saying about Microsoft was that they never really sold to end users - they sold to OEMs like Dell, HP, Compaq, IBM and, back in the day, Gateway. Users - consumers - didn't really get a choice. 
Apple, on the other hand, would continue banging the drum about the computer being a bicycle for the mind (and one day, I swear to god, I'm going to get *really* sick of that quote) and would start to push downwards. Sure, the creativity in Apple's origins in terms of the Mac and Apple ][ would still be in the top two parts of Maslow's pyramid of self-actualisation and self-esteem, but with the iPod and the Digital Hub, both of which were pooh-poohed by Microsoft as being distractions, you could see Apple actually moving further down the pyramid to attacking things like friendship and family in the love/belonging tier. 
So, this is the thing for me: users *don't care* what your corporate strategy is, or how much you've invested, or whether many decades ago you needed a local government monopoly in order to guarantee that you'd make your money back on laying your municipal cable network. What they *wanted* was satisfaction of those needs, and as much as brands might be important, satisfaction of those needs comes a long way in terms of trumping absolutely everything else. People want connectivity and communication, not Verizon or Comcast, which is why they're entirely happy to jump ship when Google comes to town and offers fiber. 
If I were being smart about this, I'd say that we're entering a new phase of the internet, computing and communication.  
The 80s and 90s brought with them the information worker (to an extent), and satisfied the top-most portion of Maslow's pyramid: self-actualisation. Photoshop, Office, Word Processing - all of that stuff - they all fulfilled the last-required needs-to-be-filled, those of creativity, morality and problem solving.
The 90s and 00s brought with them increased connectivity and communication, and with them, the next two tiers of the pyramid: esteem and belonging. Any of these sound familiar? Self-esteem, confidence, achievement, respect of others, respect by others: these were all elements that were made *vastly* more accessible thanks to the internet and personal publishing. With the internet and peer-to-peer communication, individual could speak unto individual, find each other anywhere out on the 'net, and no-one knew you were a dog. Careers were made and stars were born, and they continue to do so: witness the constant rise of new YouTube stars. 
Social networks and mobile started to satisfy the next tier of love and belonging. As Moore's law pushed us further down the stack and more intimately into our lives so that devices were not tethered to desks and instead nestled in our pockets, they would offer opportunities for friendship, family and sexual intimacy. 
So now, where are we? I think we're at the Internet of Safety phase.
If you believe that Moore's law is pushing us down the pyramid in terms of fulfillment of need due to increased and ease of accessibility to networked computing devices, then the next tier is Safety. With safety, we're going to see the opportunity to fulfill needs like security of body, security of employment, resources, morality, health and property. And *each and every single one of those* maps against the new wave of startups that we're seeing that are accruing value. Whether you like them or not, zero-hour contracts and API-mediated employment are making dents in everyday life. A proliferation of sensing devices - whether mobile or remote - are changing the way we perform resource management, at the large end like GIS and at the narrow end, like Uber and Airbnb. Social feedback mechanisms like Twitter are providing violent check mechanisms against morality in big-picture spaces for nation states, like we've seen in the Middle East (while near-term effects don't look too great, long-term, increased communication is looking like it's critical to a more accurately represented demos), and for small-picture micro-campaigns like Nintendo's conservative family values and what happened to Brendan Eich. Health is a no-brainer as devices get smarter and we're all just waiting for the one true coming of the integrated wearable and a usable electronic health record, plus joined-up services. And property, along with resources, are being disrupted as, arguably, the need to have *access* to property as opposed to the ownership of property appears to be an even easier and more accessible way of satisfying user need.
This, I think, is the next age of the internet: not some sort of web 3.0, not an internet of things, but a change in focus as to what kinds of user needs we're able to satisfy through technology. I like this, because it focuses on what the internet of things will *do*, rather than just say that hey, turns out when you can give stuff IP addresses, stuff gets IP addresses.
 http://ben-evans.com/benedictevans/2014/5/5/unfair-but-relevant [2] http://ben-evans.com/benedictevans/2014/4/19/unfairness-or-getting-something-for-nothing
2.0 Invisible Technology
Google X's Astro Teller was at Disrupt New York last week delivering what TechCrunch described as an "Anti-Technology Mission Statement,"[1] which, for an organisation founded on technological innovation, seems like a bit of a case of sub-editor (or, indeed blogger) either not understanding what they're writing about, or the language that they're writing in. But anyway. 
Now there are some verbatim quotes in TechCrunch's writeup that are, shall we say, a little bit troubling/amusing, but in this case I'm going to chalk them up to TechCrunch being TechCrunch and assume that Teller doesn't actually mean what the author of the piece, Romain Dillet, implies. 
Teller's general gist is in terms of how technology should be more like the ABS system in current cars. Cars these days are partly a drive-by-wire system: you don't actually have a direct, mechanical connection in terms of your cause and its effect, and instead you have computer-mediated interaction. You hit the brake pedal and your implied brake instruction is translated, by the ABS computer, into a series of brake instructions that are designed to carry out your intent. As Dillet puts it, "it's just an interface. You are actually making a request to a robot." Teller's implying that this is good: you don't have to worry about *how* ABS works, you just know (or implicitly) that it will Do What You Mean.  Bluntly: Teller's cheating. In ABS, you have a piece of interface - the foot pedal - that has a single intent: to brake. You can either do it fast or slow, light or hard, but it's pretty much about braking. There's no real ambiguity there, or at least, the ambiguity is only in terms of one axis. ABS's job is to take a specific outcome - wheels locking and losing control of the vehicle - and to mitigate it. That's a *really* narrow problem domain. If you're extrapolating outside of that and saying "Well, all technology should be as easy to use as that," then I've got a bunch of unicorns on a bridge that you're very welcome to buy. Teller is, in fact, just saying "Wouldn't it be awesome if we solved all the EasyHard problems."[2, 3]
I mean, the good news is that Teller admits to it, and Google X kind of has a remit for moonshot technology. He says: “[ABS] is a wonderful technology moment. We don’t have to mess with it. We just say here’s what we want,” he said. “When technology reaches that level of invisibility in our lives, that’s our ultimate goal. It vanishes into our lives. It says: ‘you don’t have to do the work, I’ll do the work.’”
I had a previous version of this that was noodling around in my head where I went and thought about what Teller might mean by "invisibility" - for example, did he mean ubiquity or mundanity, robustness or reliability. But now that I've let it sit for a few days, the invisibility is instead in the sort of strong AI, definitely-EasyHard problem space: always do what I mean, without me having to explain it. 
The flip side of this, of course, is that all of this "do what I mean" functionality in effect hides a great deal of complexity and in a sense may even disempower us. The Techcrunch writeup talks of technology becoming "more efficient" so that it can fade into the background, but this isn't efficiency: it's second-guessing or mindreading or plain smarts. 
At times, I feel as frustrated at Teller's speech (or, more accurately, Techcrunch's retelling of it) because it could be misinterpreted into laughably bullshit "the best interface is no interface" manifesto from two years ago that derailed everyone even before we had the skeuomorphic-dissing bandwagon of iOS 7 and was instead someone who had unfortunately failed to realise that "interfaces" aren't just things on screens. 
I have to admit that I'm not quite sure where I'm going with this, other than I wish I could just blackhole Techcrunch and not read it, or that the underlying mission of Google X is *far* more interesting than the opportunistic writeup that it garnered. I mean, of course Google X's mission should be way more interesting: they want (at least, from the outside) to disappear phones and make cars self-driving and so on. And if there's anyone out there who can solve EasyHard problems, it may as well be Google right now. I just wish that someone who said they wished technology got out of the way realised that a better way of getting that message across might be to not wear a face computer at the same time. 
[1] http://techcrunch.com/2014/05/06/googlex-head-of-moonshots-astro-teller-technology-should-make-you-feel-more-human-not-less-human/ [2] http://jenson.org/easyhard/ [3] http://newsletter.danhon.com/episode-nineteen-not-trying-is-a-signal-peak-game-easyhard-snapchat/
3.0 Like A Dog Whistle
Whilst it only appeared on The Verge today[1], news broke in Variety a few days ago that CBS had ordered its latest CSI spinoff, CSI: Cyber[2]. We've now graduated from YouTube comedy compilations of double-keyboard hacking prevention and making a GUI in Visual Basic to trace the IP to a full-on spinoff show capable of sustaining its own cast from week to week. If there were any doubt that residual cultural knowledge of the 'net and its effects has permeated enough of our daily lives, it's that Jerry Bruckheimer is able to get this series sold in a post-Snowden world. CSI: Cyber is likely to be a dog whistle to the someone is wrong on the internet[3] crowd, if only because it's going to be like crack for not-quite-right portrayals of technology.
What will be interesting about CSI: Cyber is that it'll be a sort of mirror into what the 40+ American heartland thinks is going on with the internet. Never one for technical accuracy (albeit having done wonders for getting people interested in forensics, of a sort), the thing about CSI is that the stories have to feel *just real enough* to their audience. If you want some quick-and-dirty research into the fears that middle America might have (or, rather, the fears that Hollywood thinks middle America might have), and the technology that Middle America might relate to, then CSI: Cyber is probably going to be worth watching. Also, if anything, the show should be more good examples of Movie OS[4] in terms of visual storytelling in user interface.
And at the very least, CSI: Cyber will be funny.
[1] http://www.theverge.com/2014/5/12/5711260/csi-cyber-crime-spin-off-coming-2014-dark-net-crime-fighting [2] http://variety.com/2014/tv/news/cbs-orders-csi-cyber-spinoff-to-series-1201176896/ [3] http://xkcd.com/386/ [4] http://danhon.com/2010/04/16/the-future-is-movie-os/ (wow, I wrote that in 2010)
4.0 Odds
 - It's not quantum cryptography (or, at least, it's not the kind that you'd instinctively reach for - ie the kind over a point-to-point quantum link), but apparently consumer phone hardware (well, a Nokia N8, so who knows if Microsoft are still making them) now gives us access to significantly better random number generators, which *are* good for better cryptography. See the Arxiv writeup on Medium: https://medium.com/the-physics-arxiv-blog/602f88552b64  
- "Organisations aren't designed to change" - http://blog.gardeviance.org/2014/05/organisational-add-ons.html, of which, designing a template that's encouraging of certain kinds of change - possibly like Undercurrent's Responsive OS - sounds like a reasonable response. 
 - With The Science of Us (http://scienceofus.com), the New York Magazine's new behavioural science journalism explainer experiment, it feels like there are enough explainers out there for someone to do a Huffington Post of educational textbook content: ie aggregate all the good, free stuff published around the web, organise it into a curriculum and, er, something something pants profit. Seriously, I don't think this is a dumb idea.
-- As ever, please send notes. I like them. 
Best, 
Dan 





Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Nine: The Internet of Safety; Invisible Technology; Like A Dog Whistle; Odds
Date: May 13, 2014 at 9:59:10 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident
The sky was tuned to the colour of a violent heatmap, or, DarkSky was telling me that there was some pretty hardcore precipitation coming down. I'm still at the farm in Missouri. It's still not quite quiet. We saw two turkeys in a field today. Calvin has taken to climbing onto what honestly looks like a 1980s era plasticised death trap on wheels and whizzing around, so we've had to MacGyver a harness to stop him from faceplanting, which he's already done once.

I am very, very tired. But I did manage to get on the phone with Centurylink to try and talk some sense into a technical support agent and persuade them that our DSL link was dropping every so often (and tried my best to be patient as I was asked to power cycle the modem and say when the "internet" light was green and then do a speedtest.net diagnostic). And tomorrow is an exciting trip to Verizon to upgrade the father-in-law to the Apple ecosystem. 




1.0 The Internet of Safety
Ben Evans had a good post the other day[1] bringing more attention to his "Unfair but relevant"[2] post, where he justified the usage of comparing unlike-with-unlike. For example, he'd compare iOS device shipments against Windows PC shipments and have to explain that, whilst they were *unfair* in terms of iOS devices being a completely different market segment than Windows PCs (and the products being on a different replacement cycle and go-to-market strategy), they were *relevant* because of the time and attention that they were cannibalising in terms of their audience. 

Evans makes the throwaway point that "customers don't care if a company's advantage is unfair", and I want to unpack that a little. A good example is in terms of the first example (not shown in a chart) where Evans compared would compare customers per employee at fixed versus mobile networks. From the fixed network point of view, that would be unfair, but like Evans says, and more bluntly: the customer doesn't give a shit. The customer gives a shit about *the job to be done*. 

I suppose this is the *really obvious by now* point about Maslow's hierarchy of needs and Moore's Law. By dint of manufacturing process, the first computers were necessarily large, slow and expensive: and because they were *expensive*, they had to justify their price and weren't trivial. So they started actualising at the very *top* of Maslow's pyramid. But here we are, thirty to forty years of Moore's Law later, and the inexorable progress of silicon in computing and communications has meant that per-FLOP cost has dropped so much, and the corresponding energy bill has dropped so much, that computing and communication has now penetrated down to near the bottom of the pyramid. 

At the root of it, perhaps that's one of the reasons why Apple ended up in the ascendant, not Microsoft. Microsoft, always attacking things from the productivity point of view, was always going to be placed at the top of Maslow's pyramid in terms of satisfying user need (and there's that crusade again: the empathy with a user necessary to determine, discern and *act upon* genuine user need as opposed to imposed user need). Microsoft's vast revenues were in the office and b2b side of things: the oft-quoted saying about Microsoft was that they never really sold to end users - they sold to OEMs like Dell, HP, Compaq, IBM and, back in the day, Gateway. Users - consumers - didn't really get a choice. 

Apple, on the other hand, would continue banging the drum about the computer being a bicycle for the mind (and one day, I swear to god, I'm going to get *really* sick of that quote) and would start to push downwards. Sure, the creativity in Apple's origins in terms of the Mac and Apple ][ would still be in the top two parts of Maslow's pyramid of self-actualisation and self-esteem, but with the iPod and the Digital Hub, both of which were pooh-poohed by Microsoft as being distractions, you could see Apple actually moving further down the pyramid to attacking things like friendship and family in the love/belonging tier. 

So, this is the thing for me: users *don't care* what your corporate strategy is, or how much you've invested, or whether many decades ago you needed a local government monopoly in order to guarantee that you'd make your money back on laying your municipal cable network. What they *wanted* was satisfaction of those needs, and as much as brands might be important, satisfaction of those needs comes a long way in terms of trumping absolutely everything else. People want connectivity and communication, not Verizon or Comcast, which is why they're entirely happy to jump ship when Google comes to town and offers fiber. 

If I were being smart about this, I'd say that we're entering a new phase of the internet, computing and communication.  

The 80s and 90s brought with them the information worker (to an extent), and satisfied the top-most portion of Maslow's pyramid: self-actualisation. Photoshop, Office, Word Processing - all of that stuff - they all fulfilled the last-required needs-to-be-filled, those of creativity, morality and problem solving.

The 90s and 00s brought with them increased connectivity and communication, and with them, the next two tiers of the pyramid: esteem and belonging. Any of these sound familiar? Self-esteem, confidence, achievement, respect of others, respect by others: these were all elements that were made *vastly* more accessible thanks to the internet and personal publishing. With the internet and peer-to-peer communication, individual could speak unto individual, find each other anywhere out on the 'net, and no-one knew you were a dog. Careers were made and stars were born, and they continue to do so: witness the constant rise of new YouTube stars. 

Social networks and mobile started to satisfy the next tier of love and belonging. As Moore's law pushed us further down the stack and more intimately into our lives so that devices were not tethered to desks and instead nestled in our pockets, they would offer opportunities for friendship, family and sexual intimacy. 

So now, where are we? I think we're at the Internet of Safety phase.

If you believe that Moore's law is pushing us down the pyramid in terms of fulfillment of need due to increased and ease of accessibility to networked computing devices, then the next tier is Safety. With safety, we're going to see the opportunity to fulfill needs like security of body, security of employment, resources, morality, health and property. And *each and every single one of those* maps against the new wave of startups that we're seeing that are accruing value. Whether you like them or not, zero-hour contracts and API-mediated employment are making dents in everyday life. A proliferation of sensing devices - whether mobile or remote - are changing the way we perform resource management, at the large end like GIS and at the narrow end, like Uber and Airbnb. Social feedback mechanisms like Twitter are providing violent check mechanisms against morality in big-picture spaces for nation states, like we've seen in the Middle East (while near-term effects don't look too great, long-term, increased communication is looking like it's critical to a more accurately represented demos), and for small-picture micro-campaigns like Nintendo's conservative family values and what happened to Brendan Eich. Health is a no-brainer as devices get smarter and we're all just waiting for the one true coming of the integrated wearable and a usable electronic health record, plus joined-up services. And property, along with resources, are being disrupted as, arguably, the need to have *access* to property as opposed to the ownership of property appears to be an even easier and more accessible way of satisfying user need.

This, I think, is the next age of the internet: not some sort of web 3.0, but a change in focus as to what kinds of user needs we're able to satisfy through technology. 

[1] http://ben-evans.com/benedictevans/2014/5/5/unfair-but-relevant
[2] http://ben-evans.com/benedictevans/2014/4/19/unfairness-or-getting-something-for-nothing
2.0 Invisible Technology

Google X's Astro Teller was at Disrupt New York last week delivering what TechCrunch described as an "Anti-Technology Mission Statement,"[1] which, for an organisation founded on technological innovation, seems like a bit of a case of sub-editor (or, indeed blogger) either not understanding what they're writing about, or the language that they're writing in. But anyway. 

Now there are some verbatim quotes in TechCrunch's writeup that are, shall we say, a little bit troubling/amusing, but in this case I'm going to chalk them up to TechCrunch being TechCrunch and assume that Teller doesn't actually mean what the author of the piece, Romain Dillet, implies. 

Teller's general gist is in terms of how technology should be more like the ABS system in current cars. Cars these days are partly a drive-by-wire system: you don't actually have a direct, mechanical connection in terms of your cause and its effect, and instead you have computer-mediated interaction. You hit the brake pedal and your implied brake instruction is translated, by the ABS computer, into a series of brake instructions that are designed to carry out your intent. As Dillet puts it, "it's just an interface. You are actually making a request to a robot." Teller's implying that this is good: you don't have to worry about *how* ABS works, you just know (or implicitly) that it will Do What You Mean. 

Bluntly: Teller's cheating. In ABS, you have a piece of interface - the foot pedal - that has a single intent: to brake. You can either do it fast or slow, light or hard, but it's pretty much about braking. There's no real ambiguity there, or at least, the ambiguity is only in terms of one axis. ABS's job is to take a specific outcome - wheels locking and losing control of the vehicle - and to mitigate it. That's a *really* narrow problem domain. If you're extrapolating outside of that and saying "Well, all technology should be as easy to use as that," then I've got a bunch of unicorns on a bridge that you're very welcome to buy. Teller is, in fact, just saying "Wouldn't it be awesome if we solved all the EasyHard problems."[2, 3]

I mean, the good news is that Teller admits to it, and Google X kind of has a remit for moonshot technology. He says:

“[ABS] is a wonderful technology moment. We don’t have to mess with it. We just say here’s what we want,” he said. “When technology reaches that level of invisibility in our lives, that’s our ultimate goal. It vanishes into our lives. It says: ‘you don’t have to do the work, I’ll do the work.’”

I had a previous version of this that was noodling around in my head where I went and thought about what Teller might mean by "invisibility" - for example, did he mean ubiquity or mundanity, robustness or reliability. But now that I've let it sit for a few days, the invisibility is instead in the sort of strong AI, definitely-EasyHard problem space: always do what I mean, without me having to explain it. 

The flip side of this, of course, is that all of this "do what I mean" functionality in effect hides a great deal of complexity and in a sense may even disempower us. The Techcrunch writeup talks of technology becoming "more efficient" so that it can fade into the background, but this isn't efficiency: it's second-guessing or mindreading or plain smarts. 

At times, I feel as frustrated at Teller's speech (or, more accurately, Techcrunch's retelling of it) because it could be misinterpreted into laughably bullshit "the best interface is no interface" manifesto from two years ago that derailed everyone even before we had the skeuomorphic-dissing bandwagon of iOS 7 and was instead someone who had unfortunately failed to realise that "interfaces" aren't just things on screens. 

I have to admit that I'm not quite sure where I'm going with this, other than I wish I could just blackhole Techcrunch and not read it, or that the underlying mission of Google X is *far* more interesting than the opportunistic writeup that it garnered. I mean, of course Google X's mission should be way more interesting: they want (at least, from the outside) to disappear phones and make cars self-driving and so on. And if there's anyone out there who can solve EasyHard problems, it may as well be Google right now. I just wish that someone who said they wished technology got out of the way realised that a better way of getting that message across might be to not wear a face computer at the same time. 

[1] http://techcrunch.com/2014/05/06/googlex-head-of-moonshots-astro-teller-technology-should-make-you-feel-more-human-not-less-human/
[2] http://jenson.org/easyhard/
[3] http://newsletter.danhon.com/episode-nineteen-not-trying-is-a-signal-peak-game-easyhard-snapchat/
3.0 Like A Dog Whistle

Whilst it only appeared on The Verge today[1], news broke in Variety a few days ago that CBS had ordered its latest CSI spinoff, CSI: Cyber[2]. We've now graduated from YouTube comedy compilations of double-keyboard hacking prevention and making a GUI in Visual Basic to trace the IP to a full-on spinoff show capable of sustaining its own cast from week to week. If there were any doubt that residual cultural knowledge of the 'net and its effects has permeated enough of our daily lives, it's that Jerry Bruckheimer is able to get this series sold in a post-Snowden world. CSI: Cyber is likely to be a dog whistle to the someone is wrong on the internet[3] crowd, if only because it's going to be like crack for not-quite-right portrayals of technology.

What will be interesting about CSI: Cyber is that it'll be a sort of mirror into what the 40+ American heartland thinks is going on with the internet. Never one for technical accuracy (albeit having done wonders for getting people interested in forensics, of a sort), the thing about CSI is that the stories have to feel *just real enough* to their audience. If you want some quick-and-dirty research into the fears that middle America might have (or, rather, the fears that Hollywood thinks middle America might have), and the technology that Middle America might relate to, then CSI: Cyber is probably going to be worth watching. Also, if anything, the show should be more good examples of Movie OS[4] in terms of visual storytelling in user interface.

And at the very least, CSI: Cyber will be funny.

[1] http://www.theverge.com/2014/5/12/5711260/csi-cyber-crime-spin-off-coming-2014-dark-net-crime-fighting
[2] http://variety.com/2014/tv/news/cbs-orders-csi-cyber-spinoff-to-series-1201176896/
[3] http://xkcd.com/386/
[4] http://danhon.com/2010/04/16/the-future-is-movie-os/ (wow, I wrote that in 2010)
4.0 Odds
 - It's not quantum cryptography (or, at least, it's not the kind that you'd instinctively reach for - ie the kind over a point-to-point quantum link), but apparently consumer phone hardware (well, a Nokia N8, so who knows if Microsoft are still making them) now gives us access to significantly better random number generators, which *are* good for better cryptography. See the Arxiv writeup on Medium: https://medium.com/the-physics-arxiv-blog/602f88552b64

 - "Organisations aren't designed to change" - http://blog.gardeviance.org/2014/05/organisational-add-ons.html, of which, designing a template that's encouraging of certain kinds of change - possibly like Undercurrent's Responsive OS - sounds like a reasonable response. 

 - With The Science of Us (http://scienceofus.com), the New York Magazine's new behavioural science journalism explainer experiment, it feels like there are enough explainers out there for someone to do a Huffington Post of educational textbook content: ie aggregate all the good, free stuff published around the web, organise it into a curriculum and, er, something something pants profit. Seriously, I don't think this is a dumb idea.

--

Best,

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  


From: danhon <dan@danhon.com>
Subject: Episode Seventy Eight: The Pre-Post-Scarcity Economy; Cities
Date: May 12, 2014 at 3:17:29 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fhod=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident
The service was yesterday. In the end, I did a short speech, one I adapted from something I had written last Thursday. I have to admit, I don't remember much of the day, now. Whether that's because of how I was feeling or, to be honest, the preventative drugs that I'd taken in order to deal with the day, I'm not entirely sure. As upsetting as the day was, it was a reunion of sorts, and it was good to see family and catch up.

Things haven't stopped moving, though - there are items on lists, and there are still enough people in the farmhouse that it doesn't feel empty and it doesn't sound quiet. And, this being the midwest, the fridges are full of food that have been unceasingly brought round by friends and family. We've only just managed to finish off the meatballs. 

Thank you to everyone who sent a note. It means a lot, and I shared some of them with my wife. 

1.0 The Pre-Post-Scarcity Economy




I've been thinking more about airbnb, Uber, TaskRabbit and other exemplars of The Sharing Economy to figure out what I like about the concept, and what's troubling about it. In principle, there's nothing particularly *wrong* about the sharing economy - it's a more efficient utilisation of resource, so what's not to like? Marc Andreessen retweeted Patrick Collisson's tweet about John McHale on the sharing economy from a 1972 text[1], of which I'll quote a little bit:

"World society need no longer be based on the economics of scarcity. There is a revolutionary shift to a society in which the only unique and irreplaceable element is man. This is one of the main points about automation. In previous periods, objects, products, resources, etc. tended to have more importance in sustaining the societal group than individual man. Man was, in a sense, used most prodigally in order that the idea of man might survive. The material object was unique. Man was expendable. Now, through developed industrialization the object may be produced prodigally. The product is expendable--only man is unique... ...Use value is now largely replacing ownership value. We note this, for example, in the growth of rental and service - not only in automobiles and houses, but in a range from skis to bridal gowns - to "heirloom" silver, castles and works of art."

I'll tackle TaskRabbit, not least because when I tweeted the other day the contents of their Mother's Day marketing email[2], it sparked a conversation amongst friends about what felt unsavoury about TaskRabbit and what didn't. On the one hand, you have what I'll admit to be the undeniable benefit that, in some cases a TaskRabbit "job" can and will be better than an equivalent less-than-minimum-wage service job, and also potentially more interesting. In my case, I'm pretty sure that my unease around TaskRabbit speaks more to its future potential than its current reality: that is, it represents the virtualization of human labour. 

I'm not entirely sure, you see, that TaskRabbit preserves what McHale would call the uniqueness of man precisely because it offers a means to automate access to man, or labour. Of course, whilst typing that, there is of course no difference in practice of history other than scale: one has for a long time been able to persuade another to do a job, or perform a task, in exchange for money. And there have long been agencies in the middle - how is TaskRabbit different than a more-efficient Manpower or a Randstad, for example?

This is going to make me sound like a crotchety old bastard, and I'm cognisant of that - but the reality of a TaskRabbit in a late-capitalism, pre-post-scarcity, non-utopian society is that it feels like it's easy to take advantage of people. That is: the *framework* of TaskRabbit seems like it would be fine in the world of Star Trek, or any post-scarcity economy (cf the Ken McLeod Star Fraction universe where you go round volunteering to do things and helping out because you feel like it), but in *this* world, where's there's gross inequity in terms of labour, or at least potential for exploitation, TaskRabbit feels icky to me. Because for every unique man for whom a TaskRabbit job is posted, there will be (or may be) another who is 

The thing about sharing economy services that we have at the moment is that, as a species, we decidedly do *not* live in a post-scarcity economy. I mean, some of us might. But the vast majority - and I realise I'm being inflammatory here - say, around 99% - don't live in a post-scarcity economy.  

A post-scarcity economy works when both sides of the economy are post-scarcity. I do believe that you can segment Airbnb hosts (and include in that bucket, say, VRBO hosts) who are operating at the capital-begets-capital end of the market, but that at the other end you're operating at the "lost some hours at the zero-hours contract job and need some extra cash to get by". For me, providing a way for the people who "need some extra cash to get by" and *simultaneously* saying "hey, this is the utopian post-scarcity economy - isn't it awesome how the internet is helping us pretend we live in the Federation" is a little bit rich. Leave a message, and call me back when the "need some extra cash to get by" hosts have a guaranteed basic income, for example. Or, as someone commented on Twitter, when the 3D printers have finished providing sanitation for all seven billion of us.

This is a side point that I believe needs to be teased out when we talk about the sharing economy. The fact of the matter is is that we're in a *pre-scarcity economy*, and that post-scarcity, when it happens, will feel like one of those technologically driven phase-changes: the kind of simultaneously fast/slow infrastructural change in society where we went from no-one having a mobile phone to, well, nearly everyone - even at the bottom of the pyramid - in an astonishingly small period of time. But what we have right now feels like teetering on the edge of a chaotic transition.

I say all of this as someone who simultaneously enjoys and appreciates the experience of both Uber *and* good public transport. Who enjoys and appreciates the experience of good hotels and good Airbnb finds. 

I think this is what I mean when I say some of what the sharing economy is doing right now feels distasteful to me. It's as if people have worked out that you could sort of provide programmatic access to people who are being squeezed. In the case of Airbnb, it's underutilised infrastructure in the form of housing that could be repurposed. Those who are best poised to take advantage of this are those who have the capital to invest to provide more services - instead of buy-to-let, it's buy-to-flexible-let. 

But in the case of TaskRabbit, the underutilised infrastructure is... us. Now, if I pull out my dusty history knowledge, around the same time as the industrial revolution in England, piecework in the form of garment work became an emancipating form of labour for women: something that could be done at home, easily, by lower-skilled and lower-paid workers and opened up a new avenue for earning where practically none existed before. Now, we have piecework in terms of stay-at-home working like teleworking. Or, I don't know - has anyone done a good survey on stay-at-home jobs (and by jobs, I mean employment conferring benefits?)

Perhaps part of what grates is a sort of cognitive dissonance in the way that TaskRabbit presents itself. You can post a task ("Outsource household errands and skilled tasks; rejoice as your to-do list disappears"), become a TaskRabbit ("Discover opportunities to make
money while helping out your neighbors") or "get quality candidates" ("Find candidates to staff your company's
long-term and short-term projects.")[3]. 

All of this is under the guise of "redefining what it means to be neighborly":

"From this experience, TaskRabbit, an online and mobile marketplace that connects neighbors to get things done, was born. Fully vetted, entrepreneurially-minded professionals contribute their time and skills to help busy people find extra time in their days to do the things they love. Neighbors helping neighbors — it's an old school concept reimagined for today."[4]

For which: really? On your front page you're talking about corporate staffing solutions. And perhaps this is a particularly American, entrepreneurial concept of "neighborly" - well, I guess it must, as it's missing the required vowel. After all, what's there to argue about when you get to a) help neighbors, and b) make a little extra money? Being a TaskRabbit, TaskRabbit reminds us, is not a job - it's "neighbors helping neighbors". 

One of the thoughts that niggles at the back of my mind, though, is why a company like Etsy doesn't instinctively get lumped in to receive the same ire (at least, some ire), that companies like Uber and TaskRabbit do. Part of it, I think, is in terms of positioning: Etsy doesn't once, I don't think, talk about "making a little bit of extra money", instead concentrating on "buy[ing] from creative people who care about quality and craftsmanship." And sure, we've all seen regretsy, but at least Etsy is up front and honest about the whole endeavour: you're making stuff and you want to sell it. It doesn't matter whether you have a job. It doesn't matter that you're helping out a neighbour. It's simply that you like making things and Etsy are providing a storefront for you. Sure, there's a bit of twee-ness in Etsy's copy[5], but at least it feels like they mean it. I would much prefer genuine twee than fake twee, no?

That's not the same as Uber and TaskRabbit, where essentially the latter is an auction where workers bid, or Uber, where customers are literally hailing down orders. With Etsy, it's seller led, not buyer-led. And perhaps that points to a difference in outlook and emphasis. What would an Etsy-style TaskRabbit look like? 


[1] https://twitter.com/patrickc/status/465545034725466112 and http://goo.gl/h4LIs8
[2] http://newsletter.danhon.com/episode-seventy-five-the-sustainable-web-taskrabbit-airbnb-cities/
[3] https://www.taskrabbit.com
[4] https://www.taskrabbit.com/about
[5] http://www.etsy.com/about?ref=ft_about

2.0 Cities

I got a whole bunch of notes back regarding my thoughts about cities, Britain's missing second city and the concept of a "minimum viable city". I realise all of this is armchair urban planning wank, but at least I get to say that this isn't my job and that I'm not supposed to be qualified in any of this. That's the prerogative of the amateur newsletter raconteur. 

There was an interesting write-up that came my way of a talk from Theorizing The Web - "An Urban Geography of the Web Industry"[1]. At the same time as pointing to it, I think it's pretty easy to take it with a grain of salt and to realise that it's pretty hard to generalise - it's pretty much talking about the Bay Area, I think, because nowhere else in the world do you have that type of concentration in such a unique situation. 

It's a compelling point: the web, thanks to Moore's law's application in computing and communication infrastructure has allowed businesses to scale non-linearly. In that, in the industrial era, and even the early information-worker era, you generally needed More People to do More Things, and the People and Things scaled pretty linearly. See: Detroit. Even with robots. With pure bits and bytes companies *and* the fact that we've passed a threshold in terms of "enough" people being online for there to be a genuine mass consumer market (see: 1 billion served), you get companies like Facebook that *could* serve a billion people and employ not even ten thousand people, of which the majority are new recruits over the past eighteen months. You can see (although, as always, you'd be wise to ask for the data that backs it up) that such a change in the nature of industry and the makeup of employment, does something to a city in terms of its makeup. 

What *is* interesting, though, is whether we'll start to see counter-examples. I'm always reluctant to bring my employer into the mix, but here's the quick background. Wieden+Kennedy is an independent advertising agency, one of the award winningest in the world. It is headquartered not on Madison Avenue, New York, but in Portland, Oregon. Why Portland, Oregon? Because its founders didn't want to make the kind of advertising that Madison Avenue made, and reasoned that if they *weren't* on Madison Avenue then they wouldn't have to waste time weeding out the kind of people who wanted to be on Madison Avenue and make Madison Avenue kinds of advertising. Long story short, thirty years later, there's a bit of a boom in Portland and the agency headquarters office is an anchor of a revitalised downtown neighborhood that sheds off fledgling businesses every now and again, much in the same way that other companies like Nike or Intel do. 

Now, you'd think in the big wide world of the web you'd be arguing for decentralisation and if you're nodding along you're probably dhh and he's got a nice book he wants to sell you about his manifesto for how you should do business. Look: there are obviously stupendous network effects at play once you get into the Bay Area - they're completely undeniable. What's possibly *less* clear is that it is probably slightly more doable than it was before to have build a successful, sustainable company outside the Bay Area (see above for Etsy), but it certainly isn't easy. It never is, of course. But one benefit of not being in the Bay Area is that you're Not In The Bay Area. 

Against all of this is the simultaneous news from the New York Times (who, predictably, are on it) that residential rents are on the rise[2], of which: nngh. In conjunction with 1.0 above, part of this reminds me of the introduction of offset current/mortgage accounts and some sort of hazy memory of consumer bank products in the UK that swept money into a high interest account "while you slept". It's this squeeze-every-amount-possible in order to maintain a standard of living that starts to feel offensive. 

The conversation on Metafilter about the rent news is somewhat predictable: a derail in the first comment about moving to a less hip city that discounts what many on the ground are feeling in terms of actually needing to colocate in the same physical space: or - you have to be where the jobs are. And if you want a particular job, then you're going to have to move to that location. The UK's experiencing that problem with London, as I wrote about earlier, where London's turning into some sort of supermassive black hole that is literally sucking the economic growth from the rest of the country, whose event horizon is no longer delimited by the M25, and while there are pseudo micro-hubs in the US (see: Austin's growth in the tech sector) it's plain to see that cities are where the action's at. News like this, of course, makes it sound like cities are being co-opted by capital-growing-capital that's pricing out the engine (ie young professionals) that are going to grow that capital in the first place. 

One of the oft-cited differences between London and the US cities is the extraordinary amount of control that has been devolved and centralised in the case of the UK's capital city, compared to, say, "the Bay Area". When you're talking about infrastructural level complexity of change and management, quite how you're supposed to manage that on a highly localised basis is unclear to me. In one way this points to the need for different types of governance models as cities scale and level up in terms of the problems that they encounter. I'm not exactly sure how this squares with the fiercely independent, pioneer spirit of America, never mind America's west coast.

[1] http://blog.rachelhyman.info/mapping-the-economy-onto-socio-urban-space
[2] http://www.nytimes.com/2014/04/15/business/more-renters-find-30-affordability-ratio-unattainable.html?_r=0 and Metafilter Thread at http://www.metafilter.com/139000/Its-only-supposed-to-be-30-of-your-income

--

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Eight: The Pre-Post-Scarcity Economy; Cities
Date: May 12, 2014 at 3:14:49 PM CDT
To: danhon <dan@danhon.com>


0.0 Station Ident
The service was yesterday. In the end, I did a short speech, one I adapted from something I had written last Thursday. I have to admit, I don't remember much of the day, now. Whether that's because of how I was feeling or, to be honest, the preventative drugs that I'd taken in order to deal with the day, I'm not entirely sure. As upsetting as the day was, it was a reunion of sorts, and it was good to see family and catch up.

Things haven't stopped moving, though - there are items on lists, and there are still enough people in the farmhouse that it doesn't feel empty and it doesn't sound quiet. And, this being the midwest, the fridges are full of food that have been unceasingly brought round by friends and family. We've only just managed to finish off the meatballs. 

Thank you to everyone who sent a note. It means a lot, and I shared some of them with my wife. 

1.0 The Pre-Post-Scarcity Economy




I've been thinking more about airbnb, Uber, TaskRabbit and other exemplars of The Sharing Economy to figure out what I like about the concept, and what's troubling about it. In principle, there's nothing particularly *wrong* about the sharing economy - it's a more efficient utilisation of resource, so what's not to like? Marc Andreessen retweeted Patrick Collisson's tweet about John McHale on the sharing economy from a 1972 text[1], of which I'll quote a little bit:

"World society need no longer be based on the economics of scarcity. There is a revolutionary shift to a society in which the only unique and irreplaceable element is man. This is one of the main points about automation. In previous periods, objects, products, resources, etc. tended to have more importance in sustaining the societal group than individual man. Man was, in a sense, used most prodigally in order that the idea of man might survive. The material object was unique. Man was expendable. Now, through developed industrialization the object may be produced prodigally. The product is expendable--only man is unique... ...Use value is now largely replacing ownership value. We note this, for example, in the growth of rental and service - not only in automobiles and houses, but in a range from skis to bridal gowns - to "heirloom" silver, castles and works of art."

I'll tackle TaskRabbit, not least because when I tweeted the other day the contents of their Mother's Day marketing email[2], it sparked a conversation amongst friends about what felt unsavoury about TaskRabbit and what didn't. On the one hand, you have what I'll admit to be the undeniable benefit that, in some cases a TaskRabbit "job" can and will be better than an equivalent less-than-minimum-wage service job, and also potentially more interesting. In my case, I'm pretty sure that my unease around TaskRabbit speaks more to its future potential than its current reality: that is, it represents the virtualization of human labour. 

I'm not entirely sure, you see, that TaskRabbit preserves what McHale would call the uniqueness of man precisely because it offers a means to automate access to man, or labour. Of course, whilst typing that, there is of course no difference in practice of history other than scale: one has for a long time been able to persuade another to do a job, or perform a task, in exchange for money. And there have long been agencies in the middle - how is TaskRabbit different than a more-efficient Manpower or a Randstad, for example?

This is going to make me sound like a crotchety old bastard, and I'm cognisant of that - but the reality of a TaskRabbit in a late-capitalism, pre-post-scarcity, non-utopian society is that it feels like it's easy to take advantage of people. That is: the *framework* of TaskRabbit seems like it would be fine in the world of Star Trek, or any post-scarcity economy (cf the Ken McLeod Star Fraction universe where you go round volunteering to do things and helping out because you feel like it), but in *this* world, where's there's gross inequity in terms of labour, or at least potential for exploitation, TaskRabbit feels icky to me. Because for every unique man for whom a TaskRabbit job is posted, there will be (or may be) another who is 

The thing about sharing economy services that we have at the moment is that, as a species, we decidedly do *not* live in a post-scarcity economy. I mean, some of us might. But the vast majority - and I realise I'm being inflammatory here - say, around 99% - don't live in a post-scarcity economy.  

A post-scarcity economy works when both sides of the economy are post-scarcity. I do believe that you can segment Airbnb hosts (and include in that bucket, say, VRBO hosts) who are operating at the capital-begets-capital end of the market, but that at the other end you're operating at the "lost some hours at the zero-hours contract job and need some extra cash to get by". For me, providing a way for the people who "need some extra cash to get by" and *simultaneously* saying "hey, this is the utopian post-scarcity economy - isn't it awesome how the internet is helping us pretend we live in the Federation" is a little bit rich. Leave a message, and call me back when the "need some extra cash to get by" hosts have a guaranteed basic income, for example. Or, as someone commented on Twitter, when the 3D printers have finished providing sanitation for all seven billion of us.

This is a side point that I believe needs to be teased out when we talk about the sharing economy. The fact of the matter is is that we're in a *pre-scarcity economy*, and that post-scarcity, when it happens, will feel like one of those technologically driven phase-changes: the kind of simultaneously fast/slow infrastructural change in society where we went from no-one having a mobile phone to, well, nearly everyone - even at the bottom of the pyramid - in an astonishingly small period of time. But what we have right now feels like teetering on the edge of a chaotic transition.

I say all of this as someone who simultaneously enjoys and appreciates the experience of both Uber *and* good public transport. Who enjoys and appreciates the experience of good hotels and good Airbnb finds. 

I think this is what I mean when I say some of what the sharing economy is doing right now feels distasteful to me. It's as if people have worked out that you could sort of provide programmatic access to people who are being squeezed. In the case of Airbnb, it's underutilised infrastructure in the form of housing that could be repurposed. Those who are best poised to take advantage of this are those who have the capital to invest to provide more services - instead of buy-to-let, it's buy-to-flexible-let. 

But in the case of TaskRabbit, the underutilised infrastructure is... us. Now, if I pull out my dusty history knowledge, around the same time as the industrial revolution in England, piecework in the form of garment work became an emancipating form of labour for women: something that could be done at home, easily, by lower-skilled and lower-paid workers and opened up a new avenue for earning where practically none existed before. Now, we have piecework in terms of stay-at-home working like teleworking. Or, I don't know - has anyone done a good survey on stay-at-home jobs (and by jobs, I mean employment conferring benefits?)

Perhaps part of what grates is a sort of cognitive dissonance in the way that TaskRabbit presents itself. You can post a task ("Outsource household errands and skilled tasks; rejoice as your to-do list disappears"), become a TaskRabbit ("Discover opportunities to make
money while helping out your neighbors") or "get quality candidates" ("Find candidates to staff your company's
long-term and short-term projects.")[3]. 

All of this is under the guise of "redefining what it means to be neighborly":

"From this experience, TaskRabbit, an online and mobile marketplace that connects neighbors to get things done, was born. Fully vetted, entrepreneurially-minded professionals contribute their time and skills to help busy people find extra time in their days to do the things they love. Neighbors helping neighbors — it's an old school concept reimagined for today."[4]

For which: really? On your front page you're talking about corporate staffing solutions. And perhaps this is a particularly American, entrepreneurial concept of "neighborly" - well, I guess it must, as it's missing the required vowel. After all, what's there to argue about when you get to a) help neighbors, and b) make a little extra money? Being a TaskRabbit, TaskRabbit reminds us, is not a job - it's "neighbors helping neighbors". 

One of the thoughts that niggles at the back of my mind, though, is why a company like Etsy doesn't instinctively get lumped in to receive the same ire (at least, some ire), that companies like Uber and TaskRabbit do. Part of it, I think, is in terms of positioning: Etsy doesn't once, I don't think, talk about "making a little bit of extra money", instead concentrating on "buy[ing] from creative people who care about quality and craftsmanship." And sure, we've all seen regretsy, but at least Etsy is up front and honest about the whole endeavour: you're making stuff and you want to sell it. It doesn't matter whether you have a job. It doesn't matter that you're helping out a neighbour. It's simply that you like making things and Etsy are providing a storefront for you. Sure, there's a bit of twee-ness in Etsy's copy[5], but at least it feels like they mean it. I would much prefer genuine twee than fake twee, no?

That's not the same as Uber and TaskRabbit, where essentially the latter is an auction where workers bid, or Uber, where customers are literally hailing down orders. With Etsy, it's seller led, not buyer-led. And perhaps that points to a difference in outlook and emphasis. What would an Etsy-style TaskRabbit look like? 


[1] https://twitter.com/patrickc/status/465545034725466112 and http://goo.gl/h4LIs8
[2] http://newsletter.danhon.com/episode-seventy-five-the-sustainable-web-taskrabbit-airbnb-cities/
[3] https://www.taskrabbit.com
[4] https://www.taskrabbit.com/about
[5] http://www.etsy.com/about?ref=ft_about

2.0 Cities

I got a whole bunch of notes back regarding my thoughts about cities, Britain's missing second city and the concept of a "minimum viable city". I realise all of this is armchair urban planning wank, but at least I get to say that this isn't my job and that I'm not supposed to be qualified in any of this. That's the prerogative of the amateur newsletter raconteur. 

There was an interesting write-up that came my way of a talk from Theorizing The Web - "An Urban Geography of the Web Industry"[1]. At the same time as pointing to it, I think it's pretty easy to take it with a grain of salt and to realise that it's pretty hard to generalise - it's pretty much talking about the Bay Area, I think, because nowhere else in the world do you have that type of concentration in such a unique situation. 

It's a compelling point: the web, thanks to Moore's law's application in computing and communication infrastructure has allowed businesses to scale non-linearly. In that, in the industrial era, and even the early information-worker era, you generally needed More People to do More Things, and the People and Things scaled pretty linearly. See: Detroit. Even with robots. With pure bits and bytes companies *and* the fact that we've passed a threshold in terms of "enough" people being online for there to be a genuine mass consumer market (see: 1 billion served), you get companies like Facebook that *could* serve a billion people and employ not even ten thousand people, of which the majority are new recruits over the past eighteen months. You can see (although, as always, you'd be wise to ask for the data that backs it up) that such a change in the nature of industry and the makeup of employment, does something to a city in terms of its makeup. 

What *is* interesting, though, is whether we'll start to see counter-examples. I'm always reluctant to bring my employer into the mix, but here's the quick background. Wieden+Kennedy is an independent advertising agency, one of the award winningest in the world. It is headquartered not on Madison Avenue, New York, but in Portland, Oregon. Why Portland, Oregon? Because its founders didn't want to make the kind of advertising that Madison Avenue made, and reasoned that if they *weren't* on Madison Avenue then they wouldn't have to waste time weeding out the kind of people who wanted to be on Madison Avenue and make Madison Avenue kinds of advertising. Long story short, thirty years later, there's a bit of a boom in Portland and the agency headquarters office is an anchor of a revitalised downtown neighborhood that sheds off fledgling businesses every now and again, much in the same way that other companies like Nike or Intel do. 

Now, you'd think in the big wide world of the web you'd be arguing for decentralisation and if you're nodding along you're probably dhh and he's got a nice book he wants to sell you about his manifesto for how you should do business. Look: there are obviously stupendous network effects at play once you get into the Bay Area - they're completely undeniable. What's possibly *less* clear is that it is probably slightly more doable than it was before to have build a successful, sustainable company outside the Bay Area (see above for Etsy), but it certainly isn't easy. It never is, of course. But one benefit of not being in the Bay Area is that you're Not In The Bay Area. 

Against all of this is the simultaneous news from the New York Times (who, predictably, are on it) that residential rents are on the rise[2], of which: nngh. In conjunction with 1.0 above, part of this reminds me of the introduction of offset current/mortgage accounts and some sort of hazy memory of consumer bank products in the UK that swept money into a high interest account "while you slept". It's this squeeze-every-amount-possible in order to maintain a standard of living that starts to feel offensive. 

The conversation on Metafilter about the rent news is somewhat predictable: a derail in the first comment about moving to a less hip city that discounts what many on the ground are feeling in terms of actually needing to colocate in the same physical space: or - you have to be where the jobs are. And if you want a particular job, then you're going to have to move to that location. The UK's experiencing that problem with London, as I wrote about earlier, where London's turning into some sort of supermassive black hole that is literally sucking the economic growth from the rest of the country, whose event horizon is no longer delimited by the M25, and while there are pseudo micro-hubs in the US (see: Austin's growth in the tech sector) it's plain to see that cities are where the action's at. News like this, of course, makes it sound like cities are being co-opted by capital-growing-capital that's pricing out the engine (ie young professionals) that are going to grow that capital in the first place. 

One of the oft-cited differences between London and the US cities is the extraordinary amount of control that has been devolved and centralised in the case of the UK's capital city, compared to, say, "the Bay Area". When you're talking about infrastructural level complexity of change and management, quite how you're supposed to manage that on a highly localised basis is unclear to me. In one way this points to the need for different types of governance models as cities scale and level up in terms of the problems that they encounter. I'm not exactly sure how this squares with the fiercely independent, pioneer spirit of America, never mind America's west coast.

[1] http://blog.rachelhyman.info/mapping-the-economy-onto-socio-urban-space
[2] http://www.nytimes.com/2014/04/15/business/more-renters-find-30-affordability-ratio-unattainable.html?_r=0 and Metafilter Thread at http://www.metafilter.com/139000/Its-only-supposed-to-be-30-of-your-income

--

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Seven: But It Keeps Going
Date: May 9, 2014 at 4:33:09 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fgap=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


1.0 But It Keeps Going
The service is tomorrow.
I haven't done this before, really, and I suppose this time round, I'm old enough to really understand what's going on. 
It's not that I haven't been to funerals before. The first that I remember was for the father of a close family, and sticks in my mind not only because the deceased was the father of childhood friends, but because it was the first time I remember seeing my father cry. 
And then there were the funerals of my paternal grandparents - who had come over to live with us in England around when I was 16, and for whom alzheimer's had already taken its toll, and with whom I couldn't really communicate. But then, as the alzheimer's got worse, we both had the Cantonese vocabulary of a five year old. Which was painful in and of itself, never mind the repeated introduction to and explanation of my wife.
But, the service is tomorrow. And family and friends are coming in. And there's not really any time to be sad - only in the down times, I guess - because there's too much to be done. There's a four week old granddaughter here, and a fifteen month old grandson here. There's sleeping arrangements to be made, decisions about music and readings and timings and making sure that everyone eats, plus the phone keeps going off every few minutes. 
And then, you take a minute to slow down and you look at the list of things you have to do, and you look through a photo library and that person you're looking at isn't coming back. And Aperture says: is this Sonia Ray? And you say: no, that's obviously not Sonia how could you be so insensitive, I just want to find some photos of her from before she had to wear that stupid wig.
Or you find photos of her from when she was helping her daughter get ready for her wedding, and it was so long ago now, and everything was so different and so completely unlike today.
But, the service is tomorrow. And just by looking through the photos - the ones we don't have digitised sitting on a hard drive or a web server somewhere, I guess we're learning so much more about family and remembering so much. It's just sad that it has to take this. 
Thank you, all, for the notes that you've sent. I know hardly any of you, and you hardly know me. But hey, apparently the internet is dehumanising. Apparently it stops us from connecting. Apparently it just gets in the way of regular empathy and feeling for someone, to which I say: bollocks to that, too. I read each and every one of your notes and showed some to my wife and I can't thank you enough. 
I knew this day would be coming. I talked to my therapist about it, weeks ago. I was terrified, for whatever stupid reason, that something would happen that would break my habit of writing, and that once I had that broken habit, I'd feel terrible about myself and another cycle of depression would kick in, right as I was needing it the least. Not that you ever need depression. But, I can still write. For now. I don't know if I'll be able to on Monday. But even if I don't on Monday, I think I'm OK with that. I hope I am. I know one of the things I need to do for myself, if I'm ever to completely (or more thoroughly) escape my depression is to be kinder to myself, and to lose this all-or-nothing attitude.
But meantime, there are things that need to be done. More photos to be collected. A playlist. Shirts to be ironed. Calvin's clothes for tomorrow - his smartest outfit yet, for his saddest day yet. Probably more errands to run. So.
Right now, I don't really care about what Apple's plans are for Beats music. Or that they might be wasting about three billion dollars. Or how big an iPhone might be or whether Oculus is building the Metaverse or if Xbox is losing to PlayStation.
I don't care.




Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Five: The Sustainable Web; TaskRabbit; Airbnb; Cities
Date: May 7, 2014 at 1:13:45 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fesd=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

I'm back in Portland, but I don't know how long for. But it's 70 and sunny (yes, I've gone native in fahrenheit, but I maintain: fahrenheit for hotness, celsius for coldness). 

1.0 The Sustainable Web



So Andy Baio had a nice surprise for us all today when he announced the return of event discovery service/website upcoming.org[1] with corresponding Kickstarter (which Kickstarter is, of course, already doing very well but could always do with your backing[2]. If sir may make a recommendation, sir would suggest the $75 or higher reward level, if only because sir thinks the t-shirt would look mighty fine on you).

There's a number of things to unpack here. First is Andy taking back this shitty corporatese of "sunsetting" things, and fuck-yes-sunrise. 

But the other starts with an admission that I hadn't been paying that much attention to the indie web[3] movement. Not because it's not important - it is - but because until recently there's been something about it that has been hard for me to get behind, and I can legitimately say that "some of my best friends are part of the indie web movement". I get bringing control of user data back to the user. In fact, just typing that makes me want to put on a TRON costume and shout from a rooftop: "HE FIGHTS FOR THE USER!" But I digress. I get decentralisation and what it buys us in this post-Snowden age of the accidental panopticon that we built with the the best, opposite intentions.

On top of that, you add the not-closure-but-probably of app.net[4] that again started with, well, not exactly the *best* of intentions, and probably misguided ones, and in the same case of Diaspora[5], a kind of misunderstanding of what you need if you're building a social network versus a social platform and what the former requires to be viable in the face of competition (lots of people) versus what the latter provides (a place). 

So my thing is this: not an indie web, but a sustainable one. One that is kind of adjacent to the indie web, but that builds long-lasting, reliable services, not ones that disappear. This adjacency comes from the answers to the question of: what kind of attributes are required for a sustainable web? Do you need easily exportable data? Sure. Do you need some element of user control? Sure. Are those the *defining* characteristics? Not really. But I think we might be verging on a sort of turning point where applications and services can, at the outset, say: "you know what, here's our plan for being around for a while so you can *trust* us and invest time in us". 

That sustainability may prevent the sort of occurrence where you have Moves being acquired by Facebook[6] and their subsequent perceived about-turn in terms of "comingling" of data with their new parent company. 

But anyway. A thought. The sustainable web. What would that look like? A middle web - not the grow fast and explode model of VC, and not necessarily the super-slow model of revenue funded. Or, actually, the super-slow model of revenue funded. But a web where we build for the long-term, and perhaps pulling back from explosive, burn bright and short products and services.

[1] http://upcoming.org
[2] https://www.kickstarter.com/projects/waxpancake/the-return-of-upcomingorg
[3] http://indiewebcamp.com
[4] http://blog.app.net/2014/05/06/app-net-state-of-the-union/
[5] https://joindiaspora.com
[6] http://www.moves-app.com/press

2.0 TaskRabbit

Okay, at this point I'm not entirely sure if TaskRabbit know what they're doing, or if they do know what they're doing, it's just because, as someone pointed out on Twitter, I'm British and naturally sensitive to such things. But I got a marketing email from TaskRabbit this morning[1] that read:

"What do working moms want for Mother’s Day? Not chocolate or flowers, but more time in the day. TaskRabbit can help with the tasks that pile up, tackling your mounting pile of laundry or dishes, cleaning up, running errands. Moms recently told the Today show: “The constant juggle to get everything done each day can be overwhelming, leaving me feeling like there just isn’t enough time in the day to enjoy being a mom.” This Mother’s Day, give a mom more time to enjoy being a mom."

For which my instant reaction is:

a) you've got to be kidding me;
b) seriously, I should be the one doing those things on Mother's Day, not a Task Rabbit - if I can;
c) this is just funny now

Of course, there's a bit a little further down in the marketing email where they highlight some of their favourite tasks of the week, of which one is "Write a poem for my mother"[2], of which, has anyone seen Her, lately?

The back-and-forth amongst Twitter was of a Euro/NorthAm divide where (and you can guess where I lie) the atomisation of humans into units of work and money that are exchangeable feels a little bit, well, dehumanising and insensitive. Hands up who reckons Piketty is a TaskRabbit supporter?

Counter-example, though: someone on Twitter mentioned that they'd used Fiverr to get someone to sing Happy Birthday in his underpants, in Welsh, to their mom, and that was the best $5 they'd ever spent. So you can obviously use this sort of stuff in a, well, more humane way. 

As an aside, it'd totally be possible to do a sort of TaskRabbit Emancipation Day where we all pay TaskRabbits to take the day off. Or a Love Your TaskRabbit Day, if you want to be more branded. But down that road lies the thought that someone might think that TaskRabbit, with its tasks and resource/work-allocation bidding system, might turn out to be a more "efficient" way for government to allocate welfare. 

[1] https://www.flickr.com/photos/danhon/14131798235/
[2] https://www.taskrabbit.com/san-francisco-ca/t/write-a-poem-for-my-mother

3.0 Airbnb

And again, seeing people talk about Airbnb frustrations in terms of last-minute cancellations by hosts, it still strikes me that on the few occasions that I *have* used Airbnb, it still feels like a service that is in favour of hosts making money as opposed to good experiences for guests. When it comes down to it, it feels like the value proposition for an Airbnb customer (ie not a host) is cheap housing. But the tradeoff for that is time - and we can always externalise certain costs onto a consumer. So instead of booking directly with a hotel and knowing instantly whether I can get a room or not, I have to invest time in applying to multiple hosts, waiting for feedback, and then - hopefully - getting somewhere to stay. At some point along that continuum of time investment, a switch is flipped and it makes more sense to just book a hotel. Especially when hotels are designed are uniformity of experience and, hopefully, predictability. 

Airbnb is interesting because it's definitely a get-rich, entrepreneurial service on the host side - otherwise I wouldn't be seeing "hack your way to retirement with Airbnb" style articles on HackerNews about how to find the cheapest properties to buy in the US that provide the best Airbnb return, or that I consistently hear stories from guests like being told "if anyone asks, just say you're a relative" or "please avoid the concierge for the building". Sure, that points to friction in the regulatory environment and Airbnb's taking advantage of that. But, hey, there'll be a reckoning. As it were.

4.0 Cities

My oh my I received so many notes about my posts about Cities. They're percolating. In a good way. Hopefully more on cities tomorrow.

--

That's Wednesday!

Send notes! I love the whooshing noise they make as they land in my inbox and glare at me balefully. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Seventy Four: Cities; Disruptive; Still Brittle
Date: May 6, 2014 at 1:21:04 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fe4d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm back down at Menlo Park today, with a 4am wakeup call, a 6am flight and a long day ahead of me. So it's a good job this couch is comfy. 
1.0 Cities
For starters, if I'm going to write about cities and urban planning, then it looks like I really need to read the seminal work on the subject, Jane Jacobs' The Death and Life of Great American Cities[1], and at the very least trawl through Dan Hill's published work because there are a bunch of people who actually have spent time thinking about these sorts of things, rather than my decidedly armchair/dining-table opinions.
One point that bubbled up was that if you take Zipf's law[2] as a benchmark, then the UK is "missing" a city in that London's effect genuinely is disproportionate and distorting. Another way of looking at London's influence, especially if you're not from the UK, is by looking at the various hubs that London serves. For example, a London-equivalent in America would be some sort of freakish combination of New York, Washington, DC, Los Angeles, Boston and bits of San Francisco. Because in London, you have an entire country's media, legal, financial, art, software and academic scenes[3]. And the UK being the size it is, the two historic academic centres of the country in Oxford and Cambridge (sorry, should've checked my privilege there) are only about 45 minutes away.  
To paraphrase Adams again, the thing about London and the UK is that you just won't understand how *big* the former is, and how *small* the latter is. It's not entirely for humour that Californian residents joke that the UK fits *inside* their state.  
And of course, all of this is reckoning, but: when or where is the tipping point in terms of commuter towns being subsumed inside what would otherwise be called Greater London? Commuter trains from places like Cambridge and Brighton to London are already packed and if you work in the right location: ie - near one of the rail termini, then your commute is potentially less time than if you lived inside one of London's transport zones itself.  
It's interesting to think of what sort of carrying capacity you need to support a genuine commuter city. It's not like there are many Western cities building high capacity mass transport (if there are, please let me know, because I'm super interested), and again it feels like London is the outlier here. There isn't the housing stock inside the central nugget of London in part because (and I really am reckoning here) of the lack of limitations on non-resident property ownership and London's real estate occupying rather unique status in the world financial market as a place to park your capital. So individuals and families move further and further out, and then... what? They keep working in London, more or less, because we've already established that that's where the jobs are, once you hit a certain level. But when it's untenable to live there, to spend a significant amount of time there, then what? The point about London is that as well as being a business strange attractor it's also a cultural one: and that once you price people out of an entire city, and the only reason they're going back is for the business - what's replacing out the hollowed out cultural centre? Do you just end up with pseudo lowest-common-denominators like the Tates, the Natural History and Science Museums, the National Galleries? Where's all the stuff at the fringe that serves as provocation? 
I feel like at some point there's a magic travel time and, arbitrarily, I'm going to say it's around 45 minutes to an hour. If I lived outside London, I'd be happy with a door-to-door travel time of up to an hour. Which doesn't seem entirely unreasonable until you factor in having to build high-speed mass transit in an environment where you can't just compulsory-purchase-order all the land you need for your no-curvy-bits-in-it point-to-point rail network, because you've got things like pesky voters who have nothing better to do than stay at home and complain about things because they didn't really want to go to London in the first place. 
Of course, if we actually get matter transportation, then all this goes out the window. I wonder what the long hedge against that sort of transportation is. 
[1] Jane Jacobs' The Death and Life of Great American Cities:
Amazon: http://amzn.to/1iZ4e0x
Powell's: http://www.powells.com/biblio/9780679741954
[2] Zipf's law: http://en.wikipedia.org/wiki/Zipf's_law, http://www.bbc.com/news/business-26472423 and http://spatial-economics.blogspot.co.uk/2012/10/are-britains-second-tier-cities-too.html 
[3] Paul Mison, on Twitter
2.0 Disruptive
So there's this New York Times article[1] that's been doing the rounds, the gist of which is that America's poor can be awash in literal material abundance but simultaneously living paycheck to paycheck and unable to claw themselves out of poverty. Most striking of all is a graph implying that costs have soared or risen for items like college education, child care, vehicle maintenance and repair and food and beverages and plummeted for "televisions, toys and phones". While housing, personal care and new/used vehicle services have shown declines of up to 40% in cost over the last ten years, the starkest change, unsurprisingly for those in the tech sector, is in "toys, phones and accessories, personal computers and equipment and television" which range from a 60 to 100% price drop over the last ten years, as well as reflecting an increase in quality. 
This is part of what I mean in terms of my critique of the Californian Ideology. Moore's law has been great at disrupting the pointy, top-end of Maslow's pyramid, but we know that those are all at the self-actualizing end. You can come to me and you can say that tech has been *truly* disruptive when it's delivered - not just promised - a 100% reduction in costs for college-equivalent education (some might say that it's started nibbling at this already), or child care, or healthcare, or the other buckets of vehicle and maintenance/repair and food and beverages. 
And don't give me that crap about services like Uber or Airbnb, because at this point they feel essentially like on-demand dehumanising services *if* one of the benefits as cited is that they are a side-method of earning income for the poor, or an alternative to employment. 
I don't know what the answer is. But I'm pretty sure it doesn't involve someone like Bobby Bingham picking up a side-Uber job and another loan for a towncar that he can use to ply his fourth part-time job:
"Bobby Bingham, 38, of Kansas City, Mo., works three part-time jobs seven days a week to make ends meet, but struggles to cover basic living expenses: his apartment, his car, his car insurance, gas and utilities. He is also heavily in debt, owing $30,000 in student loans and about $12,000 in credit-card debt with an annual interest rate of 17 percent."[1]
You want to find a way to use capitalism to drive up the standard of living of everyone, not just the middle class? Find a way to reduce the cost of childcare. If having women working in developing countries is a goal to help them advance out of poverty, then it should be here, too. But no: broadly, America wants women to not have access to contraception, it has unaffordable childcare, and it also wants women to work. Or not work. 
It's a mess. Disrupt that.
[1] http://www.nytimes.com/2014/05/01/business/economy/changed-life-of-the-poor-squeak-by-and-buy-a-lot.html?_r=0
3.0 Still Brittle
Okay, so I'm still thinking about the point yesterday on product recalls and what you need to be able to have a resilient, healthy infrastructure. Dan Hill wrote another typically smart essay in dezeen about physically connected, but functionally disconnected infrastruture[1] in the context of the morass of services that keep a city going, a tangled circulatory system that we don't even have a full picture of. Sure, a city's a few orders of magnitude more complicated than a human body (wait: is it, really? Or is it just that much harder to find a dead - or living - city to dissect. I'd buy that theory). In fact, now my head's spinning a bit and if you'll forgive me I kind of want to pursue this tangent. (If I had a Snow Crash Librarian, I'd totally be asking her to remember this fork for us to come back to).
So. We have fantastically complex and detailed tools to image the human body, which contains inside it some of the most intricate and finely designed systems that we've ever seen. What are the equivalent imaging tools for cities? They are, on another level, some of the most intricate and finely designed systems that we've ever seen, too. And, just like the way bodies have accreted various solutions for doing things thanks to evolution, our cities have accreted infrastructure that we don't quite know about, might not even know how they work, whilst at the same time, clamping on exo-suits to them, Google-Glass style in the form of smart nodes like Nests and CCTV systems here and there. So what's the MRI/fMRI for a city? What's an ultrasound for a city? What are diagnostic tests that can be performed? When you take a 24 hour ECG, what's the equivalent of that for a city? All of this instrumentation and visibility, and I'm genuinely interested in what the invasive and non-invasive diagnostic measures are that we have for looking at the "health" of a city.
There's something in an agglomeration of Nests being like a sort of proprioceptive sense for a city. That it's able to start self-regulate or at least measure itself. That's the interesting thing: when an organism or a construct has knowledge of its placement in both space and time. Basically: Gray's Anatomy[2] for cities, please.
Anyway. I actually meant to talk about the internet and all the stuff that's connected to it. That for the moment we have things like a World Health Organisation that's concerned with doing things like wiping out polio. I'm not sure what the equivalent is for, er, telecoms infrastructure. The ITU? Is there, or should there be, a public safety campaign for "What To Do When Your Home Network Is Suborned?" 
Because, of course, the thing about Polio is that while we may be on the verge of being able to deal with it, we're simultaneously dealing with pushback from groups who believe vaccines are a western plot to sterilize their children and increased interconnectivity due to international travel[3].
I guess the other way to think about it is this: bacteria and viruses exist in our world, we develop defenses against them. That doesn't mean we're never susceptible. And the environment changes, too. There's something, though, in knowing that there are (millions? tens of millions?) of devices out there that have weaknesses and that they're so stupendously dumb. 
[1] http://www.dezeen.com/2014/05/01/dan-hill-opinion-nest-thermostat-innovation-city-services/
[2] http://en.wikipedia.org/wiki/Gray's_Anatomy
[3] John Dodds
-- 
Okay! Notes please!
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Three: Recall; ATMs;
Date: May 6, 2014 at 12:34:41 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fdq5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Today was nominally a day out of office - my wife and son are back, briefly, from their trip to the family farm out in Missouri. Whilst things don't look appreciably better out there, it felt like a good time to give them a bit of a break. So while I returned from a week away working out of Menlo Park/San Francisco on Friday night, they returned from Missouri on Saturday night and Sunday morning, my mum came in from England for three weeks. So it's a full family house, albeit one that's strained due to events in the Show-Me State. I'm back out to Menlo Park tomorrow, so today was a no-brainer - an extra day to make sure that I had at least two days to remember what my wife and son look like before jetting off again. Which is why today's episode is being written late - past 10pm on the West Coast.
1.0 Recall
One of the things we did today with three generations in tow was to head out to the Vancouver Community Library[1], of which before I say any more:
a) what the hell is going on with that URL;
b) why is a community government service hanging off a sirsi.net URL;
c) one of the reasons why Google Maps is so horrendously bad is that when you search for "Vancouver Community Library", it doesn't actually return to you a Vancouver Community Library, and instead, you have teeny tiny tap targets as red dots all over the map and you have *no idea what they are*
Anyway. We went for Storytime, which was good - grandmother had a fun old time encountering American nursery rhymes, for starters, and then we went over to the Childrens' Play Area for 0-7s, of which a) it was better than the inappropriately named Portland Childrens' Museum (because that museum is not a museum, but also likes to make a point of it not behaving like a museum) and b) it was free. 
Libraries are pretty awesome these days. Anyway, again: this time two weird future-y things happened.
The first was that a whole bunch of parental smartphones went off, roughly at the same time, because an AMBER ALERT had been triggered. This was not entirely unlike that scene in The Siege where a bunch of journalists are gathered at a press conference in a theater and suddenly all of their phones start ringing because the school where all their children are at has just been fingered with a bomb threat. 
The second was that there was a binder full of consumer safety product recall notices[2], and that it told you where you could continue to get recall information:
a) they told you to visit a URL (even though the URL was a dumb one and not googlejuiceable);
b) or get the recall notices via email;
c) or through - get this - "an RSS feed reader";
d) "The Droid Recall App"
e) "Twitter: U.S. CSPC @OnSafety"
For one, it's been ages since I've seen a reference to RSS out in the wild. For two, the hierarchy of the options seems a bit interesting. But really, it's because "OMG RSS" was one of my reactions. 
Okay, so here's a bunch of reckons based around the idea of Recalls:
- internet connected objects *ought* to be better at this, but hey, they're not
- isn't it interesting who you got a Heartbleed disclosure email from and who you *didn't* get a Heartbleed disclosure email from. Did anyone get one from their banks? No? Utility providers? No? Maybe just random internet service startups like IFTTT? Interesting, huh? 
And then a whole bunch of thoughts around: you know, if we wanted to, we could get rid of (and are getting rid of) Polio. But that's because there's a whole bunch of Polio/disease infrastructure that's evolved. There's a standard delivery mechanism for "vaccines" in general, and we know how to make lots of them. In some ways, it's *just* the infrastructure that's implicated in not spreading the vaccine further - things like needing to keep vaccines refrigerated, for example. 
So here's a question: if we wanted to get rid of Heartbleed, like the way we get rid of Polio, could we? What sort of infrastructure would we need? At what point do we say: hey, you know what, being able to run arbitrary code on a general purpose computing device is cool and all, but at some point maybe we do want auto-updating mechanisms that help devices mitigate against zero-day attacks. And thus: Windows Automatic Update, OS X and iOS over-the-air updates and so on. But then, of course, that requires us to think, as a culture, or population, or whatever, about what it is that we "own" when we have devices that are merely endpoints for networked services. You don't own a thing, anymore. In fact, for that thing to be safe (and thus all the other things), you have to kind of not-own-it. You have to let some sort of service be able to reach in and make it more safe. 
[1] http://fvrl.ent.sirsi.net/client/en_US/default/?rm=VANCOUVER0%7C%7C%7C1%7C%7C%7C2%7C%7C%7Ctrue&dt=list
[2] http://instagram.com/p/nn_M5vNQ73/
2.0 ATMs
I was out at dinner tonight and there was one of those - if you're British, anyway - skeezy kind of non-bank-affiliated ATMs, the ones that look like tiny upright thin droids that you swipe your card into and cross your fingers and hope that you just haven't been cloned. This one was interesting if only because it was old and thus the user interface metaphor that it employed for "we're processing your transaction"[1] was a sort of Windows 95-era pixel-art files being copied between two folders. Which is, er, not entirely untrue and at the same time really really frightening when you think about the sort of infrastructure that the banking system is run on.
Protip: don't think about the infrastructure that the (Western) banking system is run on, because that way lies madness and the need to want to take off, nuke the various financial centers from orbit, and start again with something relatively sane. 
Anyway: if you weren't already worried enough about ATMs running deprecated, unsupported operating systems and just hanging around out there in the wild, then spare a thought for the user interfaces on them, too. 
[1] http://instagram.com/p/npEos-NQwS/
3.0 Cities
So I'm predictably and probably somewhat annoyingly first-world in that I have a bunch of (mainly Western) friends who live in lots of big cities, and they're lucky because they kind of get to decide what city to live in. 
It turns out, and it feels, that London and San Francisco are increasingly getting the raw end of the deal. London because, realistically, no one can afford to buy property there anymore thanks to, amongst others, awesome rules like allowing non-residents to purchase property, and San Francisco, because apparently San Francisco doesn't like building things. 
New York is an interesting case, though, because although Manhattan real estate may be priced high, perhaps forever so, the thing that it and San Francisco have going for them *in terms of young people wanting to live there and have jobs and stuff* is rent control. Because whilst it might be somewhat impossible for the "average young person" to buy property in any of those cities any time soon without coming into a rather unreasonable amount of cold hard cash, one thing that people can still roughly do in New York, is find an affordable place to rent. It might be tiny, but it's affordable. 
Potentially less-so London and San Francisco. And this is the bit where London feels a bit weird, because *without* rent control, what's inevitably going to happen is that people are pushed further and further outside the interesting zone-1 bit, not just because they can't afford to buy a place there, but because the rents are pretty much crazy too. 
And that's without thinking about the super crazy thing which is: at what point will the UK just kind of not necessarily give up, but recognise the fact that having a city like London in a state like the UK is *mental*. London isn't just an overpowering city, it's *the* city. Sure, you can point to regional hubs like Birmingham and Manchester and whatever, but at some point, London's pull and influence on the rest of the country is going to approach some sort of calculus where it's increasingly impossible to justify spending outside of the capital. Because, really, if they actually build any of the High Speed lines, most of the cities outside London just end up being London's commuter belt, because hey: Londoners don't actually own the property in London. 
I say this, because I've been thinking a lot about living in Portland and what it's like: and what it's like is a minimum viable city. There's stuff, but only really *one* of stuff. There's *an* art museum, *a* classical concert hall, and so on. And while there are lots of other things (lots of hospitals and people employed in the healthcare industry, for example), the other bits of what-makes-a-city-a-city don't appear to be in big supply. This isn't a surprise - we knew this going in - but part of the thing is that it's a nice city *because* it's not a big city. As soon as big city becomes a big city then there's shortage of housing stock and you either get higher prices and/or sprawl. And, well, we don't really like sprawl.
At the very least, I feel a whole bunch of reading about urban planning coming on...
--
So, anyway. It's late on Monday night and the Brits are going to get what feels like two episodes tomorrow. In the meantime, you should send me notes, and we should all celebrate because as I draft this I have 935 subscribers, which is not that many off a thousand, which is super fun.
Best,
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy Two: Symptom Masquerading As Disruption (2); The Model Is The Modeled; Labour Not Employment; Superstar Ratings, Here We Go; Not Swarm
Date: May 2, 2014 at 1:58:33 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fbvt=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident
Today's episode is mainly a response to what I wrote in yesterday's episode. It feels like I unearthed a bit of a thread, and I got some great notes from readers. So let's go pull on it.
1.0 Symptom Masquerading As Disruption (2)
Hat tips to Rowan Beentje, Kim Pallister, John V Willshire, Tim Maly and Matt Haughey for responding to the zero-hours, externalisation of employees point of yesterday's Symptom Masquerading As Disruption. It's clear there's a range of opinion on this, from the belief that capitalism will deliver us *from* evil, to capitalism delivering us *to* evil: that it will either induce an unemployment rate of up to 50% in the near future, or that things will shake out and we'll go back to a period of growth and what's happening now is a mere blip. 
1.1 The Model Is The Modeled
But first, John V Willshire's observation, that I mentioned on Twitter kind of blew my mind. Now, John *has* studied economics, and the point he made was this: this "stack" view of people - that there are those who now think of people as virtualised substitutable AWS EC2 instances that can be activated, spun up, assigned a parcel of work, and then demobilised, "is the way that economists have always liked to think of people anyway - little atoms of meat who must behave in predictable ways." 

Yes, OK, so what we have is our humans as rational actors and, in a sense, what Uber and Airbnb have done is not necessarily produced an API that controls the world, but an API that instead controls other humans. We reach out and use these services, and our requests get translated, mediated, into instructions for other humans to perform for us. You can see a sort of spectrum-disorder response to this in Hacker News comments where occasionally someone will call for an even better version of Uber where there is literally no need to interact or converse with your driver at all, and essentially the human is totally abstracted away behind a piece of glass-fronted interface. 

But John's *best* point for me, was when he said: 

"What if rather than being a way to describe the world, economics has unwittingly become a way to proscribe the world. Then we're fucked."

Abstract it away and it's kind of saying this: a model of a subject that is so successful at describing the subject that the subject takes on the attributes of the model. The model becomes the thing being modeled.

This is a thing, now. Seeing the world as addressable stacks. A kind of mankind's dominion over a computer-addressable, insructable directable world. There was someone at work who got super excited about "an API for the world!" and I think that's kind of the problem for me: an API for the world abstracts the world so that you can deal with it and manipulate it, which is great, but the thing is we have a super high bandwidth low-latency interface for the world that's super multi-modal. And I think it's fair to say that our APIs for the world right now are really coarse and in that way, treat the objects (note! objects! Not people!) that they interact with in a necessarily coarse way. And humans aren't coarse. Humans are many splendored things.

And maybe this is part of the whole "design with empathy" mini-crusade that I'm on. Sure, APIs that allow you to instruct humans to do things like Uber and Airbnb are successful right now, but I'm questioning whether they're successful good, or successful because of a symptom of changes in the labour market, or, honestly, a combination of the two. And, you know, first attempt at providing an API layer for humans that's more nuanced, I think, than Mechanical Turk, which I should've referenced earlier. But I like to think that an empathic API that's more considerate of humans will do better than one that is less considerate. Remember this, hackers of the Bay Area: you do not like being thought of as replaceable resource units, and there aren't many people who think "yeah, Human Resources is totally the best name for that department". 

Christ. Am I starting to sound like Jaron Lanier? 
1.2 Labour But Not Employment
Most of the comments were about the fallacy that you can't compare Uber or Airbnb with Hilton or a taxicab/car service because you need to count the hosts (and all the work they do, or that they outsource) with hotel staff and drivers with platform/despatch staff. 

The point here in both cases is of a disruptive service (sure, creating or finding capacity and repurposing it and serving a need) that is *also* provided via a low-cost, arguably sub-cost-of living wages farmed out to *people who are willing to perform that labour at that price*. And yes, you can see both sides of the coin: comfy overpaid cabbies protected by unions who aren't progressive, and simultaneously fair wages that will now drop to sub-minimum wage.  

Kim's not worried, because he has faith in capitalism working the way it should: either Uber has to compete and provide higher "wages" and reduce its take, or the overall service that Uber provides plummets as the quality of the labour workforce Uber's able to attract decreases. 

The correct point that Kim makes is that a job is a job is a job, whether you're doing it for zero-hours or you're doing it under contract with benefits and protection, that "whether you hammer license plates in a prison yard or a factory or in the comfort of your own living room between commercial breaks of Survivor, it's still swinging a hammer." Yes: that's the *labour* side of it, but I think the point is that we're trying to have some sort of civil society here, and it's the fringe benefits that come with the hammer swinging that are at stake here. 

Tim Maly's contribution was to examine the new labour market: that there's obviously a brand/communications story and agenda around "the kind of people who Uber and Airbnb benefit" and the reality and it would do us good to pay attention to the reality more closely. America, I feel, has always been an entrepreneurial, go-get-them state. I can't remember which book it was I was reading a long time ago, but the thought that Russia couldn't win because they didn't inculcate kids into capitalism from an early age with rituals like the lemonade stand. So ideologically, I think Americans are predisposed to the "extra ways to achieve the American Dream" concept. 

The point here is that there's a romanticised "side job", and there's a reality "side job". Again, it's not necessarily Uber or Airbnb's fault that there's a side job labour market in the first place. In fact, well done for spotting it! But, how does this play out? Do "main" employers realise that they can be much more dynamic in terms of employment and scale back hours because now not only will the state pick up the slack with welfare, but so will other dynamic humans-as-a-service, er, services? Is the endpoint, as Maly suggested to me, a world where the majority of people have 2-3 unpredictable jobs that they must do well in order to maintain high star ratings? Because, and again, I'm *pretty* sure I'll have agreement from the software engineers who read this: you kind of perform better when you're able to concentrate on a singular task. Atomised, dispersed and on-demand tasks performed by humans may not be the best way to have those tasks performed well. And the threat of a bad star rating and less employment is not necessarily the best way to incentivise "good" performance. In any case, I think we can agree that star ratings, if considered in isolation as a feedback mechanism, are a route to local optima and not necessarily the best case.
1.3 Superstar Ratings, Here We Go
Rowan Beentje responded on Twitter with the thought that star ratings can be thought of as "crowdsourcing discrimination", and in response to that, in a coarse way, I can see them as performing some sort of denormalising/anonymisation/dereferencing operation on *actual* feedback. I mean, we can agree that the regular star feedback mechanic is pretty sucky and not that useful[1]. On the other hand, yeah, good enough for Netflix. And sure, maybe better than not having any at all. Or, I don't know, the happy face or sad face feedback machines that you see at airport immigration and customs these days. 

On this, we can ask the question: are we using these algorithms to achieve the objectives we want in society, as well as in business? You can think of this as the Strong AI problem, the one that says that algorithms absolutely have needs and wants because they're designed by humans, but also need to be understood in a special way. Let me paraphrase Elizer Yudokowsky: "The [algorithm] does not hate you, nor does it love you, but you are made out of atoms which it can use for something else."

The defence here is that the algorithm is merely reflecting reality and hey, it's just following orders. It wouldn't be the algorithm's fault that non-white drivers happen to receive worse ratings than white drivers from Uber's audience. But algorithms, because they have the capacity to be blind *if they're designed that way* can help, and not just reflect existing biases. The promise of big data, of course, is that the algorithms in a way could help spot such biases and correct for them. If, of course, we decide to design them that way. 

One of the points I made in an earlier newsletter was that not doing something ("Not Trying Is A Signal"[2]) could and should be construed as a weak signal. When Dropbox takes the time to build a low barrier to entry web flow for opting out of dispute resolution compared to other companies requiring you to print out a PDF and mail it to a certain address, you can see that Dropbox "cares" more about its customers and the way it acts in the world. 

And how you act in the world is, after all, something you - whether you're a person or a corporate person - have control over.

[1] http://xkcd.com/1098/
[2] http://newsletter.danhon.com/episode-nineteen-not-trying-is-a-signal-peak-game-easyhard-snapchat/
3.0 Not Swarm
Meg Pickard[1], whom I've been friends with ever since blogging was "web logging", sent me a note in response to the point on Foursquare's naming of their new app, Swarm, and its insectile connotations. 

What if Swarm were called Murmuration?[2]. As Meg says, the concept of murmuration brings forth "lots of individual units coming together to make amazing, unreal and stunning pattens. Unique ones. Natural ones. Organic ones." A very different feeling, coming from a very different place.

Of course, the counter-argument is that "Tweet" is a verb now and so is "Google" and we don't seem to have much of a problem with that, or even "Photoshopping" things. 

But, I contend that Swarm is a name of a thing, and names come with power.

[1] http://www.megpickard.com
[2] https://www.flickr.com/search/?q=murmuration

--

Okay! Notes! Apologies to those of whom who sent notes and that I'm replying to through the medium of this newsletter. And there are *still* new people. This time from Sweden! Hello! Say hi!

Have a good weekend, everyone.

Best,

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Seventy One: A Symptom Masquerading As Disruption; Swarm
Date: May 1, 2014 at 2:38:48 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-fb7l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

Short one today, written in the back of an Uber, as always. It's hot in San Francisco and I had an It's-it last night. It was... itty.
1.0 A Symptom Masquerading As Disruption
Disclaimer: I Am Not An Economist, These Are Literally Just Random Excitations In My Brain, Transcribed Through My Fingers. 

Okay, so if you've been following along, everyone's super excited because companies like Uber, Airbnb and... well, some others in the sharing economy are able to serve massive customer numbers that formerly required lots of Company Infrastructure and costs like employees: yesterday's example from Bud Caddell's response to my critique of the Responsive OS:

"Here are the facts. As of October 2013, Airbnb has served over 9 million guests through a platform supported by only 600 or so employees (compared to Hilton’s 300,000 employees). Uber completes something like 800,000 rides per week alone through a platform supported by about 550 employees. If those numbers don’t astonish you, check your pulse."

I've been riding in a bunch of Ubers and in terms of anecdata, the UberX and Black Car drivers I've been getting have had a pretty high proportion of users who I'd call "supplemental income." Uber, as part of managing its image, wants you to understand the kind of people who might be driving you, so has published profiles of drivers[1].

So here's the reckon: Airbnb and Uber are eating the world. They are figuring out different ways of accomplishing tasks that people want to get done and they're offering choice. They're also doing that, bluntly, in a "cheaper" way, or in a more streamlined way, or, even, just looking at the world in a different way.

They are also, kind of, looking at humans as (uncharitably) a bit like meat puppets that can through financial incentive be asked to move bits of atoms around to satisfy the needs of other humans. If we're being reductionist, that's what Airbnb and Uber are, right? And we can describe employees of companies as basically fitting the same model.

So on the one hand, you have wage pressure resulting in people looking to supplement income (the symptom) and you have a way to achieve that (the disruption). Sure, you also have people looking for more options in terms of places to stay and serving user need in terms of getting from A to B (and in Airbnb's case, I'd reckon that people are looking for more good, cheap housing options). 

But the thing here is the zero-hours thing. Uber isn't a job. It's not employment. And, in a way, it's not necessarily Uber's fault that it, as software, is eating/disrupting the existing black car/taxi business. That's fine. It's more the "here's a nurse who needs some extra cash" or "Bob here got laid off and needs to find a way to make sure his house doesn't get repossessed."

There's obviously a societal implication here. Companies like Uber are externalising staff - instead of employing on the order of Hilton's staff, Uber directly employs platform staff and has zero-hour, on-demand contract workers. And they're finding it easy to attract externalised staff *because* of wage pressure and the fact that software is eating jobs elsewhere. 

So in a way, what software taketh, doth ith altoth giveth backeth in a reconfigured way? Sure software's eating jobs in one place but providing non-job opportunities in another. From an optimisation point, it is *more efficient* to not have employees and have on-demand virtual instances of "human" that you can spin up, AWS EC2-style that perform a task and then you forget about them. But hey, they're people. 

The thing about software, remember, is that it likes to scale and it likes to be general (seriously: call me on this bullshit) so hey, you human, it's your job to be distinctive and stuff and make sure you have a super nice Airbnb rental, or hey, make sure you offer a good service on your Uber, because your ability to earn will be determined by The Algorithm that implements availability and swarming. 

The Californian Ideologists here would say: hey, that's awesome. Remember that one time that one boss was totally prejudiced against you because you were $identifier, and you didn't get work? Uber dispatcher doesn't know if you're black or hispanic or speak with a lisp! Uber dispatcher only knows your five star review rating!

But hey, there were laws and regulations that were supposed to protect you from discrimination. But do you have the same visibility into discrimination from an algorithm? I mean, sure, it's not *supposed* to discriminate against you. But maybe it does? Can you look into its eye and have a feeling that it's just being mean to you, in a subtle, phatic kind of way that you can with another human?

Part of me literally cannot believe that I'm thinking this and having this conversation: because I want to believe in the algorithm and I do think computers are awesome and that they can help, and I don't want to sound like "one of those reactionary people". But I think for the *best* of us to work with the full potential and opportunity we can design with algorithmic systems, we have to be aware of the second-order effects that those systems produce. 

This is why, I think, it feels like there's starting to be a murmuring of support around a guaranteed basic income. Because the infrastructure of *employment* may well be disappearing because it's been determined by these disruptive companies to not be efficient. 

[1] https://www.uber.com/drivers




2.0 Swarm
So Foursquare is splitting in two: the checkin side of figuring out where your friends are, and telling them where you are, will be in a new app called Swarm, says The Verge[1]. And a new, relaunched Foursquare will be a discovery app. 

Now, I might be being a little cynical here. But, in true "I'm not racist but" fashion, I will say that a) I like what Dennis has been trying to do for the last what feels like gazillion years, and b) I do use Foursquare (mainly as a way to remember where I've been), when the hell is Foursquare going to figure out what it is, and what it does?

Anyway.

The new app is called Swarm. Verge says it will be "will be a social heat map, helping users find friends nearby and check in to share their location."[1]

I can make this one quick.

Things that you could say swarm:

 - locusts
 - bees
 - wasps
 - ants
 - cockroaches
 - gnats
 - flies[2]

Things that I reckon people don't like being called:

 - locusts
 - bees
 - wasps
 - ants
 - cockroaches
 - gnats
 - flies[2]  

By this point, you can probably follow my train of thought. Yes, swarming sounds cool to a tech/geek audience. And swarming does, in a way, describe the behaviour that people exhibit. But swarm-as-a-word comes with a bunch of connotations. And unless you're going to do the work to make swarming cool or desirable or something that you want people to be able to describe as their behaviour without feeling douchey (cool swarm, dude, sick!) and, well, *mass*, then, er, don't use the word swarm. So I'm not optimistic that without a large marketing campaign (sigh), Foursquare are going to do a great job with their new product. (Hunch: a cute bee logo and cursive handwriting is not enough).

Basically: Jesus Christ people, empathy. Unless you have a plan, it's generally not a good idea to compare your users to insects.

[1] http://www.theverge.com/2014/5/1/5666062/foursquare-swarm-new-app
[2] http://bit.ly/1kxYZJk, via https://twitter.com/scarequotes/status/461927009133010944 

--

I have a feeling I might get notes about this one. Please send them.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Seventy: The Book and The Library; More Responsive OS
Date: April 30, 2014 at 11:10:24 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-faeh=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident
I'm say in the back of an Uber, heading out to Facebook's Menlo Park campus again. Turns out you can get some writing done in the back seat of a car if you've got a laptop and LTE tethering. Who knew?

1.0 The Book and The Library
I had lunch with Robin Sloan[1] the other day, he of Mr. Penumbra's 24 Hour Book Store[2] and one of my favourite go-to comfort short reads, Annabel Scheme[3]. We caught up on what we'd both been doing, and Robin successfully managed to infect me with his enthusiasm for libraries. Now: I'm a good middle-class library-supporting person. When we lived in London, we made pretty good use of our local library system in Wandsworth, not least of which because while we were there the London council-wide inter-library loan system was working well and we could look something up, click a button and then in a couple days, walk over to the library and have *any book we wanted*. So, er, a bit like Amazon, only with a little bit more walking and a lot less having to deal with crap last-mile physical fulfillment. 

I suspect (warning: reckon) that for a bunch of middle class people, libraries are a bit like museums. Fond memories from childhood, a somewhat distant relationship during the middle, and then a kind of outrage at the nostalgia/experience gap when they bring their kids there and realise that a couple decades of non-engagement have kind of contributed to the withering away of a community resource. 

So we had a chat about libraries: about how they're one of the few places that genuinely congregate people of diverse backgrounds together in physical space, in relatively close proximity. Sure, you've got the stereotype of people shushing at them, but there's something, I don't know, *nice* about: here is a place for anyone, all of us, to congregate, for knowledge. It's also a good reminder that there's a large number of people, both in the UK and the US, so developed countries, who rely on libraries for internet access (those who a) don't *want* internet access - and by this time, I think we can assume that they've heard of the internet, and b) those who can't afford it).

So there's a thing here: value in physical congregation, encouraged and aided of course by the state. Because libraries do more than just act as repositories of books, they're a bit like strange attractors that way. And then there's the new libraries: the ones all glass and light and airy, designed by starchitects, communal spaces, coffee shops, play areas for children that are better than privatised ones.

But the thing Robin turned me on to was that there was a certain simplicity, he said, in the simple book. That if you had an idea, and you wanted as many people as possible around the world to have access to it, it was hard to beat publishing a book. Because once you'd published a book, it was easy, relatively speaking, for a library to acquire it. We're talking about something qualitatively different from internet access here: and I think that's the thing that Robin made me realise. Sure, anyone can *publish* something on the internet. But, to get a book from a library, or even to go to a library and read a book, compared to "access the internet" - it's more that, when you start examining the internet infrastructure closely, there's still a bunch of junk in the way that impedes access. 

The thing about the book/library infrastructure is that, in my geeky head, books are their own runtime environment. The bound paper is the interface method. They are self-executing. They have direct-manipulation user interfaces that have been standardised now and are pretty intuitive. Sure, you need to know how to read, but hey, I'm coming to that bit.

Robin said that libraries are OK in terms of DVDs and music and stuff like that. But I didn't think so: because yes, DVD players and CD players might be commodities now, but compared to a book - which is *self-executing* and *self-contained*. You can't just go to a library and get out a DVD and experience the content on it without also owning or having access to an additional access/interface layer. You can do that with a book. If, of course, you can read. 

So, say you were going to try to do something about that. Sure, you could give everyone tablets. But, that would require giving everyone tablets. What's the digital media equivalent of a book? An Android or iPad tablet doesn't count, I don't think. Still too complicated. Multiple use. Does different things. You can't, I don't think, "just pick it up" and use it in the way you can use a book. 

But I bet you could design one. I bet you could design a single-use, cheap tablet based off of commoditised hardware - because we already have hundred dollar Android tablets. They're doing gangbusters in India and other emerging markets. Sure, you could wait for flexible low-power OLED screens and all that stuff, or you could wait for e-ink to get dramatically better. But we have the hardware *now*. Forget OLPC. 

So: what do you make? A single-use, single-media tablet that's the run-time for the media on it. You want to check out the movie Sneakers from the library? Take a tablet that gets locked to Sneakers. It has play and pause on it. That's it. You can watch Sneakers now. You want to listen to Beyonce's latest? Take a tablet that gets locked to that album. That's it. 

Ah, but can we be smarter about the runtime? Sure. The runtime is the web. It's HTML+Javascript and, well, whatever an open-source browser can interpret and execute. But the point is, from a library and ease-of-access point of view to make the content and the execution/presentation/run-time one and the same, because *that's what makes books great*. And I'm not saying books are the *best* and unbeatable: because surely, they are. It's just that there's something staring us in the face about how they work that's so simple, because they *just work*. 

And sure, if you want to encourage and incentivise physical gathering, make people come to the library to go get the tablet with the media on it. That's your prerogative as government: you say - hey, it turns out that there are second-order effects inherent in getting people who would not otherwise be in the same place, to be in the same place.

Oh, right. And then you cut a deal with Google, who's trying to work out where to build fiber networks, and you say: hey, as a condition of getting the franchise to build out your fiber network, we'd like free, low-bandwidth access for library tablet devices over Wi-fi. Sorted.

What a wonderful utopian future! It's the best kind and the most depressing kind, because it's the one that's eminently *technologically* possible, just not politically so. 

[1] http://www.robinsloan.com
[2] Mr. Penumbra's 24-Hour Bookstore at:
Amazon: http://amzn.to/1mYwyYw
iTunes: https://itunes.apple.com/us/book/mr.-penumbras-24-hour-bookstore/id513340579?mt=11&uo=4&at=11ly9m (hey, iTunes, your affiliate program sucks because it doesn't also do short links)
Powell's: https://itunes.apple.com/us/book/mr.-penumbras-24-hour-bookstore/id513340579?mt=11&uo=4&at=11ly9m
Abe Books: http://www.abebooks.com/9780374214913/Mr-Penumbras-24-Hour-Bookstore-Novel-0374214913/plp 
[3] http://www.robinsloan.com/annabel-scheme/
2.0 More Responsive OS
Bud Caddell was kind enough to respond[1] to my thoughts[2] on Undercurrent's (admittedly work-in-progress) Responsive OS manifesto. And I'm all too happy to debate the Responsive OS model on its substance, and not the rhetoric around it. What I will say, though, is that if it wasn't clear, I was responding as much to the *framing* of Responsive OS as I was the substance. So there's two things going on: the substance and the way the substance was communicated. 

So Bud's right to say in his opening para, on my disclosure about management and strategy consultancy. My point, I guess, is that for a certain audience, there's a skepticism bar and obviously a number of ways to choose as to how to negotiate that bar. 

Here's Bud's response to my (admittedly pointed) "digital ninja" provocation:

"Oh, digital ninjas. Those were simpler times and easier whipping boys for agency creatives, eh? Anyway. Couple things here. First, we’re quick to tell clients that Responsive OS, as stated in that single blog post, is the goal zone not the playbook on how to get there. The landscape within every company is novel and the challenges are inherently contextual so we use a set of Responsive OS tools which are designed to allow for that flexibility. Second, and more importantly, let’s be clear – things have absolutely changed. When we talk about Uber, Amazon, Facebook, Zappos, Tesla, Airbnb, etc. we’re talking about hundreds of BILLIONS of dollars of market value that were created overnight by ignoring the traditional ways of doing things. Full stop, things have changed. When Airbnb can come boast as much capacity as a Hilton Hotels, worldwide, within less than a decade (capacity which took Hilton almost 100 years to build), something has changed about the way businesses can operate and compete. Of course we’re examining this phenomenon closely and trying to suss out what makes it tick. If you aren’t, then God help you."

So, Bud doesn't know me, and I'm writing in a personal capacity in this newsletter, in some respect, to a bunch of people-who-kind-of-know-me. So let me say that, at least in terms of the digital ninja slur, my point of view isn't that of the "agency creative" - even though, these days, I suppose from the outside I look like one - but someone who came into the ad industry only four years ago from the digital side. If you wanted to be uncharitable about *me*, you could easily have called me a digital ninja back when I joined Wieden+Kennedy. Thankfully, the agency I work for is the kind of place that would sooner show you the door and call you names than admit someone who wanted to be called, or to be seen as, a digital ninja. 

So I get this: I get that Responsive OS is an end-point and not a playbook. But I'm not entirely sure that's clear from the blog post. And I hope this is a useful outside perspective, and I recognise that, you know, it's *my* outside perspective, but I see a manifesto that is kind of selling a solution. It may well be a framework for a solution, and it's always difficult communicating that, but I do believe there's a difference. So it's my opinion that the post, and the language around *applying a Responsive OS* to different levels or layers within an organisation *does* make it feel a bit three-ring binderish, when that may not be Undercurrent's intent. 

I think where I do have a point of difference is this, though, and it's where I'd caution Bud and his colleagues to be careful with rhetoric. Bud says:

"When we talk about Uber, Amazon, Facebook, Zappos, Tesla, Airbnb, etc. we’re talking about hundreds of BILLIONS of dollars of market value that were created overnight by ignoring the traditional ways of doing things."

Sure, I get the point for emphasis, But Uber, Amazon, Facebook, Zappos, Tesla, Airbnb - they didn't create billions of dollars of market value overnight. Uber's 5 years old. Amazon is 20(!) years old. Zappos is 15 years old. Tesla Motors is 11 years old. Airbnb is 6 years old. Sure, you can say that Airbnb has built carrying capacity rivalling that of Hilton in a tenth of the amount of time (10 years to Hilton's 100), but for me, you can't legitimately call 10 years overnight. 10 years, in a corporate America focussed on hitting Street estimates every quarter, is *forever*. The overnight, to me, is a bit of a trigger sign to me, the one that hints at the implied threat. "Things are changing faster than you think!", the prophets proclaim. But, and I think Bud would agree with me here - those changes can be anticipated and planned for - responsively, so they don't *feel* like they're happening overnight. 

Bud counter's my point on the playing field having *changed* but not technically having been *leveled* by saying:

"Dan makes this point to say that technology doesn’t level the playing field, it simply has changed the playing field. That’s fair, we were leaning into idiom there. Regulation, by design, is written to address what already exists, not what is emerging. So regulation will always be a challenge for new firms, regardless of industry or driver. I don’t think that’s the strongest argument against widespread disruption, though. Plenty of money and regulation were aimed at keeping the music industry stable and predictable, yet that didn’t stop a former game designer and marketing director from building Spotify and furthering that industry’s evolution."

And yes, I'd agree that Spotify has disrupted the music industry, and we can agree that an application of Moore's law through computing power *and* communications has helped that come about. But at the same time, has Spotify stalled? Was iTunes more of a disruption? Sure, the power of the network meant that you could rely on digital distribution rather than physical distribution to do an end-run around the existing model for *consumption of music*, but for me, the playing field is not necessarily leveled, more reconfigured, when Spotify still needs to raise about half a billion dollars in funding for both infrastructure build-out and, I'm guessing, licensing. 

On planning, Bud asks:

"Have you ever spent time in a Fortune 500 company? Planning truly is the work. Well, planning, preparing for the planning, and preparing to present the planning. Companies make broad assumptions about what the competitive space will be over the next 12-24 months and then take action largely without addressing any real life challenges to those assumptions. We think there’s a better way."

And I suppose there's a difference of degree, here. Sure, I've sat in client meetings wondering why all this deck-making is happening instead of actually *doing things*. But even those companies that *do things* do planning. So I guess we can make a distinction between what productive planning looks like (ie the agile style of identifying what direction you need to be moving in, doing something in that direction, seeing what happens, and then working out what to do next to keep moving in that direction) and what unproductive Powerpoint wanking-around planning looks like.

On my point criticising "no management" and holocracy-style implied management, Bud points to proof that Valve aren't prone to mismanagement in the way other companies are through a 2011 story that Valve is more profitable, per head, than Google or Apple. Which, I suppose, is one metric to measure by (and certainly a fair one for you to judge the success of your company, and if you're a public company, you might not actually have much of a choice). And yes, I think we can all point to Valve as having taken what was initially an internal software distribution and patching system and turned it into a digital commerce and videogame distribution juggernaut as a pretty good success of having outmaneuvered the competition. And yet: there's valid criticism, I feel, on what else Valve *could have* or *could be* doing, especially in terms of their strategy with their Steamboxes. 

I had a part of my thoughts on Responsive OS questioning whether Airbnb had turned the world into a platform for millions yet. On that, Bud says:

"Here are the facts. As of October 2013, Airbnb has served over 9 million guests through a platform supported by only 600 or so employees (compared to Hilton’s 300,000 employees). Uber completes something like 800,000 rides per week alone through a platform supported by about 550 employees. If those numbers don’t astonish you, check your pulse."

Now, this is a bit of a side-argument that I'm going to take here, and it has nothing to do with Responsive OS and it has everything to do with the Californian Ideology. At this point, what I'm reacting to, is that Airbnb and Uber have figured out how to externalise a lot of costs. Notice what Bud says: 9 million guests, only 600 employees. 800,000 rides, only 550 employees. I recognise that Undercurrent are selling a management/organisational framework to corporations here. And yes, Airbnb and Uber have done something very smart and are introducing a new way of looking at the world for us, and there's going to have to be (rightfully) a recalibration in terms of regulation. But all I'm doing is simply questioning this: I'm not sure I want to live in a world where increasingly more and more people take on an Uber or Airbnb side job simply to stay where they are. So let me say this again: this isn't a criticism of the Responsive OS. It's more a: hey, have you noticed what everyone's been saying about Piketty? That, in some ways, what makes Airbnb and Uber popular for the "non-employees" who actually provide all the services for which the employees provide the infrastructure, is that they are ways to make up losses in the labour market.

I ended my post with what Bud thought was a hypocritical point about what in essence is the simplicity of the agile manifesto. The whole " Find out where you are, take a small step toward your goal, adjust your understanding based on what you learned, repeat." And yes, the devil is obviously in the implementation. But, I think maybe what I'm reacting to is that ideally, the best way to persuade of the Responsive OS, or this type of organizational change, and I'm paraphrasing the work of my friends over at the UK's GDS, is by showing it. 

And yes, Bud: I'd love to grab that coffee.

[1] http://responsive.org/2014/04/on-criticism/
[2] http://newsletter.danhon.com/episode-sixty-three-disbanded-the-responsive-os/

--

I seem to have had a sudden influx of subscribers again. Hello! Check out the archives at http://newsletter.danhon.com/archive/ and, if you're feeling up to it, send me a note either as feedback or introducing yourself or both.

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Nine: Transcendence; Broom-Shaped Objects; Odds
Date: April 29, 2014 at 6:13:10 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f9yt=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident
I'm sat in MPK 17 at the Facebook campus in a few minutes of down time. I'm in the Bay Area for work, sitting with the Big Thumb for the week, also in town for the FBF8 developer conference. 

Some housekeeping: I've now added iTunes affiliate links as well as Amazon affiliate links for my son's college fund. Get clicking, etc.
1.0 Transcendence
So I took one for the team and saw Transcendence[1] on Sunday afternoon. The quick version is this: this is like a bad, unfunny remake of Lawnmower Man[2], the only difference being that there isn't a cringeworthy virtual/cybersex scene. It turns out, obviously, that Moore's law applies to the CGI portion of filmmaking but perhaps not the scriptwriting part.

I had a bet with myself that, when it came down to it, Spike Jonze's Her[3] would be a "better" portrayal of the singularity than Transcendence would be, and it turns out that I'm stupendously smart because I was totally right. Sure, it's easy to criticise the way that Hollywood portrays something which which you have more than passing knowledge (this is a reminder of why a number of people were freaked about by Cuaron's Gravity, which, after having seen in IMAX 3D as well as screener, is really only worth seeing in Big Three D Vision), but the other egregious sin that Transcendence commits is that it's just freaking boring. Literally boring. 

So, spoilers, but you shouldn't care, because you weren't going to see this movie anyway, and if you were going to see it I hope someone was paying you to do it and that you literally had nothing else better to do with your time.

Things that are a) funny, b) wrong, c) lazy, or d) stupid about Transcendence:

 - the hilarious bit where Johnny Depp's character is putting chicken wire up in the garden to create a sanctuary (foreshadowing!) because the copper chicken wire forms a faraday cage and his wife's all: you know, you could just turn off your phone.

 - the languid slow-motion cinematography of water droplets (foreshadowing!)

 - the TED-style conference with fake WIRED magazine covers, which we can all agree were done a lot better when Tony Stark was on the cover of every magazine in Iron Man[4] which is just so lazily done because it assumes no knowledge on the part of the audience, who probably *have* seen a TED conference or heard of one, but no, the speakers at the Electrical Engineering or whatever conference have to hold mics and use a combination of really distracting full motion background video in their presentations, or stupid equations that connote "science!"

 - the kind-of referencing to some sort of dated pop-culture zeitgeist with a luddite group that's *really fucking obvious* about the assassination attempt on Johnny Depp, and then shoots him anyway, and hey, have you heard of Polonium?

 - all scientists involved in AI research - which has been making lots of progress, by the way, and the government is totes interested in it and funding lots of it (ha!) - suffer some sort of crisis of conscience apart from Johnny Depp and his wife, Rebecca Hall. And Morgan Freeman's in it, to lend some gravitas and humanity and reasonableness. And Paul Bettany, who is also in it, and a traitor to the AI cause 

 - you feel like you need to take a drink when someone causally mentions "strong AI" because, hey, you only need to say that two thirds of the way through the movie and only as a side reference

 - and you really feel like you need to take a drink when Rebecca Hall, trying to, er, decipher the uploaded data that was Johnny Depp reading out words from the OED while having electrodes stuck in his brain, because she's "tried everything: cryptography... coding... nothing's working"
 
 - all the monitors display scrolling code, because hey, er, many eyes make bugs shallow?
 
 - the luddites never really make a convincing argument against what a strong AI might do, only instead saying that machines should be servants of humans, and not the other way around. It's Depp's actions as a Physically Independent Neural Network that scare them, not that they try to talk or reason with him anyway. 
 
 - It's a physically independent neural network that relies upon physically located, specialized "quantum processors" that look pretty bad-ass because they glow and aren't black
 
 - seriously, they deal with the whole Turing test by Morgan Freeman asking an AI: "Can you persuade me that you're self aware" and the AI says "Well, that's a difficult question, can you?" and everyone's all high-fives yay we crushed it, strong AI woo!

 - nanotechnology and grey goo
 
 - computers are evil, but honestly, the one good quote they could've used to tell the story was Elizer Yudkowsky's on how an optimising algorithm is pretty indifferent to the long-chain carbons that compose you, me and every other living thing on this planet until it wants/needs to use those long-chain carbons for something else, like, er, computing power
 
 - I wasn't kidding about the Lawnmower Man thing. Depp literally says "I need more power!" and then you cut to them building a data center in the desert. And there's high-frequency algo trading. And Depp is all "I need access to the internet!"
 
 - Internet access montage! That montage is going to be awesome on Blu-Ray. There is practically no new-aesthetic style imagery of how Depp perceives the world. 
 
 - ultimately, this is all Rebecca Hall's fault because she is a woman and she loves her man and she doesn't listen to any of the reasonable men in her life who are trying to tell her: hey girl, you just woke a strong AI and we're not really down with that, because she loves Johnny Depp, see, and can't you see that? Can't you see his soul in the machine? He's real! Apart from when her newly uploaded husband is all: hey, I made these people stronger and fixed them also I installed GoToMyPC in them because I saw a banner ad for it and I can remote control them now, isn't that neat?
 
 - And here I was thinking we'd see an introducing cinematic representation of Greg Egan's introdus[5], but no, not really, it's super boring
 
 - I find it hard to believe that someone could build like a giant data center in the middle of nowhere and a) James Bridle wouldn't notice, and b) Andreessen Horowitz wouldn't notice, or c) Ben Thompson wouldn't stick it in a newsletter somewhere
 
 - "He's modifying his own code!"
 
 - Depp's visual representation (and his later physical one) literally closes his eyes and concentrates when he's, er, coding. Or interacting with the real world. Or something. 
 
 - How do you take down a hostile computer system? Virus. Oh, and shutting down all the internet. 
 
 - In the flashforward at the beginning of the film, Paul Bettany is all being Not Jarvis and saying how there are still pockets of phone service in parts of the country, betraying a complete lack of understanding as to how telecommunications systems work these days in the favour of your Standard Hollywood Technologyless Dystopia But Not Really Because Hey Look At This Imagery of People But Maybe Not Because There's A Soldier.
 
It's easy (really, it is) to throw peanuts from the sidelines about this movie and to say "well, Hollywood could've written a much better movie" without actually, you know, writing it. But, they could have. And the reason why is because everything that you see in Transcendence is stuff you've seen before, in everything from Lawnmower Man to Ghost in the Machine to All Those X-Files episodes, to that Battlestar Galactica spinoff series to Steven Spielberg's AI. There is *nothing* new here, other than just the idea of the singularity, which we don't even get to see that much of anyway, because it doesn't feel real, because we don't see the rest of the world reacting to it, because they're out in the middle of nowhere. 

Bad film, Christopher Nolan. No biscuit for you.

[1] Transcendence (Amazon Blu-Ray pre-order: http://amzn.to/1hOdc4M)
[2] Lawnmower Man (Amazon: http://amzn.to/1rCOOEq, iTunes: https://itunes.apple.com/us/movie/lawnmower-man/id310466742?uo=4&at=11ly9m)
[3] Her (Amazon: http://amzn.to/1fuZp46, iTunes: https://itunes.apple.com/us/movie/her-2013/id810314926?uo=4&at=11ly9m)
[4] Iron Man (Amazon: http://amzn.to/1nEjdVa, iTunes: https://itunes.apple.com/us/movie/iron-man/id688163154?uo=4&at=11ly9m)
[5] Diaspora (Amazon: http://amzn.to/1mVLhDx iTunes: https://itunes.apple.com/us/book/diaspora-multimedia-edition/id673540743?mt=11&uo=4&at=11ly9m, Powell's: http://www.powells.com/biblio/62-9781597805421-0, Abe Books: http://www.abebooks.com/servlet/SearchResults?isbn=9780752809250&cm_sp=mbc-_-9780752809250-_-all)
2.0 Broom-Shaped Objects
Or, things pretending to be other things. 

Fred Scharmen sent a good note in reply to episode sixty two[1] about my throwaway phrase of evolutionary unsecured back doors in the way our brains work (or: unconscious biases and all the kind of stuff like in Thinking Fast And Slow[2]). He told a story about needing to buy a broom for the first time, so bought the cheapest thing they had, which fell apart after about three uses: it wasn't a broom - it was a broom-shaped object, "designed to explicitly hack the pattern recognition faculty, and trick dumb college students into buying it."

And it feels like that's one of the fallacies here: things that look like other things, but have other jobs or agendas. In the context of physical objects, it's shoddily made stuff that's designed to trick you once, maybe, because it looks like a broom, but doesn't work the way the broom-object is supposed to work. 

So Fred's worried about "an internet of broom-shaped things, designed by agents actively interested in hacking empathy."

My first response to that was, again, because this is a current preoccupation of mine, the empathy hacking that makes up both advertising and corporate social media policy. The former isn't that novel: sure, effective advertising makes use of the fact that it attempts to form a low-level emotional bond with you. Corporate social media policy is even worse, in a way: the orthodoxy is that social media is a conversation, so what you've got to do, as a corporation, is have a conversation - or fake having a conversation - with your audience. The funny thing here is that you've essentially got stuff like Brand Guidelines and a Brand Voice going on and a bunch of social media internal or outsourced staff and, er, a sort of Searle's Chinese Room[3] for Twitter. Side note: start a social media company called Searle's Chinese Room.

The thing is that when you have a thing that's pretending to have a conversation but isn't actually capable of having a conversation, then again, that's pretty sociopathic. A bit of the organism that, in order to "do better business" learns how to form connections with people in the hope of advancing the whole, without *actually understanding* the people it's dealing with. 

You could make the argument that humans are pretty much Chinese Rooms anyway (and, er, if you're prone to introspection, rumination and generally depressive thoughts it's probably best not to think about that too much) and of course corporations are Chinese Rooms, but there's something about the bit when the Chinese Rooms start pretending to be people that feels a bit squicky.

Of course, that raises the question: how do you transparently build things that *do* leverage our ability to empathise with things and recognise faces and all that stuff, while at the same time not being trapped in an uncanny valley, or, actually, just deceiving or manipulating people? It feels a little like the more we learn about how our brain works, the more you kind of need to be dealt a user's manual or a sort of security/vulnerability disclosure: Congratulations! You are a newly instantiated human being! If you are able to read and understand this video, then it means you are susceptible to the following attacks on your consciousness...

[1] Episode 62: http://newsletter.danhon.com/episode-sixty-two-wearables-unworn-look-at-what-they-want/
[2] Thinking Fast and Slow (Amazon: http://amzn.to/1iyblgm, Powell's: http://www.powells.com/biblio/9780374275631, 

3.0 Odds
Budd Caddell has kindly written a response[1] to my critique[2] of the Responsive OS manifesto. We're going to grab a friendly coffee some time, but he's got good points that I'm going to think about and respond to.

[1] http://responsive.org/2014/04/on-criticism/
[2] http://newsletter.danhon.com/episode-sixty-three-disbanded-the-responsive-os/

I was lucky enough to grab lunch with Robin Sloan today and my brain is predictably fizzing post-conversation, so I'm excited about the next few episodes. Let's just say that he converted me with his love of libraries and books. 

The lineup at Theorizing The Web[3] looked amazing, and one of the outputs was Princeton University assistant professor of sociology Janet Vertesi's attempts at hiding her pregnancy from, well, the web. If anything, it's interesting what it would take form a regular person's point of view to practice informational operational security.

[3] http://theorizingtheweb.tumblr.com/2014/program

I had a good note from Liz Henry in response to the episode about NGO design for products and services, rightly asking what the baseline should be for "social good" objects, and if there's a responsibility for them to be dealt with in a copyleft "for the good of humanity" fashion. Which struck with me because it felt very Long Now-ish[4], and at least a bit SFnal. 

[4] http://longnow.org

I wrote in episode 55[5] about the good job I thought If This Then That had done communicating the Heartbleed bug and what they had done about it. In a similar vein, I think Github's *followup*[6] post to their frankly terrible original[7] post regarding Julie Horvath's departure was another good example of empathy-led communication. Note: I'm not saying that by communicating in this way Github have changed their ways, but I'm happy to treat it as a weak signal of improvement.

[5] http://newsletter.danhon.com/episode-fifty-five-sharing-heartbleed-a-weakness-of-the-heart-zero-day/

--

OK, big day tomorrow at FBF8. Expect Facebook-related reckonings.

As ever, I welcome your notes, and pinky-swear promise that I reply to them. So send me some!

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Eight: The iPad; The Difficulty; Tools; Silly
Date: April 28, 2014 at 12:04:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f909=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

I'm sat here at Building 16 at Facebook's Menlo Park campus with a Diet Coke. It's a pretty normal Monday morning.
1.0 The iPad
I'm an iPad/tablet bull. Yes, there's all this guff about the iPad's sales being flat and not growing. But hey, here's my incredibly naive view of the situation:
 - if you're deciding between a phone or a tablet, you buy the phone first.
 - there's a genuine question as to how much computing power (and in what form factor) different types of audience need. There's nothing wrong with the vast majority of people being OK with a 5 inch "phone"/terminal.
 - tablets are decidedly eating the majority of mundane tasks that laptops were used for *outside of the business market*. This is the parent market: people who *had* to buy laptops before if they wanted to participate in the 'net, who now have a different operating system choice that is significantly easier to use thanks to the simple addition of direct manipulation in the user interface. 
 - the iPad isn't done yet. I do think the software is behind the hardware in this case. With iPads Retina and Air, you have some pretty great hardware, similarly so in the Android space. For the iPad, it's expanding out and (I touch on this below) improving inter-app communication and making workflow better. I genuinely wonder that the single-screen application mode is a sort of Apple-esque enforcement-on-high that is *not* equivalent to the single-button mouse decision that doesn't completely aid ease of use. Sure, it allows for ease of use in some situations, but it does wall off others. And there isn't the kind of keyboard-option-click hack in this situation for taking in multiple pieces of information and synthesizing something new.  
 - Personally, the iPad (and I'm still on the first Retina generation) only really works for me in terms of consumption (and yes, I know, not *all* iPad uses are consumption only) and in the specific work use-case of me a) receiving lots of email, b) having to look at PDFs, c) replying with comments about those PDFs. Sometimes I even look at video. But that's it. I don't even write this newsletter on it because I don't have a keyboard case, and compared to my laptop where I can hit around 80wpm - well, it'd be particularly masochistic to force myself to write it on an iPad just to make a point. 
 - But, you know, this is Apple's MO. Solve problems for the base first, in terms of ease of use, and then work upwards. So far, it's working.
2.0 The Difficulty
I had a number of thoughtful replies to my note about my depression the other day. It's something that comes and goes. And, every single time I write about it, I hear from new people who say that they're relieved to see someone else write publicly about it. I don't know if it's more prevalent in the tech community. I suspect that the public face of depression is still the tip of an iceberg, that its true prevalence is something that isn't internalised by people, not properly understood, which again makes sense because it's an internal illness that manifests itself in less easy to empathise with external symptoms. 
But, and here's the thing I have to remind myself of, that I'm writing down this time. Today, I'm fine. Today, I woke up, and got myself out of bed (and it didn't take too long, this time), and I plugged myself into the network and connected with people and I don't feel alone in my head. I don't have that self-loathing. So, as it always does, it passed. And this time I'm grateful that it was only for a couple days, and instead not the weeks or months it has been for before. 
Even though it doesn't feel like it at the time, even though it's super-easy for me to rationalise why it happened or what I could've done about it, it's hard to remember that it passes and it's just temporary. Or, is more temporary than it's been before.
So I'm writing this down for me, as much as anyone else: it passes. 
3.0 Tools
Frank Chimero has a post up entitled No New Tools[1] where I think there are some interesting points for the kind of products that might be successful in the future. Chimero talks about the curse of the early-adopter - the kind of person whose brain is tweaked to respond to a certain kind of novelty, predisposed to being interested in new ways of doing things. Try this new app, this service: this new thing will be better than the old thing. 
In some ways, I think this is a peculiarly American phenomenon - and by that, I mean yes: it exists around the world, but as I spend more time here, there's a lot more of American culture that I start noticing. There's a work ethic here, sure, a hangover from the Protestant colonists and the great narrative of the American Dream - work hard, rise up. And when that narrative is so strong, who doesn't want a hand in working hard, in rising up? And so, simplistically: the entire self-help book movement.
Chimero's point is that tools should reduce pain, induce pleasure or do some mix of the two. And that if you're not accomplishing either of those goals, then those tools are, essentially, a waste of time. They're not moving anything forward. At worst, they're moving things backward. 
Where Chimero's post struck me was when he looked at technology that increase pain and reduce pleasure, and as an example, rhetorically asked: who wants to have perpetually visible email notifications? 
Inevitably, this is where I set out my user empathy stall. Taking the time to properly understand a set of users - and, I think, it does make a crucial difference when you shift from describing your audience as people and not users, the latter already makes a set of assumptions that may not be correct or desirable - would, I hope, lead to someone asking: what are the axes that we're hoping to produce a better product or service against? Is the axis *only* productivity? Are there other ways to impact productivity? 
When Chimero talks of the basic tools of text editor, spreadsheet, email, pencil, paper, Photoshop - there's a lot in there to untease, I feel. There's the element of comfort - we know how to use familiar tools. Because of that, there's less distraction. Less futzing around with figuring out how to do something in the new (often less) efficient way. 
He's right, though, that there's a trend toward ideological tools, rather than a sort of platonic ideal of a simple tool like a bare-bones text-editor. But I think that that trend also reflects the needs of attracting attention in order to build a viable audience for that tool. The tools themselves need to present themselves to you and persuade you to use them. 
It's hard then to see how you could get a genuinely *better* tool, because the promise of digital tools should be better workflow, amongst others. Chimero is, I think, biased in his examples towards tools that work in single-user environments, where perhaps the case for no-new-tools is more justifiable. 
I think that's what Chimero is asking for: design for workflow, and not necessarily for task completion. Or, rather, that increasingly the way we work involves workflow, so the "tools" you get are things like Slack (part of the Butterfield/Henderson Act 2 of "thing we accidentally make from a game"). Because I don't buy the argument that we don't need new tools. It's telling that Chimero argues that our best tool is language, because I think what he's essentially arguing is that our best tool is communication. 
Perhaps this is what feels somewhat stunted about the mobile apps space right now: while all the interest and growth is in being able to replicate social graphs thanks to the hilariously backward notion of "address books" populated with phone numbers and email addresses. While a first-layer graph is being constructed, when Chimero talks about language/communication and the idea of Getting Things Done and Couch to 5K, he's talking about "big idea" ideas, ideas that can be executed in lots of different ways. Sure, you can buy a notebook or put on your running shoes. But I think that's needlessly reactionary and sort of cutting off your nose to spite yourself: if only we were more disciplined about our usage of technology to use what was genuinely useful. 
So perhaps the thing about devising new methods of work is a lack of inter-application and inter-process communication. Sure, Android has it in spades, but the reality of the situation is that the better-designed applications *feel* like they're hitting iOS first. If the thing is about making a program for people, and the thing about people (these days, more than ever) is that they communicate with other people, then inter-process/inter-application communication needs to be a thing, and it's an area where iOS is sorely lacking. Maybe, sigh all the iOS developers, this year's WWDC will be different.
Making a program for people relies on a) understanding people (yes, my empathy soap box), but also b) programs that can communicate amongst themselves in the way that humans expect to. 
[1] http://frankchimero.com/blog/no-new-tools/
4.0 Silly
I'm in the Bay Area for some work with Facebook today, so I found myself in the back of an Uber on the way down to Menlo Park. I mean, it's a bit ridiculous *when you think about it* about being in the back of an internet-hailed black car, using a high-rez laptop with a day long battery life, plugged into an LTE modem and the internet. So then things got a bit silly on Twitter[1]. Here's a tweaked prose version of what I was wittering on about:
She was jacked into the 'net in the back of a speeding car, an ultra-high-rez aluminium laptop hooked up to a 20 megabit LTE terminal, plugged into Facebook and Twitter: a global network, updated in real-time, a street of populated by over a billion people. 
Then: she was in. The Feed. Millions of status updates scrolling past in 227ppi high-resolution in real-time, seamlessly distributed around the world according to the HyperText Transfer Protocol. The Feed had made people who could understand microcode Gods around the world. They controlled the flow of information. Distributed it. Even the Stock Market ran on Hyper Text Transfer Protocol now. And she was one of the few who understood it. Understood the code behind it. Since she was a coder, one of the new gods, she could reach inside the Hyper Text Protocol and use a Firebug to literally change the information. 
But, those days were behind her. She put her Android Cyanogen Mod phone away, and went back to work. Stringing for Gawker didn't bring in the cash it used to. Sure, maybe she could find a few choice tweets, retweet them, boost her Klout for a free burger at McDonalds. But it had been months since she'd found a tidbit on Secret good enough to pass on to Biddle before he'd seen it. 
So, in the meantime: "Do you want that tall, grande or venti?"
Because while her hacking days might be over, she was doing what America was great at doing. Serving coffee, on a zero-hours contract.
[1] https://twitter.com/hondanhon/status/460810201654771714
--
Okay, that's Monday. I'm in the Bay Area through Wednesday night, in town for the Facebook Developers conference. If you're around, say hi!
As ever, send notes. Lots of you have. Some more of you haven't. You should, because a) they're nice, and b) you get a nice reply.
Best,
Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Seven: The Difficulty; Listless Interestingness
Date: April 25, 2014 at 10:36:47 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f81d=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident




I'm sat at home at the dinner table. The TV in the other room is playing theme from Resogun, which means I must have unboxed the PS4 and plugged it in. It's 7:53pm and I haven't had dinner yet, don't know what I'm going to have. Other than the videogame music and the forced-air heating, the house is quiet, and cold.

1.0 The Difficulty
If you've been reading this newsletter for a while, you'll know that I've been struggling from depression for a pretty long time. And that various bits of medication and so on have helped. But hey, the thing about long-term clinical depression is that it doesn't go away.

And that bright period of the last few months? I knew it wouldn't last. I don't think I've felt properly depressed, or low, in the last two months or so. But I'm feeling it right now. I'm not sure what it is. I don't know if it's work or if it's not-work, I don't know if it's because of what's going on with my mother-in-law, who should've been out of hospice by now but isn't, I don't know if it's because two days ago my wife dropped off our fourteen month old son into daycare for the first time, one thousand, seven hundred and sixty miles from where I am. Or that I have yet another bout of work travel coming up in under forty eight hours.

But my brain's doing that thing it's done for over twenty years now: that thing where it's slowed down my entire body - that physical thing that my self inhabits, the one where the only real thing I need are the hands that are resting and typing on the keyboard and touchpad, it's slowed it down so that it doesn't really want to do anything. Or, it's slowed it down so it's super-aware of absolutely every little thing that's in every to-do list, of everything that needs to be done with the house, of everything that I've fucked up at work, of the light in the upstairs bathroom shower that hasn't been changed for weeks now because I can't summon the will to go up and do it, and all it can do, all that body can do is just. Sit. There.

So yeah. I have that self-loathing right now, and the slowness, but it doesn't stop my mind from racing. Some of my closer friends ask me: how exactly, every week day, do I manage to get this out. 

And I kind of say, it's because (big secret: it doesn't actually take that long for me to write, and no, that's not because I'm outsourcing it to TaskRabbits or because I have a markov chain botnet that I bought from a Russian warez site, and no, I don't know what you mean when you're asking me about my box full of infinite Amazonian mechanical turks) if I don't get it out, if I don't suck up all those spare processor cycles or whatever dominant cultural metaphor of the day we're using to explain the universe applied to how the brain works, if I don't occupy my brain with some sort of stimulus like the thinking that goes into this: then I run out of things and I basically go zombie. See that bit of identity? Go eat that. See that bit of self-esteem? Go eat that. Gorge on it. Grill it medium rare and poke it and it runs out bloody and snarf it down, because there's more where that came from, there's a bottomless pit of dark, succulent despair and self-hatred. So you may as go upstairs, hide under the covers, and just turn off the rest of the world. Because if you're looking around, you see: shit hands, shit fingers, shit arms, a shit chest covered in a shit t-shirt, shit legs with shit trousers on, shit socks, and oh: what's the point. 

So instead of writing about something smart, or something witty, or something that happened on the internet, I'm writing about this. I'm writing about what's inside my head, because the thing that's caught my attention is, right now, how much I hate myself, and useless I am. 
2. Listless Interestingness
Of course, who am I to not soldier on and attempt to still get something down. To try and crawl through. So, here are some things that even in this state of listlessness, at some point yesterday, I found interesting:

 - So, there's a new book, No Exit[1] doing the rounds about the new Californian Gold Rush, covered wonderfully by Felix Salmon[2], which had this line that a lot of people are quoting: "There is no reason whatsoever to believe that computer engineers make particularly good entrepreneurs" which reminds me of the wailing and gnashing of teeth when the British videogames industry collapsed for the nth time, and someone made the observation that perhaps people who'd grown up making games for themselves and copying the disks and sealing them up in zip-loc bags and mailing them out where, perhaps, whilst good game designers, not necessarily the best businesspeople and that might be the reason why they'd all pretty much eventually gone out of business or gotten bought. I think there's a similar point being made in the Mills Bakers' essay that I covered the other day, only with designers. Business (like design, like videogame design) is hard, and requires a certain set of skills, and I guess you're as likely to find a designer/developer/researcher unicorn as you are to find a business/designer/developer/researcher unicorn for a startup. Good luck.

[1] Kindle edition: http://amzn.to/1imtFJf
[2] http://blogs.reuters.com/felix-salmon/2014/04/21/the-most-expensive-lottery-ticket-in-the-world/
[3] https://mokriya.quora.com/Designer-Duds-Losing-Our-Seat-at-the-Table

 - Matt Haughey tweeted the other day that "brands apologizing on Twitter is the best Twitter of all"[4] which prompted me to immediately ask him if someone had made the brandsapologizingontwitter tumblr yet, which they hadn't, so we went and made it[5]. It's got that US Airways Tweet on it. Hopefully (inevitably?) it will be a long-term project, much like Phil Gyford's Our Incredible Journey[6] tumblr.

[4] https://twitter.com/mathowie/status/459369552707473409/photo/1
[5] http://brandsapologizingontwitter.tumblr.com
[6] http://ourincrediblejourney.tumblr.com

 - In amongst a discussion of a) the culture of startups, b) how awesome Captain America: The Winter Soldier is, and c) its merits compared to The Avengers, someone (and I'm really sorry that I've forgotten who) sent me a link to a paper in the Academy of Management Journal titled "Superman or the Fantastic Four? knowledge combination And experience in Innovative Teams". Now, I can't really say much to this because despite *seeming* like I'm the kind of person who's read a lot of comics, I haven't actually read a lot of comics (if you're following on from the first section of the newsletter, this is a mental trigger for feeling both inadequate and an imposter), and also I didn't even watch the Fantastic Four movies. Anyway, it's clear that the Fantastic Four would be better than Superman because a) Superman is stupid and b) Everything is Awesome When You're Part Of A Team. The point being made here, in a bit of a fanwanky kind of way, is this: is the Avengers team composition better than the Captain America: Winter Soldier team?

In the Avengers corner, you have:

 - The Scientist (Stark)
 - The Tank (Hulk)
 - The Rogue (Black Widow)
 - The Ranger (Hawkeye, but he isn't really in it)
 - The Warrior (Captain America)
 - The, er, Other Warrior (Thor)

In the Captain America: Winter Soldier corner, you have:

 - The Warrior (Captain America)
 - The Rogue (Black Widow)
 - Er, and Falcon

And yeah, I probably got all those wrong because I never played enough RPGs when I was growing up. I mean, at the very least, having a two-person team in Captain America and Black Widow (who also has her semi-leet hacking skills) isn't so bad. I was reminded of John Rogers' (he of brief Warren Ellis Global Frequency pilot fame) series Leverage[8], which has the quite fun heisty combination of a hitter, hacker, grifter, thief and mastermind, and yeah, you could probably turn that into a mediumsplainer about how you should build out your startup team. 

 - I am still on a crusade about empathy. I've had a bunch of interesting emails about it that I'm behind on replying to people (there's that voice again), but suffice to say it's going to be a strand that I'm going to be continuing. One of the random thoughts that I had was whether, from a macro-cultural point of view the general acceptance inside America of American exceptionalism, *especially* amongst the West Coast Californian Ideologues is something that inherently biases against, or acts against empathy with users. Or, are there other ways to test this theory? One thing that I've been struck by has been how the companies that I admire have some elements of similar culture, both explicit and implicit. For Pixar, Apple and Wieden+Kennedy, they're all founded by idealistic yet capitalistic hippies. They share, roughly, the same notion that money is important, because it's required to accomplish the mission. But it's not the end goal. The end goal is something bigger, or something different. In all cases, it may well be that the founders wanted to stick dents in the world. In any event, you should go and read the smart things that Alex Payne[9] and Scott Berkun[10] had to say about company culture. 

[7] http://amj.aom.org/content/49/4/723.short
[8] http://amzn.to/1imwnhC
[9] https://al3x.net/2014/04/23/mob.html
[10] http://scottberkun.com/2014/critique-dont-fuck-up-culture/

--

I'm tired. I'm going to order a dirty pizza.

Have a good weekend.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Six: On Design; New Aesthetic Zeitgeist Bingo; Odds
Date: April 24, 2014 at 10:31:51 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f6y9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

It's 8:30am in the morning, West Coast. It's stopped raining (for now) and I'm about to head into the office. I hope Skye's going to be okay.



1.0 On Design

Twitter follower @bamblesquatch pointed me in the direction of this wonderful post on Quora of designers potentially "losing their seat at the table,"[1] by Mills Baker. It's definitely worth your time. I wish I'd written it. To recap:

 - Steve and Jony elevated design's position in the cultural consciousness to a position it had never done before. Never mind the refreshing carbonated soft-drink enjoyed by homeless people and heads of state alike, now we had MP3 players and phones and laptops enjoyed and coveted by everyone! Also, Apple were (and continue) to make gobs of actual real hard cash that they are now using to be a) good corporate citizens and return to their shareholders and b) occasionally using to buy companies from time to time or whatever it is that their PR team says.

 - Well, if design's going to make money and help you scale, you can get the VCs will be at the table. Funds were raised to invest in designer-founder companies. Noted designers and luminaries are joining at the VC table to advise and guide entire portfolios. And yesterday, a change in mindset for designers was the best shot at creating products and services for social good.

Baker thinks designers, as a whole, are at risk of cocking things up and losing their hard-won place at the table, the reason being that when they *were* given the keys, they produced products like Facebook Creative Labs' Paper and Dropbox's Carousel and Jelly, which, well, don't really answer user needs so much as they scratch itches in a small niche. And there's always the example of Path of which we don't really need to say any more apart from, as one wag on Twitter asked this morning: "Path's still around?"

Of course, it gets even worse when there are the rumours going around that Square is looking for a buyer, that it's attempts to expand out of the POS ecosystem are faltering (bitcoin is hotter than Square Cash/Wallet, for example) and that it's losing money.

In all of these cases, each of these products and services are generally agreed to be "well-designed" - they look nice, they've got some nice touches to them, but Mills' point is that they don't actually solve a problem in an innovative way (and that's using the Horace Dediu-approved definition of innovation[2]. 

I'd point to a few examples (you can take it as read that I consider the work of the UK's Government Digital Service as actually solving problems for people with design), at the very least Google's Chromecast Photowall experiment[3] solves a problem experienced by *some* people, and while it's not necessarily a problem that people are calling out to be solved, and it's not necessarily a problem sufficient to organise a startup around to Change The World, it genuinely is something that I consider to be meeting a (perhaps unstated) user need. 

Mills has a good point: design isn't just taking an existing idea and chamfering the edges off to create something *slightly* better but that fits your corporate, sorry, startup-endorsed culture-approved World Changing agenda. It's actually having some empathy (and there we have my empathy crusade again) for those we serve, and in the contexts of *most* of us, we serve humans - or, you know, people. 

Chris Locke, a good friend of mine, sent a reply to yesterday's critique of Everyone Deserves Great Design[4]. Chris is the ex-director of the GSM Alliance's Mobile Fund for Development, now doing predictably interesting stuff at his Caribou Digital outfit. And he articulated something that I think was niggling at the periphery of my thoughts about the manifesto but I don't think I got down. His point was this: there's was another fallacy of assuming in a sort of Americano-centric manner that the only people building products for the base of the pyramid are the ones that the West Coast CI-complex are concerned with. But the reality that Chris points out is that *everyone* else already is: from the buckets of Chinese OEMs churning out cheap Android hardware to Indian hardware developers like Datawind[5].

In the case of designing for actual people and design that's led with some sort of genuine empathy for the people making up the market, Chris sent me five examples, that I'll happily quote him on:

"1 - [Good design] looks like Nokia's (sadly, slowly disbanding) team of anthropologists and researchers in countries across sub Saharan Africa and SE Asia.  These guys took a phone repair guy and set him up in a shop so they could watch him and note all the transactions he had with his customers to understand what went wrong when people used their phones.  This was anthropologists, not designers, and they fed their results upstream.  It's also the awesome pen portraits of base of the pyramid mobile usage that the excellent research company 2CV did for Nokia.

"2 - It looks like all of Jonathan Donner[6] at Microsoft Research's work

"3 - It looks like Eric Hersman's BRCK[7]

"4 - It looks like the massive physical ledger book in which every mPesa transaction is logged.  These books aren't a formal part of the process, they don't hold up the transaction and they're not necessary for an mPesa payment to be made, but they were introduced when the fantastic team who designed mPesa realised that digitising customer's money freaked them out, so the ledger process was brought in pretty much as a piece of theater to reassure them (best example of UX design ever)

"5 - Hell, good design for the base of the pyramid looks like all of mPesa, which was built in USSD[8] - a deeply unsexy development platform but one that was used because it was ubuitous, and everyone with any phone could use it."

This, I think, is an inspiring story of design and projects like mPesa are genuinely impactful in the markets they're used. Mobile money services like mPesa that peoples' needs don't translate over to developed countries because of existing legacy infrastructure and regulatory requirements, and a technology like Bitcoin isn't necessarily easily adaptable to low-power phones working under a specific set of environmental constraints. 

As ever, it feels like we're at the cusp of Gartner's Peak of Inflated Expectations and the transition into the Trough of Disillusionment. For every Nest there's a Fuelband, and the massive about-face investment into design is an over-correction that will play out when everyone gets a bit more reasonable and has a more heterogenous, user-led attitude to design. Which, you know, good designers should be doing. But perhaps this is also where culture plays a big part, and is part of my criticism of the Californian Ideology: I think my position is that good design results from a certain application of humility and empathy, and that feels at odds with the Don't Fuck Up The Culture-culture of the prevailing Valley movement.  

[1] https://mokriya.quora.com/Designer-Duds-Losing-Our-Seat-at-the-Table
[2] http://www.asymco.com/2014/04/16/innoveracy-misunderstanding-innovation/
[3] https://www.chrome.com/photowall/#no-chrome
[4] http://tinyletter.com/danhon/letters/episode-sixty-five-apple-and-nike-critiquing-everyone-deserves-great-design-odds
[5] http://www.datawind.com
[6] http://research.microsoft.com/en-us/people/jdonner/
[7] http://www.brck.com
[8] http://en.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data

2.0 New Aesthetic Zeitgeist Bingo

Spoilers for Captain America: The Winter Soldier. So, Dan Williams, "look away now".

There's a few things feeding into this bit. One is a side-conversation I had with Robin Sloan in response to what I wrote about Suarez's Daemon series. There's something, Sloan said, in a sort of emerging literary sub-genre, a super-niche, which is interested in exploring *ideas* through fiction and the quality of the actual *writing* doesn't matter so much, because to the audience they're tuned to, they're looking for ideas, not well-written characters and thought-through plot. They're as much looking for intellectual mental stimulation as strong character-based narrative. Almost a sort of gedanken experiment fan fiction where what you're a fan of isn't characters or setting, but being a fan of ideas or concepts. 

So with that, there's the observation that with works like Daemon, you have New Aesthetic-ish tracts pushing forward ideas about society, culture and techonlogy in the form of genre fiction as opposed to in the form of a Kevin Kelly, Ray Kurzweil or, god forbid, a Malcolm Gladwell-style pop-sci tract. Storytelling as mere background to exploration of ideas. Or, even, storytelling as a simulation running on a human brain but where the gedanken experiment is: "assume technologies x, y and z in socio-economic circumstances a, b and c. Execute" running on a substrate of grey matter that's (sometimes) pretty good at simulating what self-directed agents (er, people) might do in that setting.

Anyway. There's that. And I still haven't watched *any* of Person of Interest, which I'm reliably informed is a) some of the best television on at the moment, along with The Good Wife and all that other stuff you're watching and b) Bu one of the best filmic interpretations of our networked society.

But I have watched Captain America: The Winter Soldier. And ignoring the plot, let's play New Aesthetic Zeitgeist bingo, or just take a drink when:

 - the greatest generation betrays us;
 - a personality can be uploaded and executed on computing machinery and it's not even explained: it just *is*;
 - ubiquitous surveillance is desired;
 - compartmentalisation is a bad thing;
 - the only way to remake the world is to leak all the secrets, good and bad;
 - security apparatus is as interested in preserving the status quo as it is in disrupting it;
 - "because algorithms";
 - total information awareness is a side plot-point that only gets around three minutes of screen time, barely enough to understand it because the audience is expected to understand that a) there's a lot of information about you out there, and b) it can be used to model your entire future;
 - precrime;
 - pre-emptive military action;
 - rods from god;
 - satellite targeting;
 - USB sticks;
 - abandoned 1930s-era military installations;
 - cargo ships;
 - cargo ships that aren't actually cargo ships;
 - pirates;
 - pirates that aren't actually pirates;
 - false flag operations;
 - not being able to trust anyone;
 - self help groups;
 - post-traumatic stress disorder;
 - shipping containers.

And there's probably even more.

What's remarkable about this is that the film expects its audience to be literate in pretty much all of those concepts. In my mind, any *one* of those concepts could easily be made into a Hollywood Action Blockbuster and at least a half to two thirds of the movie would be taken up with Needless Exposition For The Benefit Of A Clinically Brain Dead Audience. 

3.0 Odds

Do you like word games? If you do, then you should play Ludometrics' new game, dsmvwld, for iOS.[1]

Facebook bought Moves[2]. Honestly I'm nearly all reckoned out when it comes to activity tracking these days. I think I should get a badge, though. I had to take a drink because they used the word "journey", but at least Moves isn't being shut down and is being run, like Instagram and Whatsapp, as a separate concern with no planned Facebook integration. Of which: Zuckerberg was apparently serious when he said his strategy was a portfolio of mobile apps. What people are waiting for is how, exactly, all those apps will tie together and where the graph of 1.3bn fits into it all.

I'm going to be at fbf8 next week, so if you're a) at it, say hi, b) in the area, say hi. 

[1] https://itunes.apple.com/us/app/dsmvwld/id728308907?mt=8
[2] http://www.moves-app.com/press
[3] https://fbf8.com

--

So, as ever, please send me notes. I like getting feedback, and I'm pretty good at replying. Or, even, introduce yourself!

Hail Hydra,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Sixty Five: Apple and Nike; Critiquing Everyone Deserves Great Design; Odds
Date: April 23, 2014 at 9:52:46 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f6ol=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident

Today, I was back at the office, where the value of "office" has been set to "spend the day down at Facebook in a workshop". I don't actually mind flying down to Facebook - depending on whether you get a prop plane or a jet plane, it's either a two hour or hour forty minute trip flight from PDX to San Jose, and then there's always the food on campus. And the people at Facebook are smart, and it's always good to have conversations with smart people.

I am, however, going back to an empty house. Well, an empty house where I might finally plug in my PS4. Also I bought Tokyo Jungle for the PS3 when it was on .99c sale and that game looks mental. And I have Agents of S.H.I.E.L.D. to watch, too! But, nonetheless, an empty house where my wife and son who I deeply miss are far away.

1.0 Apple and Nike

Well, the Apple and Nike reckons won't stop coming, so I'll throw my hat into the ring as promised on Twitter the other day when I said:

"I will eat a cupcake in the shape of a hat if Nike+ is built into/preinstalled on an Apple wearable that supports user-installed apps."[1]

Previously on "stuff people have reckoned about Nike and Apple" we agreed on the following things:

 - Tim Cook sits on Nike's board and wears a Fuelband
 - Apple and Nike introduced Nike+iPod in 2006
 - Nike is likely discontinuing the Fuelband with the Fuelband SE, and no more Nike+ hardware will be produced
 - Apple introduced the M7 motion co-processor in the iPhone 5S in 2013, demoed on stage with Nike+ Move
 - Certain Nike+ mobile software was only ever available on the iOS platform

Here's some other things I think we can also agree on:

 - Apple is definitely up to something in the "wearables" space, by which I mean: something that isn't a phone, that's more passive, and probably is designed in favour of gathering data rather than presenting (not just displaying) it. 
 - Battery life is a bitch.
 - Wearables are either in, or entering, the Creative Labs Nomad stage: a nascent, non-mass market, expensive, with a terrible user experience. The Samsung Gear Fit is, I think, exactly what cmdrtaco would be calling a Nomad, and it isn't even as good as a Nomad was. Come to think of it, I think the Pebble is the Creative Labs Nomad. 

So, that said, what are the reckons?

I think there's value to be gained from drawing a distinction from the Nike+iPod launch story. In 2006, both parties had a lot to gain: the iPod was not yet the juggernaut that it would become. Sales in 2005 were around 23 million units, by 2008 they would peak at around 54 million units. Nike had everything to gain. Apple had something to gain by tying the iPod to fitness. But it's hard to say whose needle moved more. 

I'll go right out and say it's damn out of character for Apple to launch a new product in a new category and have one of the defining aspects of the user experience of that product be another company's proprietary, third party metric. 

More simply, I don't think an Apple Wearable will be default calculate activity and present it primarily in terms of Nike Fuel. The hierarchy will, I think, be easily understood terms to people like steps and calories. 

Nike, however, has nailed its flag to the mast of NikeFuel and is attempting to build an ecosystem around its proprietary metric. But here's the kicker: for Nike's ecosystem to be *the* ecosystem in the way that I am thinking people are implying, with Tim Cook leaning into the Nike board's ear to whisper "Hail Hydra^W^WHey, the iWatch is coming and I want you guys to get on board", Nike *needs* to be a pre-install and NikeFuel *needs* to be the default metric for the NikeFuel ecosystem to be viable. I honestly don't think it's big enough. And Apple don't - or shouldn't - care. The best Nike can hope for, I think, is partner status in terms of placement in the App Store for whatever device Apple release.

At the same time, Nike is trying to get other companies to join the NikeFuel bandwagon through its Fuel Lab in San Francisco. But I honestly don't see the benefit for those other companies in the activity space. Yes, Nike has a massive brand. But you work at a startup because you want to grow something big, not because you want to partner with The Man. And here, Nike's The Man. If I were Strava or Runkeeper, I would view a call from Nike to be part of the NikeFuel ecosystem as a gauntlet-thrown challenge to iterate faster and better to grow a bigger ecosystem. Because, again, what does Nike bring to the party? Does it bring a massive audience that can convert to new Strava users? Will it be marketing third party apps? Will there be a giant TV campaign? These are all unanswered questions that need to be understood when you're asking startups to become part of your ecosystem.

I also think NikeFuel is an opaque metric. Again, if you want me to participate in your ecosystem and to use your metric (and, presumably, to use your metric *over* other metrics), then you need me to be sure that my users will understand it. And maybe that's what Nike will do: a stupendously large full-spectrum air-dominance marketing campaign that only Nike can do, getting everyone to understand what NikeFuel is and why they should measure their daily activity using it. Personally, I don't rate this as happening.

[1] https://twitter.com/hondanhon/status/458669660817600513

2.0 Critiquing Everyone Deserves Great Design

Provocation of the day comes in the form of a manifesto[1] from Ehsan Noursalehi, founder of non-profit startup madebybump[2]. Noursalehi's looking for a way "to incentivise capitalism to do good for the people of this planet independent of their respective geographic, cultural or economic status."

Every great manifesto starts with a statement that you can get behind. And with this particular one it's that Everyone Deserves Great Design. Which is true: everyone does deserve great design. Along with, say, food, water, education and the right to life and to not be coerced into slavery, for example. Let me just say that if you're looking to do social good, or if you're looking to do as unallloyed, pure good as you can, then at least saying what everyone deserves great design *for* would introduce clarity of purpose.

Noursalehi's manifesto is a sort of extension of the Californian Ideology in the same way that we saw with yesterday's manifesto from Undercurrent. It draws from the dominant examples of the Valley - highly successful, network and software-based companies that have been able to derive their success from the inexorable progress of Moore's law. In this case, Noursalehi's exemplars are Google and Facebook, because they are "relying on 'poor' users in developing countries as significant sources of revenue." Would that were true, of course: there's no doubt that Google and Facebook's plans are derive significant sources of *future* revenue from developing countries and the bottom of the pyramid, but make no mistake: current revenue is mainly derived from developed nations. Right now, significant sources of revenue aren't coming from populations subsisting on a dollar a day.

Now, where Noursalehi's right, of course, is that Google and Facebook are focussed on user need. In a broad way (and it's easy to find counter-examples where these companies may appear to have not), these companies and their products "treat people as humans - people with needs and desires. These global heuristics are breaking down traditional economic, social, cultural, and geographic barriers of discrimination in product design."

If we're just talking about "bad design", then we've got an agreement hands down. If we're talking about "the frustrations of numerous products being designed every year and given away free to people who don't want them," then we've again got agreement hands down. But I think it's the way that Noursalehi goes about constructing his argument and his way forward that has some holes in it that I'd like to examine.

Why do useless products exist?

Noursalehi opens his manifesto by asking why useless products exist. In his mind, they're the result of wrong mindsets coupled with good intentions. We can discount the people who're trying with *bad* intentions, obviously, so we continue with the essentially head-nodding statement of "just because a product has a social mission doesn't mean the product is great," which as an example of rhetoric is an unoffensive statement that can feel like it's designed to ease you into the argument.

Perhaps part of the visceral reaction against Noursalehi's position is in the examples he chooses. The LN-4 prosthetic arm that he shows is "a prosthetic arm given away for free by the Ellen meadows Foundation... ... the intention is good, but the product is little more than some plastic and a few velcro straps. The arm is difficult to put on [and] take off and can barely lift more than 5 pounds."

Now, I don't have a bachelors in Materials Science or a Masters in Industrial Design like Noursalehi does, so I'd like to assume that he's more qualified to speak on these matters than me. But, I find it hard to understand why a product is "little more than plastic and a few velcro traps" is an inherently *bad* thing, especially when the image Noursalehi chooses to illustrate the product with appears to be set in a developing country. While plastic and velcro may not be aircraft grade milled aluminium, it is cheap and, one hopes, durable and easy to repair or replace. That the arm is difficult to put on and take off may well be indicative of a bad product, but again, depends on how often that activity is expected to be undertaken, and similarly the fact that the arm can barely lift more than five pounds feels like it needs to be taken into context. Is your choice, right now, lifting five pounds, or no pounds? I know I would choose five over none. And the rest of the context around the product matters, too: I am making the assumption, due to the imagery used, that this is *designed* to be a cheap product.

Now, let's be clear here. Noursalehi isn't saying that the LN-4 Prosthetic arm is *bad* design. He's saying that it's *useless*. And if we believe that design is as much the language that we use in the world as well as the objects and services we produce that exist in it, then we should aspire to be as careful and considered in the words we use (perhaps Noursalehi himself isn't sure about the terminology he wants to use - the anchor tag he uses in the URL for this section is #bad). For me, a prosthetic arm in the possession of someone who has no prosthetic arm, that enables a person to lift five pounds when they could lift none, is not useless. It's life-changing.

For the other product examples that Noursalehi cites as "useless" design, his concerns may well be more valid. He says that an electricity-generating soccer ball often breaks in a few weeks, that there are at least ten detailed problems with a water pump design.

The last example Nouraslehi uses is that of the Free Wheelchair Mission, "made from readily available plastic chairs, mountain bike tires, castors, and a custom metal frame. Over 700,000 have been distributed in 90 countries - they could have easily and affordably produced a more appropriate and desirable wheelchair." 

I feel like it'd be a diversion to pick apart "appropriate" and "desirable", but I do have an issue with the phrase "they could have easily and affordably." From my point of view, the first person to throw stones should be the one who's actually shipped 700,000 wheelchairs in 90 countries. There's value in armchair criticism, of course, but I frequently find that it's hard to start a productive dialogue if you're on the sidelines saying that what was done could have been "easily" bettered by someone not involved in the process.

Where I do agree with Noursalehi is in his use of Kelsey Timmerman's quote - that too often we objectify people living poverty, and that "we pait them as two dimensional characters that we pity." That, I feel, is true, and requires almost a sort of leveling-up of empathy. Where I think Noursalehi is right is in saying that more attention needs to be paid to people's needs and desires and that simple do-gooding doesn't in and of itself satisfy those needs and, in some cases, may even reinforce a sort of helpless victim complex that privileged people unintentionally maintain. 

All of this equates, in Noursalehi's mind, to discrimination against the very people the non-profits say that they're attempting to serve. People I know with more experience than me in living and working with the NGO world (but from outside of it) have expressed frustration with how the NGO and non-profit world works, a world that is as in need of Californian Ideology style "disruption" as any non-digital Western business. (Chris Locke - here's your sticky)

At its heart, I think what Noursalehi is trying to say is that NGO's and non-profits have been subverted by chasing the money, who they think is their "user" as opposed to the people they're supposed to be serving. Like yesterday's Undercurrent Responsive OS manifesto, the core point here is one of agility: putting something out in the world that makes progress toward a goal, gathering feedback, and then adjusting course to better achieve that goal. It's that simple.

Where Noursalehi goes a little off-course is in saying that the appropriate mindset to adopt is not just caring about the other 90% but in producing products and objects that the other 90% *desire* to own. 

Desire, of course, is a tricky thing.

How to prevent useless products

The manifesto now sets up a problem: that social product design is driven by tough constraints, and bad design results when user desires are ignored. Even worse product results when "the poor are accidentally seen as helpless people that need to be saved who have no agency." I agree that seeing a group of people like that "strips [them] of their dignity."

The suggested solution is to embrace the constraints of the developing world and "merge it with the typical desires of the first world." By doing this, Noursalehi says we can "more frequently avoid bad products" but also produce "very innovative and meaningful products." 

What's interesting is that although Noursalehi opens this section of his manifesto with a quote from Tim Brown of IDEO that "Great design satisfies both our needs *and* our desires" [my emphasis], there's no talk of peoples' needs in this section. There is only talk of desire. And the thing about capitalism that it's not clear that Noursalehi understands (and this may well be a product of him being ensconsed in academia) it's that Western Capitalism is very, very good at *manufacturing* desire these days.

The manifesto lists four principles that should be followed in order to produce "Great Design for Everyone."

The first is to simultaneously embrace desires and constraints. I hope Noursalehi qualifies that in recognising *local* desires, or culturally specific desires. And also the danger in and allure of manufacturing desire where none exists. 

The second is to "minimise resource inefficiencies", and to use first principles to reinvent problematic aspects: and in formal Californian Ideology manner, there's reference to the work of Elon Musk at Tesla and SpaceX in terms of bottom-up design. 

The third is to "optimize value", which again, isn't necessarily aligned to the goals of capitalism. Providing the "maximum functional, social, and emotional value for a minimum initial investment and low long-term maintenance cost" sounds, in some ways, like asking for the moon to be carefully positioned on a stick of a design specified by a complex multivariate equation. Again, this feels a bit like teaching people to suck eggs, or, less charitably, designsplaining: "hey, you know what you should do? You should try to make the best product and the lowest price that lasts forever. Got that? Awesome, let's ship it!"

The fourth, and the principle I have least objection to, is that we should "dignify everyone" and here Noursalehi cribs liberally from Warhol: a homeless person and the President should be treated equally, and discrimination should not take place based on geography, culture or economic status. I feel there's a problem here, but the good news is that this is just a set-up for something that's coming up.

Noursalehi says we should be hopeful, because there are "countless great products that do not discriminate based on geography, culture or economic status." So what are they?

He has five examples.

The first is a digital watch, the Casio F-91W, introduced in 1991 and "a popular product worldwide today." It's water-resistant, features a calendar, alarm, stopwatch and a battery that lasts over 7 years."

The second is the BIC Cristal Pen, "a tool of utility and creativity," that is "highly reliable, stylish and one of the most affordable ballpoint pens in the world."

The third is the monobloc polypropylene chair, "produced by numerous manufacturers worldwide," and is "affordable, need no maintenance, can be used in any weather, and are stackable."

The fourth is "a carbonated soft drink sold in over 200 countries worldwide," and "the world's most valuable brand."

The last is Gangnam Style, the music video that became the first to have over a billion views on YouTube, "becoming a globalization phenomenom". Of this, Noursalehi says "it is without doubt a marker in history that there is now a means and interest to distribute products, or in this case a digital product, globally to everyone, without regard to social, economic or cultural status."

I'm not exactly sure what point Noursalehi is trying to make here. Is it that these are lowest common denominator products? Is it that they fulfil desire? Is it that they are, in Coca-Cola's case, a valuable brand? 

In the Casio watch example, I see how a cheap product that lets you tell the time fulfills a need. I don't necessarily see how it's *desirable* to people of both the first and third world in the way that I think Noursalehi says we should be aiming for. In any event, one critique I have with him picking this particular watch is that the illustration is of a watch built for a Western market, with English as the user interface (but then, is it patronising to assume that people want products in their local language, fit to their local culture? Or is Noursalehi saying that a successful invasive species is "good" design?) 

There are a bunch of factors that I don't feel Noursalehi is unpacking here. There's "popular products" that sell worldwide, but again, correlation isn't causation. Can I make the same accusation that the Casio coud have "easily and affordably produced a more appropriate and desirable" watch that served emerging and developed markets equally? Because let's be clear: some of these products are Western/Developed-Country-First products, that just *happened* through industrialisation and economy of sale to be easy to import into other markets. Is the Bic Cristal pen stylish? That's a matter for debate. Is it cheap? Does it do the job? Are there better pens? Is it sustainable? Can you say the same thing about the monobloc chair? 

Is Noursalehi saying that these are *inherently* great products that *also* do not discriminate based upon geography, culture and economic status? Or are these products instead just examples of successful capitalism and colonisation of market? And, let's be clear about Coca-Cola: Coca-Cola's product is as much a brand as it is the drink. And that's manufactured desire. It may well have been a *strategy* of theirs to say: you know what the thing is about Coke, it's the same for everyone. But the simple matter is, the *brand* of Coke is for everyone. Because what's in Coke isn't the same, market to market anyway. 

Does that mean Noursalehi is saying that we should be developing desirable brands for developing markets? 

Because when Noursalehi asks "have you ever wondered about how a homeless person on the side of the street and the leader of the free world consume the same fizzy soda drink just to have a fleeting moment of happiness?" it kind of feels disingenuous when you're talking about doing social good. 

This is all without me taking issue with his usage of Gangnam Style. Here, Noursalehi's falters again, because he commits that Californian Ideology mistake of saying "everyone", when he actually means "everyone with internet access," again, an interesting mistake given that further down he talks of the internet.org project. Two thirds of the world is not on the internet. Two thirds of the world has no access, or even no *desire* to be on the internet. There is still a large population of people in developed countries like the UK and the US who have expressed no interest and no desire to be on the internet. So to say that "there is now a means and an interest to instantaneously distribute products globally to everyone, without regard to social, economic or cultural status," I only have one response: bullshit. This type of thinking is, in my opinion, as bad, and as poisonous as Noursalehi alleges of the bad NGOs and non-profits. Did you hear that? There are people who aren't on the internet. And they matter, too.

The World is Constantly Changing

Yes, the world's changing. And for a lot of people - a *lot* of people, it's getting significantly better. Organisations like the Bill and Melinda Gates Foundation and the Clinton Global Initiative are working on programs that are applying rigorous methodology to actually make a difference. Programs like the GSM Alliance's mHealth run out of their Mobile for Development fund are improving quality of life through products and services that are designed to actually be used, and mPesa to this day remains the big thing in digital currency that's not bitcoin that not many people have heard of. If you're interested in what people who know what they're doing and are bringing the NGOs to task to actually deliver, then you should check out with Chris Locke, ex-director of the above GSM Alliance's Mobile for Development fund is doing over at Caribou Digital[3].

But there's a disconnect here: Noursalehi says that Apple, Google and Facebook see growth in the developing world, while at the top of the manifesto we're told that the same companies *rely* on "poor" people in the developing world for significant revenue. Which statement might be true if Noursalehi meant that those companies are reliant on bringing up those "poor" people for future growth, but not current revenue. Apple is notorious for not wanting to compromise on product, so while the Street might be penalising them for not going after "growth" at the expense of net profit, and while its products are desirable to consumers in developing markets, they're certainly not affordable. And I don't think Apple will compromise on that. 

Noursalehi similarly says that $199 Chromebooks advertised (to consumers who can afford them) are for "everyone", but again, not everyone can afford a $199 Chromebook. And, sure, Facebook has its counterpart to Google's Loon project to bring affordable internet access to the two thirds of the world that doesn't have it - which, hang on, wasn't Gangnam Style proof that you could distribute product to *everyone*? So which is it?

I don't think the GE story is particularly interesting: yes, they've done product development thorough developing for external markets first and then bringing them back to their home markets, and again I might just be being naive, but I don't see why this needs a special label of "reverse innovation" - it's just innovation.

Noursalehi's manifesto then goes on to explain to us what the right mindset is to "develop the great design everyone deserves".

Noursalehi wants designers to remember that we design for people first, and that designing for poverty means focussing on and being biased by inequality. But I think that's an oversimplification: because you can imagine situations where being able to focus on an attribute allows you to properly examine how to solve for it. In this way, designers are supposed to focus on products and services that are desired equally by the top 10% *and* the bottom 90%, but are simultaneously affordable for both the top 10% and bottom 90%. I am not sure whether he is asking for a miracle or merely something very hard, or honestly even a part of the solution space that no one has genuinely explored. 

For me, though, that bottom 90% is exemplified by the population of the world that *is* basically clawing its way up out of a subsistence economy. So the "good" examples that Noursalehi shows, at price points of $20, $130 and $40 to my mind don't solve for the criteria that he has set. 

A $20 water straw *as it stands*, does not meet his criteria. A $130 wood-burning stove does not meet his criteria (but does, interestingly, act as a step in the chain toward helping that two thirds of the population without internet access start powering devices that enable access, through USB outputs). Similarly, a $40 foam football, even if it's on a buy-one-give-one model, doesn't solve the same problems. 

I think there's a bit of a false equivalency going on here. Noursalehi says that no one in the developed country would choose the LN-4 prosthetic arm, given the choice. They would choose something better. But do those in developing countries have the choice to *not* choose the LN-4 arm? I feel that the criticisms he levels at "bad" products, or even worse, the ones he labels as "useless", can be similarly leveled at the ones he espouses as being good. 

To be sure, Noursalehi doesn't say that following this manifesto is an *easy* process. But I don't think he's done the work to show that it's a viable one, either. It's a map to a way out for a future that we can agree we all want (modulo the highly suspicious bit to me about creating brands to solve social problems through sugar water). All he's saying, with a bit of hyperbole that I think is unwarranted, is that perhaps we should be trying harder. 

He is saying, though that "companies like Apple and Samsung cannot ignore the  massive potential of the bottom 90%". With all due respect, I don't think he understands what Apple does and what Apple stands for. Apple exists in the world, and it's not necessarily Apple's job to uplift or produce a product, that can produce a profit, right now, for the dollar-a-day income people. I don't thin Noursalehi has actually advanced a concrete reason for firms that are staggeringly profitable to produce products that reduce their margins other than "because it's good for the human race". He is, essentially, making a volume number and hoping that the volume of the bottom 90% is going to make up for almost absurd wealth concentration at the top end, something that I don't think pans out when you do the maths.

And I do feel like Noursalehi is patronising when he's saying that "optimising for cheapness" is "not the most important thing" for poor people, that quality and value performance are often the most important factors in the decision making process." Well, for starters, how does Coca-Cola figure into quality and value performance? Is it the best at delivering happiness to those at the bottom of Maslow's pyramid? Or, is Noursalehi essentially saying that of the phrase "good, cheap, long-living" he no longer wants to pick two?

The manifesto ends with the giant pullquote: "No one wants a shitty product." Which isn't really a particularly insightful rallying call. Well, no shit sherlock. Words matter. If you're advancing the argument that considered design in service of people is going to make a difference, then don't throw up the straw man that people are going around saying, "Hey, you know what? We should make a useless product or service that will save the world."

No-one sets out to make a useless product or service on purpose, I don't think. Especially the audience that Noursalehi is hoping to engage.

It can be easy to write something that feels like a manifesto. It's hard to write something that's *right* and that doesn't just feel like it's moving and emotive and a rallying call. I could make the same accusation here and say: "the most misleading proposition is a badly thought through, badly expressed manifesto tarted up with a parallax-scroll style website."

Let's be clear: this type of manifesto *is* a rallying call and propaganda. And it's in the service of a noble cause. It's failures are self-inflicted.

[1] http://www.everyonedeservesgreatdesign.com/
[2] http://madebybump.org/
[3] http://cariboudigital.net

3.0 Odds

First, the random thought that an Apple wearable product could take the form of headphones. It doesn't actually make *that* much sense, because you'd have to wear them all the time, but hey, you can whack a three-axis accelerometer and pulse/blood-ox sensor package in there (earbuds, right?) and it'd be *totally* Apple to do a keynote where they throw up a picture of some headphones and say "Guys, you've been doing headphones wrong all this time." 

Anyway, on reflection I don't think it works because people would need to wear headphones the whole time. But hey, Google Glass kind of needs you to wear the glasses the whole time and maybe we need a do-over with the whole "please put stuff on your face/head" angle.

Second, following on a bit from Nick Sweeney's point that "bullshit arguments are allowed to proliferate on the web because of parallax scrolling" and his beautiful coinage of "snowfallacies". We're suckers for good presentation. But words matter. I need to find it, but there's a great manifesto at work, that self-referentially talks about how to write a manifesto. There's something in this. I bet Robin Sloan would be all over this. A sort of tap/fish means of content/presentation for rhetoric.

Third, I throwaway mentioned that Captain America: The Winter Soldier is a bit New Aesthetic Zeitgest Bingo. There are *so* many things packed into that movie that feel like they're of the moment, at least to me, so I'm probably going to write something about it this week. Oh, and Freedom, Suarez's follow-up to Daemon, is getting much better.

--

Okay, that's it. Another long one today. In fact, Tinyletter's got a little badge (sigh) down there telling me that I'm at five thousand, one hundred and fifty eight-ish words, a *new record*. Yeah! 

So, yes. Notes. I imagine there will be some following this episode. I always love notes and feedback because otherwise this really is just random neuronal firings in my brain and I don't know if I'm getting any "better" or not. And again, if you're a new reader, check out my archive at http://danhon.com/newsletter, and send a quick note introducing yourself.I promise I'll reply. 

Best,

Dan



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Four: Computer Says No, Snow Crashing
Date: April 23, 2014 at 12:48:37 AM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f5zl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>



0.0 Station Ident

As I write this, I'm nestled in a status-upgraded first-class normalcy field at an altitude of around 30,000 feet with a couple megabit's worth of connectivity, a Diet Coke (naturally) a banana and enough computing power around my person that it's mostly just idling playing music or displaying text. If it could talk, it would say something like "a brain the size of a planet". I am on my way back from Missouri to Portland.

1.0 Computer Says No
A side-effect of our current family situation (geographically distributed, divided to conquer) is that whilst my wife and son are with her family I am left on my own in Portland to fend for myself with our cat. It means that since I'm sans fourteen month old, I suddenly find myself with an expanse of free time that, in my evolution-optimised, short-termist brain looks for all the world like a limitless green savannah of movies, books, video games and TV shows, even though my bachelor period is only about a week and a half.

I've started on Daniel Suarez's books[1], which I've been meaning to get around to for a while ever since seeing Daemon come out in 2006. Of which: 2006! Eight years ago! That's got to be at least in the top ten for finally-getting-around-to-read.

I have to admit, Daemon reads like a first, self-published novel, which is fortunate, because it is Suarez's first, self-published novel. Freedom, the sequel of which I'm only about a third of the way through, is already a significantly improved read. Daemon suffers a lot from Tom Clancy-itis - a meticulously researched and technically accurate thriller that descends into at times a practical step-by-step guide to compromising a computer or network. It's interesting, because the equivalent in Trek is technobabble ("Geordi's theory was that if we reprogrammed the warp reaction chamber with a new intermix ratio, and configured the main deflector dish to emit a .47 nanosecond gamma ray pulse, tuned to the precise coordinates and the inverse phase of the harmonics Data detected from subspace rift, we would be able to seal the rift before it got too big and wiped out the inhabitants of Rigel Alpha and still make it back to the Starbase in time for Riker's jazz recital") which I find to be equally offensive as Suarez:

"Since he didn’t have the luxury of time, he opted for an attack that was effective against a wide range of devices: SNMP— a buffer overrun that exploited a known vulnerability in unpatched implementations of Simple Network Management Protocol. This service was present on the target, and it was worth a shot. He switched to the command console and quickly keyed in the commands, pointing his exploit code to port 161 on the target machine. If the target was running an unpatched OpenBSD, he’d get to root pretty quick. He executed the command, waited, and in a moment he got a return instructing him to telnet to port 6161 at the target IP address. He sighed in relief."
 - Suarez, Daniel (2009-01-08). Daemon (pp. 154-155). Penguin Group US. Kindle Edition. 

Here's some of the themes in the Daemon/Freedom duology that I found interesting:

Computers control everything these days
Daemon was first published in 2006 and it shows quite a bit. There's a bit where one of characters uses Netstumbler and I have to admit, part of me squeed a bit and did a bit of a Lexi from Jurassic Park ("Netstumbler! I know this!"). Unsurprisingly, Suarez's emphasis on technical accuracy is one thing that dates the novel, but I think we can all agree that in a post-STUXNET[2], post-Snowden world everything we'd dreamed about is finally coming true. Apart from, obviously, the jet packs bit. For a book that's happy to throw down phrases like "unicode traversal exploit" and words like "Netbios", it's interesting to note than back in 2006 it's possible that SCADA hadn't yet infiltrated Suarez's consciousness as an in-place framework for a lot of what the Daemon accomplishes. 

These days, knowledge of SCADA has spread outside of its initial domain, and Stuxnet[2], discovered a mere three years later, is probably the best example of a multi-vector, doggedly single-minded example of software reaching out and having a defined offensive physical effect. It's perhaps telling that it was much easier (in the sense that it's been attempted and, apparently, succeeded) to design a single-purpose software-eats-real-world-centrifuges piece of malware, and that it undoubtedly requires the resources of state actors than it is to design a piece of (admittedly fictional) general purpose distributed software that while dumb is capable of achieving goals through multiple redundancy. What I guess I'm saying is this: Sobol might have had cancer, but he was pretty damned busy (or he kept his two associates super busy) during the final years of his life. 

Or, more simply: software for a specific purpose is always much easier than software generalised. Acting on the user need to "disable Iran's centrifuge capability" is much easier to plan for than "destabilise and reboot civilisation". 

So my understanding is that SCADA's great and all but it doesn't necessarily provide a  homogenous attack surface and that if you want to do what the Daemon does and take over a lot of materiel quickly, you need custom modules and a lot of preparation.

Narrow AI Is Sufficiently Complicated
Suarez gets a lot better at describing exactly what Daemon is - at the start of the book, Daemon is the equivalent of a Sufficiently Advanced If This Then That Recipe masquerading as variously artificial intelligence or the uploaded consciousness of a dead man. And yes, while all the pieces do exist, kind of, and the idea of a whole bunch of malware, botnet-driven distributed components has *in theory* been possible at least since Sun starting trying to get us excited, so many years ago, about portable network computing and remote invocation, we haven't really gotten anything quite so complex yet. Later on, in Freedom, we see Daemon described as a "narrow AI" which is a pleasant way of saying that while we might not have achieved the frothy proclamations of the academic AI gang, we do have a bunch of specialised subsystems that do provide some degree of intelligence, if not consciousness. 

The bit about using the machinery of an MMORPG for command-and-control of a network, or as a Bond-villain-esque backdoor is a bit genius though, and does set Suarez up for having to explain to countless characters in the books a) what video games are, b) why people play them, and c) that the skills they're learning by playing those games aren't useless. One feels like Jon Ross would exasperatedly point Sebeck at Jane McGonigal's Reality Is Broken and not listen to him until he'd finished it. 

Perhaps the hardest to stomach part of the Daemon is its semantic analysis of the news. There's reference to the mechanical *how* of it - distributed RSS newsreaders and scrapers scanning for keywords - but what we don't see any of in the book are false positives. I'm not entirely sure how the scrapers would work in practice: we can throw Bayesian filters and train them to recognise spam (which we've recognised as spam), but can we similarly train such filters to look for news reports about WACO-style massacres? This is the bit where Sobol's planning comes in to play: did he define activation keywords for each and every single triggering event that the Daemon required? There's no mention of self-modification, so we needn't go down the route of the Daemon generating keyword lists itself (that would be a step too far, for me) but this is the luxury of fiction: it just works.

The Invisible
This is a bit more developed in Freedom than it is in Daemon, but roughly Suarez explores the idea that unseen forces shape the physical world that we live in. All of this is somewhat couched in the language of gaming and Suarez deftly uses augmented reality to bring to life and bring sight to he who couldn't see. This idea of a data shadow, a clickstream plume that is emitted as a result of your activity and never really dissipates, has been gaining a lot of steam lately, if only because a) it's true and b) I think it legitimately preys upon peoples' contemporary fears of not really being in control. While it's true that there *is* a lot going on out there that isn't visible or given a tangible presence, ie. that data moves in mysterious and opaque ways, where I feel the books get a bit fantastical is in wrapping all of that data in a user-friendly queryable interface. I think it's fair to say that if there were an easy way to aggregate, query, disambiguate and sort through all the chaff, our security services would probably be doing a better job than they are. Quite frankly the most fictional, implausible aspect of all of this is that someone's figured out a way to let regular people conduct accurate, queries across numerous stupendously large datasets. 

Follow the instructions to be part of a team
There's a whole set of examples of people blindly following instructions (and the variant, of people choosing to follow opaque instructions) in Daemon. 

What we see early on is a fictional illustration of the predisposition people have to follow along with instructions and a narrative, just because, well, there's instructions and a narrative. Almost a sort of games-as-Milgram experiment. We've seen this before in games like BioShock that (spoiler!) remind us exactly how good, and how willing, we are to follow instructions when the surrounding circumstances are constructed just right. Unfortunately, BioShock never really went that far in exploring the relationship between a computer "user" and the system encapsulating her, but later games like Stanley Parable pushed the genre a little further. Structurally, I like the way Suarez has set this up: we have Graggs playing through an Over The Rhine map that's a good example of 3D environmental storytelling that has been honed to a fine art by Valve and latterly the Call of Duties of our time. That then gets followed through with the mechanic of our characters responding to Daemon generated prompts that are only really answerable with a yes or no, and the equivalent of characters who are in such controlled physical environments (the garage that Gragg encounters comes to mind) that all they have to effect their surroundings is the equivalent of the spacebar USE key.

There's a side-alley that I feel Suarez could've gone through here: essentially, he's talking about control and the way in which we can be influenced without our executive function necessarily catching on quick enough. The canonical TED-talk examples for this are things like supermarket grocery layout design and the sight-lines that you get in controlled environments for different purposes, like Disneylands and Disneyworlds. There's a way in which Suarez could have made a point, if he wanted to, about putting people in stressful environments and showing how easy it is to manipulate them, but he didn't really have to do that. The garage sequence with Gragg, though, where Gragg inexorably follows instructions to the point that he kicks himself immediately after following them because the instinct to follow is just that: an instinct that is difficult for him to consciously override, is a great example of how a videogame level designer might think about real-world architecture in producing an action/influence funnel.

Toward the end of Daemon, there's a nicely choreographed set-piece that could've looked interesting on film that a nice one-take Alfonso Cuaron shot would've done justice. At this point, the Daemon has spread to a not insignificant proportion of the population, and orchestrates a sort of deniable hit on spammers, directing and controlling tens or even hundreds of human agents at once to deliver and assemble the assassination weapon. This is the kind of thing I'd like to see a DARPA Grand Challenge-style event for: for something like that level of orchestration to work, it feels like you need pretty granular location services and wayfinding, all operating in realtime, and all without your battery dying on you. Of course, by this time, Daemon is fabbing a whole bunch of high-spec Glasses, and we've entered into the slightly more Star Trek toy universe. The key word here I think is choreography, and that's perhaps a clearer way to think about what's being described. Imagine a ballroom and everyone wearing earpieces and a choreographed dance happening, in realtime, but through voice prompts, where none of the participants have advance knowledge of the routine (and may well have had no training, either). Anyway, if you love that sort of stuff you really should've read Bruce Sterling's Maneki Neko[3] by now.

In Freedom, there's a little Falling Down-esque moment in a fast food joint with Sebeck nearly losing it due to employees literally following what the computer's telling them to do to the letter, in an Americanised Computer Says No[4] moment. You get to illustrate this quite a lot with the enough-truth-to-them-to-not-be-entirely-apocryphal stories of people blindly following GPS instructions (because, of course, we've been taught that Computers are Perfect Computing Machines and that a bug or error is when the screen futzes with static or blue-screens, not returns inaccurate data) or even through casual reading of the RISKS digest[5]. Again, this doesn't necessarily tell us anything about computers: it tells us about how we interact with machines and the way we're encouraged to trust them. 

At least from the beginning third of Freedom, it's good to see the more nuanced (in parts - it's still a screed against capitalism, I think, but also firmly planted in the Californian Ideology of technology saving the day) plot. It's an interesting perspective to see how widespread AR might develop from a gaming-first community. There's a lot of CI tear-it-down-to-build-it-up "disruption" going on (which is why I had a feeling this might inevitably turn into a set of opinions about Captain America: The Winter Soldier, of which more later this week). That said, there's a lot of handwaving, too: the way to bootstrap a new civilization is by plundering an old one, which Suarez amply points out is the way we've always done things. It may not be nice and it may not be what we want, and the devil will always be in exactly how much tearing down needs to take place. It's not really disruption if it's managed, is it.

[1] Here's a list:
Daemon (Amazon: http://amzn.to/QCyg3L, Powell's: http://www.powells.com/biblio/9780525951117, Abe Books: http://www.abebooks.co.uk/Daemon-Daniel-Suarez/9555111019/bd)
Freedom TM (Amazon: http://amzn.to/1gP4vTX, Powell's: http://www.powells.com/biblio/1-9780451231895-2, Abe Books: http://www.abebooks.co.uk/Freedom-Daniel-Suarez/11483682581/bd)
Kill Decision (Amazon: http://amzn.to/1fnBYo4, Powell's: http://www.powells.com/biblio/1-9780451417701-1, Abe Books: http://www.abebooks.co.uk/servlet/SearchResults?isbn=0525952616&cm_sp=mbc-_-0525952616-_-all)
Influx (Amazon: http://amzn.to/1k5m3z8, Powell's http://www.powells.com/biblio/1-9780525953180-0, Abe Books: http://www.abebooks.co.uk/servlet/SearchResults?isbn=9780525953180&cm_sp=mbc-_-9780525953180-_-all)
[2] http://en.wikipedia.org/wiki/Stuxnet
[4] https://www.youtube.com/watch?v=WOdjCb4LwQY
[5] http://catless.ncl.ac.uk/Risks/

2.0 Snow Crashing (6)

It's been over ten episodes since I've done a Snow Crashing! So here's a new one, which is exciting, because in this installment we get our introduction to Snow Crash, the drug.

So I think there's something interesting about black-and-white-rendered photocopy dude, the guy who's stood in the throng at the entrance to the Black Sun. For starters, Stephenson asserts that "Street protocol states that your avatar can't be any taller than you are," which strikes me as a) completely missing the point of VR in the first place, and b) ridiculously unenforceable. Much easier to make everyone the same height, or only within a user-definable range, than to actually stipulate that your height in a virtual representation may not exceed *your actual physical height*, which instantly renders everyone going through puberty on the 'street with an interesting problem. 

Anyway: photocopy dude who's slightly taller than everyone else in the crowd for a reason that doesn't stack up *manages to grab Hiro's attention*. Which is another way of saying: look at the attention economics of this place. This isn't a crowded inbox and Hiro's not clicking on a phishing scam. This is someone who has to, in a way, be physically present in order to project presence, an interesting enough presence at the right time, at the right place, to attract Hiro's attention to get him to try Snow Crash. 

Snow Crash, as Stephenson tells us, gets its name from computer lingo - describing a low-level hardware failure so bad that it makes the electron gun in your CRT skitter wildly across the screen, giving you the colour that the sky above the port's turned to. Unfortunately, time hasn't been kind to Snow Crash: we're not really using CRTs anymore, and even in Hiro's world, he's not using CRT's either, really: the goggles that he's using are using RGB lasers to paint directly onto his retinas.

There's a bit of a disconnect too, in that Hiro's weirdness detector goes all the way up to eleven because of photocopy dude's "utterly calm solid presence" that nonetheless is affixed to an avatar that "[breaks] up into jittering, hard-edged pixels". And then we get to the next exciting bit, because Stephenson has just introduced us to Hypercards.

The card that pusher hands to Hiro is a Hypercard - as Stephenson explains, a hypercard is "an avatar of sorts" - by which we're explained it's an avatar in the way that it exists in the metaverse and it's a representation of information, just the same way that an avatar is a representation of a human. The hypercard is a representation of data, such data being anything that can be digitised. What's interesting to me here is that Stephenson's clearly played with Hypercard-the-real-software, and the description of Hypercard in Snow Crash means that what he took as being transformative about it was the packaging of multimedia. A Hypercard in Stephenson's world is a stack - a set of digitised information that can be thought of as a collection and navigated. Back then, the notion of linking sounds like it wasn't as clear: mainly because you're linking between resources inside one meta-resource as opposed to resources located on different parts of the network. Which is why Stephenson was *so close* to describing something like the internet because he had what a lot of people consider in some ways to be a grandparent to the web with his hypercard analogue, and also a global telecommunications network with stupendously low latency and high bandwidth. But all that was missing was the humble link anchor.

--

It's 10:46pm on the West Coast, which means in Missouri, where I was this morning, it's past midnight. I'm a little behind on replies to the notes that you've sent in, but I really do appreciate them. And if you're new to the newsletter, check out the archive at http://danhon.com/newsletter/, because there's a bunch of other stuff I've waffled on about. And drop me a note and introduce yourself.

Best,

Dan 



Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Three: Disbanded; The Responsive OS
Date: April 21, 2014 at 10:32:03 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f585=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>





0.0 Station Ident

I'm writing this at the family farmhouse in Missouri, and the cows are asleep across the road in their field. Cancer hasn't won yet. Our family is splitting in two: I'm heading back to Portland tomorrow, while my wife and son stay behind. This is not, by a long stretch, the best of any situation.

1.0 Disbanded

Last episode I wrote a little about wearables and the latest research from Endeavour Partners about how the market's doing. A scant few hours after I'd posted that, the Secret thread I'd been following[1] broke, with news reported in CNet that Nike had laid off its hardware/product engineers to concentrate on a software-only play[2]. Shortly after, countless[3] opinions[4] were issued to the extent that Nike later issued a sort-of non-denial[5] saying that while the Nike+ FuelBand SE would be supported "for the foreseeable future", they didn't say anything about any further digital sport products.

Now, Nike's a client of my employer - and I worked on the Nike account as interactive creative director when I arrived at Wieden+Kennedy Portland, and also was part of the (large, cross-agency) team responsible for the launch of the original FuelBand. And I'm obviously not going to betray any client confidence or speak to any juicy insider information. 

What I will say, though, is this: Nike and Apple have always been close, from the very first Nike+/iPod collaboration to the announcement of the iPhone 5S' M7 motion co-processor and demo of Nike+ Move, and yes, lots of people have pointed out that the two companies share Tim Cook on their boards. That's not to say that the relationship is *super* tight - Nike obviously had the heads up that the M7 was coming out so they could have an app ready, but the app wasn't *that* ready: it was a few weeks before Nike+ Moves was available for the iPhone 5S, and we didn't instead see the 5S ship with Nike+ Move built-in. 

I think Cook having a sly word in Nike's board's ear about an upcoming Apple product highly unlikely. Instead, I'd point to this para from the Recode story:

"Sources said that the decision over what to do has been debated for months within the company, due to high expenses, manufacturing challenges and the inability to make adequate margins on the business. In addition, sources note that Nike has been unable to attract as high a level of engineering talent as the business has grown."

which, again, without any insider information, would seem about right. I think that these articles from Undercurrent[3] and Fast Company[6] give too much credence to the Apple/Nike connection and that there are more pressing internal reasons for the shuttering of the Fuelband project.

Apple, though, I presume has been thinking about whatever "activity sensing ecosystem" exists, however nascent, and what good product can be made out of it that would get people to buy iPhones. The M7 is an off-the-shelf processor, one that's apparently so good at sipping power that it keeps running while everything else - the baseband and the CPU - is turned off, and we're seeing the stereotypical Apple MO of introducing new functionality or manufacturing techniques in a low-volume product to see how they go before they trickle down into everything else. Ask yourself this: at what point does the M7 start to appear in the new 5C and the iPod Touch? 

I'm also not entirely sure (ie I haven't completely thought this through yet) as to what an Apple/Nike partnership would look like. While legacy Nike+ functionality is still built in to the iPhone 5, it relies upon sensors attached to Nike shoes. The Nike+ Running iOS running app, however, is on the same playing field as every other app-based running system, ie, at the whims of Apple's iTunes Store fitness category manager. It's for this reason that you can get relatively successful apps like Runkeeper and Strava, all the way down to my brother's Zombies, Run!

Does Apple need Nike to sell iPhones? Not in the way that it helped having a partner to sell iPods in the early days. Does Apple need Nike to provide specific insight into activity measurement and monitoring, in the way that it was missing a critical part of the user experience stack like maps, that had to be provided by a third party? I don't think so, either. It can get that experience in. 

Nike, I have always maintained, had a pretty good product with the Fuelband, but one that was attached to an outstanding brand. 

So, here's my Unordered List of Reasons Why Nike Decided To Shutter The FuelBand And Digital Sport Projects:

 - Nike is still an atoms company. If you take a look at their current executives[7], there's no one who knows how to build, launch and sustain digital products, never mind good digital products. In fact, Nike doesn't even appear to have a CTO. They have technology executives responsible for things like supply chain management and their store.com, and even a "consumer technology officer" but their feet are still firmly planted in the pre-internet, pre-digital era. And you have no idea how painful it is to keep using the word "digital".

 - The brand was stronger than the product. Or: Nike have built such a phenomenally successful brand over the past thirty-odd years that you could practically stick a swoosh on *anything* and have it sell well-enough. Credit to Nike for not doing that, and coming up with products that deserved to have a swoosh on them. But the promise of a Nike wearable wasn't delivered upon by the current experience of the Fuelband.

 - The physical product had been commoditised. In some ways, Nike's attempt to deal with this - creating a proprietary activity measurement system in Nike Fuel - was smart: it had (still has?) the potential to create lock-in for an ecosystem. I disagree that "wearable sensors are making exponential leaps each month"[3]  - it's that kind of silly boosterism that is firmly within the domain of Gartner's peak of inflated expectations -  we're certainly not seeing breakthrough sensing platforms that can be packaged up and made consumer-scale en-masse - and everyone and their dog is using the same rough three-axis accelerometer plus magnetometer style platform, with added flourishes here and there like an altimeter. And when the physical product's commoditised, you either need to make sure you've got standout physical product (which is still a possibility when you have the *resources* of Nike) or make sure that you've got a great experience platform. Nike, having no history whatsoever of building great experience platforms (the original iteration of Nike+ Running being built by R/GA) and no executive-level experience of building out successful experiences, was always going to find that hard. In fact, while the physical product's been commoditised, you could even make the argument that wearable sensors are not only not making exponential leaps each month, they're in some ways *getting worse* thanks to attempts like Samsung's Gear Fit [8,9] which are cramming more technology with a worse user experience into the same form factor.

 - It was doing great for the stock price, but not so great for the bottom line. Unsurprisingly, Nike haven't broken out sales numbers for the Fuelband in roughly the same way that Amazon haven't broken out sales for the Kindle Fire.

 - The Fuelband wasn't necessarily the first "failure" from the Digital Sport team either - remember Nike+ Training[10] ("New-fangled, digital Nike+ Training shoe shuttled to discount stores") and Nike+ Basketball[11]? It doesn't look like either of those products are available anymore. 

 - Services are hard, whether you're a software company or an atoms company. Either way, it's not good when people can't get their Christmas presents working[12]

 - On the other hand, Nike got a great deal of press out of the Fuelband story two years ago and was able to tell a story about how the company was staying innovative. They have their Nike Fuel Lab[13] down in San Francisco, but again from an outsider's perspective and from the perspective of a hungry startup like Runkeeper or Strava - what does Nike have to gain versus the startup? Is Nike bringing a whole bunch of ready to activate daily active users? And how does a Nike software ecosystem work in conjunction with other measurements? Does Fitbit have to pay a license fee to Nike if it wants to display NikeFuel? 

 - Ultimately, they don't know what it's for. I mean, in broad brush strokes it's clear that they know what it's for: but the world and the competitive market is a lot more complicated than it was two years ago, and it shows no sign of changing. It's interesting to note that the Fuelband is part of its own category at Nike and isn't part of something like Nike Sportswear, where it would have more of a fashion and activity story. It's also not promoting a story of wellness, and is going for the younger crowd, something Nike traditionally does. But: where's the long-term play? If Nike were taking a page from a startup playbook they would've gotten a tonne of product out there at a highly competitive price (while doing the tricky job of maintaining the prestige of the brand) in order to build an ecosystem. But the product and ecosystem kind of looks like a halfway house. It doesn't feel like there's a big enough audience for Nike to attract third party developers and for a long time, the only way to generate Fuel was via Nike's integrated solutions. If you were going to develop something that *used* Fuel, though, that was fine for their API, but the problem there was that the install base was never going to be that big. And if the install base wasn't that big and you had to work with a big corporate, why not start your own and grow from there? 

So that's a bit of an unordered list. But there are a bunch of questions raised, too.

R/GA made a big deal out of its collaboration with Nike and have remained suspiciously (and contractually, I suspect) silent on the issue. The Fuelband won a tonne of awards at Cannes and everywhere in 2012/2013 because it was the "new advertising" - a partnership with an agency that had created a physical product, a service and what felt like a new category for a brand. But then the rate of innovation slowed down and, well, it didn't feel like Fuelband was iterating on its software platform as quickly as its competitors were. So what does this mean for an agency like R/GA when one of its biggest wins turns out to be shuttered by its client? 

If Apple does indeed come out with an iWatch this year (unlikely, I think, and certainly not a product that's going to satisfy the quite unreasonable analyst and rumour mill demands that Apple are now subject to), then it'll be interesting to see how the rumoured Nike/Apple partnership pans out. Will Nike get pride of place as a pre-install and the iWatch automatically, without an app store download, calculate Nike Fuel for you? My bet is on no. Nike will have to play by the same rules as anyone else and rely on a user-installed app on either the watch or a tied smartphone to convert what the watch measures into Nike Fuel. 

It'll also be interesting to see what comes out of the new iteration of the Nike Fuel Lab - is Fuel, as some say, a viable Activity Graph that can support a vibrant third party ecosystem? Again, I doubt it, if only because that graph relies on two layers worth of conversion: once into the Nike Fuel ecosystem and then again into the third party developer's apps and services. The way Nike's behaving at the moment, I'm not entirely convinced that third party developers will see it in their best interests to help Nike grow an ecosystem when they're doing quite well growing their own. 

[1] https://www.secret.ly/p/uxaztevdcicghcabkkczuzkpkz
[2] http://www.cnet.com/news/nike-fires-fuelband-engineers-will-stop-making-wearable-hardware/
[3] http://responsive.org/2014/04/nike-and-the-future-of-the-fuelband/
[4] http://recode.net/2014/04/19/hardware-is-very-hard-why-wearables-arent-working-yet/
[5] http://recode.net/2014/04/18/nike-denies-fuelband-shutdown-but-layoffs-could-reveal-new-cracks-in-wearables-market/
[6] http://www.fastcodesign.com/3029400/why-nike-is-probably-killing-off-the-fuelband
[7] http://nikeinc.com/pages/executives
[8] http://www.dcrainmaker.com/2014/04/pinnacle-samsungs-activity.html
[9] http://www.theverge.com/2014/4/14/5612832/samsung-gear-fit-review

[8] http://www.oregonlive.com/playbooks-profits/index.ssf/2012/10/new-fangled_digital_nike_train.html
[9] http://www.wired.com/2012/08/nike-plus-basketball/
[10] http://www.oregonlive.com/playbooks-profits/index.ssf/2013/12/temporary_nike_fuelband_s.html
[11] http://www.nikefuellab.com

2.0 The Responsive OS

As part of my reading on the Nike Fuelband fallout, I happened upon this essay by the team at Undercurrent on their latest product, the Responsive OS[1]. There's something about it that sits uneasily with me, and as I think about it a bit more, I think it's because there's a strong tie to that most wonderful of things, the Californian Ideology, and the Responsive OS seems like it's a bit of a side-line cheerleader, breathlessly espousing the Valley Way Of Doing Things, or, at least, The Startup Way Of Doing Things. I'm mostly always suspicious about management and strategy consultancy, mainly because in my experience a lot of the organisations peddling it promise a lot and deliver a little, with it always being easy to blame on the client (whom, a lot of the time, rightly shares some of the responsibility for failure to deliver). So I thought it'd be interesting to go through Undercurrent's Responsive OS manifesto.

Undercurrent counts as proponents of the Responsive OS (and how up-to-the-minute-but-not-quite to sell clients an "operating system" as a manner of running their companies: one would think that the dominant metaphor of the day would be more like a "platform") companies like Tesla, Amazon and Instagram. 

There's a bit of cherry picking here, of course. For every example of a software company eating the world (and I should make clear that my flag is firmly planted in the software-eats-world camp), there's a counter-example that doesn't follow the same sort of "behave like a startup" rhetoric. And, of course, there's the self-reinforcement: there are as many examples of software-eating-world companies that don't follow the rhetoric or fit the same plans, either.

The implication - or threat - is that if you and your company don't "behave like a tech startup" then you're going to get disrupted. This is the same kind of Digital Ninja talk that we've seen for the past twenty years or so: a massive tidal wave of change is coming and if you don't listen to us, you're going to get subsumed. A lot of careers have been made, and less have been destroyed, peddling One True Way to survive the coming digitisation apocalypse.

I'm not going to disagree that "technology - software in particular - has had a destabilizing effect on traditional business models." That's what technology does, and it's what technology has always done, so we can skip that particular content free sentence. What comes next is a little disingenuous, I feel: the proposition that "the proliferation of personal computing power has leveled the playing field in almost every industry." Where we can agree is that Moore's Law has resulted in both the proliferation of computing power *and* communications capability, and what that's done is *changed* the playing field. But by no means has it leveled it: if it had done so, then everyone would have an equal chance, and it's clear that all participants don't. There are massive structural barriers to entry that aren't solved merely by technology, and in that respect, the Valley's boosters aren't wrong. There's certainly a lot of regulation out there: ask anyone in the medical devices space or Airbnb or Uber, and there will be regulation out there: as disruptive as a startup like Airbnb is (and I'm not arguing that Airbnb isn't), it doesn't mean that regulation isn't or shouldn't be forthcoming (nor does it mean that the current regulation in force is proportionate). 

What seems like a weird non-sequitur to me though is when the manifesto states that "It used to be that the best day to start your business was yesterday. Now, due to the constant expansion of what you're able to invent in your garage, tomorrow is almost always a more advantageous starting point." - I don't know what to do with advice like that. It's certainly not actionable: so I should put everything off until tomorrow, because systems and processes will be more efficient then? The best business is one that's started, period: and that *is* agreeing with the startup rhetoric, because shipping product always beats an unexecuted idea.

There's no disagreement from me that there are a bunch of processes that are unfit for competing in today's world. But that doesn't mean that all processes are unfit. I can certainly broadly agree that "legacy processes that enforce bureaucracy, command-and-control structures, waterfall development, and risk management are still largely the standard among big corporations" but then management has always been an art and it's always been difficult. And sometimes, enforcing risk management can actually be useful.

We learn that today's "fastest growing, most profoundly impactful companies are using a completely different operating model" which again, in most circumstances, feels like the climbing the summit of the peak of inflated expectations. And as an aside, perhaps this is why I have that uneasy feeling about what Undercurrent are espousing: I intensely dislike those who engage in promoting that peak: because they're the ones who feel like they're ruining it for everyone else. If it weren't for the peak, we wouldn't have the trough of disillusionment. 

To be sure, this *is* a manifesto, though: it's a rallying call to "hack together products and services, test them, and improve them," all while your competition edits PowerPoint (not even Keynote!). These excellence-driven companies are "obsessed with company culture and top tier talent" and emphatically pursue "employees that can imagine, built, and test their own ideas" - but, presumably (and crucially) not work in teams? These companies are "maniacally focussed on customers" and "hypersensitive to friction". They are, the call goes, "the first generation of truly responsive organizations" - implying, of course, that no other organizations have been truly responsive to customer needs.

The inescapable conclusion, so the pitch goes, is that if you want to be a successful company - a small one, like Medium, Hipchat, Circa, Willcall and Quirky, or a big one, like Airbnb, Dropbox, Evernote, Uber, Tesla, Square and Jawbone, or a dominating one, like Amazon, Google, Facebook, Twitter and PayPal, then you need to be a Responsive Organisation.

The key to all of this is Undercurrent's Responsive OS - almost like a three-ring binder manual for converting your Legacy Operating System into a dominating, globe-spanning, cloud-enabled Responsive Organisation fo the future. It means you need to adopt a "visionary (not commercial) Purpose that guides an agile (not linear) Process that enables People who make (not manage) Products built to evolve (not built to last) which become Platforms for the world (not just your company) to build upon."

All of which is easy to write down. It's naturally much harder to do in practice. Otherwise, everyone would be doing it, right?

A Responsive Organisation's Purpose is probably the most agreeable, and in my mind, nothing more than a tweaking of that trendy 90s fad, the Mission Statement. The tweak, of course, is that Mission Statement: The Next Generation is "something bigger" than a mere commercial purpose, but then, weren't mission statements supposed to be bigger than mere commercial purposes, too? There's a part of me that wonders if there isn't confusion between causation and correlation: that of course people are attracted to world-changing agendas - do you want to sell sugar water, or do you want to change the world? (and we all know how that instance turned out) - Moore's law and its inexorable, finally, nearly, maybe this year or next it will run out drive for faster, cheaper processing and communication was the thing that *enabled* these purposes in the first place. Perhaps instead the Purpose is just the reflection of those who "got" the concept of software eating the world first - that the Californian Ideology adherents of Kevin Kelly's manifesto fervently *did* believe that the libertarian-utopian connected future would change the world, and set about making it happen - and they were closest to the coal face.

The Process part is perhaps the one that felt most galling. I can't see what exactly the manifesto is trying to get across here other than, if you're a company like Netflix and Valve and only hire the best people, then you can get away with not needing any management, because "rigid Process is unnecessary or even detrimental". And while you're not necessarily going to get scores of people arguing in favour of more process, the places where you *will* find that happening are in (surprise, surprise) areas like the recent Github Incident where it turns out that just hiring a bunch of "best people" and assuming nothing bad will happen is at, well, best, shockingly naive and at worst, the quickest way for everything to go south in a blaze of social media infamy. Unless, of course, part of your plan is hiring "the best people at managing who don't look like they're managing" in which case, you haven't really learned a thing. Oh, and process? Turns out it is good for some things: and if you guessed that I'd be including a link to NASA's Shuttle software team, you get to take a drink[2]. You know what, though, you keep hacking away at things: I bet that OpenSSL you're using is awesome right now. 

The People part is only slightly less galling. It fetishizes "makers", because that's the MO of the Californian Ideology - that if you're not producing product or service, then you're just wanking around and a waste of space that probably would be better of being converted into computronium sooner rather than later. This section appears only to be saying "be careful and hire only the best people" which, you know, isn't that bad advice really. But what really gets me is the false argument that "a typical day in corporate America is peppered with meetings and PowerPoint presentations. Planning has become the work. Intuitively, we know that's not right", which rhetoric is easy to blow holes in because a) not all meetings and not all PowerPoint presentations are a waste of time, and b) apparently I'll be painting a target as first against the wall when the revolution comes for piping up and saying "hey, planning might actually be useful you know" and c) "intuitively, we know it's not right" is the kind of statement that begs holes blowing into. 

In this world, "[Makers] are people who have skills (as opposed to credentials)" which again leads you to wonder: what sort of organisation is hiring unskilled credentialled workers and do they deserve to survive, and also the unspoken agenda here being, hey, I get to define what "maker" is and what the skills are that count. The example that's pointed to is Valve and their now-relatively-famous staff handbook, and the thing about Valve is that while it is undoubtedly a fantastically successful company, it's also not one without its detractors in terms of its company culture. Valve, it turns out, is just as prone to cliques and just as prone to mismanagement and miscommunication as any other company, and it turns out that just hiring the best people and empowering them isn't the simple rule to success that's being presented.

A lot of the work in building large-scale services and products is in internal communication and making sure everyone knows what they need to know and what direction they're heading in. It's easy for this in small startups because hey, everyone's in the room, but what often gets forgotten is the implicit nature of communication. And it turns out that ensuring communication is happening is no small task. Do those people count as makers? Presumably they aren't as important. 

The Product layer is one that seems the most sane and reasonable. There's a lot to be said for shipping, and there's even more to be said for shipping, getting feedback and then iterating on that feedback. There's no argument from me here.

The Platform layer is for those Responsive Organisations who genuinely do want to take over the world. We've got a fairly rudimentary description of what a platform is here: it simply "encourages others to build, play and/or iterate on top of it." This is almost like the super simple building block, because it's relatively easy for a platform to be built, it's a significantly harder thing for a viable platform ecosystem to spring from that intention. A phrase describing platforms as "shared innovation engines that outsource costly and uncertain discovery processes" turns me off though, if only because it sounds like consultant-speak and also because what's being talked about here is merely one aspect of the benefit that a platform brings without the caution that a successful platform is a finely-balanced one with a number of factors contributing to its success. Sure, some successful companies *have* platforms, but I'm not entirely sure if you could say that Airbnb and Uber have necessarily "turned the physical world into a platform for millions". At least, not yet.

The clash, at the end of all of this, is that on the one hand Undercurrent's piece ends with the call that "this method of doing business needs space to breathe and mature, before it spreads like wildfire" while simultaneously lacking the restraint to refrain from begging everyone to spread it like wildfire lest those who ignore it be swept aside. 

It would be unlike me to talk about something like digital transformation of a business without mentioning, again, the work of the Government Digital Service in the UK. They have, for free, actually given away pretty much the keys for implementing most of what Undercurrent call their Responsive OS for free in their Design Manual[3]. And while it may be because I'm British, the lack of boosterism and pep is refreshing to me. Look, just read Russell Davies' thing again[4]. Or watch Tom Loosemore's talk from Webstock[5].

My point is this, and I think it's a trend emerging from the last few episodes. We've known what to do about "digital" for quite a while now. There isn't a magic bullet. There's simply a question of doing the hard work. There isn't necessarily a pattern that can be followed, and it certainly doesn't have to be one that hails from the West Coast, though it can be inspired by their success. Perhaps the easiest bit to digest, and the easiest bit to understand, is that the strategy is delivery. That's it. Work backward from there. The Agile is Dead non-manifesto[6], that seeks to clear away all of the cruft and crap that's grown around it, is clear enough and you don't *need* more than this:

 - Find out where you are
 - Take a small step toward your goal
 - Adjust your understanding based on what you learned
 - Repeat

That's it. No high-fives required.

[1] http://www.undercurrent.com/responsive-os
[2] http://www.fastcompany.com/28121/they-write-right-stuff
[3] https://www.gov.uk/service-manual
[4] http://russelldavies.typepad.com/planning/2013/04/the-unit-of-delivery.html
[5] http://www.webstock.org.nz/talks/institutions-an-internet-survival-guide/
[6] http://pragdave.me/blog/2014/03/04/time-to-kill-agile/

--

As ever, I appreciate your notes and, in this particular case, your rebuttals.

Best,

Dan

Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
  

From: danhon <dan@danhon.com>
Subject: Episode Sixty Two: Wearables Unworn; Look At What They Want
Date: April 18, 2014 at 4:51:50 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f3wt=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

1.0 Wearables Unworn

Via the Guardian, news from Endeavour Partners in a white paper that one-third of people abandon their wearables after about six months[1]. Endeavour reckons that one in ten US consumers (from households with internet access - at least 75% of all households) have a "modern activity tracker" - presumably a dedicated one, and not including smartphones. Unsurprisingly, they skew male and young, and the majority are focussed on fitness and health. Even worse than the research revealing that one-third have stopped using after six months, more than half who *have* owned one no longer use it. 

So here's a bit of anecdata for you: after my initial experiment with self quantification[2], I too stopped using my devices after roughly six months. Turns out that *less* than six months is enough to initiate a habit, or cluster of habits like diet and exercise, but that in my case, any number of events (a family illness, my partner moving away to deal with the family illness, a baby on the way and a job change) all at the same time are reasonable triggers or opportunities to drop out of those habits. 

The white paper goes into a bit of detail for three factors that might increase long-term engagement but at this point I start to hear gamification alarm bells going off in my head. For example, there's the tactic of baby-stepping goals and steadily increasing the amount or type of work to introduce new challenges, but right now, that just reminds me of grinding in WoW or yet more devices that will help people ascend the same hedonic treadmill.

One other thing that I'm still a little fixated upon is what happens when wearable devices are successful. From a mental health point of view, one of the things that I realised about myself was that I was only really happy when numbers were trending in the right direction. When blood sugar and weight were coming down, that was great. But the wearable systems that we have at the moment aren't particularly good (and obviously that depends on how you define 'good') for what happens when the numbers are trending in the wrong direction. Or, what happens when you don't need to progress to a goal state, but that your goal state is instead a *steady* state. For me, stereotypical language like the Nike Fuelband includes exhortations to Crush It and Win The Day, which (again, this may be idiosyncratic) imply a relentless striving for betterment that may not be each and every user's goal. Maintenance, as opposed to excellence, requires a different type of design.

[1] http://endeavourpartners.net/assets/Wearables-and-the-Science-of-Human-Behavior-Change-EP4.pdf
[2] http://danhon.com/2012/04/28/myself-quantified/

2.0 Look At What They Want

I am, obviously, still thinking about design, empathy and the internet of things. There are a bunch of thoughts flitting about in my head, and in some ways it might just be easier to jot them down:

 - Moore's law applied without due consideration or smartness means the measurement of everything that can measured: which may lead to naive optimisation or just a local, peak maxima that's not necessarily the fittest peak. For example: cries for services like Uber to minimise the interaction needed to have with the flesh-printed actuator (er, human driver) that will take you to your destination. Sure, that's a service-level minimisation-of-interaction optimisation but it's one that strikes me that has larger second-order effects. You might say that you can mitigate stuff like that by having "good designers" who can take into account the tradeoffs, but hey, that means that we need a bunch more good designers.

 - These devices aren't necessarily anthropomorphized. They may well end up being, because anyone who's trying to maximise getting data out of human beings is going to quickly realise that evolution left an unsecured back door that would be useful for social engineering in the future: we like to help other people and we trust things with faces. We can't help it, and we spot them anywhere.

 - In fact, the whole phrase "evolution left an unsecured back door" strikes me as a wonderful way to explain and think about the way we're wired to recognise and respond to a) other humans and b) other human-type things. The whole concept of humans making human-looking things to explicitly take advantage of those back doors is fascinating. But, I expect, not an original thought, and hey, conmen have existed forever. 

 - But we're not conning you, right? That's the promise. We come from the internet and we're here to save the world. To bend it to our will. We will apply the pure power of the algorithm, which can never go wrong, can never sleep... "Watching John with the machine, it was suddenly so clear. The Terminator, would never stop. It would never leave him, and it would never hurt him, never shout at him, or get drunk and hit him, or say it was too busy to spend time with him. It would always be there. And it would die, to protect him. Of all the would-be fathers who came and went over the years, this thing, this machine, was the only one who measured up. In an insane world, it was the sanest choice."

Of course, the Terminator is a fictional machine with stupendously good AI. 

 - And most people, most companies aren't *actually* trying to bring about some sort of SF-esque dystopia, right? I mean, General Mills is only trying to limit its liability in a litigiously hostile world and "all the other corporations are doing it" - even Dropbox did it the other day, remember - so when we're talking about legally waiving your right to sue when you use an internet connected washing machine, hey that doesn't matter so much because your washing machine is awesome and knows how to order replacement parts. 

 - The big bad here isn't, I don't think, technology at all. Technology is just the easy target for humans being humans. The promise of course should be that the internet is our best bet so far for unmediated, honest communication between parties (even if those parties are honestly being dishonest, I guess), and that we should try and preserve that. And, to an extent, the internet kind of tries to route around damage like that, or at least is so widespread and so weakly diffuse (weak in the sense that it's so distributed that a vulnerability like heartbleed can fuck us over because we're not centralised enough) that it's kind-of easy enough ish to boost signals that aren't desired by the evil corporations (not all corporations, just the evil ones). 

 - In that way, the internet is our best hope for user-centric companies and services, right? Because the internet is just a connection machine that just opens a port here and connects it to a port there and stuff just flows between the two. And right now, most - I think? - of that traffic is human-initiated. Like Ev said at XOXO, it's a desire-fulfilment machine (and that's a rather depressing way of looking at it).

 - Or, the deal is this: if O'Reilly says that the Internet of Things is made cooperatively with humans (and I believe him - it is), then it's cooperatively made with *people*. And, I hope, the people, services and companies that are going to win are the ones that remember the people part. I don't particularly want to live in a world where I'm considered to be a lowest common denominator fleshy actuator or endpoint bidding for work that is requested by either another fleshy actuator or algorithm. On the other hand, algorithms might make better bosses.

I haven't finished reading Kevin Kelly's What Technology Wants. I have a copy that's been sitting on my beside table for months now. I rather think that if the supposition *is* that technology is our servant, rather than our master, then Kelly needs to have another think about what the Internet of Things and its protuberances like the Quantified Self are doing. Sure, I can *choose* to use something like a FuelBand to maintain my wellbeing, but I should ask what the FuelBand wants, too. Right now, my FuelBand wants access to all of my movement, every second of the day in service of its goal. But its other goals are opaque. It may well want to lock me into an ecosystem. It may well want me to move every hour. The point, as I'm reminded from conversations with friends far smarter than I, is that it's a lot easier to deal with servants when you know what their motivations are and why they're doing things. You can make that interrogation process easy, or you can make it hard, or nigh-on impossible and opaque. 

--

Have a good weekend,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Sixty One: I Sense Feelings, Captain
Date: April 17, 2014 at 9:43:43 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f3f5=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

I am about thirty minutes north of Kansas City, Missouri. I didn't plan on being here, but family emergencies have a habit of sneaking up on you. This one, though has been sneaking up on us for the last two years and, sadly, frustratingly looks like it might be coming to an end. Cancer, as they say, is a bitch. So my mind isn't how it normally is, but you know what, I'm going to keep doing this anyway. Because, fuck cancer.

1.0 I Sense Feelings, Captain



Tim O'Reilly wrote a piece[1] the other day in advance of the O'Reilly Solid Conference[2] where he talks about the Internet of Things and Humans, puts forward a framework for thinking about Things of the Internet ("sensors + network + actuators + local and cloud intelligence + creative UI for gathering both explicit and implicit instructions from humans"), and then goes on to talk about a shift in the way we think about Things of the Internet by making sure that humans are part of the fabric of a Thing of the Internet device or service.

And this is where O'Reilly's spiel falls down a bit for me, and I get to mount my current hobby-horse of pointing out the empathy gap in yet more things. A while back, a tweet attributed to O'Reilly proclaimed that the new startup teams would be comprised of data scientist, industrial designer and software programmer[3]. Of which, sure, but the thing that struck me (as I'm sure you can work out by now) was the curious lack of where understanding user need would come from in that new three-pronged startup team. You could make an argument that an industrial designer couldn't be a particularly good one if they didn't have capacity for empathy with their audience, but then that almost seems like circular reasoning or something of a tautology: you're presupposing that empathy is a desired trait in the first place and thus mandating that each role be able to fulfill it in some way.

My spidey-sense goes off because it's my gut feel that when O'Reilly talks about an "industrial designer" he's not really rating the capacity for empathy that highly. Or at least, not explicitly. And there's obviously the manner in which caring about the user is devolved to one person's responsibility as opposed to everyone's responsibility, but I fully admit that I could be reading into what he's said. 

But that spidey-sense is augmented with O'Reilly's piece about the Things of the Internet. Now, this might just be a byproduct of the way that certain people are able to look at systems and abstract them and reason about them as a whole without getting bogged down in the minutiae, a sort of 30k feet systems-view that shaves the edges off things so that they can work together properly. But my point is that things don't work properly, and that it's weird when humans actually see themselves through the curtain as being treated like cogs and components in a machine. No one, I don't think, wants to be thought of or treated like a cog or a component in a machine. We are all of us wonderful and special unique snowflakes. 

It's the abstraction that bugs me. O'Reilly talks about these new Internet of Things and Human systems as humans and things "cooperating differently", but the language that he uses feels less like co-operation and more like, well, not entirely like exploitation but there's certainly an asymmetrical relationship going on, not least of which one that is, I feel, more opaque on the thing-end than the human-end. Humans co-operating with other humans are a known quantity, even if they're frequently an unpredictable one because humans are opaque systems themselves. But at least we've had a few million years of evolution to get that bred into our system, if you will. Humans co-operating with algorithms that have human design (and sometimes, not so human) design behind them is an entirely new thing, and it's not even entirely clear if the co-operation is one that's enabled with consent. 

I have to admit that this is all a bit disconcerting to me. I am as much into technology boosterism and the belief that Science Will Improve Things and that, broadly, Capitalism Is A Good Thing (modulo Piketty's book[4]) and would under other circumstances be totally excited about Real Genuine Spimes erupting into our world any day now. 

But the thing is, they're Real Genuine Spimes from Real Genuine Corporations and some of them behave more like Sirius Cybernetics than, well, Nest. 

I guess my point is this: it's one thing to have corporations with sociopathic tendencies in the general environment, and hopefully those tendencies are somewhat alleviated thanks to the decreasing cost of communication. I would like to think that the successful spimes are going to be the ones that are empathic in the first place, and, in a subtle difference from O'Reilly's position in terms of being designed to take advantage of inputs from humans, are instead designed to be genuinely collaborative and co-operative with *people*. The next sentence might feel a bit inflamatory, but I feel like "humans" is to "females" as "people" is to "women", and that it's not the best mindset to be starting from when you think of people as actuators for the service that you're designing. Because, you know, actuators tend not to have feelings and opinions about things or theory of mind about what the other actuators might or might not be doing. 

Or, even more bluntly: on my empathy crusade, it would be nice if the Internet of Things revolution resulted in a profusion of *more* empathic objects in the world, rather than an orgasmic emission of sociopathic internet-connected objects that enforce stupid corporate policies like tying brand interactions to the contractual waiver of the right to sue[5], and let's be clear: those corporate policies and the way they're communicated are exactly the kind of dumb sociopathic solely self-interested behaviour I'm pissed off about.

It's different when personalities are given physical form, I think. When they're rezzed into the world and instantiated, they can so much more easily become the target of emotional outbursts. And when behaviour increasingly tends toward the sociopathic, along with devices that don't allow for flexibility, I get super excited about yet another wonderful dystopian future.

[1] http://radar.oreilly.com/2014/04/ioth-the-internet-of-things-and-humans.html
[2] http://solidcon.com/solid2014
[3] https://twitter.com/landlessness/status/443818684520624129
[4] Capital in the Twenty-First Century: http://amzn.to/1jPbtfi
[5] http://www.nytimes.com/2014/04/17/business/when-liking-a-brand-online-voids-the-right-to-sue.html?_r=0

--

It's been a long day, and I haven't had any sleep. If anything, I'm more angry than I was before, but I did appreciate all of your notes and attempts to cheer me up. So, please send me more.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Sixty: We Have Always Been At War; Our Independence Day; Spimes, Duh
Date: April 16, 2014 at 12:59:45 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f2ih=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

It's not sunny in Portland anymore, but I'm excited because I get to go to O'Reilly Solid and see a bunch of interesting people who will make my head explode. If they don't, I'll ask for my money back. If you are going to O'Reilly Solid too, it'd be cool to meet up and not in the slightest bit creepy.

1.0 We Have Always Been At War



Last episode I talked about the Chief Empathy Officer, and in case I wasn't clear, I want to make it abundantly so this time: I think having a chief empathy officer is a stupid idea, exactly the kind of tactic that makes it look like you're jumping on a bandwagon and fixing something without fixing anything at all. It's almost as bad as having a hived-off UX team and exactly the kind of thing where, as Matt Locke points out, a general good practice in business is promoted up to the C-level suite so that you don't have to do deal with it anymore. 

Let me put it clearly: no one person in an organisation should have sole responsibility for "empathy", especially in a manner that's going to make it easy for detractors to make fun of it. Instead, customer-centricism is something that needs to be distributed throughout, from the bottom-up as well as top-down

Leisa Reichelt tweeted at me in response to that episode the concept of 'exposure hours'[1], which is such a blindingly simple idea that you're kind of surprised (and then when you think about, it understand why) more companies or organisations don't use it. It's just this: the more time your designers or product owners spend with end-users, the better designed those products or services tend to be: "There is a direct correlation between this exposure and the improvements we see in the designs that team produces." And this isn't just for design personnel - as soon as non-design personnel were included in the contact hours, the entire group would fall together. This is as much an argument for audience/customer contact across each functional unit or team across an organisation. 

An aside: there's a wonderful tv series (it's true! Such things exist!) called Back To The Floor[2] which started in the UK in which, for entertainment purposes (and the occasional tear-jerker), C-level executives are forced to take entry level jobs in their organisations and are bluntly confronted with the humanity of their employees. Because, you know, living in a bubble.

At this point my brain wanders off and looks at the anti-pattern. Capitalism is all too often thought of as being combative and the American strand in particular borrows heavily from sports metaphors (crushing it, home run, left field, sprint). It's all anyone can do to try and impress that often capitalism doesn't necessarily have to be a zero-sum game, and that type of thinking feels like it's at odds with a customer-centric or empathy-driven organisation. 

The anti-pattern, of course, is dehumanising your enemies so you can make it easier to kill them. Losing shopkeepers with face-to-face interaction dehumanises customers. Interchangeable call-center workers dehumanise customers. Reducing a customer to a statistic and traffic-light feedback mechanisms. In essence, putting up barriers and abstracting away difficult-to-quantise or measure or digitise measures that seek to make the customer experience more predictable and scaleable.

In some ways, you can get at this empathy intuitively and by having strong direction - if you're lucky. And by lucky, I mean *really* lucky - you're the kind of person who's a one in a million Steve Jobs type, and remember even *he* got it wrong with things like the hocky puck mouse and, well, iTunes, where the strategy was right and the initial user experience (plug in a first gen iPod, FireWire your songs over) was great but then degraded over time with lack of focus. And Jobs, well, Jobs was just making sure that he understood *himself* really well and appeared to be pretty true to that and wouldn't stand for any shit. So at least you get clarity of vision for products like iPhone or iPad that way.

But for everyone else, and for everyone else, chances are blindingly highly likely that you're not Steve Jobs, in which case research to understand the audience and the user need is absolutely critical. So the question is: why do hardly any organisations do this?

It's interesting because for engineers and entrepreneuers the first product is often the "scratch your own itch", which makes sense, because you understand your own itch and you know exactly where it's itching and what you might need to un-itch yourself. But when that product or service starts to grow outside of that market or that population, then having the ability to understand the people you're interacting with becomes super important, I think. 

There are ways to mitigate needing to have a super-developed corporate sense of empathy, though. You can use network effects to tie people in social applications, you can use local monopolies like in fixed-line telecommunications, and plain-old regulation of competitors and limited service in air travel. But the flip side of Moore's Law is that communication and computation has gotten ever cheaper, so all of these organisations got "social", which the consultants remind us is all about having "conversations". And the thing about having conversations with an organisation that lacks empathy, or lacks the ability to act upon empathy, is that over time, they end up feeling like a sociopath.

For those of you who have been following along at home, the protracted amount of thinking in this area may or may not have something to do with one of my side projects.

[1] http://www.uie.com/articles/user_exposure_hours/
[2] http://en.wikipedia.org/wiki/Back_to_the_Floor_(UK_TV_series)

2.0 Independence Day

Never mind taking out our satellites and blocking our ability to bounce signals around the world to communicate with each other, here's what an alien invading force needs to do to cripple us: perform static analysis on all of our code and find all of the bugs thanks to C's null terminated strings. Every single thing on the planet crashes. The end. 

Or:

Terminator, but Skynet is written in C and it's trivial to find an exploit to bring the system down.
Elysium, but the station control software is written in C and it's trivial to - oh wait.
Star Wars but the Death Star runs on a SCADA implemented in C and it's trivial to bring the system down.
Star Trek but the Borg base operating system runs on C and you can easily access the sleep subroutine.
The Matrix, but the Machines run on C.

and:

Jurassic Park, bu the park control systems run on C - oh wait.

3.0 Spimes, Duh

It's rather embarrassing, but @debcha pointed out that what I'd basically described yesterday with the whole Kitchenaid beater rant (for which thank you the people who replied on Twitter saying that this *exact* thing had happened to them, and also to Rachel Coldicutt for saying that she had the opposite experience with Kenwood Chefs) was basically: spimes, duh, which is embarassingly only because I remember being sat in the audience when Bruce Sterling was busy ranting about them at SXSW years ago.

Which makes this *even more frustrating*: it's one thing to have imagined technology out of grasp ten years ago (smart objects, sure), but another thing to have a pretty complete and utter failure at the user experience of the peripheral experience or "stuff I want to do with the thing I bought, what are those things and how do I do them". I mean: it's a fucking mixer. At some point, I might need new or different beaters for it. How hard is it to imagine that someone might want those things and then to act upon that need? 

And at this point, I'm not even talking about the six attributes that Wikipedia's writeup of Sterling's Spimes posit[1], I'm just talking about stupid simple stuff. What is this. What does it work with. Where do I buy it. This isn't even cradle-to-the-grave stuff, this is elementary "I'm selling you a machine that is designed to work with other things, can you at least tell me what the other things are."

Sure, there's a stupendously complicated version of this which would involve things like giving every object and collection of objects a unique URL, which to be honest doesn't even have to be that hard, you just have to do it on the manufacturer/sell-side and then "let Amazon figure it out", I mean I don't even need to remotely identify objects over short range if I have the receipt for them. Identification is a pretty much solved problem at this point, and a use that most of us can even agree that QR codes or image recognition would be good for. But I suppose what gets me really irritated is that Kitchenaid are selling what we would call an "ecosystem" full of objects and parts that interrelate and work together and they can't even get that fucking bit right, but at least the marketing worked and we have a cinnamon red mixer in our middle-class kitchen.

And what *really* annoys me about this (I mean, even more), is that the cognitive overhead of all of this crap gets foisted on me, the consumer, who's too busy to spend time figuring all of this stuff out. Great, I can have an awesome mixing experience, but god forbid if anything related to that mixing experience is awesome too. Now I have to spend all this time figuring out what beaters to get. Actually: maybe I should just buy a Kindle Fire and use MayDay and hold it up to the stuff I bought on Amazon and just plead at the Real Live Human Attractive Red-Haired Woman WHAT BEATERS WILL WORK WITH THIS I JUST WANT TO BUY THEM.

[1] http://en.wikipedia.org/wiki/Spime

--

It's Wednesday and it's mid-week and I ended the newsletter on a rant so now I'm still angry. Please send me examples of why I shouldn't be angry, but I bet you can't, which is why I'm angry in the first place.

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Nine: Why Is This So Hard; Dependency; Chief Empathy Officer
Date: April 15, 2014 at 4:21:22 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f1up=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

I still haven't seen Captain America: Winter Soldier, but I have seen The Lego Movie twice. I have seen That Episode of Agents of S.H.I.E.L.D., so hey, Hail Hydra. I haven't changed any passwords yet. This episode should be going out to 764 subscribers.

1.0 Why Is This So Hard



Never mind disruption, I just want the easy stuff worked out. I have a KitchenAid mixer and one day we accidentally put the aluminium beaters in the dishwasher and now they are Not Burnished and Flaky and generally look like they're going to Kill Us if we use them again. This is what I want to do: buy new beaters.

To do that, this is what I have to do:

1. Log into my webmail and search for "kitchenaid receipt" because, hey, I don't remember the model number of the Kitchenaid Mixer I have other than the fact that it is Red.

2. Page through a whole bunch of results which I must read the excerpts of until I get to the Amazon email.

3. Click the link and then log into Amazon whereupon I am invited to review my purchase which is not what I want to do.

4. Give up and search for "kitchenaid beaters"

5. Look and see what models the beaters I'm looking at will work with.

6. Look up the model number of my mixer again, because I have forgotten it.

7. See that the model numbers are not the same.

8. Give up.

I mean, seriously. I probably should have Registered My Product or something but Jesus Christ all I want to do is buy some new beaters and essentially give Kitchenaid and Facebook more of my money and why are they making it so difficult? This is stupendously easy to do CRM and all it requires - *ALL* it requires - is for someone, somewhere, to know what parts work with what machines and to say: hey, you bought this thing, here's all the stuff that works with it. 

And you know what the really stupid thing is? It appears to be that the particular model I bought was a special model for Amazon or something so when I search for it, only that model comes up and not an official Kitchenaid listing and hey, I JUST WANT TO BUY SOME BEATERS.

So yes, hurrah, exciting opportunities for disintermediation and disruption but holy baby jesus all I want to do is actually have a reasonable customer service experience from someone I have spent a not unreasonable amount of money with. 

At this point, and I realise this is heresy, but I would actually be OK with a fucking QR code on the underside or side of the mixer that I could scan and it would be all: hey - here's everything you need to know about this mixer, forever, and the stuff you can buy for it. Done. But no, we can't have that because that would be a Nice Thing and fuck nice things.

I can't even easily find on the Kitchenaid site a) my mixer or b) when I have found my mixer, the parts I can use with it. Nnngh.

And Amazon - even Amazon - doesn't get this right. Amazon knows what mixer I've got and can't easily show me the stuff I can buy with it. It can show me stuff that other people have bought, like I don't know, waffle makers and sausage casings, but showing me peripherals that I can actually use? Oh no. No no no.

So here's that dumb startup idea: product lifecycle management. Just be an easy way to graph all of the product relationships a manufacturer has. This product works with these other products. These are substitutes. It's hard work, but no one else is doing it, and then you end up with a stupendous database of what-works-with-what. 

So sure, e-commerce is a solved problem if you have Amazon sell stuff, but product life-cycle stuff is still an unholy mess and will get worse (but should get better) now everything is plugged in.

2.0 Dependency

Nat Buckley has an essay[1] talking about the internet of things fostering a network of dependent things. This isn't necessarily a new argument - witness the reaction from core gamers about how the Xbox One would require a persistent network connection to phone home. Of course the distinction there is that you have a population who are used to devices that are standalone with optional network connectivity, as opposed to the connection-native devices that we have now that aren't possible *without* connection to the internet. BERG's Little Printer and Cloudwash naturally fall into those camps; they're what BERG is interested in of course - objects that are woven into the network fabric. 

What Buckley points out is that the flip side of this is being able to see all of those internet connected objects as puppets that are being controlled by an entity that isn't under your control. The remote control operator issue that at its worst manifests itself in a sort of I, Robot The Disappointing Movie[2] where a software update (spoiler) results in the End of the World, or at least, the End of the World for Mankind. 

So I guess there's a line, or a blurry one. The benefits of network-connected objects are not entirely clear yet: we still have to build a lot of them to see what they can do. But we can easily imagine a future where objects need or expect to be connected to a network in the same way that they need electricity to function. And while *in theory* you could run your own generator or live off-grid, the convenience, the trade off, is one that most people are happy to live with in terms of electricity-as-utility. 

But then, connectivity-as-utility and the balance of power and autonomy is something that comes back, especially, I guess, when you think about the cognitive model of connected devices. One way of looking at it is: I buy this thing, which I have in my physical possession, but it is actually an agent for and reporting back to, a third party. I can tell it what to do, but in practicality, what I tell it to do can be overridden. That may be bad business sense on the part of the organization that made the object, but ultimately, it is now both operating under my control and the control of a third party. 

You get into the licence-versus-own debate where Cory Doctorow will say: fuck the people who will only licence things to you, you need to own the things you buy. But you also get into the service-power dynamic where yes, I'm paying for this service to Tivo, but *really*, they could reach down the line and delete all the stuff off my DVR if they wanted to be dicks about it. 

I come back to the essay I wrote when Google bought Nest. You could look at a house right now and say: how many of the objects in this house are or may be under the active control of someone other than the owner/occupier of the physical location. There's a psychological difference to that, I think, that's going to take people some time to get used to. Well, I say that, I *reckon* it's going to take people some time to get used to. This may well be what "data natives" are completely OK with, but I'm not entirely sure if it's an *OK with* as it is an opaque and unknown interaction. Everything is all well and good with the smart thermostat in your house until suddenly what you think was yours isn't.

I don't think this is necessarily the Doctorow-esque digital rights management argument: that's quite clear with content and not owning, just licensing the ability to access it at any given moment until revoked. This is something different, I feel, because it's not quite rights-management, it's access-and-capabilities-management. I think Buckley hits on something with the idea that this is "my" phone and that I feel like I should know what's going on with it *regardless of whether that's the reflection of reality or not*. 

This line of thought feels at times alarmist and luddite-esque, the sort of fear that "hey, if I stop my in-app fridge subscription then I'm going to come home one day and all my milk will be off and I remember the old days when you just plugged a fridge in to the electricity and it didn't report back on you and couldn't, you know, stop refridgerating because it was too dumb not to." Is General Electric going to come out with some sort of EULA with fridges that says "no matter what, this fridge will always keep fridging, but other features may be turned off"? Or is some government regulatory body going to step in and say: "objects that are supposed to do things should keep doing them". 

It's a bit like the whole Other OS functionality that the PlayStation 3 had - it was sold with the ability to boot another OS and as part of a gigantic security fuckup and people rooting the console, that functionality was eventually turned off and disabled if you wanted continued access to the PlayStation Network. Now, this being America of course there was a lawsuit and that lawsuit was ultimately dismissed[3] but not without the judge noting the "dismay" that customers who did want continued Other OS functionality likely suffered.

I guess the point is this: the promise of net-connected devices is that by making them dumb and their smarts in the cloud, they can be supported for a lot longer. That's, of course, if the companies selling them *want* to support them for much longer. And ultimately: how dumb is the device going to be if it can't access the cloud? Or if the service agreement is terminated?

[1] http://ntlk.net/2014/03/20/internet-of-dependent-things/
[2] http://en.wikipedia.org/wiki/I,_Robot_(film), http://amzn.to/1t2nV0c
[3] http://www.ign.com/articles/2011/12/13/sony-other-os-lawsuit-dismissed-by-court

3.0 Chief Empathy Officer

In retrospect, the amount of fun had at the expense of Counsellor Troi in Star Trek: The Next Generation was probably misplaced. Yes, she was the one who explained to Captain Picard and Number One what the aliens were "feeling" and was the ship's counselor and resident psychiatrist concerned with the mental wellbeing of the crew. 

But here's the thing: if you're able to look at empathy as the ability to understand an audience, user or customer and their position, then it starts to feel like something that's pretty important in the business environment today. You could look at companies that place a high value on good design (and it doesn't even particularly matter what definition of design you end up using) and whether they do a good job of placing themselves in their audience's position. Ultimately, when we're talking about the (from my point of view) fluffy category of user experience, then having the capacity for empathy is pretty important. Sure, there are varying degrees: product and service design instinctively feel like they could do with oodles of empathy for the end-user, whereas engineering less so (but not none at all).

I have a thing that I'm thinking about in terms of the empathy gap: that distance between an organisation and its audience such that at worst, it's clear that the organisation is willfully ignoring how its audience might feel (cable companies, for example) and those that are making almost herculean attempts in terms of attempting to understanding and anticipating their audience's needs. This isn't just CRM and relationship management, it's the types of organisations that start from the ground-up with an understanding of what they do to help their users. 

One quick example of deep user empathy: the canonical example is Zappos customer support, who're trained to help you find the shoe you're looking for *even if they don't sell it*. Because a happy customer with a need fulfilled is one who will come back. And a customer service agent who *actually understands your problem* and helps to solve it, even when that solution doesn't in the short term align with their interests, is demonstrating that their future worth.

A bad way of doing this, one imagines, after reading the book that I haven't written yet, would be for a Fortune 100 company to appoint a Chief Empathy Officer, rather like the role of a Reader's Editor, whose role is to see things from the customer's point of view and show how aligning the company's interests and the customer's can be additive instead of subtractive. But this is like any kind of bad management: a lot of these companies and organisation, I feel, suffer from a *systemic* lack of empathy and even when they're able to be empathic, they're frequently not empowered to act upon it. In which case, front line customer service agents who *are* capable of empathy and merely following orders despite clearly understanding their customer's needs, inevitably end up with job dissatisfaction and want to leave. I rather get the feeling that I should drop Tony Hsieh a line and ask to talk to him about this. 

No: empathy is something that feels like a Core Value, something in the Mission Statement. Wait, no, that's wrong too. Empathy is something that you need to build from the ground up, something that everyone in the organisation needs to believe in. It's more important now given the number of channels that are open for communication and the expectation that an audience has. This stuff, thanks to the promise of computers, should be *easy*. Companies listen, more than ever before, and say that collect more data than ever before. But it appears that all of that data collection is, without the fuzziness of "empathy" isn't necessarily resulting products and services that are better fits that better service user needs.

--

Blarg. I kind of petered out there. Sorry. Anyway: notes. What do you like? What do you don't like? If you don't like things that I do like, then hey, it's my newsletter and I'll probably keep doing those things. Especially things like being long and rambley. 

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Eight: Kill Hollywood, Still; Sandwiches; Apple and Samsung, Still; A Weak Signal
Date: April 14, 2014 at 5:40:25 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-f16l=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

We went on a big family hike on Saturday and ow. But, waterfalls. It's 72 and sunny out here in Portland, but the vending machine on this floor has pretty much run out of *all soda ever* so I'm not even sure how I'm conscious and writing this. Anyway:

1.0 Kill Hollywood, Still

Imagine a Barbie, stepping on your face forever, saying to you: "television is hard". Well, it is[1]. There are bits about it that are getting easier and faster and cheaper, sure, but the big thing about it, the coming-up-with-a-story-that-will-connect-with-people is hard and always has been. That doesn't necessarily mean that it's *harder* than coming up with a great tech product that gets significant adoption, just that it's an equally-ish hard problem in a different domain. And sure, there are ways of disrupting it, but ultimately, those ways are orthogonal (and yes, structural), but don't necessarily solve the problem of content.

(You might argue that there are *some* ways of solving the "is this content going to do well" problem like enhanced testing and biometrics and a/b testing, but a) good luck with getting writers to agree to that and b) there are obviously reasons why tools like that aren't being widely used and *even then* there are clearly a stupendous number of complicating factors). 

So all this is background to Yahoo! trying to do a me-too Silicon Valley move on TV like everyone else that's going for the content play. And the point from the linked article remains: Netflix's biggest "original" series, House of Cards, is a remake of a successful and critically acclaimed British TV series, based on a successful and critically acclaimed novel, with casting informed by oodles of data.

But that's what jumping in right at the deep end is, and a bit like the move that Apple did with the original iPhone. They'd never made a phone before. So it was a hell of a lot of work, and they cut a lot - features that a lot of people maintained would be red line must-haves - and it turned out that they still had a compelling product. I don't think high-end TV drama works like that.

And TV drama is a highly competitive market: there are lots of people out there who know how to make good stuff and they have a bunch of options and it's *still* hard. On the other hand, the disruption that *is* happening is in the talent and content pipeline - properties like Welcome to Nightvale and Popular YouTube Vloggers are growing respectable - but not stupendously giant - audiences quickly, and happy to make the transfer to broadcast television where the advertising infrastructure has grown up to support fat paychecks to well-known stars. This area seems riper, and to be honest, more of an opportunity - but it's one that requires patience and, well, hard work. Because it's hard. One of the big things, of course, that technology is able to do is iterate and deploy quickly, and that just gets more *expensive* with television and video. It's easier and cheaper with text, but that brings with itself its own problems with mass audience takeup. Let me put it this way: Amazon's Pilot System has yet to automagically come up with a must-see.

Of course, if you're not willing to do the hard thing you can always move sideways: Yahoo! could, if it wanted to, move to where the puck is going and take a look at other forms of entertainment like games that can natively work on more devices and where the competition is (in some ways) not quite as widespread or well-honed. 

[1] http://www.nytimes.com/2014/04/14/business/media/yahoo-rolls-the-dice-on-tv.html?_r=0

2.0 Sandwiches

Matt Haughey asked me the other day why I hated Adam Lisagor[1] so much after I mentioned Sandwich Video a few newsletter episodes back. And obviously, don't *hate* Adam Lisagor, it's more that, well, I look at all of the stuff that Sandwich Video has done and it does a specific thing: they're product videos that rely, more or less, on the interestingness of the product that they're pitching. So in that respect, they feel workmanlike - which again, isn't a bad thing - it's just a characteristic of what they are. Sitting where I sit (which you will all inevitably imagine as some sort of Big Agency Throne, with a Giant Agency Desk, Surrounded by Creative Teams and Assistants where we spend Millions of Dollars), the thing about the Sandwich Videos is that they all feel *samey*. And that they're not necessarily the kind of videos that you pass on to your friends *because of the idea in the video*, but only if the product is interesting enough. Which again, makes sense if you're doing a product pitch video. But if you're trying to accomplish other goals, then the Sandwich Videos aren't that great. 

[1] http://sandwichvideo.com

3.0 Apple and Samsung, still

Todd Pendleton must be having the time of his life. He's the former client I used to work with when he was at Nike before he moved over to become CMO of Samsung Mobile USA. Fueled by recent disclosures thanks to the latest round of the Apple vs. Samsung spat the opportunity for journalists to write more Beleaguered[2] Apple articles is hitting an all-time-high. So I can only imagine what Phil Schiller is thinking when he sees articles like this at AdAge[1]. 

The big thing is this. Clients most definitely get the advertising they deserve. And I don't know who the buck's stopping with at Apple in terms of creative consideration and taste. Samsung I think have executed well (if you look at the money they've spent on media it's been *insane*) and chosen their moment - but their "creative" hasn't been, I don't think, outstanding. Especially compared to some of the great previous Apple campaigns. But, they've worked and they've gained a disproportionate share of mind, even if the lion's share of profits are still going to Apple on a device-sold basis. The news that Apple have hired a bunch of new agencies isn't encouraging to me, either: I'm choosing to interpret it as a signal that a) they're transitioning to moving even more work in-house, and b) asking more agencies for work is their answer to choosing better work. But (b) hardly ever works.

[1] http://adage.com/article/digital/fact-check-samsung-s-selfie-worth-a-billion/292625/
[2] This is Beleaguered Castle, Acknowledge

4.0 A Weak Signal

Well, maybe not so weak. News that Windows Phone 8.1 works with Apple's Passbook passes[1], of which I'm not even sure if Apple's Passbook specs are open-as-in-licensable-for-use-by-others-to-read, obviously they're open enough for you to be able to write for them. But hey, this might the beginning of some sort of standard for machine-readable location-enabled passes. 

I do still think location is a big deal. There are bits of magicness that are still breaking through: it is genuinely nice when I get to pay with Square Wallet at places that accept it, but I do end up taking my phone out just to check because it doesn't seem quite reliable enough yet to auto-check me in. The point I guess I'm trying to make is this: there is magical smartness in the computing device that's in my pocket, but the majority of the environment around it is really dumb. So the POS terminals are dumber than my phone. The signage at train stations is dumber than my phone. The checkin gate is dumber than my phone. I mean, sure, most matter is dumb until we computronium everything, but this is one of the perverse things about the consumerisation of tech when that tech gets pushed down Maslow's hierarchy and as a trojan horse into something we all (OK, enough people, and even then, only the privileged ones) carry around. There is incentive for me to go out and spend up to $600 on a smart thing, but not yet incentive for that smartness to be built *in an accessible and usable way* into the built environment around me.

[1] http://www.macrumors.com/2014/04/14/windows-phone-8-1-passbook-passes/

--

Happy Monday! As ever, send me notes. I love them. I like to eat them.

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Seven: Critical Infrastructural Vulnerability; Cultural Adaptation; The Bitcoin Moment; Carousel
Date: April 11, 2014 at 4:07:05 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ezp1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

My head is slowly imploding and feels like it's undergoing the first stage of the z-machine initiating fusion. I *think* that's a good thing.

1.0 Critical Infrastructural Vulnerability

I am still thinking about Heartbleed and everything that's going on with it. There are a bunch of explainers - the xkcd one is pretty good[1] and the jwz rant about this all, ultimately, being Dennis Ritchie's fault is pretty funny[2] (and where I mean funny-not-if-you-have-anything-to-fix funny). But I did get a good note back from Nick Sweeney regarding my throwaway comment about an equivalent being a vulnerability being found in concrete: unscrupulous builders making substandard concrete and pocketing the difference in material costs[3, 4].

Now, with my lawyer hat on (for my sins I trained as a lawyer and it's a style of thinking that you can't really extract from people), I'm thinking of other similar large-scale vulnerabilities with costly limitations. One might be: hey, so it turns out there's a structural vulnerability or danger in plastic, and plastic happens to be everywhere from kids toys to industrial applications. But then another example sprang to mind which, if I were in the IT industry, would probably scare me a bit shitless.

Asbestos.

See, we didn't know asbestos was dangerous. And then we found out that it was dangerous. And then the lawyers and governments and regulators went *mental*, and the chain of liability was basically a nightmare (but, on the other hand, still not a great resolution for people who, you know, were actually affected by lung disease. 

So let me tell you a story about C and unmanaged languages. 

C was a high-performance language, relatively easy to learn, and had been around for ages. It turned out that lots of people knew how to write software for it, and it was highly portable. It spread everywhere. It was, like asbestos, a great construction material. A great medium to make things with and in. 

The problem with C, it turned out, was the null-terminated string. Because, sure as damnit, the chain from a language that handled strings with null termination ended up with a stupendously critical *built-in* weakness that, at the time[5] actually might have made sense as a local optimisation. 

But now we have the mess that we're in with a bunch of buffer over/underruns and having to add hacks in like address space randomisation and no-execute bits and Jesus Christ this is a mess and no, maybe no one's actually *died* but you can bet there are lawyers out there who would be salivating at the financial implications and totting up causal loss. 

So then you look at who to blame. And you look at the Wikipedia list of defendants in US asbestos cases and it's, well, a bit of a nightmare. 

Is this an asbestos moment? Probably not. But hey, in the land of the US you never know when one might actually come along. 

But know this: it doesn't  look like there've been any recalls. I certainly haven't had any emails from whoever about embedded OpenSSL in any of my consumer electronics devices that now need patching or, because of firmware issues, outright replacing. And with that, there's another look at how much liability you can actually disclaim with such fundamental infrastructure.

[1] http://xkcd.com/1354/
[2] http://www.jwz.org/blog/2014/04/heartbleed-hit-list/
[3] http://www.nce.co.uk/new-management-remixes-the-recipe/827990.article (paywall?)
[4] http://www.3ammagazine.com/3am/tyneside-modernism/
[5] http://queue.acm.org/detail.cfm?id=2010365

2.0 Cultural Adaptation

Some good notes from people (James Bridle, Matt Biddulph, Dan Hill) from yesterday's bit about me having to change my pronunciation for Xbox's Kinect voice recognition to acknowledge me. 

James brought up the good point that took the analogy I had further. I was speaking purely from a linguistic point of view: that in speech acts with another speaker, we adjust our acrolect to a happy medium where we're both sure we can communicate, accent, dialect, slang and so on. James points out that what we're looking at instead with something like adjusting our behaviour so that an Xbox can understand our speech or so that a Palm Pilot can understand our writing or that Google's service understand what we're searching for is that this is acculturation: cultural adaptation. 

There was a bit in Re/Code about this[1], put forward by Monica Rogati, vp of data at Jawbone[1] about (and I apologise in advance) "data natives" as a new, er, tribe, as distinct from "digital natives". Data natives, says Rogati, are people who grow up with expectations as to big-data-smartness inhabiting the objects that they interact with. One of her examples is that a data native would expect a Nest thermostat to program itself, whereas a digital native would expect to be able to program a thermostat. Which, fine, but I'm pretty sure you don't have to be a data native to "expect" that, and anyway, I've grown pretty good at having a feeling of what you can sell people, and stuff you don't have to program (hi, VCRs), is always good. You're selling the benefit, not the how. 

Anyway. There is perhaps something in the a group of people who intuitively believe in, if you will, an *animating spark* of sentience or at the very least agency in the objects that they interact with in daily life, but again, here's a reckon: people are like that anyway. They assign agency to things all the time and we love anthropomorphising stuff. To the extent that my mate has a house that Tweets (in, I would like to add, a valuable experiment in terms of tone of voice and accessibility in the age of the internet of things). 

But Rogati's vision:

"A Jawbone Up wristband turns on your Philips Hue lights and starts your WeMo-enabled coffeemaker when you wake up. Water heaters and thermostats learn from your usage patterns and save energy. Connected door locks and doorbells make safety more convenient."

is of a world that we would like to exist, but we're pretty sure won't exist because things just don't work perfectly. They fail and miss or are short. And, for that matter, most of her examples in that paragraph aren't about big data, but are about connectedness and being plugged in to the network. The only data-driven stuff is the water heater and the thermostat. 

But then the big point is this acculturation point. We already adapt ourselves to our environments - you know this whether you live in a city or out in the countryside. And we already adapt our environments to ourselves. The question about how we adapt to an algorithmic environment is the big one: especially when so far we've been adapting to (more or less) visible forces. Even culture is visible even though some of its effects (misogyny, for example) aren't instantly clear. But algorithmic effects when we're not as a species algorithmically literate?

We're ingenious creatures, us humans. We do probe systems and do unexpected things with them: it's part of what's made us the top, most successful mammal on the planet (if there'll still be one we can inhabit in a hundred year's time). So in the same way that people hack airline miles systems (albeit not everyone: but enough people), we'll be hacking and adapting our behaviour to the algorithms that increasingly touch our world.

[1] http://recode.net/2014/04/10/the-rise-of-the-data-natives/

3.0 The Bitcoin Moment

A quick one this. Over breakfast, talking with someone who has the misfortune (paraphrasing his words) of working with the US banking industry, I realised that perhaps *one* of the reasons why the Valley investor elite are obsessed with bitcoin is not necessarily the mining and the blockchain or anything (though perhaps more the latter than the former), but really, because it's a chance to disrupt the batch-processing fucked-up nature of banking that's existed since the 1960s with computerisation. That stuff is *mental*. And any chance to build something new, and perhaps some sort of bridging currency-abstraction-layer, is super interesting.

And that's before you get into whether technology can even solve a problem like a sizeable percentage of people not even having a bank account in the first place. (But do they have mobile phones, right?)

4.0 Carousel

Ok, so a few things to unpack with Dropbox's Carousel.

One: it's called fucking Carousel. I would like to give the Valley more credit, but let's be honest: I'm pretty sure it's named after that Don Draper moment[1]. Smart? Yes. Original? Not really. A bit depressing as to the lack of originality? Yes. I have this whole thing going on where Oh My Jesus Christ are your stereotypical developers and engineers really, really fucking dismissive of *good* marketing, branding and ultimately communication. On the one hand, there's the worshipping of Apple and their products and their design, and I guess some conversation about their advertising and the strategy behind it, but Jesus Christ. Try harder. And also: in a conversation this morning with my boss, the Steve Jobs tapes[2], where *in an undifferentiated market where goods and services are easily substitutable* for which I would say "a thing that automatically backs up your photos and presents them to people" *totally* fits in that category, the *only* thing that differentiates you is your branding and marketing once you hit a certain degree of product sophistication. And there are certainly enough well-funded startups out there that can do this. Sure, there are moats that you can build around you, but this is a Nike/Adidas situation: the products have a <10% utility distinction in use with the audience.

Two: The launch video[2] is already being lauded as an instant classic in advertising, bringing the American Dream back to life[3] for which my only reasonable and printable response is a big sigh and *really*? From an inside baseball sense of perspective, and I say this with full knowledge that my day job is doing the same job for Facebook, but the Dropbox Carousel spot is a competently put together video of *meh*. They could've done so much better.

[1] https://www.youtube.com/watch?v=suRDUFpsHus
[2] http://www.fastcompany.com/1826869/lost-steve-jobs-tapes
[3] https://medium.com/on-advertising/d41ccae36988

--

Phew! Happy Friday! Send me notes and stuff, because I like those. I'm going to go hiking this weekend with my baby and stuff because outside is awesome and calming and all of that jazz.

Best, and see you on on Monday,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Six: a16z Strikes Again; Xbawks; Inside Baseball; The Continuity Field
Date: April 10, 2014 at 12:54:56 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-eyy1=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>


0.0 Station Ident

You know what, it's actually always sunny in Portland. I don't know why I said it wasn't. Also I got to see The Lego Movie again last night and it was STILL GOOD if not SLIGHTLY BETTER and the ending still made me cry because it's dad kryptonite.

1.0 a16z Strikes Again

So yesterday news broke that Andreessen Horowitz led an investment round in Omada Health[1], for which, goddamnit, they did it again. And by "again", I mean pointing out a smart area in which there's a defined need and a massive opportunity. This time it's in early-stage intervention with pre-diabetics through exercise and diet - pretty much the entire thing that I went through back in 2012, only I had to cobble it together via a bunch of proto-quantified self apps and devices[2]. 

What's the easiest way to manage or reverse-out of being diagnosed pre-diabetic? Diet and exercise. And by diet, I mean a low-carb diet and proper consideration to portion control, and by exercise, I mean: doing some. More. Anything, really. 

In 2012, like I said, I had to cobble together my response to a type-2 diabetes diagnosis with a Nike Fuelband[3], a couch-to-5K app, a blood glucose monitor issued to me by my primary healthcare provider (and software and hardware purchased from Glooko[4] so I could sync the data outside the proprietary Lifescan silo), a Withings smart scale[5] and tracking what I was eating with Eatery, an app from Massive Health (since acquired by Jawbone).

That's a lot of stuff. And, when it comes down to it, a *relatively* simple integration challenge but one that has the chance to effect a disproportionate change in health outcome for a large number of people. 

So: $23mm investment in a company that looks like it's doing a good job, in a market that's going to get bigger and that can expand horizontally (other chronic diseases require management, too) and with defined customers (insurance companies and primary healthcare providers). If this type of service can get *prescribed*, then an even bigger market, too. Because if therapy can be prescribed, then why not computer-aided chronic disease intervention?

[1] http://recode.net/2014/04/09/startup-taking-aim-at-chronic-disease-raises-23-million-in-andreessen-led-round/
[2] http://danhon.com/2012/04/28/myself-quantified/
[3] http://www.nike.com/us/en_us/c/nikeplus-fuelband
[4] https://www.glooko.com
[5] http://withings.com/en/bodyscale
[6] http://www.massivehealth.com/#eatery-page

2.0 Xbawks

As seen on the New Aesthetic tumblr noting how people change their behaviour to fit the algorithm rather than getting the algorithm to fit the people[1] in a London Tube ad about Google Voice Search for mobile (and we all remember learning Graffiti so Palm Pilots could recognise our writing, right?), nothing more than another data point and a me-too.

When we first moved to the US we left behind our UK Xbox 360 and picked up a brand new US one (and in the process, re-created an Xbox Live identity). What that meant was when the Kinect came out, we were American and I quickly found out that I couldn't get the Xbox to recognise what I was saying. The prompt is "Xbox, <command>" and that just didn't work in my English accent (my American wife had no problem whatsoever). I, however, had to parody an American accent and could reliably get the console to recognise me if I shouted "XBAWKS! <command>" in my best brogrammer impression. 

We do this all the time. In fact, humans do it - we adjust our dialect and the language we use according to our audience, and all Brits who move to the 'states inevitably end up succumbing and saying warder-for-water. So it's interesting that we do as humans do and adapt to our audience - even when our audience is an algorithm. 

[1] http://new-aesthetic.tumblr.com/post/82085140413/algopop-as-algorithmic-systems-become-more

3.0 Inside Baseball

Ken Segall's got a good blog that covers Apple and advertising, which makes sense because he's an ad guy who worked on Apple campaigns during the Second Jobs Era. So for those who don't work in the tech and advertising industries, he's good at covering the inside baseball on *how* this stuff gets made (and, for anyone who's ever made anything, it's like all sausage-making: messy, difficult and protracted and rarely easy for the good stuff). This most recent post[1] covers the emails disclosed during Apple and Samsung's latest go-around on the iPhone patents spat, and it's rare that people outside the industry get to see interactions between account directors and clients. And Segall's point is a good one: clients get the advertising they deserve, because ultimately, they're the client and they're the ones paying the bills. 

The best relationships are obviously those where the client and agency are challenged by each other and produce better work as a result. My take is that the news that Apple has taken on more agencies like AKQA and Huge to do digital work is a bit damning of the internal capabilities that they've been building up. And, the big question is this: who's the person at Apple who has the taste reins for their advertising?

[1] http://kensegall.com/2014/04/apples-little-advertising-crisis/

4.0 The Continuity Field

And finally, instead of a cutesy story how about this: we've known for quite a while that what we think we see isn't what's actually out there in the world. There's a whole bunch of perceptual and cognitive filtering that goes on to present us a *representation* of the world, but not the literal world. This can be a bit hard to understand because it feels like it removes our primacy and being able to think of ourselves as evolution's hottest shit. Well, it turns out that evolution's hottest shit is remarkably easy to fool. 

The latest news is that this perceptual representation of what's out there isn't just spatial, it's also temporal. The "current view" out of your eyes is one that's informed by the last fifteen seconds of activity (lossily-compressed MPEG delta frames!). This writeup from Quartz[1] goes into a bit of detail but I guess if you're paying or you're at an .edu/.ac.uk domain you can look up the paper at Nature Neuroscience[2]. *Cough* implications for VR *cough*. This kind of makes sense. The raw bitrate of information you'd be getting through your eyes is pretty dense and high-bandwidth, so it makes sense to do a bunch of pre-processing (which is what we see happen in the visual cortex and a successive layer of neurons that do things like edge detection and contrast and stuff like that), but I guess it *also* makes sense if that pre-processing has a temporal axis as well as a spatial one. 

[1] http://qz.com/193708/your-reality-is-15-seconds-in-the-making/
[2] http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn.3689.html?_ga=1.68876625.1979423772.1395259641

--

Phew. OK! Not even 11am West Coast time yet. You'll be glad to know I have absolutely no reckons, I'm not even being sarcastic, about the whole Dropbox/Rice thing. But I might have a bit more about Heartbleed, that's still niggling away in my head.

More notes! And, if you feel like it and you know people who might like it, feel free to forward on to them.

Best,

Dan


Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Five: Sharing Heartbleed; A Weakness of the Heart; Zero-Day
Date: April 9, 2014 at 4:51:50 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-eyep=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

Gosh, more sunny Portland. And a super stimulating day. And secrets! And, unfortunately, not enough work on SULACO BLUE. On we go.

1.0 Sharing Heartbleed



As an indication of what the general public is thinking about, I got a semi-urgent voicemail from my father-in-law this morning that warranted a callback. It wasn't about Heartbleed, but it was about Windows XP being EOLed. So there's that, I guess. (I explained that he needn't worry - his laptop is on Windows 7, I think).

Anyway: Heartbleed[1]. A piece of more-or-less backbone infrastructure powering most of the internet, and genuinely an infrastructural problem, a structural weakness due to, frankly, using tools that just aren't up to the job. There's no excuse *these days* for the type of bug that caused Heartbleed (which, quickly, if you're not familiar, is a weakness in the software that a lot of the internet uses to provide secure, encrypted communication that allows that secure information to leak out in unpredictable ways that can be taken advantage of by unscrupulous people).

(Why's it called Heartbleed? Because it's reliant upon a "heartbeat" feature built into the software that provides those secure encryption services we rely on).

There's a thread I want to pull on here. First was the quick agreement that the *branding* of the Heartbleed bug was pretty impressive, better than a lot of startups manage these days. For the community and audience it was intended for, the Heartbleed site did a good job of communicating the problem and what to do about it. I know that seems like a weird thing, but here I'm using the term branding to talk about the whole package and manner in which what needed to be communicated was communicated. As a whole, the team did a good job.

And then you keep pulling on that thread and what came out today were a steady slew of disclosures and emails from services that had patched, or fixed, the Heartbleed vulnerability. Those emails need to do a bunch of jobs: communicate that everything's OK, communicate what the problem was and, if you need to do anything (like change a password), what that is and how to do it.

I thought the If/this/then/that email[2] did a pretty good job - which I'd love to point to on their blog, but it looks like while they've sent out an email, they haven't updated their blog. Now, IFTTT isn't a particularly mass consumer-facing company. They're definitely in the enthusiast area. But, let's look at their copy. It's:

 - clearly states the problem: "A major vulnerability in the technology that powers encryption across much of the internet was discovered this week."

The only real piece of jargon that I'd say applies would be the worlds "vulnerability" and "encryption" - but again, I think this is appropriate to the audience that IFTTT has. I'd probably replace "vulnerability" with "weakness" and "encryption" with "secure communication".

 - says how IFTTT responded: "Like many other teams, we took immediate action to patch the vulnerability in our infrastructure."

I'd probably simplify here to "Like many other teams, we took immediate action to fix the weakness." 

 - and the result: "IFTTT is no longer vulnerable."

 - and then what you need to do: "Though we have no evidence of malicious behavior, we've taken the extra precaution of logging you out of IFTTT on the web and mobile. We encourage you to change your password not only on IFTTT, but everywhere, as many of the services you love were affected."

There's also a way to get in touch with IFTTT that they append - an email address - at the bottom of their message. 

All in all, a good example of timely communication about a serious issue.

[1] http://heartbleed.com
[2] Flickr screenshot: https://www.flickr.com/photos/danhon/13746427613/

2.0 A Weakness of the Heart

Of course all this is well and good. But we have managed code these days. We continue to see silly bugs like those in Heartbleed that, technologically speaking, are beneath us: they should not be happening. And yet they still do. And they don't exclusively happen to closed-source products, the many eyes that made bugs shallow *still* didn't catch something like Heartbleed even though in retrospect it looks obvious. 

But this is what it feels like to live with brittle infrastructure. A vulnerability gets disclosed and the internet community, such as it is, races to fix it, everywhere. I'm trying to think of analogies and it's a bit like, but not quite, like a massive car recall, only for *roads* and not for cars. Or God, imagine if someone came up with a "concrete" vulnerability and suddenly we had to all go around patching our *buildings*. It's that far down the stack that it's a component that's distributed in infrastructure that needs fixing. And I'm not sure how we deal with this. I remember ages ago reading about crack CERT teams and now it feels like, even more than before, you kind of need a Global Frequency-esque zero-day patch team, able to fly around the world at a moment's notice to fix the doddering Internet. Only, how in practice do you co-ordinate concentrated-in-effort-but-distributed-in-effect work like this? There's no universal back-door. Hilariously, I saw a wag comment on Twitter about the possibility of using Heartbleed itself as a remote-code-execution-privilege-escalation-beachhead to use the vulnerability to patch itself. But perhaps that's what a zero-day Global Frequency white hat team would do. We break into other peoples' computers: to fix them.

3.0 Zero-Day

And then from that thread: zero-day existential threats to humanity. Thinking about them in terms of software patching and vulnerability disclosures: is there a group of people who're concerned with such things? How might they act? A group of people - shadowy, and no doubt well-funded - whose responsibility is to act against new systemic, zero-day critical bugs in human civilization. Not so much protecting us, Global Frequency-style against the *secret* threats in our lives, the detritus left over by overly enthusiastic government-funded TLAs, but more the bottom-up protection. The ten year old in Mumbai who's just discovered that pushing this-bit-here leaves civilization hanging by its fingertips off an existential cliff-edge. And these zero-days that I'm thinking about aren't the "I've just invented a new thing" but rather the systemic vulnerability kind: the "hey, it turns out that evolution is pretty bad at making sure security holes are patched."

Something I think I'm going to keep ruminating on.

--

That's it for today! As ever, love the notes and love the senders-of-notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Three: Kill Hollywood; Not That Worried; Healthbook; Webring!
Date: April 8, 2014 at 2:14:02 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-exlx=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

A short one, this. Brain a bit frazzled. Please send brain juice.

1.0 Kill Hollywood



I was reminded the other day of Y Combinator's Request for Startups 9, Kill Hollywood[1]. 

On the one hand, it's funny, because it feels shockingly naive. Then again, a lot of great businesses get their start thanks to naivety on the part of their founders, who reflecting years later would probably say they would never do the same thing again if they knew then, what they know now.

On the other hand, it's funny because on top of the naivety, it's essentially asking for "disruptive ways to entertain people", but seeking to do so in creative output. Sure, the RFS talks about services and backend infrastructure and so on, but if you ask me, you'd do no wrong looking at a place like Pixar (again) in terms of a marriage of consistent creative output *and* a technical moat. The current crop of mobile games companies don't really do it, I don't think, mainly because the barrier is so low and the fruit is so low-hanging. There's just not a creative pressure there yet that feels easily defensible (not that excellent creative output consistently over time is an easy thing to achieve).

[1] http://ycombinator.com/rfs9.html

2.0 Not That Worried About Oculus

Chris Dixon posted the other day about feeling like the open web was being threatened on mobile[1]. New data shows that people are predominantly spending time inside of apps, not the system-provided browser, though there's some debate as to methodology and results here - it's not clear if the data show people using embedded web views, for example. I bet that Facebook (and to a lesser extent Twitter) account for a bunch of web activity through embedded web views.

Gruber's got a rebuttal wherein he offers his own opinion about what the mobile web is[2], but I think he misses the point, too. For me (and I realise this is a personal perspective) what's webby about the web is the linkiness of it. Yes, sure it's built on browsers and HTTP and later on CSS and Javascript, but as @bopuc pointed out on Twitter, one of the main characteristics of the web is the URI or the URL - the uniform resource locator/identifier that allows you to jump from resource to resource. That, to me, is the web.

But I started this off by talking about Oculus, and what strikes me is that if we're to take Dixon at his word and he values an open, unconstrained and experimental web as vital for innovation, then hopefully we'll see the same fertile medium for experimentation in virtual reality from whatever products Oculus produces.

[1] http://www.cdixon.org/2014/04/07/the-decline-of-the-mobile-web/
[2] http://daringfireball.net/2014/04/rethinking_what_we_mean_by_mobile_web
 
3.0 Healthbook
Health is pretty heavily regulated in the US and a massive opportunity for Valley-style disruption. And by disruption I mean: a far better product, more focussed on user needs, delivered at a better price. There's way too many stodgy incumbents standing in the way of making great product, but I can acknowledge that at least one of the factors standing in *their* way is federal regulation. Some of it is for the right reason, but I'm happy to agree broadly and in principle that the FDA is probably one of the better examples we have of regulatory capture.
So much in the same way that we saw Google's announcement of their contact-lens blood glucose sensor (if you think about it: why would they want to announce something so early? Could it be, like another Silicon Valley company, it seemed prudent to do so before FDA or FCC trawls broke notice of the product to manage the story?), look to a possible announcement at WWDC14 of iOS8's Healthbook as a pseudo personal electronic health record. But the industry track record for this isn't great. Google - bizarrely, for Google - gave up with Google Health, but I think Microsoft still has HealthVault lying around somewhere, if only because they think there might still be an enterprise play. So will Apple have to pre-announce a pseudo EHR at WWDC in advance of FDA approval? Maybe. The mocks that we've seen on sites like MacRumors[1] look... well, weird, to me. There's a whole bunch of information that would be collected from God-Knows-Where, and I don't think the consumer proposition is all that clear. Especially when there's not a good way to share that information with doctors, who're just going to collect it again anyway.
[1] http://www.macrumors.com/2014/03/17/healthbook-renderings-details/
4.0 Webring! 
Because newsletters appear to be a thing, Laura Hall and I have made an Internet Newsletter webring! Because it's the mid 90s and we're all hooked up to the cybernet with our Hayes Modems and AOL KEYWORD: POUND NEWSLETTERS and actually the site isn't hand-rolled HTML2 uploaded with ws_ftp or whatever, it's a Wordpress site with a plugin, and we don't have a gopher service for you to check out but I suppose we could see if someone could resurrect PRESTEL or COMP-U-SERV.
Anyway: if you have a newsletter, join our webring! It's a cool new thing if you're into webs, rings, newsletters and pages on the internet, which is where we're free from government oppression and spying[1].
[1] http://internetofnewsletters.com/
--
Phew, that's it. Going to play with some Oculus today.
Send me notes! I got hardly any for the last couple of issues. Makes me sad. You should send some. Even if they're short!
Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Three: Yet More VR; TV is still fucked; Vox.com; Ugh
Date: April 7, 2014 at 3:16:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-ewwl=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

It's a sunny Monday in Portland, Oregon - looking out the window I can see at least two mountains and to top that off I even had a good chat with a friend over a tasty breakfast. Everyone should have Monday mornings like this.

1.0 Yet More VR

With apologies to Douglas Adams:

"Virtual reality is big. Really big. You just won't believe how vastly, hugely, mind-bogglingly big it is. I mean, you may think it's a long way down the road to the chemist's (or, for that matter, the mobile revolution), but that's just peanuts to virtual reality."

Here, I think, is a baseline for the possible success of the Oculus Rift when it goes consumer. Nintendo released their Wii console in 2006; it famously became a lifestyle family console in a way that no other video gaming device had done before. Wikipedia reckons that worldwide shipments totaled around 100 million units by the end of 2013. 

That's for something that, for the most part, charitably speaking, was a *tennis simulator*. I've made fun of the Wii before in talks I've given because it feels like the main success of the device was due to the pack-in of Wii Sports and that it had thus become the most expensive (and prevalent) tennis simulator known to mankind.

That's if virtual reality is a gimmick. One of the major failings of the Wii (if you can call 100 million units sold a failing) is that it completely missed the online services boat (and, arguably, Nintendo continue to miss that boat in quite a spectacular fashion). For Oculus, though, it's pretty much impossible to conceive of virtual reality without a robust networking component.

The opportunity (or challenge) for Oculus right now is to break out what, until now, had been presumed to be their future: as a subset (albeit a successful one) of the PC gaming market. Now, in the grand scheme of things, the PC gaming market doesn't feel that big. You'd be talking about converting a portion of Steam's 75 million active registered users, for example. Which, I guess, puts you in peak World of Warcraft territory if you can convert around ten percent of Steam's users, but that doesn't really sound ambitious enough. 

No, the big thing is breaking out into mass consumer territory. 

Anyone who's played with the Oculus hardware (and hasn't been affected by the motion sickness from early developer units) can attest to the visceral, qualitative difference in experience. And the easiest job is going to be converting the ten million or so virtual reality adherents who're just waiting for Snow Crash to come about. But we're not playing for just bringing the metaverse about, we're playing for building the biggest consensual hallucination ever. 

There's the product part, of course. I'm super interested to find out what Oculus's product strategy is going to be - presumably they don't want to be a peripheral device anymore to maximise takeup, and you can pretty much buy off-the-shelf ARM platforms with enough processing power and rendering capability (especially if you're tethered to mains power). As a side-note, we finally need all that GPU power that's been hanging around for 1080p x2 rendering. I would almost say (ish) that the product part is the *easy* part.

The hard part is maybe this: how do you sell virtual reality to everyone who's not a convert?

We saw this a little bit with Facebook. While the impression that a great many people have of Facebook is in part via what they've done with their product (and how well or badly they've communicated *why* they've done certain things with their product), a big impression is also due to That Film. And while Mark Zuckerberg might not be anything like the Aaron Sorkin character, unfortunately the world doesn't work like that. 

In the same way that film got to dictate what we thought of Zuckberg having never directly experienced him, film, tv and culture are also getting to dictate what we think of virtual reality - before the product has even come out. Let's be clear: technology has been over-promising and under-delivering on VR for *decades* by this point, and every little thing, every episode of Murder She Wrote[1], X-Files[2, 3] and Wild Palms[4] and god knows what. 

This is me after four years in advertising and Wieden+Kennedy land, but I'm desperate to know: what's the world's first viable VR brand going to look like?

If you look at the staff Oculus already have on board, you can see expected roles like director of developer relations and Head of Worldwide Publishing, but then you've got Eugene Chung, Director of Film and Media. There's the gaming side of Oculus, but then there's also the *everything else* side of Oculus that the press have already breathlessly written about. What type of immersive storytelling is going to be possible? What's going to be encouraged? The gaming side at this point is a matter of execution, but I'm convinced that what Oculus needs to cross over to mainstream is some sort of the equivalent of the Wii Sports pack-in. Of course, I don't mean a *literal* Wii Sports VR tennis simulator pack-in. But something super easy and accessible to a mainstream audience. Remember when the first DVD-ROM drives came with pack-in movies and that was how everyone got their copy of The Matrix? Like that.

[1] http://www.netflix.com/WiPlayer?movieid=70077403&trkid=3325894
[2] http://www.netflix.com/WiPlayer?movieid=70134266&trkid=3325854
[3] http://www.netflix.com/WiPlayer?movieid=70134310&trkid=3325854
[4] http://en.wikipedia.org/wiki/Wild_Palms

2.0 TV is still fucked

So my friend Matt Haughey got his Amazon FireTV and wrote a review[1] and the big news is that there isn't any news. It is (and I realise I'm at risk of doing a CmdrTaco "less space than a Nomad" here) exactly the product you'd expect it to be: an ARM/Android based streaming media platform hooked up to the usual suspects of content providers as well as the device owner's with some nice touches here and there (the packaging is the same dimensions as a DVD box set and Amazon have already associated it with your Amazon account, just like when you buy a Kindle from them). 

And as good as the user experience is in terms of fast and fluid UI, it turns out that what really matters is this: can you watch the stuff you want to watch, and can you find it easily. To which the answer is: no. Still. Video content licensing is fundamentally broken from a "serve the user-need point of view" because the landscape is so goddamn fragmented, and that's notwithstanding the IP owners' attempts at creating their own platforms (see: Hulu, Ultraviolet). No provider is going to allow API access to allow anyone to implement universal search (Xbox *kind of* does this, but it's still a pain in the ass) because it's still too early in the game and they all want platform lock-in. And of course one way of getting platform lock-in is to have exclusive content licensing deals. 

So no, there is no easy way to tell you if you can watch a certain TV show or movie over whatever streaming media device. Because Hollywood hates you.

[1] http://www.pvrblog.com/2014/04/amazon-fire-tv-first-impressions.html

3.0 Vox.com

So Vox.com has launched and it's... interesting. It's explain-y which, if you've been paying attention to organic traffic these days, is a pretty good characteristic to have for a news organisation. It even looks to be espousing the writing-for-the-web design principles as held up by current standard-bearers the UK Government Digital Service (of which: read theirs[1,2]). 

The whole cards metaphor is worth taking a look at because it's chunked up their content in easy-to-digest, well, chunks. Each chunk looks like it answers a specific question (check out their Obamacare[3] article) in a way that, well, Wikipedia doesn't, really. At first glance it looks super nicely designed.

I'm not entirely persuaded by the visual identity - the yellows and grey/blue wash makes it feel like an also-ran Economist with pull-quotes looking like an also-ran Bloomberg Businessweek at the moment, and something about it feels bland and unnecessarily dense in Ezra Klein's debut article[4]. That said, this is a one-dot-oh release, and hey: when was the last time you saw a news organisation with *version numbers*[5] for their platform? Used to be, you'd look to an outfit like The Guardian for interesting news/web innovation, now it looks like the Guardian is being out-agiled.

[1] https://www.gov.uk/design-principles
[2] https://www.gov.uk/design-principles/style-guide/writing-for-the-web
[3] http://www.vox.com/cards/obamacare/what-is-obamacare
[4] http://www.vox.com/2014/4/6/5556462/brain-dead-how-politics-makes-us-stupid
[5] http://www.vox.com/2014/3/30/5564404/how-we-make-vox

4.0 Ugh

Speaking of my favourite British-based Borg collective, Wired UK published a quite frankly amusing recount[1] of an "event hosted by EMC and Policy Exchange" on how technology can be used to reinvent government. Apparently the two organisations are currently writing a joint manifesto to advise the government which, I have to admit, is pretty hard to read without hearing "to serve their interests."

I suppose the real problem I have is the incoherency of the writeup, which appears to not actually understand the positions being advanced. It's a bit clearer when you read Mark Thompson's blog post[2] but only, from my point of view, in the sense that there's one good point buried under a whole bunch of dreck.

I'll start with the one good point. It's true that "digital is... disingenuous without an open, honest debate about how reinventing govt [sic] will reshape the public sector and alter the nature of public sector jobs." Doing digital government properly will by necessity involve radical change: the disruption of hierarchies, abolition and merger of departments and so on. But to effectively write-off current progress because the next part of the journey hasn't been done yet strikes me as more than a little disingenuous, especially when it appears like you're not appearing to offer any solutions yourself. And speaking from a personal point of view, I side with what appears to be GDS's current notion of delivery driving progress rather than top-down rearchitecting. Pragmatically, I believe the former will actually have a chance to effect change rather than the latter.

Now the dreck.

Thompson says that rather than contracting-out, the government is now growing its own capability to build bespoke IT (such bespoke IT that he's knocked in the previous paragraphs), and saying that "the fact that it's using open source makes little difference." With all due respect to Thompson: bollocks. From the outside, it appears that GDS is actually doing the hard work to make sure that the right software and tools are being built in the first place through strict embedding, co-operation and partnership as well as, how do the Spanish Inquisition say, an almost fanatical devotion to uncovering and serving user need.

And then this: "The tech is still special, requires upgrades & maintenance, and the UK remains in its cul-de-sac, decoupled from the innovation of the global marketplace."

Where to begin? All technology inevitably upgrades and maintenance - that's the nature of technology. Thompson, I am sure, would be decrying the use of ball point pens, referring to the far superior and more reliable technology of fountain or quill pens. And what of this rhetorical device of the UK remaining "in its cul-de-sac, decoupled from the innovation of the global marketplace."? 

The issue isn't around closed source: it's about the right tool for the right job and having the expertise to ensure that it stays that way with interests that are aligned. I think it's fair to say that at this point, procurement contracts for big government IT (or even any government IT, for that matter) haven't successfully managed to align goals. A weak government with no implementation capability is a fat easy teat that I'm sure EMC is incredibly unhappy they're less able to suckle from. You can use all the open-source software you want and still create as big a pig's ear of a software solution as Accenture or Capita would. 

And finally, because if I go on, I really will completely lose it, what exactly does "decoupled from the innovation of the global marketplace" mean, exactly? Does Thompson not realise that some of the most effective "innovation of the global marketplace" is being achieved with the right in-house, vertically integrated tools and services? Or is this some sort of conscious coupling that must be achieved, Gwyneth Paltrow style? Presumably governments may only be consciously coupled with the innovation of the global marketplace by *buying* that capability and never developing it, thus ensuring that they only benefit from second-order optimisation and never actually get the tools and services they need.

Oy.

That's why I think Thompson has grasped completely the wrong end of the stick. He's looked at the delivery and output aspects of what GDS has accomplished (the 25 exemplars) and seen them, amusingly, given his tract, purely in terms of "technology" and failed to realise the actual political and bottom-up change that has to have occurred in order to effect the exemplars in the first place. Does he think, for example, that GDS winning design awards for clarity of provision of service, is a technological "agile" deliverable, or one that's required a genuine change of working inside the civil service?

Oh, right.

[1] http://www.wired.co.uk/news/archive/2014-04/04/digital-disruption-government
[2] http://www.blogs.jbs.cam.ac.uk/markthompson/2014/04/05/government-digital-is-in-danger-of-losing-its-way/
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty Two: Disintermediation & Externalisation; Housing; Odds
Date: April 4, 2014 at 3:55:58 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-evi9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

It's Friday. I have a Diet Coke near me (as ever) and I even managed to do some work on SULACO BLUE yesterday, which is a relief, because I haven't ever done anything like it before, but at least I'm still excited about it. What I am not excited about: jet lag. I successfully fell asleep in the middle of a meeting yesterday (I think), and also managed to pass out at around 8pm last night, a scant half hour after my thirteen month old son. He slept through the night; I woke up at 3am. 



1.0 Disintermediation and Externalisation

Thanks to a note from Phil Gyford, I'm still thinking about yesterday's pseudo-rant about informed consumer choice. It feels like there are so many factors working together in this area.

Point the first: disintermediation can be seen as broadly a good thing in terms of the quality of service and consumer choice, right? Take something like travel agents. The vast majority of them performed a so-so service that you were required to use (you couldn't book a flight or hotel directly, really) and following sturgeon's law, five to ten percent of them were probably actually any good. Disintermediate the travel business and what do you get? In theory you get better choice (now I can choose any hotel, not just the ones recommended to me by a travel agent), and you get a better deal (you don't pay for the privilege of having to use an ineffective middleman, right?). 

What instead happens is the intermediaries get hollowed out because *most people* can afford self-service and instead the intermediaries (can? should?) focus on the higher-end. You can get a travel agent, but now it's Amex Black/Centurion type stuff: concierge services. Or, costs have been externalised in terms of the hotels and the airlines fishing to acquire customers directly or through affiliate relationships through the travel search engines.

But again, turns out we're not good at assessing costs, right? Turns out we're not quite so rational economic actors. Because it turns out that the cognitive overhead - the tax, as it were - of going to Expedia and Orbitz and Booking.com and wherever, and navigating through their good-enough UI to tweak the details to find what you want, is actually pretty time-consuming. So time-consuming and so difficult, in fact, that startups like Hipmunk bubble-up to make the process easier! And Hipmunk is *still* a cognitively taxing process - because you end up looking at an array of choices and having to pick one.

In some ways, sometimes we just want to be able to outsource the decision making and trust that someone can make a choice for us, on our behalf. And this is what a travel agent might do for us.

One reader remarked on Twitter yesterday that this is why sites like The Sweethome and The Wirecutter exist: trusted sources in the Consumer Reports/Which? vein that make their money through affiliate links and purport to reduce the mental drain involved in things like: "which headphones should I buy?", or "What's a good iPhone external battery?" 

Gosh, I mean: you take all of this stuff and roll it into the fact that we have research now showing that decision-making and willpower is a resource that gets drained over time, and not only do you have problems for people dealing with poverty who are time-starved, but the middle-classes start complaining as well. 

Would Amazon test, for example, an Amazon Express option for browsing their site where they *only* show you the highest-rated, most-recommended items against your search? Because even the presence or indication of hundreds or thousands of other options can be stress-inducing. And perhaps pair it with a liberal return policy?

I guess the thing is this. Disintermediation and increased consumer choice rely upon the assumption (if you care, I suppose) that your consumer or audience is a rational economic actor who *has the time and the resources to be a rational actor*. I get pissed off at stereotypical, straw-man privileged engineers who just want a spreadsheet with a table and do all the research and go buy the best thing because seriously: who has the time for that?

And there's a significant, vulnerable section of the population that *doesn't* have time for that, that doesn't have time to be a rational actor. And who are you supposed to trust? Do you trust the financial advisor who is getting kickbacks? Do you trust your health insurance company? Do you even have health insurance to trust? This isn't a mere case of "information overload" in terms of a firehose of stuff coming to you. This is: how do I make a basic decision and ensure I am informed to make a rational, appropriate choice.

The other side of this is the fantastic one for businesses that get to externalise formerly internal costs under the guise of consumer choice. So instead of having knowledgeable salespeople (for example), "the information is available on our website". This is perhaps the difference with a retailer like Apple where I believe their store employees are taught to listen to user needs (there's that phrase again) and help them accomplish them rather than being commission-driven and pushing everyone to buy the most expensive model, for example. And so a place where retail can be improved both offline and online: Amazon doesn't have salespeople that understand their products to help you choose one, they externalise that cost by having you write reviews and lists instead.

2.0 Housing

Man, finding a place to live in Portland was *hard* three years ago, and it sounds like it's even harder now. You've got a place with low supply and high demand and also, for someone coming from London, an absolutely god-awful user experience that, I think, appears to be mirrored all over America. For the non-Americans, it works a bit like this:

1. Ask people how you go about finding a rental place
2. Get told that you should use Craigslist
3. Do a double-take because, really, Craigslist?
4. Take a look at Craigslist to check if it really hasn't changed at all in the last five years, realise no, it hasn't changed at all in the last five years
5. Even though they were absolute cunts, miss estate agents like Foxtons in London which at least provided a central place for rental listings, standardised floor plans, photographs and panoramas, TEN YEARS AGO
6. Look at some Craigslist listings that don't even have photographs, don't mention how much square footage they have, and send an email through Craigslist
7. Realise that there's no decent mobile interface
8. Try, in a futile manner, using something like Trulia but then realise that there's hardly anything on it
9. Jesus Christ What The Fuck I Actually Have To Use Craigslist 
10. There's not even rudimentary search or structured data that will reliably return 2-4 bedroom places because, fuck it, it's Craigslist and anything that isn't a free text field isn't the One True Way

I mean What The Actual Fuck, America.

Anyway: all of this was prompted by a chat over breakfast where some friends and I were talking about the rental experience and came up with the quite horrible idea that, in addition to the credit check (which, you know, absolutely fair game for a rental application) and the application letter (Letter! In America, you write cover letters to beg and PLEAD for the rental!), what a landlord might actually want to see is a list of all your social media profiles to see if you're the kind of person who does, or does not, throw awesome orgies or like playing the drums.

This is not a new thing: I remember being asked by Airbnb to supply my Facebook address so prospective Airbnbers could stalk^Wcheck me out when I applied to stay at their place. It feels like this type of credit/social check would work doubly so in a residential rental environment. But don't worry, it's not going to happen because America doesn't have its shit together.

3.0 Odds

I mentioned in a previous episode that I thought Oculus would plug into a mobile, not a desktop PC. I completely missed the fact that you might as well build the mobile processor and rendering chipset into the headset itself and just give it wifi. Because hey, why not. But then batteries. Oh, I could have loads of thoughts about this. Also, the nagging suspicion (along with Kim Pallister) as to whether anyone has a more-developed business model than "Snow Crash".

I hope I never, ever have to have with my son the kind of conversation Eric had to have with his daughter, Rebecca. You might have read his earlier piece about speaking with her about chemotherapy (http://meyerweb.com/eric/thoughts/2014/01/04/the-choice/), but I can't help but share the latest conversation he's had to have with her:

http://meyerweb.com/eric/thoughts/2014/04/03/the-truth/

With that, I hope you have a good Friday, a good weekend and perhaps we all try to be as good people as we can to each other in a world that reminds us how indifferent it is to our existence. 

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty One: Internet of Poor People; Re-introductions; Odds
Date: April 3, 2014 at 4:06:42 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-euq9=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident

It's a cool, cloudy day in the Pacific Northwest. I have copies of Hawkeye to catch up on and the Veronica Mars movie poster has just arrived at my desk. I am still thinking about VR. 

Projects wise, I need to pick up work on SULACO BLUE, which I kind of set aside for a couple of days. And there's another one that I'm (tentatively) excited about but won't hear back for a while, which I'm calling NOSTROMO BLACK. The more attentive amongst you might spot the pattern here.

1.0 Internet of Poor People



I am at massive risk of privilege-splaining here. I'm practically white, (upper?) middle class, live in a comfortable (rented) house wife a wife and a gorgeous baby. I have a creative director position at a stupendously well-regarded creative advertising agency and in terms of Maslow's hierarchy of needs, the types of questions I need answers to are things like "where is the Apple Remote?" and "when is the replacement Apple Remote we ordered through Amazon Prime arriving?" or "what place are we eating out at tonight." So believe me when I say that I am writing this with as much self-awareness as I can.

The thing that pisses me off, that really, really, really pisses me off about a) America and b) a subset of the engineer mindset is the whole "I don't want to be advertised at, just give me all the information and I will research and buy the best product."

This rant is prompted in part because of a particularly middle-class problem in America, and it's one of healthcare. My primary care doctor (who let's just assume I have), recommended late last year that it was probably time I got some professional mental health care. I'd been seeing a therapist weekly in London before I moved to the US, but it had been nearly two years since I'd seen someone. 

What I needed to do, he said, was this:

1. Discreetly ask friends and co-workers if they had any recommendations as to good therapists
2. Call up my insurance provider to see who was in-network (if I didn't want to end up paying out of pocket up to $200/session)
3. Call up my insurance provider Employee Assistance Programme, who would also recommend in-network therapists
4. Look up some therapists
5. Call some therapists and speak to them, maybe set up a few appointments
6. See a bunch of therapists and see if I got on with them
7. Decide which one I wanted to see after I had "shopped around" a bit

I'm lucky to have the kind of job and the kind of employer where I can take the time out to do those things. In the UK, of course, we didn't have consumer choice and the way it worked was something like this: my GP would say "you need to see a therapist" and she would write a letter for a referral which would go in the Actual Mail and be printed out and everything, and then an interminable amount of time later I would be invited to an appointment. I didn't get a choice: I got a therapist and I was damn well grateful.

I don't understand how one is supposed to have the time to make an informed consumer choice in this case. For someone who's working minimum wage and doesn't have an understanding employer, how exactly are you supposed to sort out those multiple appointments? When are you supposed to do all of that research?

This is the paradox of choice for the lower-middle class and working class. There's zero-hour contract jobs, where not turning up for a shift can put your contract at risk of termination, and they don't even come with healthcare in the first place. The profusion of choice isn't just cognitively difficult to work with (so many options), but the practical aspect of it: of actually sitting down and having a clear enough head to assess the pros and cons is, in Californian Ideology terms, a *tax imposed on the consumer*.

It might not be an explicit tax, it might not even be an intentional tax, but it is one nonetheless. And in America, there appear to be some structural taxes: like - in the UK, insurance is pretty easy to buy without having to talk to a human being. There exist online options and also online comparison sites that actually compare amongst different providers. There's an entire business of them, and some of them are fairer than others and some even disclose the kickbacks that they get in terms of affiliate marketing. But, importantly, there's one place you can go to, and it's relatively easy to make your decision there. Here, I assume for states' rights reasons, it's difficult if not impossible to do that.

I mean, come on America. In the UK we have comparison sites for *grocery delivery*. I realise you're a big country and all and you have certain geographic realities to deal with, but it's amusing that there are some things that are easier to do in the UK.

But this is the thing for me: all this talk of startups that deliver freshly cooked local sustainable food to other startups aren't fucking changing the world. They're scribbling idiot notes in the margins. You want to change the world? Save time for people who don't have any, and make their actual lives better - and I mean *really* saving time, not shaving a couple hundred milliseconds off your laundry startup's rendering page. And see if you can get an empathy transplant in the meantime.

2.0 Re-introductions

I've had a bunch of new subscribers in the past couple of days (even more yesterday than the day before), so I want to make a few things clear for all you newbies. The great thing about this newsletter - for me - is that it's a personal project, something I started in January to practice my writing. I set myself a task: to write every weekday and send it out there. It's not on my blog, because there's something qualitatively different about the type of relationship and attention you get from newsletter subscribers. So: understand me when I say this - the newsletter is this way because I want it to be this way. I realise it's long. I ramble. It is, pretty much, a sort of unedited stream of conciousness straight from my head through my fingers into this browser TEXTAREA and then spurted into your mailbox. If you are a trendhunter or a forecaster or someone in advertising: this is unashamedly exactly what I say it is: things that interest me. 

I'm not writing for an audience, I'm writing for practice. Some people happen to have found that interesting, stimulating and/or useful. Which is great. And I've had some great conversations. All this is to say that when I see the subscriber numbers tick down (which I'm sure they will) I know why, and I'll be OK about it.

3.0 Odds

More odds and ends.

Amazon announced (and released) FireTV, because hey didn't you know the bill of materials you need to produce a streaming video device that plugs into HDMI are pretty much a commodity these days (and so, I imagine, is white-labelling a streaming video service). The only thing of note for me is: a) how easy is it to upgrade to Amazon Prime from the device and b) for what's in the box, it's curious that Amazon aren't being more aggressive with the price and undercutting the Apple TV. They obviously can't reach Chromecast levels, but the price (for now) is an interesting signal.

My friend Minkette is a game designer at Wieden+Kennedy (we used to work together at Six to Start) and is keeping a game diary: http://minkette.wordpress.com which, you know, interesting ephemera.

Barco, a display company, has this old demo of a multi-touch glass cockpit setup for planes. There's a great bit about halfway through where the guy demoing it answers the rhetorical question of "but how do you use a multi-touch display in turbulence?" https://www.youtube.com/watch?v=FAITKeKdk7I (actually, it's not that great. I know about expectations and YouTube videos).

Brendan Eich stepped down as CEO of Mozilla because it turns out that your protected first amendment rights of free speech don't come with corresponding protection against the consequences of you exercising that free speech. And this C|net interview with him (http://www.cnet.com/news/mozilla-ceo-gay-marriage-firestorm-could-hurt-firefox-cause-q-a/) is just shocking in his conflation of the open web and inclusiveness means being inclusive of people of bigoted opinions. Sorry, Eich, but moral relativism appears not to have worked out for you.

If you know how to (and want to) explore Europa for less than a billion dollars, NASA wants to hear from you. http://1.usa.gov/1j6jJr2 Alternatively, if you believe that ALL THESE WORLDS ARE OURS APART FROM EUROPA ATTEMPT NO LANDINGS THERE then, uh, I don't believe we have giant monolith outside context problem risk mitigation strategies in place, so good luck.

--

Okay, that's it! See you on Friday. As ever, hugs, kisses and please send notes.

Best,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 
  
 


From: danhon <dan@danhon.com>
Subject: Episode Fifty: Cities; Snow Crashing 5; More Television
Date: April 2, 2014 at 5:44:25 PM CDT
To: <dan@danhon.com>
Reply-To: danhon <reply-eu41=4002f456-abe1-4895-a791-ddc741034e67@tinyletter.com>

0.0 Station Ident



I'm back on the West Coast of the USA after what feels like a stupendous amount of travel. I'm not entirely sure where my head is. So: warnings ahead of today's episode of my newsletter. The fiftieth episode! A half-century! And halfway toward syndication! I appear to have had a *bunch* of new subscribers over the past couple of days and I can't quite tell where you've all come from. So if any of you feel like dropping a note introducing yourselves, that'd be fantastic. No pressure, of course.

1.0 Cities

One of the things I was asked about when I was in Perth was what the City might do to start punching not just above, but at, its weight in terms of creative output. Apparently (and Australians, feel free to jump in to defend the honour of your city), but Perth is a bit of an ugly duckling or the Cinderella of Australia. Our driver who picked us up from the airport told us that Perth was apparently the most remote city on Earth - that is, it was the the farthest distance from any other big city. And at the same time, it's growing massively (taxi driver conversation put it at around 8,000 immigrants a *week*). 

One of the things I referenced was this idea of a playable city, something Bristol's made a good start with through the work done at their Watershed[1], and last year's project, Hello, Lamppost[2]. Now, I make no illusions to having properly-formed opinions or relevant thoughts about cities. For that kind of stuff, I direct you toward Matt Jones' The City Is A Battlesuit For Surviving The Future[3], a fantastic essay on io9 which if you haven't read already, you should do, and then you should just feel inadequate and dumb for not having the kind of thoughts Matt does. And then you should read the referenced Greenfield and Hill essays, and you should also read Kieron Gillen's run at Iron Man, which only surprised me by having a giant quote and dedication to Jones in the Iron Metropolitan storyline.

Anyway. Playable Cities: I can have opinions about those. 

There is something about making otherwise inert objects in a city interrogable. As in: there's all this infrastructure around us, and while it might not necessarily be *smart* yet, it does form the fabric of what we need and use to survive. And so often, we don't really pay any attention to it, at least until it breaks. If we're to have a better understanding of and appreciation for the kind of infrastructure we're dependent upon, then being able to interrogate it and interact with it in a non-destructive way, and being able to query it and form a relationship with it feels like a Good Thing. And the thing is: to even put that type of infrastructure into place you have, like something like Hello, Lamppost, you need to have enough open-ish data. So there's a prerequisite, almost some sort of Civ-type tech tree (ha!) that a city needs to implement before it can become Playable. 

The other thing that struck me about Hello, Lamppost was the tone of voice of the objects. They seem pretty British. In the video, they talk about "light, charming, friendly products" 

One of the projects I was lucky to work on at W+K's London office was the second iteration of Nike Grid, something that turned the ubiquitous red phonebox into a piece of infrastructure for a running game, a persistent reminder that the city could be something else that could be toyed with. There have been numerous branded attempts to try to get us to reconsider and recontextualise urban space: Nike likes to think of devices like their Fuelband making the city a playground, for example. And yet it doesn't quite yet feel like the data is there yet, in enough of an open format. I mean you kind of need a base-level of awareness, a kind of city that has some open sense of proprioception. Parallel to all of that you have the requirements Google is making of its next candidate cities for Fiber[4] and they're the kind of things (placement of infrastructure, utility poles, etc.) that allow a city to have a sense of itself. 

The thing about play for me, and it's a super high-level thing, is that it's a safe context for experimentation. There's all the stuff about play being how babies learn, yadda, yadda, and I suppose the safe context/space for experimentation is the focus of it all for me. Our cities now are such regulated places, and the encroachment of the private onto the public is just a matter of another footnote of documentation these days. Where's a safe place for experimentation in a place like London, blanketted with CCTV cameras? Or what would be required to enact a safe place for experimentation if you *are* going to blanket everything with CCTV? There's also something intriguing in the notion of a city that presses back when you poke it, but the way that it presses back encourages further experimentation, and, bluntly, participation. Or, at least, the notion that a playable city could be one that would increase the degree of empathy amongst its inhabitants.

[1] http://www.watershed.co.uk/playablecity/
[2] http://www.watershed.co.uk/playablecity/about/the-winner/
[3] http://io9.com/5362912/the-city-is-a-battlesuit-for-surviving-the-future
[4] https://static.googleusercontent.com/media/fiber.google.com/en/us/about/files/googlefibercitychecklist2-24-14.pdf

2.0 Snow Crashing 5

So, we've now got a bit about hacking, the production of software and The Black Sun. As it ever was, "when Hiro learned how to [code], a hacker could sit down and write an entire piece of software himself. Now, that's no longer possible." Now, we don't know too much about what Stephenson's talking about here. Because writing an entire piece of software himself, even fifteen years ago, wasn't exactly possible - there was definitely a whole bunch of reliance on libraries and other supporting infrastructure in the stack. So, assuming Hiro wasn't doing everything from the OS upwards and pulled in networking libraries rather than hand-rolling his own TCP/IP stack, Stephenson means Hiro was writing the application code single-handedly. Which, even now, is still possible. We're just building on top of an ever-more abstracted stack. I don't think Stephenson meant that Hiro was coding an OpenGL implementation on his own, for example.

These days, says Stephenson, "software comes out of factories, and hackers are, to a greater or lesser extent, assembly-line workers." Which is probably true for a lot of software (and certainly *explains* a lot of software out there) but at the same time doesn't take into account (or does, kind of) the view that people like Jobs had about the virtuoso hacker. The one-in-a-thousand, who is literally head and shoulders better than the rest. This worry about going back to get a regular job preys on Hiro's mind - he's scared of becoming an assembly line worker, or worse yet, a manager, but it's clear (especially later on in the book) that he is the prototypical *ninja developer*. He could probably have whatever job he wanted, and Juanita makes that clear later on. Hiro, it seems, has Issues he has to deal with. And so we get back to him remembering that he owes the mob the cost of a new car, and that he needs to get back onto his day job of selling information. 

And then we're at the Black Sun, the club, a squat black pyramid, "not an architectural masterpiece", something where Hiro and Da5id went in for simple geometric shapes, or in the parlance of Second Life, the cheapest Prims they could get their hands on. And then another interesting thing: there are *millions* of people milling about on the Street and "the computer system that operates the Street has better things to do" than do the collision detection calculations. Which, you know, seems weird for a place that's so defiantly wedded to physical representations of things (no teleporting, remember), but purely for reasons of expediency decides not to bother with it in terms of the interactions of peoples' avatars. So, just another place where Stephenson doesn't look too prescient in the face of Moore's law. There's a pretty cool throwaway line in terms of the misogynist display (it's a boys' hacker club, of course, so there are airbrushed Playboy pinups) being updated at 72fps, and just like that, Hiro's in the Black Sun.

3.0 The Naming Of Things

So Cortana is the name of the assistant built into Windows Phone[1]. We've all been there: the codename that stuck. But here's the thing about Cortana: she's another example of our SFnal future echoing back in time to our present-day. For those playing along at home, Cortana is the name of your AI companion in Bungie/Microsoft's HALO series, and in *that* toy universe, as in most of the ones we've collectively dreamt up, AIs eventually go mad. Only Bungie came up with a cool name for it: rampancy[2]. 

The other thing about Cortana is that she's your typical SF nerd boy dream AI. A mostly-naked, large-busted female form rendered in movie teal with "data" flowing over and through her, she's every straight teenage boy's pinup: your best friend who's plugged into every network, looking out for you, sexy but you can turn her off and stick her into a chip in your helmet. She can't hurt you, not really, but she can damn well help you. 

And then this: she's now been rendered, reduced, into a scrolling, pulsing circle, made family friendly but her roots are relevant. Because that's part of her history: Cortana, the personal assistant in your phone and the cloud, named after the AI from the first-person shooter.

Not that I've got something going for Apple, but at least they had the taste to name their assistant Siri, at least something androgynous sounding. 

And that's the thing: anyone googling for an image of Cortana today? First they'll see is a topless, teal, avatar of an AI.

[1] http://www.theverge.com/2014/4/2/5570866/cortana-windows-phone-8-1-digital-assistant
[2] http://bungie.wikia.com/wiki/Rampancy

3.0 More Television

Honestly, television in the US is fucked. There are two great recent essays on this, the first from Benedict Evans, where inside of the second paragraph he points out exactly how locally-optimised the US television system is: ie - it's great for what it's doing right now, but it's very, very brittle[1]. The second is from Jean-Louis Gassée, where he maintains that TV 'done right' is still a dream[2], and I'm inclined to agree with both of those smart people.

Ultimately, the problem is this: the user-experience, especially in the US, sucks. Period. As yet, there is *still* no way to search across competing video providers - only the Tivo comes close, allowing you to search amongst YouTube, Hulu, Netflix and your cable provider's video-on-demand platform but not even allowing you to search through your iTunes library, I don't think. There's no sign that Amazon's newly-announced FireTV does a better job, either. And Evans makes a good point: it's the content - the shows - that people care about, not the networks. The shows - the video - are the atoms of content that people will follow around. And it's necessarily the bundling of show to network to provider that's the sticking point here: the incumbents have no incentive to offer substitutability. And this is why Comcast wants to (and did) buy NBC - to get the content as well as supply the pipe. 

It feels like the only way out of this brittle situation is through content, too. And it's one of those things that will only work over time or when it's good enough. The user experience bit is easy *in principle* and it's here where I admit to falling into the same trap as Gassée - in principle, you just need to execute user experience well. But you also need the rights and the APIs and the cross-licensing deals to offer a service that at the moment we only *think* audiences want.

This might be where Google Fiber is coming in - the pipe into the house that comes with the service (that may as well be substitutable once you're able to provide a good enough IP connection), but ultimately it still feels like a way to do a content play. Google could, for example, buy the rights to the NFL in the same way that Sky bought the rights to the Premiership in the UK and effectively pull an audience in by holding the content they love hostage. In the UK that meant anyone who gave a damn about football had to get a dish and a subscription, in the US, that means that anyone who gives a damn about football would need to get a Chromecast. Which, to be honest, Google could afford to give away for free. But, see, the 'net access that its new NFL subscribers (or not: probably the matches would be free on YouTube with extensive pre/post-roll, right?) need to view the matches would only be supplied via... the existing cable companies. For whom we know net neutrality is a hot button topic right now.

In fact, it's exactly this kind of bullshit and protection of misguided moats that leads to stuff like the Veronica Mars movie being released through Ultraviolet, a crappy user-experience but one that makes absolute sense if you own a studio, instead of a similarly DRMed but actually-useable service like iTunes.

There are few areas where I agree that it'd be quite nice for the internet titans to have a regulation-free innovation zone. One of them, though, is a space where they just damn-well fix the tv experience.


[1] http://ben-evans.com/benedictevans/2014/3/27/notes-on-tv
[2] http://www.mondaynote.com/2014/03/30/tv-done-right-still-a-dream/

--

I was on a plane yesterday, so I didn't get the full exposure of April Fools. I highly recommend international air travel as a carbon-expensive way to avoid all of that tedium on the 'net. 

See you all tomorrow,

Dan
Things That Have Caught My Attention by danhon 
55 NE Fargo St Portland, Oregon 97212 USA 
Sent to dan@danhon.com —  Unsubscribe 
Delivered by 

Episode Forty Nine: Living In An Immaterial World; Snow Crashing 4; Odds
by danhon

0.0 STATION IDENT
I’m writing this at around 25k feet on the final leg of my trip back home to Portland from Sydney. I have no idea how long I’ve been on the move now, and the international date line doesn’t help. What I can say is this, though: take some ativan when you’re travelling long-haul because that shit’s awesome. 14 hour flight and I slept for 12 of it.

I’m thinking a lot, still, about VR at the moment and where it’s going to go. There are those who’re bullish about it and those who’re bearish – Benedict Evans, now at a16z, who was bullish on Facebook/WhatsApp is bearish on Facebook/Oculus. I’m not so sure.

1.0 LIVING IN AN IMMATERIAL WORLD
Peter Berkman has an essay, ultimately about the ethics of virtual reality[1], on his Tumblr that’s getting a bunch of (valid) attention, not least of which because John Carmack turns up in the comments to discuss the issue.

So let’s think a bit about what a world with cheap, ubiquitous access to high quality virtual reality might look like.

The first assumption is that the giants are smart and self-interested enough to not have a locked-down monopoly or to try to implement a walled-garden all over again. In the conversations I’ve had over the last few days since the announcement, one familiar refrain that I’ve heard is people simply don’t know what Facebook is going to do, and the only heuristic they have its Facebook’s past behaviour on its own products. Which, admittedly, is pretty good data (what else does one have to work on?), but I don’t think Facebook have been very good at telegraphing their intentions.

The easy version of this future is that Facebook continues to operate Oculus as a separate concern a la Instagram or WhatsApp and finds some sort of way to be embedded into the service/infrastructure level. There’s evidence already that that’s the intention of Oculus’ founders – the hardware is the razor. The services to support a fully-functional virtual reality service are the razors.

What this means is that I highly doubt Oculus is going to be merged with Facebook-the-product proper (ie no Likes and blue thumbs turning up inside Oculus environments).

The walled garden thing is interesting, though. How do you have an open, non-walled garden standard that allows for the required level of data and intent gathering (Google levels of intent or higher, right?) and yet allows for easy user extension and build-out.

The last company to try this was Twitter, where you have a centralised network with a canonical application experience – the official Twitter apps – and an ecosystem built around the core experience but not replicating it. This came about in Michael Sippey’s now-somewhat-famous blog post suggesting that developers concentrate on “the upper-left, bottom-left and bottom-right quadrant.” I’d suggest that anyone looking at what might happen in a possible Oculus future take a look at that shift in Twitter’s direction[2] and the way they communicated it.

The difference here, of course, is that there’s the opportunity for software/hardware integration (the Oculus service might only work with an authenticated Oculus interface unit, for example), which poses the question: how rich an ecosystem can one build with an integrated software/hardware stack?

If we look elsewhere than Twitter, another answer is Apple, with its hardware/software iOS ecosystem. But then Apple’s business model is one that *at the moment* is alien to the subsidiaries of Facebook Inc (Facebook the product, Instagram, Whatsapp and now Oculus): Apple charges for hardware *and* acts as a middleman in a pseudo-curated application ecosystem with a micro-transaction powered environment. Advertising, though, is equally alien to Apple (one need only look at their stupendous success with iAd). In Q1 2014, iTunes saw revenue of $2.4bn[3], in comparison Facebook’s Q4 2013 saw revenue of $2.6bn[4].

So if you were to kickstart an ecosystem business around Oculus, one of the first considerations is where all of the content is going to come from. There’s some infrastructural stuff that you can do for starters without monetising attention. Just setting up the cost of existing in the world a la Gregarious Simulation Systems does in OASIS and the ACM’s Global Multimedia Protocol Group in Snow Crash – a registration/property system analogus to Second Life’s land and DNS, transactions for teleporting, etc.

And then there’s the content. First, the easy stuff: license all existing audiovisual content (movies, tv shows, etc.) and just show them via Oculus as stupendous big floaty screen experiences.

Now, the hard stuff. How do you actually enable an extensible, thriving third party ecosystem (hopefully, one at least as active as the iOS ecosystem – $15bn in developer payments to date[5]).

So here are some basic possible layers and the revenue streams:

1) hardware: Oculus sound like they’re going for the razor model. So, cheap (even cost?) hardware to make this one of the fastest adopted consumer technologies ever. But, remember Oculus (as it stands) requires partner hardware for rendering. Within a couple of years (if not sooner) that partner hardware would be a mobile device, not the desktop/laptop kit it’s currently plugged into. Negligible revenue here.

2) prime VR experience: difficult one, this. Software infrastructure on a lobby model (think the Xbox or PlayStation console experience) with first party titles. Xbox has historically had this as pay-to-play for network experiences, Sony only just joined them in charing in their fourth iteration. This “prime” 3d rendered environment doesn’t necessarily need to have revenue streams, but it could probably have:

2.1) VR-related microtransactions: in-world first-party objects and services such as inventory management (buy a bigger bag of holding, etc.) transport (teleporting) and so on;

2.2) VR-related recurring transactions: licensing or “building” – equivalent to SecondLife land rent fees, superuser tools, developer registration,

2.3) Third-party content-related microtransactions: the “app store” purchasing of and access to third party content and experiences (3D environments, flat content, in-experience purchases for those environments). Everything that most people are talking about fits in here: concert recordings, visits to the Space Station and so on through to building custom models inside the prime environment and having them available to others. A good example of what’s been done in this space is Sony’s PlayStation Home. Oculus takes a cut here, and potentially becomes a middleman of the next phase of the internet’s growth.

3) Advertising: This, I feel, only really starts to work when you’ve got appreciable scale. There are a gazillion ways to measure attention inside a fully-simulated universe, and to be honest I’m not sure what degree or level of eye/gaze tracking will be in the first consumer version of Oculus. If there’s a Prime VR environment that models something like the Street, then it’s conceivable that advertising would happen there, but I don’t think that’s necessarily thinking big enough. In a fully simulated environment advertising can appear, well, anywhere. But: and this is an important point – I’m not necessarily sure that advertising is something you’re going to be able to pay to remove. Facebook is built on the model (and the vision) of connecting the world and that, for the end user, the most economical way of doing that *for everyone* is on an advertising-funded model. Of course, your ability to achieve 100% conversion and connect everyone relies upon one of the factors being the intrusiveness and usefulness of advertising. We clearly don’t have norms yet as to how intrusive advertising on a VR communication platform can be, or how much users will tolerate in exchange for free, or nearly free, service.

I imagine I’ll be thinking about this a lot more.

[1] http://peterberkman.tumblr.com/post/80827337212/wrong-and-right-reasons-to-be-upset-about-oculus
[2] https://blog.twitter.com/2012/changes-coming-to-twitter-api
[3] http://venturebeat.com/2014/01/27/apple-sees-record-itunes-software-revenue-at-4-4b/
[4] http://investor.fb.com/results.cfm
[5] https://www.apple.com/pr/library/2014/01/07App-Store-Sales-Top-10-Billion-in-2013.html
[6] http://us.playstation.com/psn/playstation-home/

2.0 SNOW CRASHING 4
And we’re back with more Snow Crashing so it’s a VR-tastic episode today. I think, at last count, we’re up to around Chapter 5, after having covered YT’s RadiKS SmartWheels and her interaction with the mob upon delivering their pizza. There was a part about the identifying LASERs flickering out to touch and read her barcodes and visas at White Columns and not using wireless technology, which a reader helpfully pointed out was potentially more to do with lacking a good literary way to describe spooky wireless action at a distance. And yes, LASERs are cooler, especially when you capitalise them the way they’re supposed to be.

In Chapter 5, we’re back on the Street, and Neal Stephenson has just introduced people to the concept of avatars for the first time, for which: look for a corresponding input deal on the Oculus side (we’ve got the output technology down, now we need the sensing technology. Apple’s already picked up PrimeSense, so maybe the hardware’s already commoditised). There’s so much more inReady Player One about avatars, all it’s used for here it feels like is a little bit of worldbuilding to ready us for the universe we’re going to be spending narrative time in. Indeed, “you can look just like a giant talking penis” seems to describe most of peoples’ Second Life experiences at some point. There’s an interesting point here where Stephenson says that Hacker types don’t go in for garish avatars because they appreciate the computing power required to accurately render a realistic talking human face than a human penis, to which I would say: my how things change. You wouldn’t believe the realistic talking human penises you could render these days with all those TFLOPS.

Again, there’s something intrinsic about three-dimensional embodied environments that kind of messes with everything we’ve been used to in general interaction with computer interfaces. Stephenson points out that you can’t just materalise anywhere – that’s rude (in which case: we’re going to spending the next 18 months working out what is, and isn’t rude), but we can take cues from our massively multiplayer 3D FPSes – and we know that those quickly solved those concepts – in combat multiplayer instances, at least – in the form of (re)spawn points, not least of which because even if it’s *not* rude, it’s disorientating. We get a sense of the economy here, with Stephenson describing Metaverse “tourists” as those with off-the-shelf avatars – but there are those who “bought” the Avatar Construction Set(TM) a piece of third party software, as well as those who “run down to the computer games section of the local Wal-Mart and buy a copy of Brandy”, the latter of which is (even still) eminently possible and realistic these days.

I guess the big difference between the Metaverse envisaged by Stephenson and OASIS as imagined by Ernest Cline is that the latter has had about twenty five years worth of exposure to the idea of the hyperlink. In the Metaverse, indeed, in the entire toy universe, the concept of linking and hypermedia appears to only exist inside a discrete object: the hypercard. Now, Stephenson’s done his homework here and clearly played with, well, Hypercard, but what’s so utterly alien now is that all of this hyperlinked information exists inside–and only inside–a container object inside a fully realised 3D virtual world. It’s as if the web was chopped up into bits and then you had to use a piece of semi-sentient software to use it, the Librarian, to browse it. That’s just weird.

And that’s where the physicality of the Stephenson’s Metaverse falls down: it doesn’t embrace the link. You can’t teleport. The Metaverse is a single globe (so we’re told), and you have to physically travel from one place to another. There are, I don’t think, no places that are bigger on the inside than the outside. We get all of the adverts of course, one Hiro steps onto the Street, but we also hear about amusement parks, and they’re places that you have to *go*.

How weird.

3.0 ODDS
I continue to work on Secret Project, which at this point feels like it needs a codename. I’m going to call it SULACO BLUE.

Via Alexis Madrigal’s newsletter, news of Flash Boys, Michael Lewis’s (Moneyball, The Big Short) new book, shortly to go into the pile of “oh god, I should be reading this”. Amazon: http://amzn.to/1mIPFWd, Powell’s: http://www.powells.com/biblio/9780393244663, Wordery: https://wordery.com/flash-boys-michael-lewis-9780393244663

Over in the UK at some point (yesterday? Today? I have no idea) was Future Everything (http://futureeverything.org) a conference, apparently, about the Future and also Everything, but also one at which a bunch of friends spoke at and attended. I’m looking for write-ups to see how it went, but by all accounts and purposes it seemed like a good time, not least of which because one of the results was 2048: Dan W edition (http://games.usvsth3m.com/2048/dan-w-edition/), a clone of a clone of excellent iOS game Threes and one that works with New Aesthetic concepts instead of numbers. Also it’s possible to play while out of your head jetlagged.

Over on CNN (CNN!) news of OKCupid’s browser-sniffing protest (http://www.cnn.com/2014/03/31/tech/web/firefox-okcupid-protest/) at the Mozilla Foundation’s appointment of Brendan Eich for his $1k donation to support California’s Prop 8. It feels like the first time a big-name site has used browser-sniffing to bring to light a social-justice issue (SOPA doesn’t count, for me) and once the idea’s out there, it’ll be interesting to see how else the technique is used.

—

That’s it for me, today. No April Fools in today’s episode. That’s how much I like you all. And, it looks like some of the replies I *think* I’ve sent to you have instead been replies that have gone into the gaping maw of Tiny Letter’s email servers. So, uh, sorry about that. It means I have to go back and, er, reply again.

Again, I only get to reply if I get notes and I do love getting notes. They make a lovely whooshing sound as they Douglas Adams reference by.

Best,

Dan

Episode Forty Eight: Not Yet A Phyle; Ready Player One; Fantasy Acquisitions
by danhon

0.0 STATION IDENT
It’s Monday (in Perth, Western Australia, at least), so I’m writing episode forty eight. I have a long trip ahead: tonight I’ve a three hour flight to Melbourne, then a fourteen hour flight to LAX then a two hour flight home to Portland. Hopefully I’ll be able to sleep for most of it. If not, there’s a whole bunch of reading (Kate Losse’s The Boy Kings has been on my list for a while, plus I have Leander Kahney’s book on Jony Ive to finish). When I get to Melbourne, I’ll work on Episode Forty Nine.

1.0 NOT YET A PHYLE
“Then there were the tribes that people just made up out of thin air–the synthetic phyles–but most of them were based on some shared skill or weird idea or ritual.”

I’m not quite sure where this one is going, and I’m a little worried that it’s going to seem cliquey. On the other hand, I think it’s worth taking a look at.

I was reading Charlie Loyd’s tiny letter[1] (as pointed out on Twitter, a brand name on the verge of becoming lowercased and genericised, at least amongst a certain group of people), and it’s such a good example that I want to preface it by saying this is an observation of one group (of which I think I’m a part, so there goes detachment), and trying to see if there’s anything to extrapolate from it.

So settle down: it’s story time.

One day, Dan Williams was trying to write his talk for Future Everything, a conference being held in Manchester, England. As these things are wont to go, he joked that instead of a talk, he could simply play the game 2048 on stage. 2048, for those who’re following along at home, is a game based on 1024, which is a game based upon Threes – more here[2].

It would be better, remarked a wag (and there’s a significant number of wags on Twitter, the medium is pretty much designed for it), if there was a version of 2048 that replaced the numbers on the tiles with conference topics. And because this is the internet, and because the source to 2048 was widely available, it turned out to be trivial to knock up a fork of 2048 that gently poked fun at the idea of playing a game on stage instead of presenting a talk. That game was then deployed to the the usvsth3m website[3], a project out of the Trinity Mirror group designed to quickly build bits of fun internet culture journalism, such site run by Martin Belam and his merry cohort of internet culture jokesters, and I use the latter term in nothing but an affectionate term.

And then here’s the bit: Charlie and Robinson Meyer, a journalist, have an IM conversation about 2048, (iamdanw edition), have a conversation about it, the gist of which is “What can we say about the people who think this is fun and clever?”[4] Now, here’s the bit which gets potentially clique-y, for which I apologise:

Rob: Have you played 2048, Dan W edition yet?
Charlie: No.
Rob: It is a hoot.
Rob: http://games.usvsth3m.com/2048/dan-w-edition/
Charlie: Astonishing.
Charlie: Died at 2656.
Charlie: What can we say about the people who think this is fun and clever?
Charlie: Can we make a more interesting description than “people who have heard of the New Aesthetic”?

Now, you kind of have to play the game and know about the New Aesthetic to know what’s going on here. Or, rather, you can play the game and not know much about the New Aesthetic, too. In this version of the game, the numbers are represented by New Aesthetic-y concepts – you start with a shipping container, progress to a cubesat, then a drone, then a freight vessel, then the 2012 Olympic Mascot Wenlock, then the Epcot Centre, then a Space Shuttle, then the London Shard, then a Big Dog and so on.

All this is kind of to say: okay, it’s a very funny in-joke, if you’re in-enough to get the joke, and that’s where the charge of cliqueism comes from. But at the same time (and having just come out of finally finishing Ready Player One), there are onion-skin layers of cultural reference that make this thing pretty complicated.

Charlie’s question “Can we make a more interesting description than “people who have heard of the New Aesthetic” is an interesting one to me, because it points to a kind of categorising of people. And I’ve never had an arts background or upbringing, and I’ve never really considered myself that up on culture or subcultures, but, and this is the thing – is this a *thing*?

Perhaps the best expression of Bridle’s New Aesthetic is Bruce Sterling’s writeup of the New Aesthetic panel from SXSW 2012 (2012! Two years ago now!)[4]. And I think the answer to Charlie’s question is this, again from Sterling:

The “New Aesthetic” is a native product of modern network culture. It’s from London, but it was born digital, on the Internet. The New Aesthetic is a “theory object” and a “shareable concept.”

A theory object and a shareable concept that can be used as an attribute to describe a group of people. All very wanky, yes, but then Sterling says ultimately that the New Aesthetic is “a typical avant-garde art movement that has arisen within a modern network society.”

Here’s where I think it’s different, though. And again, I caveat this with not having an art history background or, really, bluntly, not knowing what I’m talking about and just mouthing off with an opinion. But this is my newsletter, etc. If you were to map the core practitioners of the New Aesthetic and where they are, you’d find an inordinate number of people *doing* things. This isn’t the art that you’d look at and make you think, these are services, internet-connected objects, things that because they live in a networked world and are *designed* for a networked world are necessarily mass or at least have the opportunity to be mass. Bitcoin, for crying out loud, is New Aesthetic, and the things made with it are. And the people playing with this stuff associated with this New Aesthetic have got day jobs. Or are designing how people interact with governments.

So I think the answer to Charlie’s question feels like a nascent phyle, Diamond-Age[5] style. A loose grouping of people with a networked sensibility with the power to actually alter, or nudge, the behaviour and affectation of that network in the physical world. They don’t all work together. They share roughly the same values, ish. But they’re definitely not recognised as a formal group.

[1] http://tinyletter.com/vruba/letters/6-5-hills
[2] http://asherv.com/threes/threemails/
[3] http://games.usvsth3m.com/2048/dan-w-edition/
[4] http://www.wired.com/2012/04/an-essay-on-the-new-aesthetic/
[5] Amazon: http://amzn.to/1gGGdiP, Powell’s: http://www.powells.com/biblio/9780553380965, Abe Books: http://www.abebooks.com/Diamond-Age-Young-Ladys-Illustrated-Primer/10820649916/bd

2.0 READY PLAYER ONE
Okay, so I finally finished Ready Player One[1]. And yes, you can properly describe it as a cultural nerdgasm, the ultimate end-game of what happens when a bunch of geeks got together and make referential in-jokes and quote bits of culture as self-expression.

I *think* if I’d read this at a younger age, it’d probably have the same effect as Coupland’s Microserfs did. As it is, my brain is decrepit and its neural structures have probably lost all of their malleability, so the impact of this book feels like it’s somewhat lessened. And yet.

For anyone who grew up with the net – and there are a few of us, by now – it probably strikes a personal chord. It’s not like I didn’t get on with people at school and didn’t have friends, but I definitely found it easier to express myself through a keyboard. And, most of the people I’ve met through my life who’ve stayed the closest friends are those who I met through the ‘net. Whether it was the blogging scene in the late 90s in the UK all the way through to the way it’s easy – for certain values of easy – to get to know people over Twitter now, there’s been something about the network mediating relationships that does some good.

Of course, all of those friendships were then mediated in the real world. We met in pubs and drank and made in-jokes and quoted shared culture at each other, finishing each others’ sentences. But it genuinely felt to me that the time we spent with each other with a keyboard and a screen separating us helped us to get to know each other better. Now, this might have been self-selecting: we were pretty honest people, or at least, people who liked expressing themselves through text. But at exactly the same time, we were learning that people weren’t taking the opportunity to express their true selves and instead were playing out with different facets of their personalities that might not have been so grounded in reality.

There’s a wonderful section toward the end of the book about Aeche, our protagonist Parzival’s best friend, that treads over a well-worn aspect of identity on the ‘net and it’s done (in my view, at least) in a touching and human way that feels genuine. For a lot of people, still, pseudonymity on the ‘net is a leveler where our society hasn’t caught up out in the physical world. And it’s telling that when that pseudonymity is removed, we painfully revert to privilege, bias and misogyny because, well, that’s what we are as a society right now.

I don’t really have an opinion about OASIS versus Oculus Rift, I have to admit. It’s clear that OASIS occupies a different place in our shared consciousness if only because of time and the fact that Snow Crash’s Metaverse and the cyberspace envisaged by Gibson was seminal. When Michael Abrash, now at Oculus, admits that Snow Crash was a direct inspiration[2], we know where we stand. I see OASIS as a direct descendent, merely the latest version of the same family tree. That’s why OASIS isn’t that interesting: it’s just a written record of where we wish VR was, rather than anything particularly new. Sure, it’s coloured in and a bit more detail has been added, but (and I hope this doesn’t feel like a cop-out), but at some point it feels like there’s only so much pontificating you can do about a subject like VR without actually making a lot of it.

[1] Amazon: http://amzn.to/1oh3rRB, Powell’s: http://www.powells.com/biblio/9780307887443, Abe Books: http://www.abebooks.co.uk/Ready-Player-Ernest-Cline/9530178007/bd
[2] http://www.oculusvr.com/blog/introducing-michael-abrash-oculus-chief-scientist/

3.0 FANTASY ACQUISITIONS
“Apple buys smaller technology companies from time to time”

A short one, this one.

The other day I did a thing I sometimes do which is tweet out fake tech company news because, I guess, I’m weird. This one was along the lines of Apple announcing that it had acquired, in a double whammy, both Muji and Uniqlo, the former for Internet of Thingsish type reasons, and the latter for wearable clothing fashion-y type reasons. It’s fun (for, er, certain geeky values of fun, I guess) to imagine sometimes which companies would buy which other companies and why and how they wouldn’t be complete wastes of time and money and instead genuinely offer an opportunity for advancement.

So here’s the reasoning: you’ve got a company that makes computers and has always made computers and you’ve got for the first time, what feels like tangible movement toward ubiquitous computing. There are a *tonne* of smart mobile devices out there, all networked up the wazoo and everyone’s looking for the next big thing. Oh, and you’ve just hired the CEO of Burberry.

The CEO of Burberry doesn’t know how to make computers. She does know how to do fashion. So then the question is this: Apple ignited the personal computing revolution with the Mac, yes. And then ate the music industry with the iPod, yes. Which – note – was not anything to do with personal computing. And then ate the mobile phone industry with the iPhone, which had everything to do with personal computing, because *get this* – phones are way lower down Maslow’s hierarchy than Personal Computing in its desktop and latterly laptop phase because those things tended to solve problems at the self-actualisation pointy-end because they were tethered to a location, whereas something that’s in your pocket all the time can actually help you at the physiological/safety/belonging end of the pyramid. And how did they do that? Because of Moore’s Law and the phone being a trojan horse: the vast majority of people might not feel like they have need for a desktop general purpose computing device to accomplish, basically, White People Things, but stick the same power in a pocket device whose main use historically was “talking to people”, and suddenly you’ve unlocked the ability to service a whole bunch of latent need.

Where was I. Right.

Is Apple going to *invent* more computing devices, or is Apple going to *add* computing to more things. I reckon the answer’s the latter – in which case, when do they start buying expertise into those areas? There are already reports of Apple recruitment being rebuffed by the Swiss watchmakers. Nest, it feels like, is a little bit too close to the tree.

Apple was lucky, I think, with phones. Phones were an adjacency. But when it’s possible to add computing to anything, are they going to learn that industry every single time?

—

OK. I’m going to head out to Perth airport and hang out in the Virgin lounge for a bit. And work on an exciting Secret Project.

As ever, send me notes, because I love them.

Best,

Dan

Episode Forty Seven – Building Better Worlds; Mobile; More video
by danhon

0.0 STATION IDENT
It’s 8:36am and I’m at the State Theater Centre in Perth for today’s xmedialab conference, the reason I’m in Perth. I’ve been up since 4am, but that’s not so bad because it meant I had time for a one hour Facetime with my wife and son, the latter of which gleefully showed me how to pull all the toilet paper off the roll.

1.0 BUILDING BETTER WORLDS
On the way to the hotel in Perth yesterday I had a good conversation with one of my fellow speakers. We were talking about – and, generally, processing – the implications and strategy behind the Facebook/Oculus Rift deal, and got onto the subject of internet.org and the various internet titans’ recent projects du jour of bringing connectivity to the bottom of the pyramid – the four billion or so people on our planet who subsist on under $2.50 US per day.

Now I’m lucky to have the benefit of knowing a good friend who works in the development area – lots of projects with the US State Department, Clinton Foundation, Bill & Melinda Gates Foundation, DFID, all that sort of stuff. And this guy’s smart – he doesn’t want to waste money and he genuinely wants to make a difference, plus he’s a more-or-less believer in economic progress and capitalism being a driver to help bring people out of poverty and to higher standards of living.
From his point of view, the problem isn’t connectivity – not bandwidth or networking. It’s things that are lower down the stack – like power. Because when you get out in the sticks, you don’t have the generators and you don’t have the power lines and while you might have cell service, you definitely don’t have anything to stick your charger into to once your battery dies.

Electricity? Now there’s a thing. Electricity brings with it light, refrigeration and yes, a way to power and charge all of those phones.

From my naive and external viewpoint to both international development *and* the machinations of the internet gods of Google and Facebook, all three of whom organisations undoubtedly and unassailably employ smart people, it looks like the latter two – the Valley internet gods – see problems in terms of the context that is around them. They see a chronic, debilitating lack of connectivity, because connectivity is what powers them.

Note what I’m saying here: I’m not saying that deploying drones and aerostats and ‘loons is bad – it’s just that there’s a fair chance it doesn’t and won’t fix the whole problem and is merely a piece of the stack further up the chain. Connectivity may well be a human right, but there’s work to be done further down Maslow’s stack. This isn’t a zero-sum game. What I suspect is frustrating to some people, though, is seeing the resource being deployed at solving problems higher up the stack when there exist opportunities further down. But hey, I’m a pragmatist – I’ll take what I can get.

It’s easy when looking at this influx of foreign aid as some sort of colonialism 2.0, but having learned its lesson from the last time and genuinely bringing gifts of data that aren’t virally laced. Well, not much, at any rate.

So this is what I’m getting at: it’s not colonialism.

It’s terraforming for capitalism.

You have an environment that’s nigh-on inhospitable or at least hostile to capitalism. You get your Weyland-Yutanis in, with their Atmospheric Processing Units or their ‘loons or drones and install engineering projects designed to change the environment so that it’s conducive to capitalism and economic growth.

2.0 MOBILE
I mentioned the other day that I’d been asked to speak about video, social and mobile for this conference in Perth. I covered video yesterday, and only just realised that I’d also covered the social part in episode forty four’s section on danah boyd. So here’s the last bit: mobile.

This is probably going to come across as a bit high-level and simplistic, but hopefully some of you at least will get something of value from it.

The thing about mobile is that, alongside video and “social”, it’s at least an order of magnitude more important. I felt pretty pleased with myself when I was able to categorise video as a content-type, one whose format boundaries are changing but ultimately “just” content. I felt less pleased about my insights about the social thing because, honestly, they’re basically danah’s insights and she’s a smart person we would all do well to pay attention to. And that social is, well, one of looking at it is a directed graph description of behaviour.

But mobile. Mobile is the big one, because mobile is the interface. In the talk, I paraphrase Douglas Adams by saying:

“Mobile is big. Really big. You just won’t believe how vastly, hugely, mind-bogglingly big it is. I mean, you may think it’s a long way down the road to the chemist’s (or, for that matter, the PC revolution), but that’s just peanuts to mobile.”

Because the simple thing is this: mobile’s the force multiplier. It’s what computers were meant to be, but computers were tied to desks and computers were for doing work things and you needed to have a reason to have one – the justifications were so much higher up Maslow’s pyramid, whereas the proposition of a mobile phone is this: you want to talk to people. Moore’s law was the trojan horse that enabled general purpose computing to infiltrate a formerly single-purpose device, and with that, not the Mac, was the personal computing revolution *really* ignited.

I have a shtick about Tetris which to be honest I’m not even sure if I’ve already used here or not. It’s the one about everyone being able to understand that Tetris was a cultural phenomenon when it was in its Gameboy instantiation, and if you thought *that* was big when you needed to justify having a portable game-playing device, imagine how big Angry Birds or Candy Crush is when you *don’t* need to justify having a game-playing device with the corresponding social implications, because hey, it turns out your social-fulfillment device or business-doing device accidentally also does a good job of playing Angry Birds.

This is why mobile is big: it’s all the reasons before, like it’s the first time the majority of people will experience the internet and it’s the first time the majority of people will experience general purpose computing. It’s what the internet and computing were *meant* to be. Not hulking things tethered to desks thanks to the gravitational force of our planet.

Mobile is Steve Jobs’ bicycle for the mind unbound.

Everything but everything has the opportunity to be remade again.

3.0 MORE VIDEO
In response to yesterday’s section on video, Dan Williams was curious to know what I’ve learned about storytelling through video: how does it work? How do you know if something’s good or not, “compared to all the ukelele music startup demo videos where some Gmail users stalks his ex-girlfriend”.

I wish it were easy to articulate. One of the things I think I’ve learned – and it’s all been through osmosis and praxis – has been a sort of Shannon-esque information density for effective storytelling. There’s only so much you can accomplish in terms of coherent information transfer in fifteen seconds. Only so much in thirty, sixty or ninety. You’re constantly struggling to balance novelty (an interesting and new creative idea to hook attention), clarity (it’s no use if no-one has any idea what you’re saying) and a third thing, because the rule of threes.

And then sound design. And then the editing. And then casting. It’s a stupendously complicated process.

In his email, Dan mentioned that he thought the Lisagor Sandwich Videos were good – and on that point, I think my (somewhat) considered opinion is that I disagree. They’re certainly competently put together, from my point of view, but they rest (and again, perhaps rightly) on the product, and not the actual storytelling. When we were working on the launch film for Facebook’s Paper I remember looking at all the reference we’d pulled and the problem was that it was *all* Sandwich Video stuff. And there’s a shtick and a formula to what Adam does, which is patiently explain using a talking head and a locked-off camera what the product is, and they all accomplish their goal effectively. So are they good? They’re fine, I suppose. Are they great? I don’t think so. But they’re probably stupendously cost-effective *if* your product is right.

—

OK. Big conference day today. Have a great weekend, and I’ll see you on Monday.

As ever, I appreciate all the notes.

Best,

Dan

Episode Forty Six – Snow Crashing 3; Video is a Content-Type; Blame Your Tools
by danhon

0.0 STATION IDENT
I’m writing this at 1:25pm on Thursday, March 27 in Perth, Australia. I have the next few days in Perth – I’m doing this xmedialab thing tomorrow, then spending Saturday in a studio recording what I presented on Friday. I’ve added Yet Another International SIM to my collection – two dollars a day for five hundred meg on Optus, and while I know I’m in a vanishingly small market, I wish international roaming would get its act together.

1.0 SNOW CRASHING 3
I remember thinking that millimeter radar sounded so cool when I first read about it in Snow Crash. And then it started turning up, I think, in movies like Robocop and Total Recall as the technology that would show firearms on active security scans. Right now, millimeter-wave radar hasn’t yet made the jump to consumer technology, and you’re most likely to encounter it when you go through a security scan at an airport. So while YT’s RadiKS Mark II Smartwheels use sonar, laser rangefinding and millimeter-wave radar to identify mufflers and other debris, the only place where you’ll encounter the whole package right now are self driving Google Cars. Practically, though, that’s a gnarly engineering problem. The smartwheels consist of hubs (presumably where your computing and battery/kinetic energy generation lives) and extensible spokes with contact pads – all makes sense, until you think about how small that package has to be. Perhaps the board is all ruggedised battery and computing power, and the wheels pull data from sensing built into the board.

n when forecasting the future, you have wildcards: the sudden availability of high-k ambient temperature superconductors would definitely qualify. (As an aside, I used to enjoy reading Peter Cochrane’s[1] annual forecast reports out of British Telecom). As it stands, I’m not aware of any radical advance in materials science that’s going to make cheap and mass-produced superconducting electromagnets anytime soon. Suffice to say that for them to filter down to harpoons for skaters they’d already have made an impact for someone like Elon Musk.

There’s a wonderful description of the fire hydrants at The Mews At Windsor Heights: brass, robot-polished (another aside as to how the economy works in Snow Crash’s toy universe – perhaps they’re cleaned by relatives of Rat Thing designed out of Mr. Lee’s Greater Hong Kong?), designed on computer screen with an eye toward elegance of things past and forgotten about: that is, artisanal fire hydrants designed to maximise property value, brand-perfect, maintained without needing any human touching.

Later, YT takes a shortcut through White Columns, a sort of capitalist-endorsed racial segregation through property values, a future not entirely unenvisagable if the religious discrimination legislation had passed in a variety of US states over the last month: WHITE PEOPLE ONLY, they say, NON-CAUCASIANS MUST BE PROCESSED. So, not strictly *denying* service to non-caucasians, just… processing them. This is another opportunity to remind ourselves about the other big thing that Stephenson – and a lot of other people – missed. Ubiquitous wireless data, or even the concept of wireless data at all, just doesn’t figure in Snow Crash’s toy universe. YT has a visa to White Columns, but it’s encoded as a barcode on her chest, and a laser flicks out to scan it as she rides past. No RFIDs here or Bluetooth iBeacons or short-range wireless coms – it’s as if she literally has a QR code pasted to her chest, ready to be read by anyone.

I’ll leave this Snow Crashing installation with this one quote, though: “the world is full of power and energy, and a person can go far by just skimming off a tiny bit of it.”

[1] http://www.cochrane.org.uk

2.0 VIDEO IS A CONTENT-TYPE
The topic I’ve been asked to speak about in Perth is of trends in video, social and mobile. Which is pretty excitingly large, and I’ve decided to cover them that way in my keynote – mainly because they seem helpfully ordered in order of interestingness and impact. Once I’d sat down and done some thinking, a sort of hierarchy emerged where video was at the bottom – the least interesting and a mere content-type or format, followed by “social” as a relationship graph and open to way more interesting combinatorial explosion, followed by “mobile” – the two of which I’ll cover in subsequent issues.

So here’s what I’ve been thinking about video.

First, the easy stuff. Video’s just a content-type. It’s one of the best and most effective storytelling methods that we have at our disposal, mainly because we’ve spent so much time with it as a species that we’re literate in both its consumption and production. At the day job, I can assure you that there’s a stupendous amount of care and attention that goes into making sure that, at least in the 15-90 second ad format end, you’re emotionally engaged. Same goes for TV shows and longer-format stuff like movies.

But because video is a content-type it’s escaping the strictures of its dominant media. So goodbye, broadcast with your programme lengths and scheduling issues, hello, and I paraphrase the BBC here, the “amazing creative opportunities” that just getting rid of those two constraints promise. With digitisation, video as content-type can go anywhere now. For the people who make good video, that’s great news: more demand, more opportunity for distribution. The work my team and I did on building Sony’s brand site couldn’t have been done without the expertise built from an understanding of animation, CGI and filmic storytelling. Sure, the end result wasn’t film (and I’d argue that it wouldn’t have been the same to just produce a film, either) but it couldn’t have been made without that knowledge. Adam Lisagor does a good line in video storytelling to communicate the benefits of apps, regardless of what he thinks of our effort for Facebook’s Paper. Now that we have (more or less) the right kind of distribution system, genuine multimedia packages like the New York Times’ Snowfall are making use of video in a way that news organisations wouldn’t have considered before in order to deliver compelling stories. And, of course, all of this is alongside the promise of companies like Condition One that have been developing 360 live video for delivery on the iPad and now looking at platforms like the well-funded Oculus Rift.

So the need for more video is great for people who’re good at producing it. The people who need good video, though: their budgets are being squeezed because everyone’s budgets are being squeezed. And the thing about video is, just like with the amateurisation of everything else on the internet, you can get quite far if you’ve got lots of time and no money. For brands, what they have instead is a frequently misplaced sense of urgency and not enough money, exacerbated by being able to point to what people with no money and lots of time are able to and wondering why they can’t have nice things.

But that’s not the biggest thing about video, I think. I think it’s this:

I’m not quite sure what Google’s doing with all the video that’s being uploaded to YouTube, but I hope they’re working on a way to understand it. It’s a sufficiently hard problem, because you’re essentially talking about speech recognition and a pretty good degree of semantic understanding. Or, you know, hard AI. It seems, to a geek, untidy to have to rely on human-supplied metadata, especially explicit descriptions and tagging, especially when you have so much unstructured data. And I’m not entirely sure how you go about implementing some sort of human understanding checksum: it’s one thing to have OCR candidate text run through Recaptcha to help train OCR algorithms to mine data out of books, but given that most of the video (I’m guessing, here) is user-generated and not the kind that comes with broadcast closed captioning and there’s *already* too much video to watch, I don’t know who’s going to check all those algorithmically generated transcripts against what’s being said. Maybe the algorithmically generated transcripts will be good enough, though.

So here’s a thing: at some point, Google will turn on “good enough” machine transcription and suddenly every YouTube video will have a searchable transcript. At some point, Google will turn on “good enough” entity recognition and its neural nets will get smart enough so that they can recognise individuals and not just cats, across up to 60 frames per second at 1080p. And then what? No one was watching most of that video in the first place, but there are always extra corners of information you can monetise.

That’s the thing about video for me: it’s a black hole. There’s no Douglas Adams-esque VCR, watching all the realtime YouTube feeds and discerning knowledge from them. At least all the textual documents getting sucked into Google are being subsumed in some way and knowledge and understanding being mined out of them. Video is incredibly far behind, I feel.

3.0 YOU CAN BLAME THE TOOLS
Bret Victor has done a fantastic talk[1] that you really should check out. It’s called Inventing on Principle and though it’s been out for a while, even if you have seen it, I think it bears and withstands re-watching. Although it’s an hour long, the real meat of it is in the first thirty minutes.

Over the last three years I’ve been doing a bunch of thinking about what it means to be able to produce great creative work – and I’m using the word creative loosely, here. Victor’s got a good general principle which is that to produce good creative work, especially novel work, the gap between you and your work needs to be as small as possible. Think woodworking and sanding, or planing: there’s a tactile dimension to the work being done and feedback is instantaneous and visceral. In physical media, it’s easy to achieve this sort of low-latency high-bandwidth sensory feedback because, well, we’re embodied in a physical universe (and if you disagree with that, then we can have a separate conversation about Nick Bostrom).

So: pencil and paper is good. Draw. Don’t like it? Rub it out, make a new one.

Typewriter. Word processor.

Non-linear editing in film? Also good. Think the piece might play better with this scene over there? Move it and watch it. Put it back if it didn’t. Cut it here, cut it there: and in my last three years I’ve had a somewhat unparalleled education in what it takes to make great TV ads, and let’s just say that it always pretty much involves sitting in an edit suite and trying things out to see what they’re like.

Photoshop… is interesting. Watching screencasts of people who know what they’re doing with Photoshop is a bit like watching Yehudi Menuhin play the violin. Photoshop is an instrument and these people know how to wield it.

Victor’s point is that when it comes to code, our tools are nigh-on useless. Adapted from another era when we didn’t even have interactive screens, even the best tools that we have, like when Microsoft introduced Intellisense for code-completion are predicated upon code-as-text. Not code-as-output.

Interactive work, say, building a web application that shows you running routes on your smartphone or a branded iPhone app that lets you give a Coke to someone on the other side of the world – my examples are necessarily drawn from the brand-driven world I’ve been living in – is a complete fucking nightmare.

At its worst, that kind of interactive works like this:

Someone comes up with an idea. That person explains that idea to another person. If they’re being masochistic, the idea will be explained without drawing anything: as a paragraph in a Word document, for example (and it will most likely be Word, not Google Docs). Now the second person sits down in front of a development environment and, in her head, pretends to be a computer. When she’s pretending to be a computer, she programs herself to work out how she would tell the computer what to do. Then she writes down, in something that ultimately is just another version of Microsoft Word, a bunch of instructions that may or may not do what she has guessed she needs to tell the real computer to do.

Then she tells the computer to run what she wrote. And swears and then tries again. After a while, she gets the computer to do what she thinks she needs it to do. This might have taken days or weeks. Then she shows it to the first person. This is all wrong, the first person says. This isn’t my idea at all. Our developer now commits ritual suicide.

This is a familiar refrain from the agency world. Agencies like mine prize themselves on being able to do two things: come up with a strategic framework that leads to the right kind of idea, and then coming up with the right, breakthrough idea.

Ideas trump execution, in the world of advertising.

Coming from the world of code, execution trumps idea. And thus our inevitable clash.

Now, it’s obviously not a black and white divide. Sometimes, a so-so idea can have an unbelievable execution and you can still get something magic. I’d put the work that our agency did for P&G and their Winter Olympics campaign in that category – a stunning insight, one that all Olympians have mothers, is paired with a script that isn’t groundbreaking (mothers supporting their Olympian children as they grow up, cut to reaction shots as they compete and win or lose) but absolutely wins in terms of pixel-perfect execution. Music, editing, composition, casting, strategy: all work together to create something good.

In the environment of an agency, in the majority of cases, those entrusted with answering a brief with interactive work don’t actually know how to craft that work. And it’s hard enough to communicate ideas as it is, without having, essentially, the blind leading the blind.

This is why, naturally, there’s a well-meaning drive to prototype and iterate. As soon as a germ of an idea exists, prototype that idea, bring it to life. But then you look at the other side of the coin, which is this: where are the prototyping tools? Facebook ended up building their own on top of Quartz Composer[2] – and having seen it in action with Paper and Facebook Home, never mind what you might think about the actual products, I can attest that their development would have taken significantly longer without having shortened the iteration loop.

I keep coming back to Pixar, and I don’t mean to, but it’s just because they’re so frustratingly good. They’re a storytelling organisation that, in part because of its roots in computer science and the fundamental understanding that computers can help you do things, have a team dedicated to pre-production tools. Imagine that: a team devoted to building software that helps you, as an organisation, make better creative work. When Ed Catmull says that all of Pixar’s movies start out sucking and that it’s their job to make them not-suck, why does it feel abnormal for them to be one of the rare companies that sees an opportunity in software helping to do that? Is it because they’re a creative company, and computers and software are soulless entities, sucking out the last bastion of human distinctiveness? Because bollocks to that.

Victor’s charge is that we need better tools. It’s easy to see what might happen when software eats the creative industry in terms of metrics and analytics. But software should, and will, eat the world of creative concepting. Anything that helps us iterate our ideas more quickly, and share with more clarity, is a good thing. Who’s building this kind of software? Where’s the continuous integration for scripting? Sure, ideas need time to settle and nurturing. But they also need to be kicked and prodded and then, when they’re right, polished and polished and polished. Not for the last time am I left wondering if Word isn’t the best tool for that job.

[1] https://vimeo.com/36579366
[2] http://facebook.github.io/origami/

—

Best,

Dan

Episode Forty Five – Station Ident; Snow Crashing 2; Computers, AMIRITE?; A Book on your Face
by danhon

0.0 STATION IDENT
I’m at an altitude of thirty six thousand feet travelling at five hundred and sixty one miles per hour, with a head wind of nine miles per hour. I’m at 171 degrees 2 minutes 53 seconds south, 13 degrees, 12 minutes, 54 seconds south on tail number 7102. I am 1,879 miles from my destination. I am in a mundane technological marvel; experiencing the plainness of commercial air travel in a Boeing 777-200. I am about eight hours and three quarter hours of travel time from my final destination of Perth.

A track from Music Together: Flutes has just come on (Shake Your Simmons Down) and I’m a bit teary eyed because I can see in my head how my son jiggles and dances around to it whenever it comes on over Airplay.

1.0 SNOW CRASHING 2
Okay, so the last installment of Snow Crashing turned out to be pretty fun to write, so here’s some more.

The Street and The Metaverse are probably the most stupendously (perhaps temporarily) wrong things for Stephenson to have gotten. It may well be that right now our grasp for VR has just caught up with the reach we hold in our imaginations with renewed interested in VR from companies like Valve and Oculus, but the vision portrayed in Snow Crash is so of the era that it’s been rightly seminal.

What he got right, kind of: like the web, Stephenson hopes that the protocol is open and hammered out by a working group, but the reality we’re in is that something like the Street these days wouldn’t have its protocol hammered out by just the one working group – that’d be too easy. We’d have the W3C weighing in, various HTML working groups, plus Khronos weighing in with whatever was happening with WebGL these days. Because the best way to implement VR would be in some ungodly combination of WebGL, HTML, CSS and JavaScript.

I can’t work out whether Stephenson is being smart with the Street and the Metaverse or if he missed a fundamental point about networks and computing infrastructure which is that scarcity isn’t really a problem. There’s only one Street, and the equivalent scarcity is in replicated physical proximity to the Street, whereas in our world it’s having a memorable dot com domain. Or, you know, that attention is scarce and typically congregates. The dumb thing that everyone knows and really should know better by now is that simulated physicality scales only as well (if not worse) as real physicality: ie. not very well (thanks for the reminder, Kim Pallister). Now, to be working at a company directly figuring out how to mass scale VR and have it adopted as fast as mobile phones or tablets? Along with defining all-new UI affordances when we can barely figure out how to design multi-touch surfaces? That would be a job…

Of course, Snow Crash pre-dates the web and envisages a hyper-capitalist future where capitalism has sort-of failed and income inequality has made things bad, if not downright terrible, for a lot of people. So in the world of Snow Crash, you actually have to do the equivalent of apply for *planning permission* and get permits and bribe inspectors and observe zoning laws to build in the Metaverse. Not so in our world, where no one is really in charge of the internet, or the web. Sure, Stephenson allows for those applications to be made to the Global Media Protocol Group – the equivalent of having to apply to the W3C, I suppose, if you wanted to build a website, and another form to fill in if you wanted to use “HOMEPAGE / SCROLLING/ PARALLAX / LAZY LOADING” and then pay them – and those fees being held in trust for further development of the Metaverse.

And then there’s the bit where Stephenson breaks down the economics of the Street in ways that I think are completely alien to the VC and growth fueled universe that we live in right now. In the universe of Snow Crash, there’s a total human population of around six to ten billion people – matching up to what we have now. Of those, perhaps a billion have enough money to have a computer, and of those only a quarter of them bother to own one, and then a quarter of those have hardware powerful enough to render the Street. That’s a TAM of sixty million, plus, he says, but you get to add another sixty million who visit from public terminals. Only a hundred and twenty million total users! At any given time, he says, the Street is populated by double the population of New York City, giving a daily active user count of about 16 million which, by today’s standards, is a bit shit. EVEN if those 16 million are, as Stephenson exposits, the 1%.

I don’t know about you, but something tells me that the economics in Stephenson’s toy universe are a bit off. He never really goes into *why* the Street’s simulated physicality was such a big deal and my guess (acknowledging that this is fanwanking territory into the motivations of fictional characters in designing an ultimately global, yet fictional, social multimedia protocol) is simply that a bunch of geeks, just like Hiro, did it was cool and because, er, they read about it in Snow Crash.

Which again leads me to this: what sort of VR are we going to build, if the short hand of Gibson and Stephenson are what we have to hand? It’s clear that Stephenson fundamentally didn’t get that the *most* important thing about hypermedia was the links. Otherwise we wouldn’t have motorcycle chases in the metaverse (but for he wanted to write a particularly unfilmable pulp action screenplay). It’s all bits in the stream, so you apply a matrix transformation and suddenly what was here is over there. You don’t even have to click your heels three times.

It makes me think that Stephenson and Hiro are trying to point something out about humans actually *liking* scarcity.

2.0 COMPUTERS, AMIRITE?
Matt Jones made a quip that in the Top Gear of Quipping On Twitter About Things I’d make a good Jeremy Clarkson, and I’m not entirely sure whether to take that as a compliment or a slight. He declined to elucidate further, the cheeky sod.

Anyway, this bit is probably going to sound best written in an exasperated-at-current-technology Clarkson (but definitely not the tight jeans railing at political correctness and climate change Clarkson).

I’m in a lot of meetings where lots of people bring laptops to meetings and then fiddle around with cables and dongles and displays or projectors and Oh My God if presenting things on a big screen isn’t one of the most stupendously fucked up things ever that if you thought even Apple could get it right, you’d be so deadly wrong. I mean, you’re not doing the whole Windows era of Function-7 to turn on the external display and then maybe Fn-8 to turn off mirroring or was it turn on mirroring and oh look just give it to me I’ll do it.

Here are the things that happen when people plug in Mac laptops and try and present.

It doesn’t work
It doesn’t work because the screen isn’t on the right input
No-one can find the remote control to change the input
No-one knows, or wants to try to figure out what input the screen should be changed to
There’s some sort of Crestron thing on the table and jabbing at the “laptop” icon finally puts something on the screen
It’s the wrong screen because the laptop has extended its screen and the user wanted mirroring
It’s the wrong screen because the laptop has mirrored its screen and the user wanted extended
The user doesn’t know how to switch between mirroring or extension
Everyone waits while System Preferences loads up and we hunt for the “turn on/off mirroring” checkbox
The presentation is in Keynote, so that’s OK until they want to sort out presenter display which is either great if you’re using Old Keynote or a nightmare sent from the depths of hell to torment you if you’re using New Keynote, and doubly great if you remember the shift-X hotkey to swap the main and presenter display around
The presentation is a PDF which is marginally OK if you’re showing it in Preview and you know how to make Preview full screen which you can do a number of ways oh god why are there so many ways and you didn’t embed a video in a PDF did you because that won’t play so
The presentation is a PDF with an embedded video so you have to use Adobe Reader and you wonder what was it you did in that past life, were you Hitler or something, because now you have to make Adobe Reader go full screen and that means realistically you have to use mirroring which means you lose presenter display so good job you brought those hard copies and now you finally get to the embedded video and it a) doesn’t work, b) works but the framerate is stupendously low because god knows Adobe knows how to make not even high-performing software but software that just works for christ’s sake, c) the video works but then Reader quits when you get to the next slide because that’s great that doesn’t disrupt the flow of the presentation whatsoever, d) none of it works, none of it ever works, that’s why you also asked for the video files on their own so you can just use Quicktime
Oh god now you’re using Quicktime and pop-quiz hotshot, when you hit that full screen button, which display is it going to maximise on to? Bonus points if you’re using display mirroring at this point but hating yourself
But wait, someone just pointed out that none of those videos played back with sound and you plugged in the little sound thing to the little sound hole but this is because someone smart someone figured hey, if you’re plugged into an HDMI port on the display end let’s use HDMI audio and you forgot to option-click the little loudspeaker icon in the menubar and select whatever indecipherable string of supposedly Roman alphabet characters is the symbol for the audio input of the screen you’re using.
No, throwing the display over Apple TV is not an option are you insane?
Of course, Steve’s solution for this was to probably shout at people until it worked. Or never have to set this stuff up on his own in the first place. Also, he didn’t need presenter display because he practised this shit a million times, could do it in his sleep. Only you weak people need presenter display and your notes, you should cry yourselves to sleep.

It’s weird that it’s perfectly fine to pop-up a modal dialog when a USB mass-storage device is plugged in (what do you want to do? Open iPhoto? Aperture? Just show finder?) but not when something significantly more complicated like an HDMI cable is plugged in (Mirror? Extend? Reroute audio?).

It shouldn’t be this hard, and it makes me despair.

3.0 IT’S LIKE A BOOK, ON YOUR FACE
Watching the internet peanut gallery (of which I am painfully aware I’m a part) is painfully addictive. I was reading the Hacker News comments on the Oculus Rift/Facebook story and then it was only a click away to Notch’s post about the future of virtual reality and how he didn’t want any part of a Facebook-funded push into VR.

So this is where Facebook has a branding problem. They might also have a behavioural problem, but let’s just focus on the former for starters. It is impossible to argue with the user number: even if they were off by fifteen percent, the daily and monthly active users of Facebook-the-product for both “desktop” and “mobile” are off the charts, incomparable to any other in that class of technology so far deployed.

And yet the common perception – at least (and remember to check your recency bias here) – is that they’re evil and in it for the money when, try as he might, Zuckerberg has tried to make clear that the *goal* of Facebook is to connect the world, and that advertising is the least-evil way of doing it. Isn’t it?

Ian Betteridge calls this a sort of tech-snobbery – that the internet commentariat can’t see or won’t acknowledge the value that “regular people” get out of Facebook. That despite what the elites on the coasts of America might say, the middle of America is quite happy posting cat pictures and re-posts of memes or participating in grooming, phatic communication in some way through the platform. And again, you can be sure that if Google (or even Microsoft!) had announced the acquisition the reaction would be different.

So no, it’s not really like a book, but on your face. In fact, like I said last episode, it’s got nothing to do with Facebook the product and everything to do with Zuckerberg, the vision. So I suspect that, because they’re smart people, Oculus Rift and their partners at the big thumb aren’t going to care much about what the peanut gallery thinks. Because they’ve got their vision thing going on, of variously a) finally bringing about the VR we’ve all been dreaming of, and b) connecting the world, and they’re just going to go ahead and implement it.

So the question is: what were all these other conflicting visions? One common one is that Oculus was annointed as the first great giant tech company to be born through the fire of crowdfunding. But Kickstarter was never about *ownership*, and they’ve been clear about that. Andy Baio retweeted the valid, I think, thought that a backer’s relationship to a Kickstarter is that of parent. You help bring them into the world, but they’re their own entity. You might kick and scream and wish that they didn’t go and do the weird things that they did, they might let you down, they might not make the choices you wish they would make, but in the end: your role is that of parent and to let them go. They can choose to listen to you or not, and you can choose to help birth another Kickstarter or not.

This goes as much for the Veronica Mars fulfillment kerfuffle of which I’m as guilty of for stoking the flames. As someone who paid $100 on a whim (which on another level kind of disgusts me) to back the project because I loved the first two series, it was good to know that I’d be getting a digital download. But when I found out that the download would be fulfilled via Ultraviolet, like many others, I flipped out into nerd rage because the customer experience and service wasn’t good enough.

Sometimes, people and entities make choices that you might not agree with. You might bite and kick and scream in one hundred and forty characters, but that was kind of the deal with Kickstarter. The line that demarcates what the project may or may not owe you may be blurry, but it does exist.

But all of this is new. Kickstarter isn’t a shop. It isn’t a funding agreement. It’s a new thing, and we’re all discovering the norms together.

—

I’m still in the air, so I’ll send this when I land. Hopefully I didn’t say anything racist before I got on the plane in LAX.
As ever, send me all your notes. I do like getting them, and I do respond to them. And if I don’t respond to them, they’re preying on my mind until I know the right thing to say. Also: I really like it when you introduce yourself.

Best,

Dan

Episode Forty Four: Snow Crashing; danah boyd; Facebook and Oculus Rift
by danhon

1.0 SNOW CRASHING
If you were going to read Neal Stephenson’s Snow Crash again, which you should, because seminal science fiction and all that, never mind business plan and direct inspiration for a stupendous number of things that we now have to live and deal with on a daily basis, then you might re-read it substituting all the stuff that didn’t exist when Neal Stephenson wrote it with all the stuff that does exist now.

So here’s the first installment of a bunch of observations about Snow Crash followed by reckons.

Deliverators don’t exist and they certainly don’t belong to an elite order. Probably one of the Swiftian parts of Stephenson’s observations about the trajectory America was on, not least of which because he was pretty much right about nailing what America was good for: music (mostly, the role of YouTube in proliferating the odd bit of international music like Gangnam style notwithstanding and the constant import of new European genres), movies, microcode (software) and high-speed pizza delivery. Apart from the drones, of course.

Stephenson needed a bad-ass protagonist (ha), though, and a high-speed pizza delivery freelancer feels like the sort of step-up, adult job that a washed out ex-microcode whiz would take, rather than be a kourier. These days it’s not the deliverators that get the props in culture and the delivery environment isn’t as much a warzone as Stephenson imagined, but instead in, er, the food delivery vertical, it’s the startup founders of companies like Grubhub that get the attention. Where we might be seeing a weak signal of a new Deliverator is in the Uber and Lyft drivers of the present – mob run companies (just you wait) who emphasise customer service, quantification and big data (“graphed the frequency of doorway delivery-time disputes, wired the early Deliverators to record, then analyse, debating tactics, voice-stress histograms” – sound familiar to you?) who at some point might emphasise personal security and shit-hot rides to get you from A to B before the light stops blinking to ensure top ratings and continued employment.

And, of course, the Deliverator these days drives a Tesla S – moving people from place to place, pickup and delivery points not inferred by phone number but by a system of geospatial positioning satellites, plotting a glowing route on a heads-down Android display in a car that packs, well, lots of potential energy in the metaphor of the day.

All that’s missing is Uber getting into the personal loan business – just watch for that shift where startups like Uber, Lyft or TaskRabbit start offering payday loans or short-term personal loans in exchange for ’employment’.

Despite having more advertising than ever, it appears that we don’t have that persistent background visual noise of loglo. Powered screens aren’t that prevalent yet,and billboards still rule the day in outdoor advertising, installations of children pointing at planes up in the sky near Heathrow notwithstanding.

Burbclaves? Got them, but they got hollowed out by the mortgage crash. Didn’t see that one coming. People living in storage units? Give it a couple of years.

Hiro’s business card is pretty interesting. No doubt a Moo Card his would probably *still* have a phone number on it, but lose the “universal voice phone locator code”. Lose the P.O. box, too. But the address on half a dozen electronic communications nets? Try just one: his email address. And the address in the metaverse? Just the one URL. For all the talk we see later in the novel of hypermedia, one missed observation is that Hiro’s business card only needs one pointer, one URL, for anyone to find him.

We don’t have Sukhoi/Kawasaki Hypersonic Transports, but we do have Boeing 777s (and 787s and Airbus A380s), mainly because it turns out that one of the most powerful forces in the universe is not one of the nuclear strong forces but either a) NIMBYism or b) the cost of jet fuel. Slower and bigger and quieter and more fuel efficient is our thing now, not faster and more crushing-it, when it comes to air transport.

And when it comes to Hiro’s computing setup – well. A featureless aluminium wedge maybe, one softly glowing with a stylised Apple with a chunk bitten out of it, and just about doing without a power cord. But for the fat bandwidth connection? Gigabit ethernet, totally – not a fiber optic socket, but just some of your regular Cat-6 because seriously, wireless doesn’t cut it. And naturally, he’s got the VR headset Valve are convinced we’ll all be using in five year’s time.
Hiro’s main “job”, though, as freelancer stringer for the CIC. Now that’s weird. It’s almost as if Stephenson needed to retcon some sort of job for the overqualified underutilised information worker who just kind of hangs out and picks up on useful information. The weird part is that the CIC pays for it, which is some strange alternate universe where organisations use a centralised information system and pay for stuff. Hiro’s universe hasn’t been attacked by a race to the bottom in the content and information market – despite the loglo everywhere Stephenson needs to find a job for someone like Hiro who merely finds information but then doesn’t do anything useful with it. Hiro doesn’t analyse, he just uploads. These days, of course, Hiro would be a blogger and maybe have a nice little Adsense business on the side. Or a writer for Buzzfeed.

[1] Some of you have objected to buying things from Amazon. So I’m going to start including regular links to Powell’s and Wordery where possible, too.
Powell’s: http://www.powells.com/biblio/9780613361620
Wordery: https://wordery.com/snow-crash-neal-stephenson-9780613361620
Amazon: http://amzn.to/1dtBGR6 (physical) http://amzn.to/OXhpb3 (Kindle)

2.0 DANAH BOYD
I’m writing a couple of talks at the moment – both for xmedialab’s Video+Social+Mobile event that’s being held in Perth on Friday. And by “at the moment” I mean at about 30,000 feet on the way from Kansas City to LAX where I get to touch my feet to the floor for a bit before the epic journey from LAX to SYD and there to Perth. I lose an entire day in the process.

But the talks that I’m writing, I’ve decided to structure them (unsurprisingly) in the form of reckons because I’m entirely happy to professionally reckon, it’s when I get asked to have Proper Opinions that I start to get nervous. I like to retain a certain degree of flippancy. It’s probably a defence mechanism.

Anyway: it’s a conference (well, my bit is a keynote and a masterclass) and what’s coalescing is small, medium and big thoughts about each of those three areas of video, social and mobile. Video and mobile are easy – the first is simply a content format that’s being applied all over the place now, and mobile is easy because it’s just so big.

But social. Social is simultaneously difficult and easy, but fortunately easier because danah boyd’s new book It’s Complicated has come out and if you haven’t read it, you should[1].

Anyway: boyd’s been saying this for ages, and hopefully someone’s actually going to listen to her – social context and place is important. She puts forward a persuasive argument that the last few years with peak attention focussed in one place – Facebook – is an aberration and that people (teens especially) are moving toward having different social spaces for different contexts. Matt Locke hasn’t written his updated version of Six Spaces of Social Media[3, 4], which he should, but you should read it because it’s pretty much one of the definitive pieces on the subject.

With my work hat on, I ask questions like “But what are the brand/advertising implications?” of acknowledging different kinds of at-scale social spaces. Well, most of the implications are along the lines of further shattering of aggregated attention along with (hopefully) better targeting and ability to reach the right audience, as well as having to deal with pseudonymous audiences. But then, you had to do that with TV media anyway.

It looks like Facebook’s leadership is waking up to this (in fairness to them, the rest of the industry is waking up to this, too). With mobile, there isn’t (and doesn’t have to be) a one-size-fits-all communication/social networking utility or app. Facebook may well be the thing that everyone ends up having an account on, but in their latest earnings call, they reiterated their strategy to build more mobile apps and with the acquisition of WhatsApp alongside Instagram it seems clear to me (without my work hat on) that Facebook’s goal to connect the world is through Facebook the holding company, not just through Facebook the product/platform.

You can contrast boyd’s work with that of Paul Adams’ in his book Grouped[2], the result of which was Google Plus Circles shortly after he left Google for Facebook. Circles (and Google Plus) appears to me to be the sort of social network you end up building where you want everyone *and* you want to solve the problem of having different spaces and contexts. But we don’t work like that, not as people: Google Plus is the place and it doesn’t matter how many different circles I might have there – the cognitive overhead involved in placing people in circles is just too great and causes too much friction as opposed to just using a different app like Snapchat or WhatsApp or Twitter or Secret that comes with intrinsic contextual cues to being another place.

Adams’ research was right – people don’t like inadvertently sharing different facets of themselves to the wrong audience. No product has successfully catered for multiple facets, I don’t think, and trying to build it into a one-size-fits-all product has failed so far. Mobile, which has reduced context-switching to near negligble, as well as provided a new social graph through the address book, has finally let a thousand social flowers bloom at scale.

[1] Powell’s: http://www.powells.com/biblio/9780300166316
Wordery: https://wordery.com/its-complicated-danah-boyd-9780300166316
Amazon: http://amzn.to/Qd09A3 (Hardcover) http://amzn.to/1js1PSR (Kindle)
[2] Powell’s: http://www.powells.com/biblio/61-9780321804112-0
Amazon: http://amzn.to/1p1NUC7 (Hardcover) http://amzn.to/1ixPLM9 (Kindle)
[3] Original version: http://test.org.uk/2007/08/10/six-spaces-of-social-media/
[4] Medium version, where you can recommend it to increase his PartiRank rating: https://medium.com/a-brief-history-of-attention/8de460a23302

3.0 FACEBOOK AND OCULUS RIFT
I promised you reckons, and in the best style of someone who’s uninformed and responding to a BBC News Online request to vomit into a TEXTAREA, here are your reckons about Facebook buying Oculus Rift[1] for $2bn.

I’ve spent coming up to two years working on the Facebook account at Wieden+Kennedy, and I’m not going to talk about anything that’s not public. But in that time, I’ve spent time with others figuring out what exactly it is that Zuckerberg and his band are trying to do, why they’re doing it and why it’s so important to them. That type of thinking and strategy is at the heart of any good communications work, for starters.

Nothing I’m going to say isn’t anything that Zuckerberg hasn’t said before in public.

They’re serious about connecting the world. You go down to campus and it’s buzzing – just like the set of Dollhouse, in all the good ways and the bad ways – full of young people all committed to what they believe in. You can make it sound like a cult, but they’re genuinely excited and driven and believe in the basic tenet that more communication more easily, amongst everyone, is a net good thing. Sure there might be mis-steps along the way, but that’s a side-effect of someone who’s so driven in a utilitarian pursuit of what he believes to be a noble goal. And it’s a hard one to disagree with, allowing everyone to easily communicate with one another.

The devil, of course, is always in the detail.

I’ve said above that I reckon danah’s right about Facebook-the-platform commanding peak attention of such a wide swathe of population. And it’s not necessarily that teens are *leaving* Facebook, it’s that they’re spending less time on it.
This is going to sound horrible, but you kind of have to pull on the thread of the end-goal of connecting the world to get to it. It’s going to sound doubly horrible because I’m going to use Valley-speak as short-hand: Facebook want to be the full-stack of communication. Forget about whether Zuckerberg is evil or not or if he has a public company, because for the latter: he really does own Facebook. Take a look at the voting stock. Have a think about what that means for board meetings. Zuckerberg is already stupendously rich. Like all of our software gods, he’s *vision* driven, not money driven. If he wanted to make more money out of Facebook, we’d know.

So when you’re vision driven, look at Facebook the way you look at Google. One way of looking at Google is that they want to organise the world’s information and make it freely available. One way of looking at Facebook is that they literally want to connect the world and enable every living person to communicate as frictionlessly as possible with everyone else.

Like I said, the devil is in the detail.

Facebook – the product you and I use, the one with the newsfeed – is just one way Facebook the holding company is connecting the world. Instagram is another. WhatsApp is another.

Some of those products are ad-funded, some others aren’t. And if you’re thinking about an end-goal of connecting the world, what’s going to connect more people more quickly? Them paying for it, or the connection being available for free?
This might sound like having drunk the kool-aid, but try crediting Zuckerberg with more intelligence and think of him as the prototypical smart nerd: optimize for a connected world. What do you build? How do you deploy it?

It’s against this background that they buy Oculus Rift. And don’t think agency people have any knowledge – I’m in a plane at 30k feet, and when the news broke about WhatsApp, we were in a meeting *with our clients* – we find out about this stuff when you do, when Twitter explodes.

Like everyone apart from Apple, Facebook missed the boat. But Oculus as display technology – as another way to augment the human social experience is provocative and interesting. In the PR, Zuckerberg is quoted as saying:

“Oculus has the chance to create the most social platform ever, and change the way we work, play and communicate.”

He’s not wrong. You are always going to be able to meet more people through mediated experiences than physically. Physicality doesn’t scale. Is this a terrible harbinger of the replacement of physical social contact? Probably not. We have always invented and looked for more ways to connect with people. boyd says in her book that teenagers aren’t addicted to Facebook in the same way they were never addicted to texting or tying up the house landline for hours. They’re addicted to *people*. And if Oculus genuinely has the way to change the way people connect, then that makes perfect strategic sense for Facebook.

It turns out that today, people are still using Snow Crash as a business plan.

[1] Press release: http://online.wsj.com/article/PR-CO-20140325-912577.html
—
OK. I have my two talks to finish off and a thirteen hour flight, plus Wednesday’s newsletter to write which will be interesting because when I land it will be Thursday local.

As ever, send me notes. Short ones or long ones or just ones railing about how I work in advertising and no, I haven’t heard that Bill Hicks quote before.

Best, from the metal bird in the sky with an internet up/downlink,

Dan


Episode Forty Three: Wearable Reckons; Mirror Neurons; More Google
by danhon

Phooey.

A short one, today. I’m on vacation in Missouri with my family and my wife’s parents before I fly out to Perth, Australia, to speak at the xmedialab Video+Social conference. The farm is quiet and relaxing (albeit a bit snowy today), the cows are fed and my 13 month old son has just figured out to clap.

1.0 WEARABLE RECKONS
Okay, so there’s a lot going on with wearables. Google just released/announced an Android SDK[1] for them, and apparently if Apple doesn’t release an iWatch in the next 60 days, the end will be nigh for the company that’s been forever teetering on the precipice of disaster and irrelevancy. So here’s a bunch of short reckons about wearables:

Obvious reckon number one: if you’re thinking about wearables you should distinguish between sensing and interface.

If you’re sensing, then you’d better have either novel sensors or outstanding data manipulation, because the sensors have become pretty much commoditised now that it’s trivial to whack a three-axis accelerometer in a thing and now that everything has a three-axis accelerometer in it, you’d better be able to deliver on the promise of your sensing which, to be honest, probably doesn’t live up to what the public thinks of your device, no matter what you actually tell them. Fitbits and Fuelbands should measure *effort*, in a consumer’s eyes, but don’t, and the degree to which they’re able to fulfill that promise relies upon your smarts with data.

If you’re interface, well: that’s the one that’s a lot more complicated and where it feels like no one’s really done anything good yet. It should be pretty obvious that Google’s Android wear demo/showcase videos[2, 3] are pretty much doing the best that anyone’s done yet, but that’s more damning the field with faint praise where players like Samsung are just taking advantage of Moore’s law and scrunching and integrating COTS hardware and whacking a not-really-thought-through interface on top, while Pebble is clearly catering for the early adopter (and niche) geek market. Designing the interface for a wearable requires that you actually have a pretty good idea of what it’s going to be used for, which is why I find examples like the red/green LED interface of Nike’s Fuelband and the vibration interface of the various Jawbones useful, novel and as if people have given some consideration to the use-cases. And wearables, for reasons of industry myopia, have focussed only on the wrist, where that doesn’t necessarily have to be the only use-case. Earpieces are technically wearables, and it’s quite easy to spot the fake-analyst amongst the ones who have proper, professional reckons, because the real ones are looking to see what the opportunities are across the entire body, and not just having to release a watch because everyone else is.

Wearables are a great opportunity, for example, for coarse, contextual information. Given that most of them require tethering to a master device like a smartphone that’s already on or relatively near your person, they have to do a different, better job than you could accomplish by simply pulling out your phone. Or, they have to do so in a qualitatively different way. This doesn’t mean stuffing the wearable with an OLED screen, for example – because screens are screens are screens. But if you reduce the information density of the wearable device (for example, something that can only vibrate), that forces you to think about what it can be used for and how it can contribute to (if you want) some sort of contextual situational awareness without having to pull out a phone every single time you get a notification.

One of the promises of wearables is that you end up being surrounded by a personal cloud (ha) of information processing and interface devices: a suite of sensors and a way of interpreting and internalising that information.

We aren’t even at the point where there were enough crap MP3 players for Apple to know that they could nail the solution, so I’m not holding my breath for anything coming from them soon. And even if it does, we’d all do well to remember that first Slashdot review of the iPod[4]

[1] http://developer.android.com/wear/
[2] https://www.youtube.com/watch?v=0xQ3y902DEQ
[3] https://www.youtube.com/watch?v=QrqZl2QIz0c
[4] http://slashdot.org/story/01/10/23/1816257/apple-releases-ipod

2.0 MIRROR NEURONS
A very quick one this. Mirror neurons spring in and out of the collective pop science/pop cognitive science/pop evolutionary biology consciousness every now and then, but the main gist is this: there are neurons that have been discovered in monkeys, and then possibly in humans, that fire when an action is performed (e.g. reaching out and grasping an object) but *also* fire when that action is observed. Some scientists, like V. S. Ramachandran, believe that the existence of mirror neurons is a big signpost as to how human beings uplifted themselves into consciousness – because once you have mirror neurons, it’s easier to see how things like empathy and theory of mind emerged: indeed, studies have linked mirror neurons in monkeys as being key to understanding the goals and intentions of others.

So the quick, terrifying reckon is this: if our western capitalist world’s corporations by their nature reward sociopaths with leadership positions, then what does this say for a possible instinctual, neurological level bias toward mirroring the behaviour of those sociopathic leaders?

Also, something something new science fiction book to do with zombies, mirror neurons and YouTube.

3.0 MORE GOOGLE
It’s a surprise that there isn’t more fiction about or inspired by Google. At least, it is to me. They’re such a stupendous influence upon the world right now (well, they are if you live in certain circles) that you’d think they would figure in literature more. Or perhaps the only literature they *could* figure in is the SFNal kind, which is never going to get any love. I mean, if you think about it in that freshman three-in-the-morning deep philosophical kind of way, writing books that include Google – especially contemporary fiction, never mind that science fiction stuff – is kind of like writing a book that doesn’t include a mobile phone or electricity.

That said, here’s some great Google-related fiction that’s also an excuse for me to point some books your way.

Robin Sloan (hi, Robin!) has written a few wonderful pieces and it’s a strand that has followed from his seminal EPIC 2014[1, 2] through to his sublime novella, Annabel Scheme[3] which I can’t really describe for fear of spoilers suffice to say it’s set in a San Francisco heavily influenced by a Google-like entity, all the way into his most recent novel, Mr. Penumbra’s 24-Hour Bookstore[4] that definitely does reference Google in a pretty plot-fundamental way.

Alongside that, I’ve been reading William Hertling’s Avogadro Corp[5] which name should be a dead giveaway that it’s been influenced by a certain search-based corporation named after a mathematical concept. Bonus points for being based in Portland, of course.

And lastly, Dave Eggers’ The Circle[6], which as Eggers points out, was researched in no-way at all and bears no resemblance whatsoever to any Valley-based social network or search company in any way whatsoever. Eggers hasn’t written a realistic book at all, but he’s certainly written a skeweringly painful one. And if you work in the Valley and you *don’t* think it’s skeweringly painful and don’t see the tropes that he’s lambasting, then you probably need to move away for a bit, unplug and there’s a chance you should engineer your personality so you’re not Robert Scoble.

[1] http://www.robinsloan.com/epic/
[2] http://en.wikipedia.org/wiki/EPIC_2014
[3] http://amzn.to/1gk4E5k
[4] http://amzn.to/1iW3YDG
[5] http://amzn.to/1h39K5M
[6] http://amzn.to/1fVPOwT

PS. You’ll be excited to know that the Amazon Affiliate links have earned my son’s college fund *nearly sixty cents*. So if you’ve been worrying about clicking on those links, er, don’t.

—

Okay, that’s it. Tomorrow I do the whole MCI->LAX->SYD->PER thing which means in theory I should be able to write a newsletter for Tuesday, but given that I don’t actually land until *Thursday* local time, I’m not exactly sure what will happen.

As ever, send wonderful notes. Or send ones that are really mean and nasty (I haven’t actually received any mean and nasty ones yet) – if you do, I’ll just delete them.

Best,

Dan

Episode Forty Two: OK Google, Initiate Singularity; Random
by danhon

1.0 OK GOOGLE, INITIATE SINGULARITY
I give Google a hard time. It’s easy to, and that’s perhaps a lazy position to take, to knock the eight hundred pound gorilla in the room. But there are a number of reckons that I have swirling around the whole idea and concept and execution of Google, not least of which the recognition that Google as a singular entity is a pretty difficult thing to pin down.

But then, maybe I should just get a bit weird. So here’s the first one.

The singularity’s already happening! It’s just not happening the way we thought it would. A bunch of people working at Cyberdyne Systems are not creating a singular computer system, they have not created a neural net processor capable of learning and it’s not being hooked up to US CENTCOM or NORAD or any other ALLCAPS US military organisation and being handed the keys to the nuclear arsenal. No: it’s instead roughly fifty thousand employees and, well, anyone who uses the internet, hooked up into some sort of symbiotic system full of designers, developers, marketers, ground-truth experts, PhD researchers, interns, HR specialists and Starcraft players turning into the biggest semi-public repository of big-data “stuff” that’s ever been assembled.

The second is that the world already deals with Google as a bootstrapping artificial intelligence with opaque aims because: guess what! Corporations are like that already. And some are just more weakly godlike than others. Charlie Stross has a great post on how corporations are alien invaders from Mars[1], exhibiting distinctly inhuman attributes. Instead of imagining Google as headed up by Page, Schmidt and Brin, imagine it as a Big Dumb Object that suddenly appears inside our space/time horizon, installs itself all over the planet and opaquely starts deploying sufficiently advanced technology indistinguishable from magic. I’m not sure whether to be more, or less scared, when viewing the situation like that. At the very least it’s problematic because while it acknowledges that as a super-organism Google can’t be ascribed motivations in the way a regular human being can, that simultaneously absolves Page, Schmidt and Brin of any responsibility why they still have some degree of authority.

The third is this: it might just be the hyperbole and propaganda talking, but Google feel like they’re mounting the private equivalent of a bunch of Manhattan projects all at once. On the one hand: terrible! On the other, at least someone’s doing something. For every skeezy thing that Google does (Google Plus) they do a bunch of hard research that does genuinely feel like it advances the state of the art. And to be honest, even if they don’t nail the user experience the first time (and they are getting better), they provide shoulders for the rest of the world to stand on.

The fourth is this: I have weird dreams, and if you’ll excuse me (which you’ll have to, because this is my newsletter) I’m going to tell you briefly about the one weird dream I had where I was hopping between different parallel universes all of which had idiosyncratic executions of Google. Perhaps the most interesting one was where Google still dominated the search business but did so not through Pagerank but through the mass employment of tens of millions of librarians. The public in that particular universe thought Google was pretty good, if not slow and sometimes wrong or inaccurate (sorry, librarians), whereas us travellers from algorithmic Google Prime universe were straight up perplexed.

The fifth and last is simply Justine Tunney, who as self-styled “founder” of Occupy (so far as said movement can be said to have a founder) and latterly software engineer at Google, started a petition (widely regarded to be a troll) at the White House’s website calling for the entire US Federal Government to be dismantled and Eric Schmidt to be installed as CEO-in-chief. Tunney appears to be one of those types of people who openly admits to trolling, but it’s also hard (given some of her previous public statements regarding her politics) to distinguish whether she’s actually being semi-serious. Troll or not, certainly another weak signal.

[1] http://www.antipope.org/charlie/blog-static/2010/12/invaders-from-mars.html

2.0 RANDOM
A collection of random thoughts and reckons:

One:

I continue to dabble. I have a half set-up Heroku instance running a clone of Phil Gyford’s Little Printer example that LP’s you your most favorited/retweeted tweets[1], and I’m hacking away at it (which isn’t *hard* – I know what to do and how to do it, it’s just sitting down and finding the time and the head space) because I want to put together a push service that tells me “Dan Hon you have been fined sixteen credits for violations of the Verbal Morality Statutes”[2] because a cultural reference joke plus internet of things hardware is what passes for humour in my brain these days. Even better if it can fine you in {bit, doge}coin.

I was wavering on whether or not to write about this seeing as that now I have, someone will go off and do it, which suits me fine.

[1] https://github.com/bergcloud/lp-your-best-tweets
[2] https://www.youtube.com/watch?v=BffgC5DKQG0

Two:

Secret, the latest reminder that as a species we never learn and are doomed to repeat elementary and easily avoidable mistakes, is best of thought of as a) something that young, inexperienced people come up with because honestly they just don’t have the life experience to understand what happens when you allow a pseudonymous large-scale rumour mill; b) thus the equivalent of Penthouse Letters for the Bay Area (it’s for entertainment and most of it is made up); c) not a disruptive thing at all and frankly d) something that definitely isn’t worth the level of investment that has so far been poured into it.

Three:

I continue to receive well-meaning notes from a variety of people as to the true civil or non-civil service nature of the UK’s Government Digital Service. Now let me draw a line under the matter and make clear what *my* reckon is: the long-term future of the ideals of GDS is only ensured by GDS *being* the civil service. Not separate from. The author will entertain no further correspondence on this subject.

Four:

Over at the regularly too smart and goes woosh over my head blog Ribbonfarm[1], an interesting post about advertising, marketing communications and an inversion from the medium is the message into the message is the medium[2]. Rao’s conclusion feels like pulling on the thread of something: increased certainty in execution (which initially I didn’t understand, but he backs up with data-driven communications and techniques like a/b testing) and decreased certainty of objective – the latter of which Iain Tait used to describe at work as moving away from the lumpy campaign driven model to one that was more persistent and layered like a lasagne. One of the many things I miss about not working with Tait is his way with meatphors (which I spelt correctly, but then decided to leave because funny). Rao describes the latter as being more-open ended and infinite rather than being spiky, and I have to say that *most* of the clients I’ve worked with would probably surprise you as to the degree of their lack of visibility into what they think they’ll be doing in the future.

And it’s not always as charitable as being able to say they’re “agile”.
[1] http://www.ribbonfarm.com/
[2] http://www.ribbonfarm.com/2014/03/20/the-message-is-the-medium/
—
I am on vacation in Missouri, at the grandparents’ farm, with the lovely wife and son. There is a road to the south, and at the bottom of the road, a gate.
> South, open gate
You are in a field. There are cows here.
Have a good weekend, everyone, send me more wonderful replies and I’ll endeavour to send even more wonderful replies back.
Best,
Dan



Episode Forty One: When You’re Part Of A Team; The Dabbler
by danhon

An experiment – I’m going to start using Amazon Associates links when I link to, well, things on Amazon. There are a couple of references to books in today’s episode. You don’t pay any more than you usually would, and I get a little bit back from Amazon to spend on things like baby toys or Lego.

1.0 WHEN YOU’RE PART OF A TEAM
Or: do we really have to do this thing about the silos again?

One of the things I’m really interested in is organisational culture. How is it that groups of people get together and do things that would be so much harder, if not impossible, to accomplish singly? There’s obviously a stupendously wide spectrum that encompasses a bunch of people getting together and just barely managing to scrape some sort of achievement or forward momentum together, all the way up to organisations that many of us hold up as exemplars of, well, teamwork and doing something truly greater than the sum of its parts.

The ones that do stand out to me are ones like Pixar and my current place of work at Wieden+Kennedy. When I was busy prepping for my first interview at the latter I did that thing where you hoover up everything you can to learn about the place (starting premise: where, exactly, is Portland, Oregon?) to try to understand: what kind of people are they?

The mythology around Pixar is fantastic, and there’s a book about Pixar which looks like it’s going to soon become the second-most-fantastic book about Pixar now that Ed Catmull’s book is nearing release[1]. David Price’s Pixar Touch[2] is pretty much the go-to readable textbook that covers the founding of the company, Steve Jobs’ arrival onto the scene and what happened with the Disney deal. By all accounts, Catmull’s book is looking to be a good companion and offer an insight into one of the world’s most consistently astoundingly high-quality creative companies.

I like looking for parallels and connections and drawing inferences, so one of the things that struck me about these successful companies – Wieden+Kennedy is consistently recognised as one of the top creative agencies in the world, and a look at its creative output over the last thirty years invariably yields first admiration for their early achievements (coining Just Do It, for starters), then a kind of grudging respect as you recognise more of their work, then a sort of jealousy as you realise that their output appears to just be a list of some of the most influential advertising in terms of cultural impact over the last twenty years, then the nagging suspicion that you must be missing something because clearly something interesting is going on over there.

For starters, both companies have strong hippy-capitalist leaders with a clear (if not always easily articulated) sense of values and the notion that they’re not in it for the money, they’re in it for the art. Ah, you say, but those people who are in it for the art are invariably not canny businesspeople – and this is where the hippy-hyphen-capitalist part comes in: they’re cultural heads of states with the opinion that they’re not doing it for the money, no, but they do need to *make* money. Making money is the thing that enables them – and by extension, their following – to do what it is they want to do in the world. Money is not even a necessary evil, but more of just a requirement for survival, like air. Accepting this, and not railing against it, and being savvy (although clearly there are degrees of savviness and empathy for those doing the work, illustrated in Price’s book by Jobs’ black-and-white stance toward redistributing equity in the saved Pixar) in terms of a long-term mission, appear to me to be shared values across the two companies.

The thing is, a lot of this behaviour is very easy to mistake for cult-like behaviour from the outside. Apple frequently gets described as a cult – not only are its employees members of the cult, but its customers are described in terms of being followers, too. And you see this cult behaviour in terms of the reverence expressed toward dear leaders (Messrs Wieden and Kennedy, for example, or the brain trust at Pixar, or Steve at Apple) but also in terms of the transmission of the values of those leaders. Wieden prides itself on a number of maxims ranging from a thousands-of-thumbtacks installation done by members of its advertising school of the slogan FAIL HARDER (with requisite misplaced thumbtack) to pretty much every employee being able to understand what’s meant by “the work comes first” even if they do need a bit of re-education as to how, exactly, the work comes first (ie: it is not a get out of jail free card when you disagree with the client about what counts as good work). Then there are the Other Rules, the ones practically handed down from the mount (or, more accurately, discovered in an office scribbled in pen) that state:

1. Don’t act big
2. No sharp stuff
3. Follow directions
4. Shut up when someone is talking to you

and turned out to be a parent’s note to their child but actually not that bad advice when you think about it.

And now, another nascent organisation, another one that I constantly harp on about: the UK’s Government Digital Service. I don’t think it’s a coincidence that from the outside two of the people (but certainly by no means the only people) influential in the success of GDS and its culture are Russell Davies and Ben Terrett, both of whom have been through the Wieden+Kennedy, er, experience.

Russell is an exceedingly smart, unassuming and humble person who has a singularly incredibly ability to be almost devastatingly insightful and plain-speaking at the same time. It feels rare to see both at the same time. But what he’s articulating at the moment in terms of GDS strategy and implementation is the thought that “the unit of delivery is the team” and when you’re building a new organisation from the ground up, and one whose success is tied directly to its ability to embed within and absorb the culture of an existing massive entity, the UK civil service, it feels like watching a (so far successful) experiment in sociology and anthropology being deployed in realtime. A note (and thanks to Matthew Solle for the clarification because it’s an important one): while the GDS works with the civil service, it’s not actually a part of it, instead being a part of the cabinet office and being more tied to the government of the day.

So there are macro-level observations about Pixar that you glean from books and other secondary sources, but it’s not until you visit the place and start to talk to the people who work there that understand starts to feel that it unlocks a little more. I’m lucky enough to know one person at Pixar who’s been gracious enough to host me a few times and while we were talking about the culture of the place and how, exactly, they get done what they get done, one thing that struck me was the role of the individual and the individual’s place in the team.

You see, one of the things it felt like they concentrated on was empowerment and responsibility but also those two things set against context. My friend would talk about how every person on his team would know what their superpower was – the thing they were good at, the thing that they were expert at – and everyone else would know what that superpower was, too. And the culture thus fostered was one where everyone was entitled to have a reckon or an opinion about something and were listened to, but when it came down to it, the decision and authority rested with the expert.

Now, this might not sound like a stunningly insightful revelation. Allowing people to have opinions about the work of the greater team and then restricting decision-making to those best qualified to make it sounds on the surface like a fairly reasonable if not obvious tenet, and maybe even one that because of its obviousness would seem reasonably easy if not trivial to implement. Well, if you think that, then I’m sorry, it sounds like you’ve never been a good manager before: it turns out to be exceedingly difficult.

At this point the narrative begins to sound rather trite: Pixar, and the companies like it that consistently achieve “good” results and are able to marshall the resources of large teams to accomplish something greater, are simply trying harder than all the other ones. And in the end, it may well be as simple as that. It’s easy to have a mission statement. It’s easy to have values. It’s significantly harder to try as hard you can, every single day, for thirty years, to actually live them.

In the same way that one does not simply walk into Mordor, one does not simply say that one has a set of values or culture and it magically happen.

This is perhaps best illustrated in the blindness of the new wave of stereotypical valley startups that rail against bureaucracy and instead insist that their trademarked culture of holocracy inures them to the requirement of bureaucracy. That the way they instinctively do things is sufficient in and of itself. Well: bullshit to that. That simply doesn’t scale, and the companies that think they’re doing that – and I’m looking at you, Github, winner so far of the Best Example Of The Need To Grow Up award of 2014 and we’ve not even finished the first quarter of the year – are living in some sort of hundred-million-dollar VC-fueled fantasy land. Which, I suppose, goes without saying.

I began this part by implying something about teams, and I sort of alluded to it when mentioning the GDS maxim that the unit of delivery is the team.

I think it’s becoming clear that the type of delivery that is expected in this age by its nature requires a multi-disciplinary team that works together. It’s not enough, anymore, to have specialisms siloed away, and one thing that jumped out at me recently was the assertion in conversation on Twitter with a number of GDS members that there isn’t anybody with the role of “user experience” at GDS. Everyone, each and every single member of the team, is responsible and accountable to the user experience of delivery, from operations to design to copy and research.

The sharpest end of this is where digital expertise had traditionally been siloed away in a sort of other. In a sort of check-boxing exercise, organisations would recruit in those with digital experience and either for reasons of expediency or for their own good, would shepherd them into a separate organisational unit. Davies’ point – and one that is rapidly becoming clear – is that this just doesn’t make sense anymore. I would qualify that and say that it doesn’t make sense for certain organisations, but I’m not even sure if I can do that, and instead should just agree that it’s a rule across the board.

Of course, the devil is always in the detail of the implementation. I’ve worked with clients that don’t have explicit cross-functional multi-disciplinary teams but are fluid enough to enable those teams to come about. Facebook’s development of their Look Back product in celebration of their tenth birthday required what on the outside might look like an unprecedented degree of collaboration across operations, marketing, design and engineering at the very least. As ever, perhaps there’s a continuum and at one end there are embedded teams and at the other end there are structures that allow for cross-functional teams to come together and dissolve at a moment’s notice. But my suspicion is that while the latter might work for one-off projects, the long-term benefits only really accrue when cross-functional teams are the default.

This is, of course, a long-winded way of saying that everything can be great when you’re part of a team. I think many of us are able to relate to moments when you get the right people in the room together and you’re able to collectively figure out a problem. But my experience is that those moments are not as frequent as I would like them to be.

This issue of siloing has most recently raised its head through at the UX team at the BBC who, it appears, have finally had the latest straw placed upon their back and struck back in the medium of the age: an open letter published on Tumblr. Railing with incredulity at the notion of UX being “over there” is, in my mind similar to having digital “over there”, despite protestations of collaboration. Long-term, the only solution is to raise all boats and not instead to have a zippy speedboat over in the corner. In my experience – and, I have to admit, my humble opinion – concentrating expertise, especially digital expertise in any organisation striving to remake itself in this age, never mind one attempting to do so under competitive pressure is, uncharitably, a way of doing that implies that the problem of digital has been dealt with: it’s over there. Funnily enough, it’s also the easiest way to ignore what’s over there, too. When it comes to service or product design and the delivery thereof, having such a vital part of the team that would be involved in such delivery not in persistent contact with policymakers or the others involved in the architecture of that service is at this point seeming like willingly punching yourself in the face. But then, perhaps some organisations enjoy punching themselves in their face.

Again, from my individual point of view, it feels like agencies are in a practically inescapable bind. On the one hand traditional agencies are being explicitly asked by clients to move with the times and ‘be digital’ and deliver the kinds of concepts that, for whatever your value of ‘digital’ is, are accordingly digital. That sort of explicit requirement, combined with the implict increasingly breathless proclamations from trade press, media and the digital ninjas who strike silently and with deadly disproportionate influence pretty much end up creating a culture of panic amongst management that Something Must Be Done, resulting in either half-hearted attempts at silo-breaking or the creation of a new, digital, silo. Simultaneously, agencies, being smaller and more focussed on advertising and communications, are able to do this faster than their clients, who are facing their own battles from overly restrictive corporate IT policies (the age of clients enviously eyeing agency employees iPhones while being chained to their corporate Blackberries are hopefully nearly over) that mandate creative delivery against a prehistoric version of Internet Explorer running at an archaic desktop resolution because that’s what clients get issued by central IT – and that’s before a genuinely disruptive digital concept gets delivered toa client which by its nature would necessitate the breaking down of silos on the client’s part. At which point everyone, and one would not entirely blame them, gives up and agrees to instead just do a TV spot because that’s easier all around and a smaller group of people shake their head and wonder whether what they’re actually being paid to do is tilt, albeit creatively, at increasingly stodgy windmills.

Anyway. Order and read those books about Pixar! They’re much more cheerful and optimistic about doing great and good things in the world. That said, they also remind you of the sheer obtuseness of Jobs and his uncanny knack, later in life, of being a stubbornly successful git.

[1] http://amzn.to/1oysnAM
[2] http://amzn.to/1l6hqYc

2.0 THE DABBLER
“Side projects are where it’s at,” proclaimed a good friend over breakfast, and I have to admit, I agree with him.

I don’t want, though, for this to be an indictment against my current work – the day job is certainly incredibly interesting, thank you very much (build a brand identity for a social network used by over a billion people that reached unprecedented scale without having explicitly built a brand in the first place? Figure out what advertising and marketing means for a digital-first service that was birthed in the web age and is navigating the transition to a mobile one? Those sound like interesting, meaty, problems, sure). But the day job is advertising, and as I remind myself, I never *intended* to end up in advertising, it just kind of happened, officer.

That said, I’m not a fan of the current trend, especially in the field of developer recruitment, or requiring candidates to demonstrate significant extra-curricular activity. The types of startup or organisation that recruit solely based upon extra-curricular github repos feel to me to be startlingly short-sighted, but then I’m the kind of person who broadly prefers to work with a variety of well-rounded individuals who also have specialisms rather than exclusively with mono-minded savants.

My fear is that this extra-curricular requirement in an increasingly competitive job market leads to the stifling of any other sort of personality or expression of self, but quite when you’re supposed to exercise all these hobbies is also unclear when you’re also on call and tethered to the workplace at all times. The thing about clouds, you see, and the work that takes part and is stored in them, is that they float around, following you home.

But, dabbling in hobbies. That’s what feels like a British pursuit (Americans, I feel, are distinctly more, shall I say, enthusiastic, about their hobbies, whereas the stereotypical Brit is quite content to sit with their weak lemon drink in their anorak and spot trains or collect stamps) but again the application of the network to everything means that hobbies are now attributes that get imbued in the social graph, labels that describe connections between nodes. Knitting isn’t just knitting anymore, it’s a social network powered by Ravelry. Being an enthusiast about the quantified self isn’t just something you can do on your own when meetup.com is emailing you about it all the time (and for the record, meetup.com, requiring me to login to unsubscribe from your emails is the kind of thing that gets you a bad reputation these days).

The thing about hobbies in the networked age is that it’s incredibly easy for them to become performative instead of insular. That’s not to say that insular hobbies are great, but the networked performance of a hobby comes with seductive interactions built not necessarily for the hobbyist’s benefit but for the benefit of the network substrate or medium. As a general reckon, hobbies in their purest form are nothing but intrinsic motivation: whether they’re an idiosyncratic desire to catalogue every single model of rolling stock in the UK or increasingly intricate nail art, before the hobby becomes performative it is for the self’s benefit only, a sort of meditation in repetitive action and a practice.

The hobby as the networked performance, though (and I realise that at this point I may well sound like a reactionary luddite who doesn’t ‘get’ the point of social media) perhaps too easily tips the balance in favour of extrinsic motivation. Whether that extrinsic motivation is in terms of metrics like followers, likes, retweets, subscribers or other measurable interaction with the hobbyist the point remains that it’s there, and it’s never necessarily for a clear benefit for the hobbyist. You could perhaps absolve blame and say that such metrics are intrinsic properties of the enactment of a social graph and that they’re making explicit what would be rendered as implicit feedback cues in any event, but I don’t buy that. They were put there for a reason. Friend counts and subscriber counts were put there because those of us who are product designers and of the more geeky persuasion realised that we could count something (and here, we get to point the finger at the recording pencil of the train spotter), and the step from counting something to making visible that count was a small one and then our evolutionary psychology and comparison of sexual fitness took over and before you knew it people were doing at the very least SXSW panels or if you were really lucky TED talks about gamification and leaderboards and whether you had more Fuelpoints than your friends.

So that’s what happened to the hobby: it moved from the private to the public and at the same time the dominant public medium of the day, the one that all of us had access to, marched inexorably to measurement, quantification and feedback loops of attention.

So again, here’s the nice thing about this newsletter. The newsletter service provider that I use, Tinyletter, does not either by design or accident have a dashboard that surfaces statistics about the open and read rate of every single newsletter that I publish. I do not see sparklines or trends or graphs illustrating my subscriber count over time (although I do log in, more often than I would perhaps admit to, to check on which direction my subscriber numbers are going. I am only human). So unlike my neglected WordPress blog, an automated tumbleweed of aggregated links blowing through it, this newsletter gets back to the satisfaction of intrinsic motivation for me, and minimisation of external recognition and validation.

In other words: yah boo sucks, I get the best of both worlds. A performative media wherein I broadcast, but that still, for the moment, feels like it’s for me, and not for you. And while I could choose to publish on my own site, using my own instance of WordPress or whatever blogging software, there is something about the web right now, and I fully recognise that this may well just be a reflection of my own neuroses, where the success of something is marked by the attention it gathers, and if it doesn’t gather attention, it isn’t worth doing.

Well, with all due respect, fuck that. I want to do this, and I’m doing it. You just get to read it and follow along for the ride.

—

Phew. I might do some shorter reckons tomorrow. These were long ones. Anyway, as ever – replies, please! Even if they’re of the “first time writer, long time reader” variety, because I don’t deduct marks for using that cliche.

Best,

Dan


Episode 40: IP and the Federation; A Thousand Digital Hubs In Your Pocket; Your Server Recommends
by danhon

1.0 IP AND THE FEDERATION
Look, if Paul Krugman can write a genuine paper about the economic implications of interstellar and relativistic trade[1], then I can use Gene Roddenberry’s toy universe as a sort of gedankenexperiment about intellectual property in a post-scarcity society.

Which is not always the kind of opening paragraph you expect to write, but still.

Over dim sum the other day, the inevitable discussion about what happens when software eats not just the world, but jobs. So bear with me, this is going to be some intense reckoning.

Assume that a bunch of jobs have gone. Assume that unemployment isn’t going to trend downward and is instead slightly trending upward as capital has figured out that it can get a better return on itself through more capital, instead of labour. Assume that the governing classes reckon the only real way to deal with that without formenting some sort of permanent disaffected Youth Spring situation is to institute basic income. Assume that basic income, because it’s basic, can only really pay for basic things, and that what ends up happening is increasing wealth inequality but that instead of things getting worse at the bottom, they just kind of stay steady state thanks to basic income. (That assumption – and picture me as a nineteen year old undergrad at one in the morning slumped in an armchair having a particularly juvenile discussion – feels like the most reckon-y in the chain so far, so I’m happy for it to be demonstrably false).

Then what? You have most of the money at the top and essentially a long, log tail of humans and spending power. How do you claw yourself out of the long tail of basic income?

Are we at the kind of attention economy where, because you’ve got basic income and a more or less safe existence, you can dick around and spend five years experimenting with things until you create Flappy Bird and capture the attention of the people with the Money?

So then is pretty much everyone at the basic income level trying to attract the attention of the monied class? Are billions of people reduced to the monetised version of the attention economy and then sell that attention to the people and organisation who ultimately employ the monied class?

What does *that* mean for the concept of intellectual property?

And (a jump here, so bear with me and apologies) was it software eating the world that led to the post-work and post-scarcity world of the Federation, or was it the replicator? You have a similar situation in the toy universe of Neal Stephenson’s Diamond Age where Nell’s brother teachers her how to use their [replicator/fab] and nanotech and universal feedstock allows a basic level of existence. That doesn’t stop Miranda, of course, from needing money to play for the implants she needs to train up at being a Ractor to break into the big time and crawl out of the mire.

So wait: in a post-scarcity replicator world of the Federation, the thing that’s still scarce is attention. And, well, if Riker wants to play submissive in the latest Fifty Shades of Grey holonovel sweeping the ship, then a) who writes it and b) how does he get it? If I wrote it, can I decide that anyone can have access to it, other than Riker, just to spite him and his smarmy smile? Is the only implication of that that I’m a dick? Or, does the Federation computing system include stupendously powerful DRM? (Remember that episode where Wesley, Data and Geordi spent forty one minutes circumventing the Trusted Computing Module in the Enterprise’s main computer core and installed an after-market mod to the main deflector dish? That episode was awesome.)

Paul Mison suggested that perhaps the Federation operated on roughly the same principles as Iain M. Banks’ Culture universe: that sentient beings minds are inviolable, but whatever escapes into the physical universe and off the substrate of pure thought is fair game. Your ideas are yours until they are uttered.

Let me put it this way: would Riker pay for a new sexy holonovel? You bet he would. And thus I humbly birth Rikernomics and how it breaks the post-scarcity world of Star Trek.

[1] http://www.princeton.edu/~pkrugman/interstellar.pdf

—

2.0 A THOUSAND DIGITAL HUBS IN YOUR POCKET
The strategy that served Apple well over the last twenty years – that of the personal computer being your digital hub – is only coming under more speculation. Jobs said it himself when declaring that we were in the post-PC era, so where did that leave the PC he had put at the center of the hub? Apple was – and is – surely excited about the cloud, but let’s just say that Apple’s intentions toward the cloud are, well, more of the wishing variety than the practical variety: just because you’re transporting (note: transporting, not delivering) a metric buttload of iMessages every day does not mean you get “cloud” and services, it just means you get (and yes, I’m obviously being facetious here) message transport systems. It’s a Solved Problem, as Whatsapp and its fifty-strong team of Erlang supporters, have demonstrated, and iMessage hasn’t even solved it particularly well yet. Boring. Next.

The idea that the digital hub is your iPhone or whichever portable device you’re using and that terminal, with its physical instantiation and opportunity to be the housing for more powerful local processing, casts its computing and network field around it is intriguing. In a sense, it means that Apple’s future is in PADDs – their future rooted in devices just as surely as their history was – and that Google’s future is in Main Computer.

But that future is a little bit terrifying for Apple if you take a long-term Moore’s Law view of the world because as we well know from historical texts documenting the Culture, you end up with things like terminals which are tiny pieces of local computing infrastructure that you use to talk to the nearby Ships which are inherently less sexy than things like combat drones with their own Minds.

I mean:

“Apple reignited the computing revolution with the Skaffen-Amtiskaw series of combat drones,”

doesn’t really have the same ring of believability to it than

“Apple reignited the computing revolution with the discreet personal terminal,”

does it?

So fine, there’s a bit of a middle ground where your just by sheer dint of Moore’s law you’ve got a slab-shaped thing that you carry around with you that handles your local processing and low-latency needs and instead of wearables you have charms or earpieces or terminals or jewelry or watches or brooches as a cloud of interface objects that orbit you, and I have to admit that the circular watch-face Android Wearable UI with big flashing things and readable text[1] is probably the best watch-based body-substrate computing that I’ve seen lately. An aside: I feel like the quality and craft of Google’s explain-y type videos has dipped of late, and this might just be a function of the sheer volume of work that they’re producing, but they don’t feel as crafted or genuine as they used to. Also that the linked Watch video felt a bit lazy compared to the precedent that had been set with the Glass concept film. Also while I appreciate the lack of plinky-plonk music, it’s just a bit… off.

That said, you know what those watch concepts are like? Combadges.

See, I knew I could get another Star Trek reference in.

[1] http://www.youtube.com/watch?v=QrqZl2QIz0c

—

3.0 YOUR SERVER RECOMMENDS
Another GDC, another opportunity to sit at dinner to listen to people put forth their reckons about how the iTunes App Store is a) terrible, b) terrible for discovery, c) why is it that Apple doesn’t care about such an important part of its ecosystem.

Because this is my newsletter and not your newsletter and we don’t have to sit through dinner, instead we can just assume that we’ve had that conversation and just have some reckons about concrete things Apple could do about the incredibly successful hot mess that is its App Store.

Well, first they could just rock up to Netflix and license their recommendation algorithms. Or at least ask to take a look. When it matters, Apple have obviously done this: they did it with the Amazon one-click patent.

Why Netflix? They have the least-shit recommendation algorithm out there, and they have one that’s actually used by lots of people. Why not Amazon’s? Because their People Who Bought X Also Buy Y thing is, from *my* anecdata at least, mostly shit and only really fodder for poor stand-up comedy (oh look! People who bought toasters also bought sex toys! Haha! Aren’t algorithms funny!).

No, Netflix because: you all saw that wonderful piece by Alexis Madrigal where Netflix reverse-engineered out all those movie and tv micro-genres[1], right? Your app store deserves micro-genres. I mean, I totally feel like a Flappy Bird Inspired Erotic Hidden Image Game for the next few minutes or, you know what, I’d really try out Minimalist Weather Apps That Use Crowdsourced Photography or To Do Lists Apps For The Bro Lifestyle.

And yes, Apple presumably has, or could have, the same kind of usage data that Netflix has for its a/v content and then, really, what you’re wondering is: where are the micro-genres for *everything*? Could they be at Tesco or Whole Foods or Barnes & Noble or iTunes (for music) or types of soda? I mean, I wouldn’t mind, when doing my online shopping, the exclusively targetted micro-genre of Vegetables That Go Well With Diet Coke And French Bread And Proper Salted Butter.

So, this: Netflix algorithmically micro-genre all the things.

[1] http://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/

—

OK! That’s it for Wednesday 19th March, please send notes (especially overly geeky ones about Star Trek futures), and if you know someone at Netflix who wants to license an algorithm you know what to say to them.

Best,

Dan

Episode Thirty Nine: On Creativity; But What Is The User Need; Universal Service
by danhon

And now, back to your regularly scheduled programming after the good Robin Sloan’s intervention. Let’s dive straight in.

1.0 ON CREATIVITY
This particular reckon is based upon my last four-ish years of experience inside an advertising agency, but at the same time also drawing on the admittedly weird tentacles I have into other creative industries.

There’s a lot of groups talking past each other about creativity and what it means, how you do it, how you preserve it, is there a particular kind of office environment that fosters it (at the absolute lowest end of the spectrum: foosball tables, at the highest end of the spectrum: full-service employee benefits, never having to think about what you’re going to have for lunch and essentially some sort of childlike pampered existence where every whim is catered for apart from, say, having enough meeting rooms because who ever has enough meeting rooms?) and have you read Fast Company lately because they’ve probably got some reckons about creative environments.

Anyway.

As I was saying, I work on the fifth floor – the creative floor – of a pretty well-respected advertising agency. Sometimes it calls itself an advertising agency, sometimes it calls itself a communications agency, but all the time it definitely does not call itself a consultancy. And where the rubber hits the road is in the application of this weird thing called “digital” which really shouldn’t be called “digital” anymore because once a thing has a label you can point at it and say it’s over there but not over here, when instead, what we really should be taking away from what the word “digital” means in this context is “holy shitballs, this is just how we do things these days can we just get over it.”

Anyway, again.

Clearly, if you are a reasonable person – the kind who spends all day riding back and forth on the Clapham Omnibus – there are lots of ways you can be creative. In an ad agency, you can be creative in a traditional two-person formation, art director and copywriter, wherein your copywriter is traditionally assumed to be more “conceptually” creative, i.e. she comes up with, I suppose, ideas and more abstract concepts, and your art director is more traditionally assumed to be: please make this thing aesthetically pleasing and worthy of diverting attention purely from the point of visual input. That is what creative has historically meant, and is broadly taken to mean, in the latest industry I appear to have accidentally found myself in.

And thus we had print advertising and then radio advertising and outdoor and television and so on.

And then “digital” came along and spoiled the party because: hey! It turns out that there are suddenly other “ways” you can be creative, like, oh, I don’t know, “coding” something. And digital, as a medium, is a bit confusing because it’s not just a communications or broadcast medium like television or radio or print because it’s got this pesky two way channel (no matter how hard communications utilities attempt to foist things like the asymmetric part in ADSL upon us), which means you can actually *transact* in that medium.

And then everything got a bit more confused because, well, if coding could be creative (which, let’s be clear: it is), then planning and strategy could be creative too, and if you opened that door just a little crack it wouldn’t be too long until everyone and their monkey would start reckoning that they had ideas about things because, as Gusteau reminds us, Anyone Can Cook.

Because really, what a lot of people mean when they mean creative is, amusingly, creative *in that box*.

This might seem somewhat facetious (if you have read more than three of my newsletter episodes, Robin Sloan’s challenges notwithstanding, by now, you should have recognised that much, if not the vast majority, of what I say is somewhat facetious), but everything is so much easier when people who have spent a long time being creative *in a particular domain* actually mean being creative *in that domain* when they say “creative*”.

Alternatively, you can just say the word “creative” lots in a paragraph and the word does that thing that words do when you repeat them a little too much and they appear to lose all meaning. I may as be writing “smock” at this point.

Anyway, again.

This sort of institutional excellence or focus in a particular domain is what leads to outwardly bizarre statements like the head of TV content for the BBC’s iPlayer heralding its lack of fixed programme scheduling and ability to support arbitrary lengths of programming as a genuine creativity opportunity which, I guess, if you’re from the world of television *is* a genuine creative opportunity, but if you come from anywhere in the rest of the world that’s been exposed to this little site like YouTube is a bit like this one horse telling this other horse that’s still in the barn about this awesome new opportunity that’s being introduced by exciting barn door openings, while this other horse is going “Holy shit I’m outside and there’s this whole post-barn universe and honestly it’s disrupting everything you guys should come see this,” and the other horses are all “Oh, I don’t know, this barn seems pretty good, we have a good thing going with wooden structures and a roof over our heads.”

I think this is where frustration can set in, and if I may, I’d like to put forward a massively generalised reckon: the rhetoric in asking people to solve problems and asking them to be creative, but then demanding a siloed approach is damaging. If the promise is: “we want you to be creative in achieving this goal” whether that goal be artistic or business or whatever, and then constraints are put on in a sort of “oh well actually there was an asterisk and if you see the asterisk means that we’d prefer you solve the problem in broadly the manner associated with a particular domain” then that can be frustrating. It’s as if one is being told: “There are no rules! Unleash creativity! But then solve problems in a particular manner!”

And then, in fairness, solving problems in a new way inside a particular domain *is* creative: theaters streaming productions for the first time over the internet *is* creative if you’re a theater professional and something that you’ve never done before, even if it’s not new news in a bunch of other domains. So perhaps where the really interesting stuff is, as ever, in the edges and in the mixing and semi-permeable membranes of collaboration: for me, what’s been interesting about an industry about television or book publishing has been stripping away and getting to what’s at the *core* of creativity in that medium and then seeing what you can do with it when you radically remove constraints. Removing the constraint of fixed scheduling and programme length *does* unleash some creativity but perhaps not as much, or as quickly, as I might prefer.

In other words, and less charitably, less helpfully and altogether less excitingly: that’s the wrong kind of creative thinking for these parts. Not because it’s not creative, but because it doesn’t fit inside the particular institution (publishing, software, game design, business consultancy, advertising) and the way that institution solves problems.

Or, even more bluntly: yes, that’s the problem that we’ve been asked to solve, and yes, we can all agree that that’s a particularly novel solution to that problem that may well solve it, but what you’ve done there is that you’ve been, how shall we put it, a little bit too creative and now we don’t know how to go about executing that particular solution because, well, we expected you to be creative in box A, not to wander outside of that box.

2.0 BUT WHAT IS THE USER NEED?
There is a window, at the offices of the Government Digital Service, in London, where someone has taped a form of caption to the glass – a cut out in a piece of paper – so that when you look through the window the effect with the caption (which reads to the effect of “These are our users”) reminds you, in a simultaneously subtle and provocative way, of who exactly you’re working for.

Now, the GDS is a special case: it’s part of the civil service, the part of government in the United Kingdom that remains constant across changes of governing party, and one literally dedicated to public service. It is one of those rare organisations that by sheer virtue of existence is able to simply point out the window and say: those are the people we work for, those are the people we service.

It is hard, I think, to foster the sort of business or corporate culture, especially at scale, and harder in general, I think, for large-scale pre-internet companies, to be so clear as GDS is in fulfilling user need.

Zappos, I think, is an interesting example. Their application of answering the “But what is the user need?” question is one that anecdotally inclues them happily pointing you to a competitor if that competitor stocks the footwear solution (ie: shoes) that you want if Zappos does not stock them. If that’s not a bloody-minded, stubborn application of answering the user need, I don’t know what is. There is no upselling. There is no “well, this is kind of the shoe you want, and we have it.” There is instead, it appears, a respectful consideration of the fact that the user knows what they want.

Comcast, I feel, does not know what the user need is. Google Plus, I feel, does not know what the user need is. Or at the very least, is not articulate enough in representing that it understands what that user need might be.

This is all part of the thinking that I’ve been doing in the background during my time at Wieden+Kennedy. At work, there’s a tremendous amount of respect placed upon the right strategic insight that leads to the right brief that produces the right work: and that work is creative work that resonates with people as people. That doesn’t mean that it’s schmaltzy work, because “good” things are as true insights about people as “bad” things are.

But to even get at those insights that prepare the strategy that inform the brief that inspire the work requires, I think, a dedication to one thing: which is empathy.

There is the anecdote about users not knowing what they want, in which case Ford would have built them a faster horse (are you kidding – a gasoline powered horse would be pretty awesome) and that you don’t necessarily uncover latent needs by just *asking*. And I wouldn’t want to be fluffy and talk about some sort of intuition and purely touchy-feely stuff. But, if you want to be all science-y and empirical about it, I suppose it’s this: there’s a degree of understanding, of theory of mind, of perhaps over-indexing on those good old mirror neurons that I think helps when you’re designing products, services or communications for people.

Contrast that empathy and that almost painfully hard to acquire understanding of what a user or audience’s true need is with the startup and business ideology of almost needing to be clinically insane in not accepting the world as it is and having the fervent, religious, unshakeable faith that this, this thing, this product service design new Nest-esque a/v receiver that finally works properly, this thing: this is what user’s need.

Asking what the user need might just be that one, simple, hard to ignore, pernicious needling equivalent to a small child asking: but why? Why do we do things this way? Why is this system set up this way? And when the answer illustrates something other than user need, “well, you see, we need to do things because accounting does things this way” or “because it implements our strategy for growth into the consumer robotics armed security market that we’ve identified in middle America” you get a little peek into a glimpse of: who does this benefit. And if you’re a consumer-focussed organisation or attempting, in any way, to garner some sort of attention from people, then it feels like you’d better have the answer to those questions figured out. It feels almost like instead of taking the Five Whys of root cause analysis, a classic example of some parent suddenly having the insight that perhaps their kids were on to something when asking why something that happened, happened, you take the Five Whys of Why The Fuck A User Would Want This and then bludgeon everyone into submission with it.

3.0 UNIVERSAL SERVICE OBLIGATIONS
That Nick Sweeney prompted a background thread to spawn a week or so ago in my brain about a requirement for a persistent, globally available basic data service. We have universal service obligations for first-generation communication networks like the postal service and telephone service and it’s a surface level reckon that I have where the universal service obligations for wireless communication spectra are things like “be able to make an emergency call” but not much more than that.

So here’s a thought: what happens when universal data service is legislated for? Say, inside a particularly large enough nation state (America, China, India, All Of Europe – but I have issues with All Of Europe, so strike them from the record) public spectrum regulators put forward a requirement a bit like this:

– free, guaranteed trickle bandwidth of, say, two to six symmetrical kilobytes per second

What sort of bootstrapping of devices and services would proliferate based upon such a pervasive ether of data? Now, let’s be clear: this isn’t trickle bandwidth for humans. This is trickle bandwidth for *devices*. Human-level guaranteed bandwidth of the “connectivity is a human right” sense feels like it needs to be in greater-than-five-megabit symmetrical range, scaling over time as payloads increase much like some sort of petrol tax escalator or tied to (ha!) the concept of “data inflation”, increasing to keep up with, say, the current state of the art in full motion video distribution.

But this, this is interesting: because the excitement over the internet of things is a bit weird when you realise that the internet of things needs a) power and b) connectivity and that relying on private infrastructure and per-device contracts might be a little… constrictive.

On top of that, though, how about this for another universal service obligation: I’m in correspondence with a few readers about (and this point I’ll pull the ninja move of distancing myself from remarks) Barbrook and Cameron’s assertion of Jefferson’s property ownership as a direct root to the current Californian Ideology. Now, whether that’s fair or not is a side point for the one I want to make, which is this: Jefferson felt that people should have their own property to do their own thing, but if we *really* want a free and open web, maybe what we need is not just connectivity, but hosting.

“Learn to code,” they said, so I went to the library and learned to code, “break free of the centralisation of corporate entities like Facebook and Google that want to control the flow of information and become an information worker in the revolution of the free web and run your own server,” they said – and my options were a free Amazon Micro instance for a year?

No. Notwithstanding the irritation at having asymmetric bandwidth foisted upon us that naturally makes the internet at the edge a service for consumption instead of publishing thanks to all the entrenched interests who are quite happy with that consumption model thank you very much, how Californian Ideology is this! Not only do I want my 50 acres with which to forge my own destiny, but what if every citizen had access to a guaranteed basic right of computation and network connectivity? Welcome to the world, Baby Boy Hon, you get the right to education *and* a one megabit virtual private server!

I can’t tell if it’s a stupid crazy idea or if we’re just supposed to rely on the latent power and connectivity in the personal network terminals we carry around with us all day, but they’re certainly not designed, at the moment, for that kind of usage. Of course, the libertarians would argue that the government owes you nothing but I imagine that if one were to emigrate to Thiel-land, penniless as an asylum seeker from, oh, I don’t know, France, seeking protection from overly intrusive government regulation and a committee that, gosh, regulates *words*, the border guards at Thiel-land would say: you are now a free woman! And here are your AWS credentials! Go forth, code and disrupt!

Learning to code, then, isn’t worth a damn if you don’t have anything to deploy your code to. And I’d like to try to distinguish this from a bit of a weird “ooh, let’s give every kid a laptop” because a) stupid, b) reasons, but less facetiously giving every kid a laptop is giving them an opinionated bit of kit, a physical instantiation of an idea that begins losing value as soon as it’s cast into the universe whereas the idea of a universal service obligation of *availability of computing resource and network connectivity* feels like it actually gets to the root of the idea without being bogged down in a particularly bone-headed implementation. AND for absolute clarity, let me say that it’s not like I’m suggesting these universal service obligations as some sort of substitute for existing welfare like not starving or having a roof over your head or the right to education because, Christ, do you think I’m sort of libertarian or something, no, these are additional public services and obligations, potentially the ones that you get where we move into a post-work, basic income, not-enough-jobs-for-everyone society.

And if I may round off with a Star Trek analogy, no, they don’t pay for computing resource to deploy their new exciting cloud-based customer relationship management suite when dealing with Ferengi. Computing resource appears to not cost anything in the Federation.

—

Just lots of ramblings today, then. And no links or footnotes! That certainly feels like cheating.

I have a heavy week ahead – travel to Missouri to join with my wife and son to visit my mother-in-law – and then an exciting excursion to Australia wherein I get to Profesionally Reckon in front of people, which Profesional Reckoning in conversation with Alex Fleetwood felt supremely reasonable as it seems to come with an in-built shrug of shoulders and “well, it’s just my opinion, and I’m just this guy.”

Again. Notes. Love them the way Doctor Who loves humans. Send me all of them and I’ll eat them up and excrete them in the form of brain ideas. Which is perhaps not how Doctor Who treats humans.

Best,

Dan

Episode Thirty Eight: Challenge / Response (3)
by danhon

Previously, on this newsletter:

Robin Sloan challenged me to write three consecutive newsletter episodes that had nothing to do with technology or the culture/economy thereof. Flatteringly, he compared it to “one of those runs in X-Men comics where Professor X is in a coma or something, so someone else has to lead the team for a while, and it was always interesting to see what happened ;-)”

This is the third, and final, response to his three-part challenge.

ZERO.
I don’t know what time it is. A midwife has just woken me up, and there are the kind of machines that go beep, beeping. They must feel incredibly self-actualised at the moment. There’s a bustle of activity in the room. For a second, one of those interminably long, unbearable seconds, it feels like something terrible has happened.

Something terrible has not happened. Not yet.

Cassandra, our midwife, explains to me that our baby’s heart rate has dipped. The epidural and rest that my wife has had hasn’t helped, and the doctors have decided that it is time for our baby to come out. We are going to be having a caesarean.

This wasn’t the plan. The plan was for us to have a natural birth, because births are natural things. The plan was for us to have gone through weeks of hypnotherapy classes together, on the recommendation of friends. The plan was for us to be at the birth center, in the Fern room, the one with the fireplace, and for this to be an easy experience, not a hard one, not one with fluorescent lights, not with people wearing scrubs, not with prepping for surgery, not with me being asked to wear a mask, not like this.

Not like this.

And then there’s the bed and the wheeling and someone hands me scrubs and a mask and the anesthetist and the drape goes up and people are talking and I’m holding my wife’s hand and I’m so, so tired and I know this isn’t what she wanted and I’m terrified and Cassandra is taking photos and then I hear:

a cry.

And I swear to god, it’s the most beautiful thing I’ve ever heard.

And he’s so big and there’s hair on his head and he’s absolutely fine and everyone’s smiling, I think, but they can’t be because I shouldn’t be able to see their mouths because they’re wearing masks and someone says in response to his weight that of course that explains everything about how difficult he was coming out and they do tests and everything

is.

fine.

I’m a dad.

ONE.
I am in London, in John Lewis, the department store on Oxford Street and I miss my son so badly. On this work trip, and every work trip since his birth, I have become a parody of the Apple Facetime advert, I can’t get enough of seeing him, whether he’s sleeping or awake.

It is a cliche, but I did not know I could love something this much.

I mean, we have a cat, a really awesome cat: his name is Wandsworth because he was a stray who was found in Hackney but we lived in Wandsworth at the time, and I’d always wanted two kittens, one called Elephant and one called Castle, but Wandsworth is just such a good name for a cat. He is a big, fluffy tuxedo cat who scratches everything and is not a lap cat.

I love him.

Wandsworth was my first human-scale pet, gerbils don’t count.

Wandsworth went missing once, for about five days. My wife and I would arrive home from work together, walk up to our front door and then stop. Because we didn’t want to open the front door, because there was a chance that he wasn’t home. We would literally stand there.

Then, I didn’t know I could love something that much, that stupid ball of black and white fur that scratched things and pissed on things but would jump up onto furniture in our bedroom and cast cat-shaped shadows onto the walls so we could watch Cat TV.

But this.

This: I find myself in John Lewis, in the department store on Oxford Street, in the infant department, staring at baby clothes and toys and I want to buy all of them. Every single one. Because I’m not at home with him, and I am the guilty dad, even though I know at this age, he doesn’t even know I’m gone. At this age, his entire world is his mother and her breast.

But I buy all the toys anyway.

And some socks with monsters on them.

TWO.
I quip, on Twitter, that the best keynote at South By Southwest this year was in our front room, where our son’s toys are, when he gave a talk about Things That Fit Inside Other Things.

Right now, he is putting things inside other things. It doesn’t matter that they don’t fit but there’s something so fantastic about his mind at work. You read books about how children are basically empirical scientists, testing suppositions (although some suppositions about the world could do with less thorough testing, for example: repeatedly throwing things out of a) the crib, b) the bath, c) the high chair).

Things That Fit Inside Other Things, though: I mean, imagine what it was like when you played Portal for the first time and your brain suddenly adapted to Portal physics and you realised what you could do. Imagine grasping, for the first time, the concepts of solidity and exclusion of volume and partitioned spaces. It blows my mind.

It blows my mind to watch this tiny human, barely a year old, figuring out the world and doing it with so much enjoyment.

I mean, I wish I could have as much fun pulling all of the tissues out of a tissue box and then figuring out what I could put inside it, taking those things out, then putting them back in again.

The most fun I get to have during the day is being needlessly facetious during meetings.

There’s a wonderful xkcd comic[1] about people discovering things for the first time and that’s what my son feels like.

Right now, pouring water over his hands when I’m giving him his bath is The Most Interesting Thing Ever, and fine, I might be speaking from some sort of biologically kidnapped state of mind but fuck me if watching him observe The Most Interesting Thing Ever is simultaneously The Most Interesting Thing Ever for me.

He isn’t even able to express the interior state of his mind yet – at least, he does so only rudimentarily through the sign language he’s picked up – and after playing with a friend’s two year old this weekend, I’m so looking forward to him talking.

[1] https://xkcd.com/1053/

THREE.
I am so, so tired.

Tired and simultaneously energised, of course.

Energised when I see the smile, or receive an iMessage of a video of him doing, well, anything.

Tired: the Entire Rest Of The Time.

Our house looks like some giant hand, or, more accurately, two small ones followed by four regular adult sized ones has picked everything up, moved it about three feet to the left, shaken it a bit, and then thrown it to the floor.

Laundry is an intriguing concept for which we’re grateful for and are increasingly perplexed as to how anyone actually completes the entire laundry cycle, which as we’re perpetually reminded by The Pile In That Room, comprises the latter two stages of folding and putting away, both of which feel like they’re some sort of herculean effort at the moment.

And by herculean, I mean: please, could Hercules be resurrected from fiction in some way and be employed to pick things up, fold things and put them away in our house. That would be great, thanks.

We have attempted to explain to friends that our schedule is somewhat fluid and by fluid I mean: we do whatever we can at random times during the day depending on whether the baby is awake, asleep, hitting something, pooping, peeing, eating something, not eating something, “reading” a book or if we are trapped under him, which happens surprisingly often and generally ends badly.

Rotating someone around their vertical axis using your arms is tiring, but the giggling you get from an upside-down baby means I finally understand how laughter is more powerful than screams in the Monsters, Inc. universe.

My left arm is very strong now, and it is also tired. My right arm is pretty good at playing Threes now, while my left arm is holding about twenty one pounds.

I am tired partly because we co-sleep and I get woken up periodically during the night by a tiny foot in my ribs. Or face. Or neck. Anywhere, really. Or it could be a small sweaty head. The general idea is this: I get woken up during the night.

When wife and baby are away, it’s suddenly possible to do things around the house like: put things away. It’s a heady rush of excitement, I tell you.

I am swaying during meetings, still, not entirely because I am tired, but because, more often than not, things go well when I’m swaying, so hey: why not just sway all the time, just to be sure. Can’t hurt, right? It’s probably a bit like being agnostic.

I am tired because leaving the house has become a stupendous exercise, one that could probably be immeasurably improved by at the very least a checklist, or the aforementioned Hercules making sure we have everything. I probably have scope to be a lot more tired in the future, though, because son does not have his own checklist he wishes us to follow.

I await that tiredness excitedly.

I am so tired of being tired that I’m seriously entertaining the practicality of deploying In The Night Garden *on myself* in the evening.

I have never, ever, loved being tired this much.

—

Okay, so that’s it! I’ve discharged Robin Sloan’s challenge and I eagerly await his grading of what feels a bit like some sort of school assignment. In the meantime, a whole bunch of thoughts have been noodling away in my head, so the remainder of this week’s newsletter episodes stand fairly good chances of including reckonings about Netflix recommendation algorithms, Apple’s post-digital-hub digital hub strategy, why it doesn’t do us any good to talk about “creativity” when it’s patently obvious we’re talking past each other, and in all likelihood something will happen where I will be inclined to rail against the Californian Ideology, again, because, well, they just ask for it.

Happy Monday, I hope you spotted the swaying parents in your meetings today.

Best,

Dan


Episode Thirty Seven: Challenge / Response (2)
by danhon

Previously, on this newsletter:
Robin Sloan challenged me to write three consecutive newsletter episodes that had nothing to do with technology or the culture/economy thereof. Flatteringly, he compared it to “one of those runs in X-Men comics where Professor X is in a coma or something, so someone else has to lead the team for a while, and it was always interesting to see what happened ;-)”

This is the second response to his three-part challenge.

THIS IS A STORY ABOUT A BRAIN AND ITS HANDS.
This brain thinks it’s a fast brain: it sees patterns and pieces of things and jumps from place to place and then suddenly, *snap*, there is a new thing made from those pieces of things that is not quite the same as one of the old things: it’s subtly different and then *boom* we’re suddenly at one of those large maps in the situation room where troop deployments are being planned and the fast brain is pushing things around using a large wooden stick to get things into the right hands.

But the fast brain is hooked up to slow hands.

A fast brain is reading a lot, skimming a lot, taking in a lot, but more than just the surface, more than just the gist, it thinks, and then trying to figure out if it fits together – which it might not – or just waiting for it to fit together, for the right moment to happen when everything rotates *just so* and then the fast brain remembers that one little piece and it slots into place and then everything shatters and reforms.

A fast brain does not like the details.

A fast brain gets frustrated by the details because it can already see the shape of the end result, see, it curves over there and there’s a sharp point here and it’s gestures and motion and a point cloud so not solid and the idea of a silhouette and then if you ask it: come and look over here, look at this piece of the shape, did you mean for it to be this angular, should it work this way, should this part flap or ooze or when you press it should it bounce back quickly or slowly then looking at the overall shape I will say: yes, it should be like *this*, because if it is not like that, then it is not like the overall shape.

A fast brain when it’s growing up gets asked to do chores and wash a car and understands the idea of washing a car and has processed that idea, and the idea of a clean car is apply this process to these components and there is a *system* for that and maybe if we tweak the system then perhaps it could be faster or it could be cleaner but do we still have to clean the car because the car in the fast brain is clean now, but then the fast brain missed a bit and it was all about that bit, so what’s the point of the fast brain because the idea doesn’t matter when the car isn’t clean.

A fast brain needs patient hands. It gets frustrated and flips out because it can see: okay, this is the shape of the music, it doesn’t want to learn how to read sheet music because it can *hear* the music, see, it moves here and then it moves there and there’s a relationship did you spot it, it was there for that bar, and it’s *faster* if it hears the music and translates it into fingers but then its fingers don’t move fast and they ache and they’re so slow, sound isn’t right, but the idea of the sound is right. The fingers need patience and then seven years later, the fingers have caught up with what the brain wants to do.

But the fast brain is already on to something else.

A fast brain is fractal. It takes an idea and splinters it, makes thousands of copies of itself, spawns millions of threads, boots up billions of instances, multiplies connections and does a path analysis, not a random walk, a concerted walk, and all this while the body is there, paused: because the fast brain is trying to figure out – what is the right thing to say, what is the solution to the question posed in this relationship and then the face is beachballing because the brain is racing, exploring deeper and deeper down the tree of conversational probabilities and then…

A fast brain ruminates. A fast brain pulls the thread on a thought, the scab of an idea, the tiniest tear of a piece of self criticism and then devours it, falls down the rabbit-hole, explodes and re-forms, constructs towers of self-reinforcing arguments about worthlessness and futility and self-hatred, self-similar reflective concepts of loathing and goes on and goes on and doesn’t know how to solve the halting problem because it’s just an infinitely long piece of ticker tape that will eat itself and won’t stop at three o’clock in the morning or two o’clock in the afternoon or after fifteen years.

A fast brain looks at microexpressions and tone and cadence and delivery and eye contact and says to itself: this person is screaming meaning but not saying it look at what this person’s brain is saying and the person who is supposed to be listening is hearing the wrong thing and everything is so slow the fast brain has to tell the mouth to jump in and help explain because this is so frustrating why can’t people understand each other, but then the fast brain remembers: it is always jumping in, it can’t always jump in, people don’t like it when it interrupts with the non-sequitur that it has to explain because it got from a to b to c to d and then applied that function and now it’s at a1 to b1 to c1 to d1 and why are people so slow.

A fast brain looks at the washing up and says: the concept of clean dishes has been applied to this collection. It is a trivial, solved problem. Next?

A fast brain takes a single piece of music and puts it on repeat and uncovers new details every single time and can listen to it for eight hours straight, will listen to it all the way from New York to London and come out of it not sick of the music but practically worshipping it, and the fast brain will have eaten it up and then it will say to the fingers: you know this now.

A fast brain feels inadequate and useless and pointless because although it remembers the idea of a thing it doesn’t remember the steps of the thing; it remembers the shape and maybe how many steps and what the idea does to the input and what the shape of the output is but then the fast brain didn’t remember the details: why is it so stupid, fast brain. Why can’t it make things.

A fast brain walks into a meeting about a giant problem and no time and fifteen people and then it zooms out and sees a pattern and a direction and a goal and then the people aren’t people anymore because it’s zoomed out and there’s objects with properties that need adjustment to vectors and there are field lines that need tweaking, so the fast brain looks up in its table and sees: to adjust this field line here disarm the system here so deploy humour here to release tension there and recognise that object there to influence this object in the corner and make this observation but do it aloud so that object thinks it’s their idea and then when the fast brain adjusts the system *just so* and provides the instructions and un-pauses the system and then watches it go the system races toward the goal and there is no problem any more and then you zoom back in and there are people again and then the fast brain decides to execute the program with the jokes in it to disarm and that result in an increase in the amount of reciprocal social capital that may be used at a later date.

A fast brain looks at itself and sees all the rules and algorithms and if-then-elses and considers: what does the fast brain want. What does the fast brain feel. So the fast brain pauses the slow fingers and turns its gaze inward, constructs a giant reflecting parabolic mirror and focuses its attention on itself and sees: nothing.

The fast brain is just a massively complicated computing engine for taking in input and then performing operations on it and when it looks at itself it doesn’t even know if there’s an itself there’s just: a giant sphere. A solid, impenetrable, giant sphere.

And then the fast brain has to pause because a piece of input has come in from the slow world outside and the question is this: would the fast brain like some ice cream?

The fast brain considers this: ice cream is just a food, a way to ingest energy, which the fast brain needs and which the fast brain knows in abstract has been designed to hit this receptor over here which causes a cascade over there which results in this physical, chemical, electrical reaction. So the fast brain reasons to itself: the fast brain can decide to like ice cream, or the fast brain can decide to not like ice cream.

So the fast brain can’t decide, because like is a value in a look-up table and the location of the look-up table isn’t in read only memory, it’s in writeable memory so its value is arbitrary.

A flick of a bit and the value is yes, another flick and the value is no.

Meanwhile, the brain’s body is beachballing.

“I don’t know,” the fast brain says.
—

Phew.

Have a good weekend. I’m going to spend it trying to think about things to write about. As ever, send me notes! I got great replies to yesterday’s newsletter and really, really appreciated them. Plus I try to reply to all of them, long or short. Even ones from Nick Sweeney and Paul Rissen.

Best regards,

Dan

Episode Thirty Six: Challenge / Response
by danhon

Robin Sloan challenged me to write three consecutive newsletter episodes that had nothing to do with technology or the culture/economy thereof. Flatteringly, he compared it to “one of those runs in X-Men comics where Professor X is in a coma or something, so someone else has to lead the team for a while, and it was always interesting to see what happened ;-)”
Now, on the one hand it’s nice, I think, to be compared to Professor X because that’s also an implied comparison to Sir Patrick Stewart who is also Captain Jean-Luc Picard, but on the other, my first reaction to Sloan’s challenge was: that feels like *work*. The thing about writing about technology and its effect on culture and the economy is that it feels like it kind of just dribbles out of my brain through my fingers into a keyboard and into some TEXTAREA, laps at the shores of the internet and then makes its way into the Giant Content Ocean. I don’t have to think *hard* about it, it just kind of happens. Writing about other things? Well, that would involve Thinking.

On the third hand, perhaps that’s a useful exercise. So, in full knowledge that this might cause a drop-off in subscribers (which I must remind myself: I’m not *completely* doing this for you, it is still mostly for myself), here I go: I hereby accept Sloan’s challenge.

1. DIFFERENT
I like to think I have the self-awareness to not make this feel like some sort of worst-case parody Thought Catalog or Medium piece where a wide-eyed twentysomething talks about what they’ve learned about the world and their struggle in defining themselves. But, in the year that I turn thirty five I figure that I’ve lived for at least an appreciable amount of time, and lived in enough places, to have some semblance of an idea as to who I am, and how I feel about that. And, obviously, to realise that identity is complicated to everyone. And that some might be more complicated than others.

I’ve never really felt like I fit in. I don’t think that most people do, at least on some level. Especially when we’re growing up, and especially (said without any deep insight) through the tumult that is secondary school and the teenage years. And there are so many ways now for people to *not* fit in with each other.

All of this introspection has been brought home to me all the more with the birth of my son in America, where I’m an immigrant, but where my wife is at home – such as you can be at home in America, where I’m learning that sometimes, moving from one state to another can be as different a cultural shock as moving from one country to another. So I find myself wondering: how is he going to fit in? And is he going to know who he is?

I was born in Bath, England, in 1979, the first child to Hong-Kong Chinese parents who had emigrated to the UK in the mid 70s. Both of my parents were, and are, academics – my father now a professor of manufacturing engineering and my mother with a PhD in Child Psychology who was a teacher in Hong Kong.

It’s clear that most people find growing up difficult as they struggle to define themselves. But growing up as a first-generation, British-born Chinese immigrant, I *really* felt like I didn’t fit in because hey: for starters, everyone around you doesn’t look like you. They don’t eat rice for dinner every night. They have things like fish fingers and chips and have tea. We didn’t call dinner tea. And it’s not even that I necessarily felt like I wasn’t accepted, because hey: I went round to friends’ houses and had tea and fishfingers and sleepovers and all of that stuff. But again, and through no fault of your own, you’re growing up in a culture that’s different to the one your parents grew up with. As different as it is for them, it’s different again for their children.

This is what it felt like growing up. I remember being younger than seven years old, in primary school in Birmingham. *To this day*, I remember when a girl in our class was playing kiss-chase in the playground with everyone and when it came to my turn, wouldn’t, because I was a “darkie.” And I don’t know if it’s through the haze of post-rationalisation or twenty-five odd years worth of memories, but I think I was confused. Because I didn’t feel any different than anyone else, I thought. I was just another kid. I didn’t understand what skin colour had to do with anything, and I certainly don’t feel like I understood what a darkie was.

The word darkie, though, brings with it its own can of worms. What’s difficult for me is that it doesn’t feel like I encountered institutional racism of any kind. My parents looked after me, I went to good – state, public – schools and had a thoroughly middle-class upbringing. I feel more middle-class than I do Chinese, most of the time. My parents, in an effort to make sure that my brother and I would fit in, made sure not to push us to go to Chinese school at the weekends in the way that they saw their friends doing.

So I only feel different when I’m reminded that I’m different. Most of the time, that can be when I look in the mirror: I clearly don’t see a white or anglo-saxon person staring back at me. Rarely, though, it’s when it’s forcibly pointed out to me – and that can be in a bad way, when walking back from lectures in Cambridge someone would shout “Chink!” at me. Because I certainly don’t feel culturally Chinese. It can also be in a good way, when on one of our early dates, my now-wife surprised me with tickets to a taping of The Daily Show and I got singled out by the warm-up guy who proceeded to be amusingly *freaked the fuck out* by me, an asian-looking person, who he presumed to have an American accent instead having a British one.

I honestly don’t feel like I can say I’ve been subjected to racism. I don’t feel like I’m a victim of profiling. I never get pulled aside at TSA checkpoints every time I fly, and I fly a fair amount.

That doesn’t stop me from feeling other, though.

The Chinese have a term for people like me: bananas. Yellow on the outside, white on the inside – superficially Chinese, but lacking any of the cultural upbringing and even lacking knowledge of the language. Only I don’t feel white on the inside, because I didn’t have enough white growing up. And I have to be clear: I don’t and can’t blame my parents for that. At times it might have been easier to, but with the benefit of hindsight and, well, just plain growing up, I can see that they were just trying, by leaving Hong Kong and heading for Britain, that they were trying for a better, different future for their family and surely it was a difficult one, leaving their own parents. And over time, I learned that it was also potentially their parents who pushed them away to emigrate, in a particularly Chinese vision of achievement and wanting success for their children.

So my relationship with my cultural heritage is easily described as “it’s complicated.” With well-meaning parents who placed priority on integration with British culture, I don’t feel like I particularly understand my culturally Chinese roots other than remembering to call my parents at Chinese New Year to wish them gung hay fat choy or to remember to give my son a packet of red lai see at Christmas. It would take the dinner ladies at school to remind me of Chinese New Year, that’s how aware I am. In Portland, there’s a Chinese Garden that I appreciate as an outsider. I take my son to Cantonese story time where, to be frank, I’m learning more Cantonese than he is, and honestly take an innocent joy at being read children’s storybooks and learning the words for different colours and singing nursery rhymes. When I read articles about how Cantonese will inevitably die out due to Hong Kong having reverted back to China, it makes me sad, because I can understand it but not speak it (my parents frequently speak Cantonese at home, but allowed us to respond in English) and it’s hard if not impossible to find schools teaching it.

The perversity to me is that in a box ticking exercise, I’m “ethnic”, despite, in the absolute long-run, being Han Chinese and therefore part of the largest contiguous ethnic group on the planet. The ethnic majority, if you will, once all the pot-mixing and lifting-out-of-poverty is all said and done. My socio-economic status and educational background pretty much place me as someone not needing any help at all: and yet at university, I qualified for a Fast-Track Civil Service internship designed for ethnic minorities. But then, I always wonder: was I accepted to Cambridge because I was ethnically Chinese? Was that a factor? Or was it just because I was smart enough? Or did the combination of being an ethnic minority that was monitored for, combined with a state school education, sway the admissions process?

But I don’t feel white, and I don’t feel Chinese. I don’t feel British, despite the efforts of successive governments promoting multi-culturalism, despite having an opinion about the weather and worshipping public transport and being protective of the ideals of the NHS and the BBC and tearing up at Danny Boyle’s opening ceremony, despite finally, finally, *finally* being able to witness a British winner of Wimbledon – I don’t feel like I can properly claim to be or be accepted as British.

And now that I live in America, I don’t feel American: I have not tailgated. I have not inner-tubed. I have not been on family road trips to National Parks. The Superbowl is a relatively new phenomenon to me. I have only done Black Friday a few times and never again.

On the other hand, perhaps that’s why I was drawn to America in the first place: give me your tired, your poor, your huddled masses. I may be none of those, but I was looking for a place to belong, and America has always projected in its rhetoric its arms open. Despite my experiences with its visa programme. And what more could I ask for a country that birthed itself for those who felt they had no home?

My wife, who I should listen to more, tries to remind me that this in-betweenness I feel although a source of pain is simultaneously a source of strength and individuality. It may well be something that I find difficult, but the way I feel about myself – trapped between cultures, countries, the liberal arts and the sciences, working in advertising but not from advertising, hanging out with friends who make stuff on the internet and yet not actually making stuff on the internet, is only now something I’m beginning to see not just as a weakness and the reason for a sad yearning to belong properly and to be accepted but as something that makes me wholly unique and valuable as a person (as if any person would ever not be valuable). Being between things enables me to see and feel things that might not be possible from either side.

It is not always a comfort, though.

My son, at just over a year old, constantly surprises me and fills me with an unprickable, unburstable balloon of pride and happiness just because of how amazed and delighted he is with the world. And while I can relate to him how I felt, the child of immigrant parents in Britain, he is now the child of a mixed-race couple in a historical melting pot of a country. And when I see his smile and innocence, I don’t want him to have to encounter with confusion and a lack of confidence what I did when growing up looking different. Maybe things have changed in the last twenty five years, and that won’t happen. I am not so optimistic, even living in crunchy Portland. I don’t want his world to fall down, as it feels like it did for me, when I was called a darkie in the playground.

I want him to be okay with being himself.

—

Tomorrow, another very special episode, wherein I complete part two of Robin Sloan’s challenge.

As ever, I appreciate all of your notes, whether they’re short, long or even just an emoticon. (I have not received just an emoticon, yet).

Best,

Dan


Episode Thirty Five: Humane Technology; They Shoot Jobs, Don’t They; On Depression
by danhon

1.0 HUMANE TECHNOLOGY
I am still preoccupied with the Californian Ideology and what, ultimately, technology is good at, versus what we wish technology were good at. Chris Butler pointed his post about the screen-mediated life in my direction[1], and what I took from it was this: we have a glut of technology created to enhance the human condition designed by people who prefer interaction mediated by screens. And I know it’s not *that* bad, sure, the technology is created with the best intentions to enhanced the human condition and sure it’s only at its worse when designed by people who broadly prefer interaction mediated by screens.

Reporter’s nagging is exactly that: the nagging of an inhumane service designed to gather data, and not in a personable way. Samantha, Reporter is not.

So this is the thing: how does, and what software or technology, makes us better humans? And by better, let me be clear: more empathic humans. And also: there’s clearly a lot of technology made to be used by other technology. But the thing about technology to be used by humans is that ultimately humans are the ones using it, and while that might sound like a limp tautology, I think it’s incredibly important.

What gets the Californian Ideologists excited – and here I’m talking about the venture capital hockey-stick driven ideologues – are concepts like *scale* and *growth* and *disruption*. Humans, being messy things that are kind of unpredictable and unable to communicate to themselves let alone each other *accurately* necessarily need to be reduced down and abstracted away into structures – data structures, indeed! – that can be map/reduced and iterated over. Get a value from a human. Get a value from a billion humans. Perform this operation on it. Put the answer over there. The very thing about scale and map/reduce and all of these clusters, at a high level, is iterating and *doing the same thing*. Not necessarily doing lots of different things. Reporter gets nagging and treated like a chore when it always reacts the same way, does the same thing, *acts robotically*. Samantha, Reporter is not.

When Tim O’Reilly remarks that the future startup team will be “data scientist, industrial designer, software programmer” I wonder where the person who understands, on an emotional and empathic level, their audience. Sure, you don’t need that for, oh, I don’t know, flow control software or the bit of a driverless car that interprets its surroundings and context. Maybe. But for software and products used by humans? If I felt like I had enough energy or time I would be busy pitching a Business Leadership book *right now* with a trite title like: The Empathy Gap: What Silicon Valley Needs To Learn To Make The Next Big Leap and basically not say anything new other than Jesus Christ Why Haven’t You Been Listening To Those Anthropologists And Field Researchers Like Jan Chipchase You Casually Employ And Then Don’t Ignore.

[1] http://chrbutler.com/2014/03/this-mediated-life/

2.0 THEY SHOOT JOBS, DON’T THEY?
Not Steve, no.

But a fascinating discussion the other day about what’s exactly happening with all the jobs the information economy (alternatively, late-stage capitalism) is eating up. Nick Sweeney pointed out the paradox in yesterday’s episode, that of technology being a labour-saving means of allowing you to do mindless work at all hours. And yes, some of this is the inevitable end-game of capitalism being some sort of Ferengi perversion of the Vulcan phrase Infinite Diversity In Infinite Combinations, Infinte Profit and Infinite Growth.

The flipside of course is the labour-saving technology that saves so much labour that your job disappears and it’s not so much that you have free time anymore as you’re actually looking for a job, anything, to earn money because if you don’t have any, well, no one likes living in poverty.

This happened before, of course, when we moved from the agricultural age to the industrial age, as Tom Coates pointed out[1] and whether there’s any scope for a different post-work world or whether we’re just going to create new work. Of course a fear is that politically there’s always going to be someone on top and someone on the bottom and before you know it the 1% will be using us all as their personal TaskRabbits to buy things from high-end IKEAs and then assemble them. It may turn out to be TaskRabbits all the way down.

It turns out that this fear of a revolution in productivity eating and never reconstituting and reformulating jobs or work isn’t a new one: it’s one that the smart Keynes already foresaw in the 1930s, where he worried about technological unemployment – when the increases in productivity would outstrip our ability to find uses for labour[2]. Seriously – read that economist article. Not being an economist, or someone particularly well-read on the subject, it feels like a pretty good backgrounder (although as ever, I’m entirely pleased to be pointed out wrong…)

Bluntly: jobs might be going away, and they might not be coming back in the numbers that we had for them. Employment may actually be trending down. And what is euphemistically called a “temporary phase of maladjustment” may well end up being the very thing that people like Perkins fears is the writing on the wall, unless society decides to do something about it.

[1] https://twitter.com/tomcoates/status/443482458428678144
[2] http://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less

3.0 ON DEPRESSION
This is what it feels like to be depressed: It is February. I am in New York, a wonderful big city. It is Friday night and I am thinking about what I can do tomorrow, Saturday. In theory, tonight, I could even go and see Punch Drunk’s production of Sleep No More. But I’m not going to do that. I ask all my friends: that is, the people I feel capable asking, the people I feel a connection with, and pointedly, the people with whom my relationships are mediated through screens where I’m able to hide when I need to hide, and speak when I need to speak, about what I could possibly do the next day. The suggestions come back pretty quickly.

What ends up happening is that I spend the entire day, apart from a last-minute venture outside to visit friends, cooped up in my hotel room.

I guess what I’m saying is this: it took me a long time to figure out, and accept, and then deal with, and then to make what feels like minute progress (and sometimes didn’t even feel like progress, to be honest, instead multiple relapses) with my clinical depression. The real diagnosis (and the real first this-is-really-really-serious) moment happened at the first startup I was at. And since, in the various managerial roles I’ve found myself in, whether in startups or in larger organisations, one thing has been inordinately clear: mental illness, of whatever kind, is way more common than anyone thinks.

Another thing has been this, and I’m still not sure I can deal with it, to be honest: this is who I am. The particular patterns in my brain, whether grown or inherited or simply a result of an environmentally triggered chemical imbalance or over or under-reaction, are actually me. And might even be a good thing, because maybe I can’t do the good stuff, or be the good bits of me, without the bad bits. Or that they’re what make me, me.

—

A bit of a woolly one today, I feel. Head’s a bit all over the place. But still: managed to do one. And that’s what I like about this (and what I have to remind myself about this) – the practice of writing.

See you tomorrow,

Dan

Episode Thirty Four: On Advertising; On Schmidt; Shorts
by danhon

1.0 ON ADVERTISING
I have a shtick, a story, about how it is that I came to be involved in advertising. Usually it involves saying something like I never intended to end up in advertising (true), and that I don’t actually like most advertising either (also true). Nevertheless, I do find myself in the weird situation of having ended up at what at least some people think is one of the best advertising agencies in the world, making advertising.

When I first interviewed at Wieden+Kennedy (W+K), I didn’t really know anything about them other than the fact that they’d just hired Iain Tait and that I was pretty sure that he was pretty awesome. So I did my homework: I read Where The Suckers Moon[1], I read pretty much all of their blog archives and any article I could get my hand on and generally stalked the hell out of them.

And I found out that, out of all the advertising that’s been made, W+K had been responsible for a not insignificant chunk of it. And there were even some pieces that were damn well beautiful, not least of which their campaign If You Let Me Play[2], for Nike’s support of Title IX legislation in the US that leveled out the playing field for women in sports.

So here’s the thing: it’s not that I hate advertising. Like most people, I hate bad advertising, and like most things, most advertising is bad.

But, there are the occasional moments where I feel I get to do something good that has personal meaning to me, and if you’ll forgive me, there’s one particular piece of work I’ve been involved in recently that produces that warm fuzzy feeling inside. It’s a piece of work for Facebook: that forever interesting, thorny client used by over a billion of people who have simultaneously strong and vague feelings about, that by design has never had a brand or any real *meaning* behind it, other than the one espoused by its technocratic leader to connect the world. So what does connecting the world actually mean to any of those over 1.2 billion? As part of the current campaign (such as it is a traditional advertising campaign in the first place), we produced a spot internally called “Sci-Fi”[3] for obvious reasons and externally called We Are Not Alone.

And for me, it’s about this, and it’s as much about Facebook as it is about the internet an. d the promise that the ‘net and communication brings. It’s about cosplayers, who never really get that much love, but whom I *absolutely* love even though I’m shy and lacking in self-esteem and not happy enough about myself to proudly dress up and have fun. But I defy you to look at cosplayers and footage and photos of them and not see how much *fun* they’re having, in essence, being themselves by pretending to be and dressing up as other people and things. The rest of the (western) world only really gets to do this at Halloween and even then in America it’s the weird kind of Sexy Halloween, but there’s an innocent fun to cosplaying. And it annoys me so, so much when I see others sneering down at it. So when we get the chance to do a piece about how the ‘net and Facebook help people find each other and show the fun that they have doing that *and then* we see people jumping to cosplayers’ defense in comments (one commenter on an AdAge article jumped down the parent’s throat for saying Facebook were terrible for showing ‘nerds and outcasts’ in a brand spot, instead saying that the parent was part of the problem and should loosen up, that it was wonderful to see people celebrated in this manner) it feels *great*.

Advertising might not be many good things, it might do a whole bunch of things badly or inefficiently, but sometimes it does things fantastically. And to have the chance and platform to openly celebrate a bunch of people who’ve historically been jeered at? That’s fantastic.

[1] http://www.amazon.com/Where-Suckers-Moon-Advertising-Campaign/dp/0679740422
[2] http://www.youtube.com/watch?v=KkLyeKJAqgs
[3] https://www.facebook.com/photo.php?v=10152580205436729&stream_ref=10

2.0 ON SCHMIDT AND THE CALIFORNIAN IDEOLOGY
In the continuing series of “can these guys really be serious,” Google’s chairman Eric Schmidt took to the stage at SXSW a few days ago[1, 2] in what I can only assume to be a personal attempt to make sure that our outrage toward the Californian Ideology never dies down and stokes some sort of persistent fire which we can harness in some sort of sustainable energy (if only we could hook up Schmidt to a sound-and-fury harnessing apparatus).

Anyway: Schmidt was unrelenting – the solution to the inequality the first world countries are currently experiencing is, obviously, more capitalism, less regulation and more education. The end goal of this? So that every man, woman and child may be the captain of their own startup, hustling and growth-hacking their way to better living conditions for all. We are all entrepreneurs, all disrupting, all tirelessly laboring. Schmidt perhaps loses a bit in quotation and being relayed second hand when he says that “fast-growth” startups are the answer because he obviously didn’t get to expand on what he meant by Fast Growth – Uber, which provides a service to a large (but admittedly “wrong” end of the inequality spectrum) by employing drivers (of which I’d argue a lot of Uber’s success comes from a company managing to externalize costs onto its employees *as well as* some smart technology and guileless business hustle), or a company like WhatsApp (fifty employees, nineteen billion dollar earn out, hundreds of millions of users – those undoubtedly at both the bottom *and* the top of the pyramid) for whom quality of life has been improved in some way through messaging).

Now, I have no disagreement with the idea that capitalism as a larger force *has* been a net positive in the world: more people have been brought out of poverty than ever before, and the living standard of a great many people has definitely been raised. But.

The flip side to this, of course, is that the blind worshipping of capitalism and its sister, consumption. There’s a fascinating Medium article (much better than the version of the type of SXSW talk common a few years ago of the type “Here’s some reckons about cognitive psychology I just read from a pop-sci book) that riffs off the book The Two Income Trap (which book puts forward the equally interesting theory that double income earning families are in a perverse way worse off because they end up fighting for the same resource, spending more because of that, at higher risk of losing income, and ultimately ending up with less disposable income.

The model that *appears* to be espoused by Schmidt and his Californian Ideology colleagues is one of perpetual, economic-version-of-rational and ceaseless opportunity of productivity. Need some extra cash? Drive a Lyft or Uber at the weekend. Need to pay for the bottled water and charger cables in your Uber car? Maybe you can do some TaskRabbit errands in the morning before going to work. Driving to work? Perhaps you could drop off a package.

Education itself needs more “disruption” but perhaps this new(er) generation of Californian Ideologue can see (a likely story) the limits of technology. Schmidt admits that perhaps only the jobs related to creativity and caring will be the ones safe from robots, but that’s demonstrably not true based on the yearly drip of elderly care robots and social proxies that come out of Japan. And while the One Laptop Per Child project looks to be on its deathbed (thanks, inevitably, to Moore’s law and the solving of a sort-of-real-problem with mobile phones and tablets), instead we get something like the Khan Academy which is the Californian Ideology brute-forcing and application of scalability to *one man’s method of teaching*, spamming it (in some cases, pretty effectively) around the world. But that’s Khan. And there’s one thing that I won’t forget which is the impact great teachers (and, to be fair, shitty teachers) have had on my life. But technology never solved *that* problem.

In the end, Schmidt appears to be grasping for some sort of post-scarcity Star Trek utopia, but doesn’t realize that the embarrassment of riches he’s promulgating feels more District-9 and Elysium than it does Star Trek. Sure, there’ll be a basic income and what feels like gruel fed out to everyone (California will, of course, have perfected its Soylent by then) and basic healthcare (administered by robots) by Schmidt’s view still provides no space for a vision of a future outside of the Creators and the Servers.

[1] http://www.theverge.com/2014/3/7/5481748/eric-schmidt-sxsw-let-us-celebrate-capitalism
[2] http://techcrunch.com/2014/03/07/googles-schmidt-says-inequality-will-be-number-one-issue-for-democracies/

3.0 SHORTS
– In reply to yesterday’s note about the BBC, Rishi pointed me to this blog post (http://www.bbc.co.uk/blogs/aboutthebbc/posts/New-iPlayer-Celebrating-the-Best-of-British-Creativity) about the BBC and iPlayer “celebrating the best of British Creativity”, specifically new forms of storytelling, which after reading I warned Rishi about because it was precisely the thing about the BBC that got me angry and frustrated at it. Now, as friend pointed out, it’s not like the world needs that many more reckons about the Beeb so let me just say this and leave the matter: removing the limitations of “fixed durations” and “transmission slots” isn’t a new form of storytelling, especially when your audience is familiar with YouTube. It’s fucking looking at the barn door, wide open, and saying that you’ve discovered a new method of connecting previously segmented areas to each other using some sort of portal. No it’s not. Jesus Christ, BBC.

– Little Printer is going to work (http://blog.bergcloud.com/2014/03/11/little-printer-for-business/) which I’m sure will crystalize to a lot of people in a more understandable way why Berg Cloud is potentially a big deal: it’s because it lowers the bar for people to create IoT services. Yes, kind of like in an If This Then That manner, but also they’ve done a lot of hard work in terms of rendering output (the server-backed Webkit instance is *smart*).

– This is a great explainer (and it’s interesting – well, predictable, I suppose – that the NYT had done it rather than any of the companies hawking their wares) about what your activity tracker can and can’t see and how it’s (if you think about it) an EasyHard problem: http://well.blogs.nytimes.com/projects/2014/03/accelerometers.html

– Sheryl Sandberg’s Lean In launched what my time in the advertising industry has taught me to see as a Provocative campaign to ban the word bossy because little girls get called bossy and little boys get called leaders. Which, in broad strokes, I can agree with, apart from this: http://foreveryourgirl.tumblr.com/post/79262601684/heres-the-problem-with-banbossy

—

And that’s your Tuesday. As ever, I appreciate all of your notes and comments and the little sound they make when they enter my mailbox is completely indistinguishable from spam or any other email which just makes me irritated at email but seriously, I do like it when I get them.

Best,

Dan

Episode Thirty Three: BBC Heaven; Shorts
by danhon

1.0 BBC HEAVEN
In a past life, I used to do a fair amount of work with broadcasters and tv production companies. The company I founded with my brother, Six to Start, got its, ahem, start doing work for the BBC and Channel 4, two public (read: state-owned, non-commercial) broadcasters in the UK. There’s something simultaneously noble and tragic about the BBC and Channel 4: the former, is a capital-I Institution, something that, like the National Health Service, inspires a great deal of pride within the majority of the populace of the UK. Originally a private, non-state-owned broadcaster founded by John Reith, in 1927, following a difficult seven years of birth, the British Broadcasting Corporation was established by Royal Charter with Reith as its first Director-General. One way of describing the BBC is of fulfilling Reith’s mission of informing, educating and entertaining the populace. It’s why – and how – the BBC gets away with doing a lot of what it does (which would be hard to justify, commercially).

There is, though, it has to be said, a lot of “what the BBC does”. The BBC’s total income for 2012/13 was around five billion pounds, which at just over eight billion dollars is still less than half of a Whatsapp, of which around three billion pounds came from the collection of its licence fee.

So: the BBC is *big*. And with a remit of informing, educating and entertaining pretty much seventy million people (again, a sixth of a Whatsapp), one could imagine how that remit might find it difficult to be reigned in, much like software’s tendency to grow until it can read and send email.

When the digital broadcast era arrived in the UK multi-channel TV finally arrived, too. Because of the particulars of geography, urban planning, distribution of population and communications licensing environment and existing choice, multi-channel tv didn’t catch on at the same time as it did in the US with cable tv; it wasn’t until cheap hardware (and compelling content, in the form of sports programming) was available through both terrestrial digital broadcasting and digital satellite broadcasting that a viable audience of households started receiving multi-channel tv. When that happened, the previous constraints of only four (and then in the late 90s, five) main terrestrial channels, disappeared and a profusion of channels abounded. For the BBC to deal with this was easy, in some respects: television programming was what they were good at, and in any case they were able run library programming. These channels included, at times BBC Knowledge (latterly BBC Four), BBC Choice (latterly BBC Three), CBBC and CBeebies and BBC News (optional 24).

All this is merely a preamble to say that one of this newsletter’s readers asked if I could do a reckon about the “closure” of BBC Three, the youth-oriented channel[1]. The internet (never mind the world) is never short of a reckon about the BBC, but here I go anyway. For all of that preamble, I’m pretty sure that this reckon is going to be pretty short.

For starters, having looked over the channel’s output over the years, it doesn’t look like having an audience with its own home produced a tremendously large number of hits. The ones that stand out are Being Human and Gavin and Stacey. What might be thought of as BBC Three programming like Little Britain actually got its start on BBC Radio before transferring to BBC Three and then BBC One. My particular reckon here is that for serving a younger and less affluent audience, moving online and especially to on-demand makes a lot of sense (that said, I don’t know whether it actually costs more, less or about the same to deliver programming over iPlayer than it does over broadcast infrastructure).

It’s especially telling to me that in the budget announcement, the director general of the BBC said he wasn’t prepared to compromise on the heart of the BBC, which he saw as drama. I mean, I take issue with *that* – the BBC does far more, and should have more at its heart than merely great drama – but the other issue is that *still* in this day and age the fixation appears to be on medium rather than content. The BBC is such an old institution it’s hard to necessarily forgive them this – their name includes the word “broadcasting,” for starters, and it’s been an age-old debate as to whether the BBC’s mission of informing, educating and entertaining must be forever tied to the medium of broadcasting. No media organization has ever really successfully navigated the transition or opportunity made available by the internet, and the preoccupation is on the “closing” of a broadcast television channel that receives an annual programming budget of over eighty five million pounds. It’s a drum that I’ve always been banging about what you get for that eighty five million pounds and the BBC’s role in both serving its audience (through whichever means?) and developing the United Kingdom’s creative base. It’s disappointing to me that, yet again, the focus is on television broadcast, and not the opportunity of what the internet means for the BBC to deliver its mission *especially* when we’re talking about, naively, a digitally native audience.

Frankly, I’m more than a little annoyed by the comments in the article from “celebrity supporters of the channel” like Matt Lucas saying the closure would be “really bad for new comedy” given that he thinks broadcast is the only way that the BBC can support new comedy and that online isn’t a stupendous opportunity. But then, if you’ve grown up always wanting to make a TV show, as opposed to just entertaining people, perhaps that’s the way you look at the world. Again, this is the kind of thing that really annoys me: this is a way for creative people to get closer to their audience and the focus is on the closure of a broadcast medium, so the BBC does something that it could’ve done for a bold reason instead for a cost-cutting one. Sigh.

So there you go: a reckon, probably one that the world didn’t need, on how yet again the debate is around closing a programming avenue when the programming budget could’ve been doing far more interesting things in a far more relevant way to its audience. But then, I suppose, it is the British *Broadcasting* Corporation.

[1] http://www.bbc.com/news/entertainment-arts-26464007

2.0 SHORTS
– It turns out that that, on very large scales, the cosmic microwave background radiation of our universe (the afterglow of the energy from the Big Bang) seems to have some asymmetries – or lopsidedness. Now, our regular theories state that, in general, there should be nothing especially different about one part of the universe from another and that there isn’t any particular special place because of the way the early universe suddenly inflated. It could be that we just can’t see enough (we can’t see the entirety of our universe, not yet) and that there’s something big lurking just outside of our field of view that explains this weird lopsidedness. http://arstechnica.com/science/2014/03/is-the-universe-lopsided/

– More Deep Structure: here’s a paper on a gigantic neural network built (more accurately, built and trained) by Google to recognise numbers to help parse Streetview data. Remember that Google also has a gigantic neural network that can recognise cats. http://arxiv.org/pdf/1312.6082v2.pdf

– Two pieces on the Quantified Self: one from my brother (http://mssv.net/2014/03/10/perfection-quantified/) and another from Kevin Nguyen (http://bygonebureau.com/2014/03/10/me-my-quantified-self-and-i/) as well as a bunch of Tweets it feels like in reaction to various announcements and talks at SXSW which get at a few important nuggets, I feel. Firstly: yes, I reckon Felton’s reports got a lot more attention due to the care and quality in which the data he was collecting were presented, but not necessarily whether they were actually *useful* or not – undoubtedly, they were useful to him. Secondly, my brother’s screen capture of Reporter’s endless prompts “Time to Report!” recall a shrill, shoulder-perching parody of a time-and-motion clipboard-wielding analyst, certain nothing of which tone of voice indicates a collaborative process. But this may just be a by-product of the nature of iOS push notifications. Thirdly, in tweets (for whom I can’t remember the author), yes, it’s increasingly trivial to just store (and track) as many things as we want, but as I railed a few episodes back: I don’t give a shit. I want *intelligent and contextual* analysis of the raw data, not the raw data. Because who has time for that stuff?

– Kevin Kelly wrote an op ed in today’s Wired entitled Why You Should Embrace Surveillance, Not Fight It (http://www.wired.com/opinion/2014/03/going-tracked-heres-way-embrace-surveillance/) which, as Tim Maly pointed out to me, doesn’t necessarily add anything new to the debate and re-hashes views on radical transparency forged in the 90s (albeit with perhaps renewed relevance given the post-Snowden revelation as to exactly how pervasive surveillance trawls are nowadays). He repeats without criticism Zuckerberg’s law, that humans want to share more than ever before and that all technology ever has enabled that, cites again that cities are merely an aberration and that in the golden age of the village and the tribe, everyone knew everything about everyone. Well, with all due respect, Mr. Kelly, fuck all of that. I am all for an equitable and symmetrical view of surveillance and what gets tracked. But I’ve been on the internet, Mr. Kelly, and I don’t believe that the de facto availability of technology has broadened our empathy. We have so many problems to figure out, and so many divisions due to lack of empathy: technology doesn’t solve empathy. People do.

—

That’s it for Monday. I’m tired, I have a headache, and even though I haven’t seen him for only four hours, I deeply miss my son.

Best,

Dan

Episode Thirty Two: The Machine; Route Around Failure; The Most Expensive Selfie
by danhon

1.0 THE MACHINE
Ok, so I caught a little bit of flack for my freshman late-night philosophical rambling about the Internet being the most complicated machine, more complicated than the Space Shuttle. And yes, if you think about it, anything can more or less be a machine if you loosen your definition well enough. But I promised myself I would dig myself further into the hole I started.

Whether the internet is a machine in traditional-moving-parts sense is a bit of a red herring. Yes, it’s useful to consider it that way from the building-and-design-and-engineering side of making a machine, but I’m more looking at this from an end-user’s point of view. Look, here’s another Star Trek reference.

“Computer,” in Star Trek: The Next Generation is a singular thing. Sure, its processing and transport might be distributed, but it’s one singular system in terms of its (magic, conversational) interface with an end-user.

In the same way, I reckon, that the constituent parts of the “internet” with its all-pervasiveness and the fact that it powers so much stuff now, are becoming more machine-like – as in, a singular piece of machinery that accomplishes a task. I refuse to stoop to the level of school essay and looking up the definition of the word “machine” in wikipedia, so you’re not going to provoke me that way.

It’s interesting, sure, as an intellectual exercise (and also in understanding the internet as a complex system) to envisage all the moving parts involved in an http request[1] – an exercise I facetiously remarked as not being fair due to the profusion of SSDs and asking if electromagnetic waves or photons counted as “moving parts”.

But although we didn’t top-down design the internet as a closed-system machine like Shuttle, that includes lots of moving parts, we have instead designed something bottom up that has started to feel like it fits together in a certain way. And at that point, where do you stop, what constitutes the parts that make up the internet? Certainly the servers and the infrastructure involved in the storage and computation of data. But then also the transport of that data. And the computation involved in figuring *out* the transport of that data. And then do you count the environmental and power systems? And then what of the end-user systems like endless cellphones and laptops and desktops? Or Televisions? Do the mere end-clients, only serving as display services (witness all the IP-address bearing transport signage) count as machinery? Do they count more if they send data back (which they certainly do) that alters the state of the machine? And then: are all networks then machines? Or is it just the complexity of the internet that makes it a machine?

So anyway. That’s my contention. The internet is a fabulously complicated machine, the likes of which we have never made before, not least of which because no one has the plans for it. This has spun my mind off in a variety of wonderful directions, like: a) which museum is going to make a bona fide effort at collecting the Internet (I’m looking at you, Messrs. Chan and Straup Cope) and b) I would quite like to go to an exhibit that shows me what happens when an http request is made. Preferably in a building as big as the Tate Modern turbine hall. And probably sponsored by Google.

[1] https://twitter.com/flaneur/status/441795244611231746

2.0 ROUTE AROUND FAILURE
This thinking about machines got me on to another point about the internet. It’s a positive characteristic of the internet that geeks get to say it routes around damage – that it was designed as a defense ARPA project for a resilient network post nuclear-fallout. Nuke out a node and the network would still work, routing around the physical damage.

It now turns out that part of the damage that we’re encountering on the internet is in its infrastructure itself. That it’s been pretty easy (ish – for the surveillance agency of the world’s superpower, but still) to suborn and listen in on.

We’re even fond, as geeks, of saying things like the internet routes around censorship, which, to be honest, I haven’t really ever had that much truck with, because that’s not a concept that the internet gets to own just like that. Humans, I prefer to say, route around censorship. Sure, the lack of centralized control means once something’s on the internet it’s always on the internet, more or less, and there are lots of ways to publish.

This talk of routing makes the internet *as designed* seem resilient to failure. But that’s routing around of failure modes that were contemplated for, by the current internet. I don’t know if it means that the internet can route around surveillance. Not when it feels like sometimes that surveillance is so deep. With knowledge that the three letter agencies are doing everything from sampling peer to peer webcam sessions through to physically splicing through fiber trunk (and sometimes even undersea trunk?) how do you route around that, when the physical layer is interrupted and repurposed without your knowing? Sure, we have things like TOR that work to anonymize traffic to a certain extent, but is it really a surprise when we find out that TOR nodes themselves have been compromised? In a way it almost feels like an achievement, when you think about it from this point of view, that the internet has been so successful when it’s been (kind of) so easy to repurpose.

Put another way: the internet we have now is what happened when DARPA asked academics and scientists to imagine an network resilient against the fear of the day: a nuclear attack. Is DARPA asking the same kind of people what kind of network they would design that would be resilient to surveillance and cyber warfare? (And how much I hate that latter term). We have made – and continue to build – a beautiful thing that is riddled with holes, and in the meantime we’ve learned so much that we can’t trust *humans* with security. So what type of system would we build from that knowledge?

3.0 THE MOST EXPENSIVE SELFIE
Well, maybe. I’m referring of course to Ellen’s Oscars selife, the one that smashed Obama’s record of previously most-favorited and most-retweeted image. Now, you might not care about such things (in which case: well done! Have a pat on the back that you don’t have to care about such things) but in the world that I live in, an extraordinary number of people were prepared to have opinions and reckons about that selfie. And now here I am, too. No, I don’t think that anyone particularly noticed (other than, again, the people whose job it is to notice) that Ellen took the photo with a Samsung Galaxy Note. Allen Adamson, the Landor ad exec who claimed that you couldn’t buy this sort of magic virality[1] immediately fell victim to what at times feels like the journalistic prank of the unfortunately placed quote that makes you look dumb in an article that claimed you could, indeed, buy that kind of magic virality, and it turns out that it cost Samsung around twenty million dollars, all in all. “So what,” you say, isn’t this the kind of thing that Apple has been doing for ages? And isn’t this exactly what happened when Will Smith waxed about his Converse in that awesome movie about the dangers of Software Update, I, Robot? Well, yes. Which is why all this hullaballoo is bizarre and decidedly inside baseball. Instead, of course, we should be talking about the nous of David Cameron and his utter inability to realize how others see him[2] and the awesomeness that is Sir Patrick Stewart who reminds us that it’s always much more fun to dick about on the internet than to take oneself too seriously.

[1] http://online.wsj.com/news/articles/SB10001424052702304585004579417533278962674
[2] https://twitter.com/David_Cameron/status/441306815733579776
[3] https://twitter.com/SirPatStew/status/441340093643894784

—

That’s it. It’s Friday. Have a nice weekend, maybe go for a walk, give someone a hug. I’ll see you all on Monday.

As ever, I appreciate any and all of your notes and feedback.

Best,

Dan

Episode Thirty One: Everything’s Made Of Blocks; How The World Works; Advances In Quantification
by danhon

1.0 EVERYTHING’S MADE OF BLOCKS
I have a secret confession: I’m not that into Minecraft. I appreciate it, sure, and understand it (I think) and its appeal, and, for the record, *some of my best friends are into Minecraft*, too. But other than having bought it a long long time ago and occasionally wandering onto a friend’s server, I haven’t spent that much time with it. (The last time I remember looking at something because it was a genuinely interesting cultural phenomenon, i.e. for ‘research’ was World of Warcraft and I only managed to escape something like 67 levels later. It may well be that I’ve just developed better self-preservation instincts.)

All that is to say that this is clearly an Olympic-level reckon, in that what’s interesting about Minecraft is its accessibility (not to be confused with *simplicity*) and its depth. Now accessible things that can be deep often appear to be impenetrably complex from the outside – but (and this is why certain games are so interesting) it’s precisely that combination that allows for a long-term and rewarding experience.

Minecraft, a simple combat/building game feels like the real-world incarnation of OOP!, the product of Interiority, the startup team detailed through Daniel’s journal in Douglas Coupland’s Microserfs. When Microserfs came out in 1995 (the year I was excited by a Microsoft operating system, and the year I turned sixteen), I devoured that book like I devoured that other Douglas’s book, The Hitch-Hiker’s Guide To The Galaxy. Based on a short story Coupland wrote for Wired in 1994, Microserfs inevitably became the textbook for this introverted geeky teenager – and it didn’t help that I shared the same name of its protagonist – almost a how-to manual for how I wanted my life to turn out. But I digress.

Minecraft is the building game that LEGO would hope to be if it were incarnated digitally. Blocks, yes, but oh-so-many. And combined with a crafting system, I can see how if I were an eight year old right now, I’m be totally into that.

Anyway: you know that you’ve got a good thing going when people are subverting your original platform and turning it into things that it’s either unsuited for, or just plain orthogonal. This isn’t completely off the walls, *but* the thing that caught my eye was the story that PhD student Christopher Mitchell has a project called Sparseworld[1] which is using off-the-shelf (ish) open datasets from the US Geological Service, Google and OpenStreetmap to programatically recreate Manhattan (and, of course, once you’ve programatically recreated Manhattan, the world is literally your Minecraft block-recreated oyster). This is *fantastic* because you can a) see it right now[2], and b) he’s using a server cluster of 300 cores and 200GB RAM to render Manhattan which is pretty achievable for anyone with a credit card and an Amazon account these days. But it’s being done in *Minecraft* – not Unreal or Unity or anything. *Minecraft*. Which was never really intended, I think, to do these sorts of things. But is a wonderful example of the perversion of a just-good-enough and accessible tool.

[1] http://www.cemetech.net/projects/item.php?id=47
[2] http://nyc.cemetech.net:8123

2.0 HOW THE WORLD WORKS
This might sound a bit like wankery, but I think we’ve reached the point in society now where our reliance upon networks and computerisation have pretty much forced upon us a new layer of understanding how the world works. This isn’t the “Learn To Code” model of how the world works because it feels like learning how to code, at least in the English model of “here’s how we make a website” or teaching Jquery is nothing more than an updated version of “learn how to use Microsoft Office” – because you don’t really need to learn *how* to code, but need to learn *what* code is, and what it does.

So here’s (possibly) an ongoing series of concepts that I reckon are required to make sense of and understand how the world acts the way it does, especially when that world is touched, repeatedly and often without consent, by computers.

Computers do what people tell them to. They are exceedingly dumb. This means that we can make them do exceedingly dumb things, or exceedingly smart things, but, and only but: they only really act in or towards what we tell them to do. Now, this holds true because for now, we don’t have self-modifying goal-oriented programs (right?) – because even when Google accidentally builds a neural visual system that identifies cats, the people involved were still *intending* to build a system that recognised features in YouTube videos. They may very well not know *how* it recognises cats, but that’s by the by. Similarly, we *tell* computers to execute Flash crashes. They may well be unintended consequences, but that’s not to say that they weren’t *contemplatable* consequences.

So the thing about the internet not being secure and everyone freaking out about what the NSA and all our other nation-state (and corporate) organisations are doing is this: we *told* computers to send information over the wire, in the clear. That was *by design*. The bitstream and the clickstream are clear because a human made a decision somewhere and that propagated out over the network. We have to remind ourselves that we have a remarkable degree of agency, still. There might be different reasons why, for example, we decide to retain everything ever (from corporate data-mining for profit, to an instinctive packrat tendency) but the fact of the matter remains that ultimately, computers do things that we tell them to do.

The corollary to that is being aware of the infrastructure that the network is built upon. It’s so unbelievably complex. You wouldn’t normally (or would you?) want to worry about which particular part of the OSI 7 layer model has been suborned. Or that, as it turns out, one person on one mailing list could have an opinion that turns a special interest group in a certain direction which means a certain implementation of a certain cryptographic standard gets implemented into standard libraries.

Here’s the thing. You can *just* about understand how complicated the Space Shuttle is. You can look at it, especially as it moves from its hanger on that awesome caterpillar thing over to the launchpad and then you look at Mission Control and there’s all those complicated people there and remember that movie Apollo 13? That was some crazy stuff! All those people, working so hard!

The internet is *harder*.

The Shuttle gets props for being, I think, regularly named “the most complicated machine.” With all due respect, bullshit. The “internet” is the most complicated machine. From the physical layer through to the presentation layer that’s some dude using BroApp to send a text message to his unfortunate girlfriend, *that* is the most complicated machine we’ve ever built. Because with the Shuttle, we could fix the fucker. There was that story about how we might, just, could’ve saved Columbia by NASA mounting the most daring rescue mission ever. If we found a similar flaw in the internet? Goodbye internet. We can’t just do a code audit of every machine connected to the network. We can’t just turn it all off and on again. The entire thing is just like one massive, distributed, single point of complicated failure.

I guess what that point is getting at is this: the internet is complicated. Although the answer to some questions about coding are, in some respects “easy”, the implementation is nigh-on difficult. So when someone asks if you could make a triangular web browser, the answer is “well…” because, *in theory* the thing about code and computers is that you can more or less literally do whatever you want. It just depends on whether you want to build an entire toaster from scratch or not.

We haven’t had, I don’t think, an infrastructure failure of (not on) the internet yet. I don’t know if that’s because of its slimy tentacle-y design, or just because we’ve been extraordinarily lucky. But it feels incredibly brittle to me.

3.0 ADVANCES IN QUANTIFICATION
Friends-of-this-mailing-list Product Club[1] released the first Product as a result of their Club today, Up Coffee, by Jawbone[2].

A few observations.

One: someone has finally released something that makes use of quantification that actually feels like it’s *useful* or solves some sort of user need (I want to sleep better) other than “I want to measure things because I’m into measuring things” or “I want to lose weight”. Or, at least, what I mean to say is this: Up Coffee has a point to it that is something other than intrinsically just measuring something to see what that says about the something you’re measuring. It is about coffee, and caffeine and sleep. Thank God for that.

Two: it makes me yearn for a *passive* personal trainer model. Nike’s new FuelBand software has this thing you can turn on which reminds you Win The Hour, which is great if you’re trying to remember to be active throughout the day, but if you’re like me and British, there are only so many times I can be reminded to crush it before I have to crush something else.

The thing about a lot of these bands and quantification devices is this: they’re great at calibrating behaviour and setting in motion a new habit. They worked great at that for me. But then, when you have the habit in motion, you kind of don’t need the persistent monitoring. It’s almost as if you need some sort of “OK, you’re in the rhythm of it now, I’ll only disturb you *when something drastically changes*.”

Almost as if, after a while, the default view would be wide and would pretty much say: “You know what? You’ve been OK for the last three weeks. Nothing to see here! Keep it up!” because really – *there’s no need* to see all that data. It’s just stress inducing. God, imagine if your legs emailed you every day to tell you how much you’d used them. For your entire life. Shut up, legs. I’ll make a rule for you and not listen to you.

This is the thing about personal quantification software that is like a shrill little demon sitting on your shoulder and never shutting the fuck up. You end up hating and resenting it. A good friend, a good trainer, knows when to back off and when to be relevant. What we have now is very far from that. And really: what’s the use of all this big data if you’re just going to *show all of it to me*. Seriously.

[1] http://productclubsf.com – still suffering from “everything else is more important than our own website” syndrome
[2] https://jawbone.com/up/coffee

—

Instead of a sick baby, I have a baby with a sick mum, so we took the baby to the play gym so the sick mum could rest. In my mind, the play gym was a wondrous world full of Things, but in the reality of Parks and Rec, it’s a gym that babies can play in. My baby’s awesome, though, so nyah.

Thanks for reading, and as ever, please do send me notes, even if they’re really short. Or even if they’re really long. I reply to both kinds. Honestly, I do: people who’ve received replies have been surprised. I like surprising people.

Best,

Dan


Episode 30: Numbers; Performance and Practice; The Kessler Run In Over 12 Billion
by danhon

Today’s a short one – mainly because my wife and baby have come home from a week away and work has blown up.

1.0 NUMBERS
There are a few numbers that have jumped out at me lately.

Benedict Evans remarked yesterday that a little over four billion square feet of screens would be sold in 2014. To put that in context, that’s about five Manhattans worth of screens. This might sound like a trite thought, but on the one hand: bloody hell, that’s not very much screen. I was busy looking things up like the surface area of the Earth (a lot more than four billion square feet), the surface area of the Moon (similarly, a lot more), and even Australia. So: four billion. Not that big.

Even less than four billion is one billion: the amount of dollars distributed by Kickstarter, which crowdfunding system has been going from strength to strength. In comparison, Apple’s iTunes App Store has distributed around fifteen billion dollars to date. All of this serves to show how digital distribution has created new ways for money to move around. Again, that might sound trite, but (and again, this being a reckon) this is a new economic ecosystem that’s allowing quite a bit of point-to-point financial transactions (the barriers to entry for being an App Store developer are certainly lower than they’ve ever been in comparison to the previous requirements for ‘receiving money for creating, selling and distributing software’). The ramifications of this – again, because of the kind of raving that you get from the Kessler contingent of the Californian Ideology (see below) – bear untangling.

2.0 PERFORMANCE AND PRACTICE
Thanks, I think, to some very nice tweets yesterday, the subscriber numbers for this newsletter broke through 500 yesterday. Which has led to a period of reflection on why, exactly, I’m writing this newsletter in the first place, and what I’m getting out of it. I’m not flaming out or anything, just checking in after thirty episodes with some thought.

I’ve spent probably the last twenty years of my life dealing with clinical depression, at times pretty serious and at other times just the regular fog that never lifts and leaves you listless and generally ineffectual with a side of self-loathing.

One thing about the newsletter writing is that I’m back to writing for myself. It feels like I’ve worked through five plus years of writer’s block of increasingly feeling unable to express myself on the internet (other than in the short form of Twitter, for example) for a number of reasons. They include things like: well, *everyone* has an opinion, or a reckon, about something, and there’s nothing particularly unique about mine. In fact, there’s more than enough. In which case, I’d better be saying something damn insightful or useful for it to be worth writing down and distributing. And also: wow – there’s so many smart people out there! There’s a crushing responsibility, at least personally, to live up to there.

So what’s interesting about the newsletter model is that I’m not necessarily putting this out there in such a public way as a blog. The people who’re receiving this – you people – have chosen to. And you can choose to stop receiving it. This newsletter then doesn’t have to fight for attention (or at least, feel like it’s having to fight for attention) amongst the rest of the internet. It’s almost opted out, by expressly being opt-in.

At the same time, I’m also the kind of person who has the sort of self-esteem deficit where just knowing that there are people out there who’re interested in what I have to say (and are pretty receptive or positive in response to that) is a big influx of positive external validation.

What I’m saying is: it took me a while, but I figured out that I *enjoy* writing. There’s an intrinsic Csikszentmihalyi-style flow and good feeling that I get out of it. But at the same time, the pressure of having an audience – and one who has chosen to pay attention to what splurges out from my head, is a persistent reminder to do a thing every day that I do enjoy doing.

The practice of the thing: writing every day, organizing my thoughts (such as they are, and I realize they’re ramble-y) I can’t emphasize enough. For someone who’s working out that he enjoys thinking about things and breaking them down, one of the valid outputs of that thinking is *writing*. Having the self-awareness to look at the validation as just a factor, or merely a prompt, instead of the only reason for doing something, has been incredibly powerful for me.

3.0 DOING THE KESSLER RUN IN OVER 12 BILLION
Yesterday’s episode continued what’s now becoming a multi-episode rant against the Californian Ideology and included oblique references to an Andy Kessler. For those who are new to the program (I feel like I’m writing “Previously, on Dan Hon’s Newsletter” and the appropriately Majel Barret-voiced “and now, the continuation”), here’s the brief recap:

Episodes 28 and 29[1,2] covered me being introduced to Andy Cameron and Richard Barbrook’s rant and manifesto against the utopianism of new/hypermedia Silicon Valley and California that had begun emerging and its recent eruption and evolution through the likes of Tom Perkins (he of the 1% being preyed upon like some sort of Kristallnacht) and, ultimately, Andy Kessler, an ex Wall Street VC guy with a sociopathic and Jeffersonian every-self-made-man-for-himself attitude to the universe in general, and that the only way (or best method through which) we can improve our lot as a species is by being greedy.

One particular failing of the Californian Ideology that I continue to pick up on is this myth of the self-made man. It’s one thing for followers of the Randian philosophy, but the thing about Rand (and here I really *am* reckoning) that’s so insulting to me is the idea that the singular person is able to change the world. Well shit: the world’s complicated and interconnected in ways that Ayn Rand was never exposed to. Have you seen how hard it is to even make a toaster on your own anymore? That’s why this forging-your-own-path business is bullshit: because it needlessly limits the types of problems and challenges we can overcome to only ones that we can overcome on our own, through sheer force of will. Here’s where I tie things, inevitably, to yet another GDS comparison: the unit of delivery is the team. Kessler’s like and their go-get them attitude are so *individualistic*. Berners-Lee could only build the web upon the work of people who built ARPAnet. Apple could only build OS X and then iOS and then the App Store which distributed billions of dollars to developers through the contributions of open source and projects like FreeBSD. The idea that you can stand up – and should – stand up just seems so backward looking when what we’re showing with the network is the *multiplicative* factor that humans bring to the productivity equation.

We are better, together. People like Kessler feel like they want to keep us apart, at each other’s throats.

[1] http://tinyletter.com/danhon/letters/episode-twenty-eight-only-connect-they-stole-our-revolution-policy-as-code-dance-central

—

And with that, I end Wednesday at 8pm, with about as much anger in my system as I can bear, because really.

For all of you new people who’ve subscribed – this is the kind of stuff that I write. It changes pretty much every day. I hope you’ve enjoyed it.

Best regards,

Dan


Episode Twenty Nine: That Most Peculiar Thing, Cargo Cultism, That Californian Ideology
by danhon

1.0 THAT MOST PECULIAR THING
Thinking about other British startups – and please, if you have more examples that help me break out of those that are immediately to hand, do send them along, because I’m painfully aware that this is under-researched reckoning – one that resurfaced to at least the frothy bit of my brain was the fine people at Newspaper Club[1]. Newspaper Club is one of those ideas I’m very happy to label as disruptive or insightful or just plain innovative. It relies in part on thinking against the herd mentality and being inspired by having a long, hard look at what it is that people actually do, how a new thing might fit into that, and what people care about.

What the tremendously clever people behind Newspaper Club realised was that there was a bunch of incredibly potent infrastructure lying around that was being used for, more or less, a singular purpose: printing newsprint. And only for a very small set of customers! This infrastructure is *expensive* and big, and the exact kind of thing that you need a lot of capital for, never mind people who know exactly how to use it. And the interface to it is particular and individual involving a whole bunch of specialist domain knowledge that hasn’t really escaped (because, of course – who would want to print a newspaper other than the type of people who print newspapers? We have a name for them: newspapermen, and they evoke the Murdochs and Morgans and Rusbridgers of the world. This Extra, Extra, Read All About It heritage is nicely reflected in Newspaper Club’s “brand” design, a cheeky scamp of a newspaper boy, eagerly delivering the latest installment.

Well, it turns out that quite a fair few people would like to print newspapers – they just haven’t had the chance before. And, perhaps, printing newspapers isn’t a hockey stick kind of business where, before you know it, we’ll be counting Newspaper Club’s Daily Active Users in the hundreds of millions. But: and this is an important but, Newspaper Club is a thriving, growing business.

You want case studies? They’ve got case studies[2].

You want an antidote to the gag-inducing Eat People not-even-Swiftian-parody take-no-prisoners attitude of people like Andy Kessler, for whom progress must always come at the cost of other people? Look at what Newspaper Club helps people *make*.

Like Berg, Newspaper Club are another example of that most peculiar thing. Or, as I’m going to start pointing out, the *normal* thing. A business, grown slowly, identifying its market, with thoughtful, considered progress. No, they didn’t try to launch with everything at once (lean startup rhetoric). But they knew what they were selling and, I suspect, pleasantly surprised when they saw what people created with what they offered. An imaginative service that repurposes infrastructure and makes it creative? Some sort of weird software/internet/giant-piece-of-machinery bicycle for the expressive mind?

[1] http://www.newspaperclub.com
[2] http://blog.newspaperclub.com/category/case-studies/

2.0 CARGO CULTISM
Apologies for the brief interlude and rant into advertising land. There are brands out there – trust me – that are right now thinking how they can capitalise upon Ellen’s record-breaking selfie tweet, circulating urgent emails about how this is a Cultural Moment that can be used to show Relevance to their Audience. Bullshit. It’s 99.9% junk, flotsam and jetsam clogging up already clogged up realtime feeds where people have already given up trying to discern signal and where the noise in the signal is the best bet at signal itself. All of these brands (and, let’s be clear, they’re not brands: they’re run by people) are afraid of not showing up, that something big is happening and they’re not involved when really: their involvement at best is some sort of tangential cry for relevancy, some sort of please don’t you forget about me as you scroll on by. Well, shit. The best brands create culture, they don’t mimic it. And that kind of stuff is *hard*. Besides, right now, the even better brands aren’t even creating culture. They’re trying to do something else entirely.

3.0 THAT CALIFORNIAN IDEOLOGY
I’m still angry at Kessler. I’m still angry at American Exceptionalism, even though I can read it as inspiring and noble and grasping at wanting to create something better. But I’m so, so incredibly pissed off at its rugged individualism and fuck-you attitude to everyone else, that, forged in needing to escape from oppressors it lurched (understandably) in completely the other direction and implies that logically what all the Randian types should do is get off the fucking ARPANET and build their own Internet if they’re so assured of their own success and maybe leave Tim Berners Lee off to himself, but OH WAIT: AOL didn’t create the ugly, beautiful monstrosity that we have right now (that has inevitably been suborned into the literal panopticon, where the bitstream and clickstream is easily transparent).

Fuck that.

I’m disgusted.

Reader, I bought Andy Kessler’s book and he thinks he’s being funny and yes, he’s demonstrably smart and intelligent and happily wealthy, but God, he’s no Swift and it’s not a parody, because he sincerely believes it and he doesn’t speak on his About page the way he speaks in his book because rightfully he’s embarrassed about it. I’m entirely happy that he lives somewhere with freedom of expression because he gets the chance to show off exactly how much of an inhuman, profiteering, zero-sum, sociopathic cock he is.

There are countless examples of things that are moving forward the standard of living around the world that have absolutely nothing at all to do with the revelling in the eating of people, of the casual disregard for and destruction of dignity. These, I would like to remind Kessler, are actual fucking human beings he’s talking about and he’s lucky to have been born in a particular place at a particular time where he was able to take advantage of that fact and no, just because someone in California invented a fucking iPod that can hold a thousand tracks in your pocket doesn’t mean that he’s got clean water or a chance to escape the particular socio-economic trap that he’s in. But oh no. Kessler is that brand of person who lacks empathy and the biggest piece of justice for hi that I have in my mind is that that lack of empathy is the one thing that’s going to stop him from being as successful and to afford as much “stuff” as he wants as he could be.

—

It’s not even 9am on the West Coast and I already feel like taking no prisoners. Have a good Tuesday, and think about what you’ve done.

Dan


Episode Twenty Eight: Only Connect; They Stole Our Revolution; Policy As Code; Dance Central
by danhon

1.0 ONLY CONNECT
The Pew Research Center, an American non-partisan think tank, recently released the first part of a report covering the changes America has borne through the first 25 years of the World Wide Web[1].

For whatever reason, there has been a wave of nostalgia palpably moving through a lot of my friends. There’s been Fast Company’s Oral History of SXSW Interactive[2], which celebrates its twentieth birthday. There’s been Nick Sweeney’s wonderful look back at the tenth anniversary of O’Reilly Emerging Technology conference[3], and at the same time, Time’s story of Flickr’s tenth birthday[4].

This is going to be a bit introspective and may come across as self-indugent. I apologise in advance.

I started blogging in 1998/9, on my college’s student webserver, with a tilde address reflecting my university computing service username. It was, I’m (somewhat) happy to admit (after a bunch of therapy, probably) undoubtedly immature, but there’s a long, direct line from 1998/9 on www-stu.cai.cam.ac.uk/~dyh21/ through to where I established my home at danhon.com.

Back then – and it wasn’t really *that* long ago – publishing was still hard. I’m not telling you anything you don’t already know – we can all play the Four Yorkshiremen sketch and talk about how we hand-rolled our websites with notepad or BBedit or vim or emacs and laboriously copied them over via FTP and had to remember whether we needed active or passive FTP or slapping our foreheads when we had transferred images as ASC rather than BIN. If you look hard enough, it was always going to be all fields as far as you could see.

Let’s skip that bit.

Let’s instead concentrate on how the web felt at that time.

Because it felt small and it felt intimate. It wasn’t, of course. Millions of people were on the internet back then. But, for a while, you could count on both hands (even if you weren’t using binary) the number of self-identified “webloggers” in the UK at the time. And we would do things like go and meet up and awkwardly talk about how weird it was that we were all publishing things on the web.

Funnily enough, hardly any of that original group write much on the web anymore.

I don’t really know how to talk about this other than in an intensely personal way. We were living at least a portion of our lives in public (or, at least, exposing the parts of our lives we were happy exposing, in public) and a number of us remember having to explain to people that the information we chose to publish about ourselves was not, in fact, the totality of our selves.

The web (at least, our bit) felt small because it *was* small. We didn’t have to worry, as much, about other people, because, for the most part, other people weren’t looking. Similarly, when Twitter first started its service, for the first fifteen thousand users, there wasn’t really a need to have a private account. That changed, later.

The web was a room back then, and it felt like we were the only people in it, and we formed intense relationships and camaraderie with the others we found, even if, in fact, the only thing we had in common with them was that we were almost obsessively interested in connecting and what this network could do for us as people. And we felt like we could know them.

The web is different now, of course. It’s so much bigger. In 2014, in the US, 87% of adults use the internet now. In households earning about USD 75k, it’s 99%. 97% of young adults aged 18-29 use it. You can’t hide on it anymore.

I can see that this means that the feeling of a wide-open expanse, populated sparsely but still with strong connections, has gone away. That wide-open expanse is incredibly populated now. There are so many groups. Instead of the one knitting blog ring, there are multitudes. What’s happened instead is that a singular community has not so much splintered and fractured as been fractally copied and pasted, self-similar versions spammed across the internet in a reflection of every single thing about us that makes us unique, good and bad. By necessity, those groups are potentially harder to find because, well, there are multitudes of them. Instead of just the one, that some of us grew up with. (And, it has to be said, it turned out that some of us had nothing in common *other* than an attraction to the network, back then, and didn’t end up forming long-term friendships).

I don’t personally know if the web feels anything like the way it did when I started participating in it. If the experiences that I was a part of and created can still be reproduced in some way. One of my friends laments the smallness of that old web and, I think, the defined small social space that we implicitly had, rather than explicitly created. None of us really write online anymore, at least, not in the sense that we used to blog regularly. Instead, Twitter takes up time and, honestly, the intervening fifteen years have inevitably changed us as we’ve grown up.

My initial reaction to my friend’s sadness was instead a sort of optimistic “but a thousand, million, million flowers bloomed!”. But now their sadness has caught on – and I wouldn’t be surprised if it had anything to do with the wet Portland weather outside – and the more I think about it, the more I do miss it. The non-corporate, small web. I’m not even necessarily saying that I wish things stayed the way they were (barring, of course, the wonderful methods of surveillance now perpetrated upon us) – the growth of the web has been a good thing. I don’t even want to make some sort of trite gentrification metaphor of interests coming in, buying up and then bulldozing nascent communities in the way that you could interpret Yahoo! doing to Geocities. Whatever; more people than ever before are online. And on balance, that’s a good thing.

[1] http://www.pewinternet.org/2014/02/27/the-web-at-25-in-the-u-s/
[2] http://www.fastcompany.com/3026402/oral-history-sex-drugs-apps-and-sxswi
[3] http://nicksweeney.com/2014/02/27/revisiting-the-distant-now/
[4] http://techland.time.com/2014/02/10/flickr-turns-10-the-rise-fall-and-revival-of-a-photo-sharing-community/#ixzz2swYvzkvu

2.0 THEY STOLE OUR REVOLUTION
I was watching Bruce Sterling’s talk at Transmediale 2014[1] and a number of things collided in my head. He railed, as you would expect him to, against the latest protrusion of the West Coast Randian boosterism into our world, whether we liked it or not, and its inevitable metamorphosis into the sort of security and surveillance state protested by its very architects back in the 60s. And he introduced me, embarrassingly, to Barbrook and Cameron’s critique of the Californian Ideology[2, 3] – the very least of which because I spent close to a year working with Andy Cameron (at an ad agency, of all places) who introduced me to Richard Barbrook.

What does the Californian Ideology look like now?

It looks like Software Eating The World, and by extension, The People Who Live In It. Software Eating The World, of course, refers to Marc Andreessen’s 2011 essay[4] in The Wall Street Journal on the opportunity for software and computing power to disrupt with a lower-case d existing industries and provide opportunity for massive structural change in businesses like finance, logistics, energy, healthcare and education. Andreessen’s essay – notably in the *way* in which it is presented, but not necessarily the content itself – is in a way the non-offensive, good cop face of the Californian Ideology. The story of inexorable progress and American exceptionalism. Fair enough: the logical end-game of the seeping of Information Technology into every day life and its promise of increase in productivity in the name of efficiency.

Andy Kessler[5], on the other hand, is the bad cop face of the Californian Ideology, the “I’d be happy to call him a cunt,” kind of Wall Street and West Coast capital veteran, who gleefully exhibits stereotypical traits of corporate sociopathy, so much so that his 2011 book on entrepreneurship is entitled, with corresponding lack of empathy or moral centre, “Eat People”.

Kessler’s 2011 book is a rulebook, a manifesto for aspirants wanting to share in the wealth of the new American software-backed entrepreneurial gold rush, of which one central tenet is that “the road to wealth passes through the graveyard of today’s jobs.” Indeed, Kessler maintains, “the best way to leverage abundance and scale, and to create productivity, is to get rid of people.”

This is the new Californian Ideology, and it isn’t for everyone. Not by a long shot.

To be fair, Kessler doesn’t mean *all* people should be eaten. He just means some of them. Alright, most of them. The ones who can stay are those he terms as “creators”, bluntly, those – and only those – who in his view create productivity. They are those who write “code that automatically lays out magazines, getting rid of expensive graphic designers. Or design a robot to pick and place a product into an Amazon box for shipping, getting rid of workers in a warehouse. Or writing algorithms for trading stocks in milliseconds, something humans couldn’t do even if you threw a thousand of them at at the problem.”

The more astute of you will see purely financially oriented creation here, but Kessler will throw some of the others a bone. Creators may also “come up with a drug that lowers the risk of some debilitating disease, or a test to identify cancer ive years early.” A creator, in Kessler’s view, can be a creator by “increasing output by saving lives and keeping people healthy, too”.

Kessler places the ultimate value of a human on those who increases output per worker hour. To do otherwise is to impede inexorable human progress and the raising of standards of living for everyone, everywhere.

Everyone else, he says, is a Server. In Kessler’s world, the Creators are the Eloi and the Servers their Morlocks.

Why am I bothering with what uncharitably feels like a hit piece on such a sociopath? Because Kessler’s updated Californian Ideology is an especially pernicious view upon the world, growing increasingly shrill when it feels increasingly threatened. One populated by Tom Perkinses who only half-jokingly (but not really?) suggest that the rich should have more votes than the poor (because they are, naturally, more valuable) and that the attacks on the 1% by movements like Occupy are some sort of Kristallnacht (pro-tip: if you are suggesting something is like Kristallnacht and it is not, in fact, Kristallnacht, it probably isn’t Kristallnacht). One also that shows up in advertising, with Cadillac’s recent Poolside[6] ad, catching flack for apparently going after (variously) the 1, or the 1.2%.

Kessler and Perkins are the sharp, pointy, massively wealthy (and wealth-accumulating) stick of the logical end-run of the bright-eyed optimism of this formerly counter-culture California Ideology.

You see, signs are increasingly apparent that the bounce-back recovery (not that it was ever a bounce-back) from the 2001 era, isn’t a bounce-back recovery. Jobs that vanished, vanished, and have been replaced by zero-hours contracts. Kessler talks of Creators/Makers and Servers/Takers, and exhorts as many people as possible to become Makers, lest they become parasitic drags upon society and humankind.

Kessler doesn’t go far enough. He is implying some sort of productivity Moore’s law where ever increasing human ingenuity, applied in the right ways to root out inefficiency, will increase the standard of living for humanity as a whole.

Bluntly: fuck that shit.

The principles espoused by Kessler are nothing but a hollowing out of society, the pursuit of nothing but the almighty motive of profit, dressed up in some vague handwaving about increasing quality of life for the citizens of the world. Bullshit. While in broad strokes, capitalism has indeed been a means by which to lift a sizeable proportion of the world from subsisting on cents to dollars per day, it remains to individuals like Bill Gates in the guise of his Foundation, to finish the job[7].

Walmart and Amazon certainly are succeeding in widening access to access to low-cost goods that enhance your quality of life. But the way Walmart and Amazon treat their workers is counter-productive[8] if you take Kessler literally. In general, more work, done by less people, for less money: because the productivity increases are accruing at the top. The Amazon employee who cannot afford what it is that they’re selling, who does not have a safety net.

Ah, but Kessler says we have a safety net. Well, we don’t, not really. Not in America, at least. A few days ago, an email went out to all staff in our office, appealing for donations to the order of $75,000 for a friend of the agency with a recent diagnosis of brain cancer. There’s no safety net. Kessler is not advocating a universal basic income.

I don’t know what it is, exactly, that Kessler hopes to achieve other than its fixation on the profit motive makes me gag. I am tempted to recall part of Joseph N. Welch’s outburst during the McCarthy hearings:

“You’ve done enough. Have you no sense of decency, sir? At long last, have you left no sense of decency?”

This sociopathic shrug-shoulders “don’t look at me” attitude of increasing productivity at any cost is dangerous because it inspires people to write Medium thinkpieces like On Eating People[9], who don’t know any better.

Teachers are important. Doctors are important. Poets, Artists, Musicians, Builders, Lawyers, Parents – I don’t care who you are, you’re all people and you don’t deserve to be ground up and spat out if you’re not efficient or productive enough. Sure, there are other systemic problems and no one likes regulatory capture or the fact that Comcast has a government mandated monopoly and is able to raise your cable service fee every single year.

But for the love of god, can we agree that our future is one predicated on empathy with one another, and not to monomaniacally follow the sociopathic worship of profit.

[1] http://futurismic.com/2014/02/02/if-it-works-its-obsolete/
[2] http://en.wikipedia.org/wiki/The_Californian_Ideology
[3] http://www.imaginaryfutures.net/2007/04/17/the-californian-ideology-2/
[4] http://online.wsj.com/news/articles/SB10001424053111903480904576512250915629460
[5] http://www.andykessler.com/about.html
[6] http://adage.com/article/news/cadillac-clears-misconceptions-poolside-ad/291925/
[7] http://annualletter.gatesfoundation.org/#section=home
[8] http://www.theguardian.com/technology/2013/dec/01/week-amazon-insider-feature-treatment-employees-work
[9] https://medium.com/hackathons-anonymous/34b42fb2e0f1

3.0 POLICY AS CODE, CONTINUED
Three years ago, AT&T won a Supreme Court decision that affirmed their ability to include a clause in standard terms and conditions blocking class-action lawsuits and instead compelling binding arbitration.

Sony Network Entertainment International (the corporate entity operating the Sony PlayStation network) more-or-less immediately followed with an amendment to the terms and conditions of the PlayStation network, similarly enforcing the practice of waiving class-action rights and instead compelling individual binding arbitration. SCE did provide a way to opt-out of that particular waiver (if, of course, you were able to spot it in the updated terms and conditions) – you would have to make such opt-out in writing, to a provided address, within thirty days of acceptance of the EULA/Terms and Conditions. From a user-advocacy point of view, if *acceptance* of terms and conditions is perfectly fine when clicked-through on a tens-of-thousands-of-words EULA, then it’s hard to see why opting out is *only effective* when made difficult.

Last week, Dropbox, VC-backed providers of the online filesharing and syncing service, announced[3, 4] a similar change in their terms of service on their blog, that they would be, in their words, now using arbitration to resolve disputes.

The difference in Dropbox’s adoption of binding arbitration was that their TOS change was accompanied by a (dare I say it) accessible, useable and friendly method of opt-out[5].

This is pretty much a perfect illustration of the point I was trying to make in episode nineteen, in Not Trying Is A Signal[6]. In that episode, I said: it isn’t hard to do this (in this case, provide an opt-out service).

The fact that Dropbox have done this in this particular instance proves the case, and Dropbox makes a point of it in their blog post: “If you prefer to opt-out… … there’s no need to fax us or trek to the post office”. Sure, it’s a shitty thing to do, but the fact that they’ve provided a usable alternative is a signal that, more than Sony Network Entertainment International, they actually give a shit about their users.

This is what being user-focussed means, and I think the Dropbox example shows a way forward where companies can still do shitty company things, but can *execute* those things in ways that aren’t, for the most part, stupendously user-hostile. And I hope that whoever at Dropbox was behind this particular policy – ie the one that said that they didn’t have to make the opt-out process user-hostile – gets credit for this, and that Dropbox don’t shy away from doing such things in the future.

[1] http://consumerist.com/2011/04/27/supreme-court-rules-that-companies-can-block-customers-class-action-suits/
[2] http://consumerist.com/2011/09/16/sony-changes-ps3-terms-of-service-to-avoid-class-action-lawsuits/
[3] https://blog.dropbox.com/2014/02/updating-our-terms-of-service/
[4] http://consumerist.com/2014/02/21/dropbox-jumps-on-forced-arbitration-bandwagon-but-offers-online-opt-out/
[5] http://dropbox.com/arbitrartion_optout
[6] http://tinyletter.com/danhon/letters/episode-nineteen-not-trying-is-a-signal-peak-game-easyhard-snapchat

4.0 DANCE CENTRAL
This one simply collates a bunch of thoughts I had about the skeletal recognition engines in depth cameras like the Kinect for Xbox 360 and Kinect with Xbox One.

The Skeletal Recognition Engine from Dance Central but:

– used in a body language game where you have to sit across the table from someone and lay them off;
– in a game set in a restaurant where you have to gesture wildly and order food from a menu you can’t understand;
– to teach you ever more complicated gang signs (and chain together moves, obviously). DDR but for your fingers;
– used in a Quantic Dream game where you have to match jerky escape movements in order to prevent your rape;
– in a cutscene where you have to attract someone’s attention at a gig by shuffling around, because it’s too noisy;

My wife asked me why I randomly tweeted these out the other day. I think they were prompted by the news of GCHQ’s Project Optic Nerve and their wistful thinking that there was probably a bunch of useful data they could capture via Kinect.

—

Happy Monday everyone. Try not to eat anyone.

Best,

Dan


Episode Twenty Seven: Shorts; Code as Law; The Real Revolution; The Flip
by danhon

1.0 SHORTS
Some short thoughts.

– It is quicker, and easier for computers to guess what you can remember than it is for you to come up with something memorable and difficult to guess, which is just another way of computers trying to make us bags of meat feel inadequate: http://boingboing.net/2014/02/25/choosing-a-secure-password.html

– Kepler is hockey-sticking its planet-finding capability, which is such a wonderfully optimistic sentence I never could hope to type, but one that simultaneously makes me sad about what I feel is feasible within my lifetime. But perhaps not my son’s. http://www.washingtonpost.com/national/health-science/nasa-kepler-telescope-doubles-number-of-known-planets-outside-solar-system/2014/02/26/e83af186-9ee0-11e3-9ba6-800d1192d08b_story.html Also, holy shit, Washington Post URLs.

– Ars Technica takes a look at moving image representation of messaging but doesn’t include nearly enough screenshots, in my opinion. http://arstechnica.com/business/2014/02/the-pathos-of-the-text-message/

– Remember when Will Smith was all “I don’t trust robots” because some robot saved his life instead of the other person and he was all guilty about it and needed therapy but phew he had Converse boots and an Audi? http://www.wired.com/opinion/2013/07/the-surprising-ethics-of-robot-cars/

Speaking of Will Smith, so I have this thing where I want to throw a film festival and the theme would be Haxploitation and we would show things like Hackers (obviously) and Swordfish and Sneakers (Sneakers is such a good movie, I spent at least six months of my teenage years wanting to grow up to be Robert Redford for entirely different reasons than most other people who wanted to grow up to be Robert Redford) but also Firewall and Stealth and The Net and AntiTrust and I, Robot and maybe TV shows like Killer Net and Attachments (my British sensibility showing through) or even that stupendous supercut of the Mainframe[1], or even just watching episodes of NCIS[2].

[1] http://www.youtube.com/watch?v=Hcywf9mwF5U
[2] http://www.youtube.com/watch?v=u8qgehH3kEQ

2.0 CODE IS LAW
When I raved, a few episodes back, about the potential of the Marvel Universe API, Kim Plowright rightly wrote back and pointed out the other side of the double-edged API sword. That entire fictional universes under the control of an API with binary decisions (albeit enforcing human will) could well be a severe stunt to the creativity of fandom. The geek desire to catalogue and mechanise my necessity organises, categorises and sets up barriers. At the BBC, Plowright (along with others) spent an inordinate amount of time trying to create the one true datamodel that would handle comedy and drama storytelling: because, well, part of the beauty of the BBC is that it’s able to think about things in such a large, systemic way. It is, of course, that very British institution.

With hindsight, systematizing and coming up with a framework to describe All Storytelling might seem a little like a fool’s errand: before you know it you’re knee deep in ontologies and RDF and if you’re unlucky someone might even have crowbarred some XML in there if only because it was a buzzword that helped the project retain momentum. This being the BBC, though, where the design of any sufficiently large system is (was?) the driving goal of the place, you end up trying to produce a framework that can satisfy the edgiest of edge cases, and that means something like a multi-decade running storyline like Doctor Who or EastEnders, the latter of which might be defensible but the former of which involves Time Travel, for crying out loud and a singular consciousness inhabiting multiple physical instantiations. It’s almost as if the series creators were trolling the requirements capturing process.

The wonderful, wonderful point and parallel that Plowright made in a series of emails to me is what fandom needs to do what it does. It needs dense text as source material, but it also needs an intimate knowledge of that test. It also needs some sort of innate, instinctual understanding of the interconnectedness of all things in terms of that text – how each piece relates to each other piece and in context with all the other pieces. That’s an incredibly amount of data, unstructured data, at that. And that’s not what an ontological organising system like RDF is good at, really. It’s not a coincidence that at *exactly* the time this research was going on at the BBC, a number of other ex-BBC ejecta were busy inventing folksonomies with the introduction of tagging over at Flickr, and the whole idea of bottom-up organisation. And at the same time, what do we see with things like Pinboard and Delicious and their adoption by the fandom and slash-writing community? Exactly.

This is where I drop in to Mike Rugnetta’s talk from 2013’s XOXO[1] because he explains so eloquently what it is for fandom to be fandom and what it is for fandom to create. The creative tension is in the looseness that can still be preserved against the power unlocked by a queryable API that makes reaching for that information about a story universe so much easier than having it all in your brain.

Plowright’s last point also sticks with me: that this post-event construction of a storyline – ie that the linear narrative that emerges when you gasp for air coming up from an extended tvtropes dive – is rather like the way your brain constructs narrative out of the frankly disjointed yet occasionally awesome fragments you see whilst dreaming. Or, even: isn’t this what we’re being told consciousness is? A post-hoc rationalisation of a bewildering barrage of sensory data, comingled with unbidden retrieval of memory and sense, and only then, only afterwards, do we find a way to describe to us what we’ve just experienced.

[1] http://www.youtube.com/watch?v=-D9Xq3Xr8aE

3.0 THE REAL COMPUTER REVOLUTION
So here’s the thing. Mobile computing is capital D disrupting everything and our VCs are running around like the world is literally on Fire. Marc Andreessen is Tweeting, for Christ’s sake, so something serious must be going on.

One of the favourite stories that I like to tell is about Tetris, Angry Birds, Game Boys and iPhones. I say: there was a time when Tetris could’ve been on the front cover of every magazine in the world, the latest fad that had caught the attention of children everywhere. Most people nod their heads at this point: yes, I can see that as a thing that could’ve happened. But Tetris was only so big, right? Because the people playing Tetris needed to have portable video games consoles. But this thing here – an iPhone, specifically – is an Adult Device, it’s an important thing that I use to make phone calls and do business business business numbers[1]. It just happens that it’s accidentally also powerful enough to be a games console, I mean, Angry Bird playing device. And so Moore’s law inexorably drove down the cost of computing and made it more available so that eventually everything could read email and play Tetris. And the stigma, such that culture afforded it, attached to videogames, vanished a bit, because it could be hidden behind a veil of adult productivity.

Computing, at some point, became this thing that was wrenched from the hands of women — computers — and thrust into the, well, thrusting hands of men. Realise that this is generalisation, of course, but manly productive things are done with computers – like business business business numbers, sorry, I mean Word Excel PowerPoint – and Microsoft’s ambition to put a computer on every Desk.

The liberation of computing by the inexorable application of Moore’s law (in the efficiency direction, not in the hot and fast desktop direction) has meant that as a direct result of needing to find more things to put processors in (or, more charitably, the things for which it is now trivial and pennies on the dollar to put processors in), by definition, the audience for things that can process things has expanded beyond People Who Wear Shirts And Sit At Desks.

The wonderful thing about this is that it’s going to happen anyway. Moore’s law doesn’t really care. The Bay Area doesn’t even have to notice.

I mean, it’d be nice if it happened *faster*. But I think it’s going to happen anyway. That’s the optimistic version of me.

What’s going to happen? Things like this: the Bay Area only sees the top of the ice berg. The bay area gets excited about a trend like wearables and quantified selves and is good at seeing things that it thinks it can sell to closely-aligned versions of itself. The smartest thing a company like Apple ever did was to decide to make things for ‘the rest of us’ and for Jobs to be such an outsider. So, with something like quantified self, the Bay Area can get excited about charts and dashboards and graphs and tracking and journalling whilst completely forgetting that Weight Watchers has been doing quite well at this tracking and measuring lark and that hey, maybe scrapbooking is totally a thing and do you remember Zazzle because they’re totally still around.

The rest of the ice berg is *everyone else*.

There are clearly structural barriers to a more equitable gender balance in the field of “making apps”, but the confluence of factors such as (relatively) easy digital distribution as well as pretty much approaching the point of “free Android smartphone with your cereal” mean that the chances of something for the rest of the iceberg being designed, developed and deployed are *so much* higher than they ever were before.

So that’s the real revolution. I feel like it’ll happen anyway. And yes, it should happen (or have happened) sooner, and the fact that it’s going to happen anyway shouldn’t preclude efforts to accelerate it. But. I am looking forward to the Bay Area and the traditional White Male Scratch Your Own Privileged Itch model to have to compete with a wonderful diversity of ideas that can’t be held back.

[1] Look, if you haven’t seen The Lego Movie at least once by now, you’re just going to be left behind.

4.0 THE FLIP
Abraham Loeb’s paper got published over a month ago on arxiv[1] (which, from what I can make out, is where scientists go to publish their reckons before they get run through some sort of peer-review validation system where they can be published alongside markov-generated non-science, but I digress).

This week, the Kepler mission team at NASA announced that, with a new crop of 715 discovered planets, we’d practically doubled the haul of planets we know about in the universe. This is really exciting. I mean, really, really exciting: to actually know that there are other planets out there; I don’t know. You should be shitting yourself with excitement. It shouldn’t make you feel small. It should make you feel amazed to be part of something so wonderfully complex that we’re just scratching the surface of its understanding.

Of those 715 discovered planets, four are in the habitable zone of their system’s star. The habitable zone is also called the Goldilocks zone because it’s not too hot, not too cold and is just right in terms of its planet surface temperature to allow for the existence of liquid water, one of the things (in our admittedly limited knowledge) that allows life to take place. All the life that we know about requires liquid water as a solvent – and while we can imagine different types of life supported by different solvents, like ammonia or methane-based life, we obviously haven’t discovered those yet.

That’s why we get inordinately excited about planets which are in a star’s goldilocks zone. They’re the closet we’ve gotten to even the most tantalising evidence that we might not be alone, and that life on Earth isn’t a fluke.

But what if there were another way of thinking about the goldilocks zone? What if there were other habitable zones?

That’s what Abraham Loeb figured out, in such a stupendously smart, inverted way of looking at the problem of finding habitable zones. See, we were preoccupied with finding habitable zones as a function of physical space. A habitable zone, we thought, was a narrow strip, a spherical envelope around a heat source capable of sustaining the only life we know about.

Abraham Loeb didn’t look for a habitable zone in any of the physical dimensions. He looked in the temporal one.

See, one of the most amazing things about science and how it works is its power for prediction. This is a digression, but an important one, I feel. We had a theory about the big bang: that the universe originated at a single point and inflated everywhere, at the same time. If it did that, then it meant that everywhere would’ve been the same temperature at the same time. That was the theory. When the Cosmic Microwave Background Explorer (COBE) mission[3] flew, it would observe the cosmic microwave background radiation – essentially, the heat and echo left over from the birth of our universe. And it turned out that the data from COBE fit the theory perfectly. Absolutely god-damned perfectly. Science. It works, bitches[3].

Our universe started small and hot. Like, really, really hot. And it inflated and cooled down.

Abraham Loeb realised that there would’ve been a point – in his paper, he refers to it as a red-shift of 100<(1+z)<137 – which essentially means around 10-17 million years after the Big Bang – when the temperature of the universe would’ve cooled to somewhere between zero and a hundred degrees celsius.

In other words, the temperature range that allows for liquid water.

In other words, the goldilocks zone.

In other words: the entire universe was a goldilocks zone.

Small, rocky planets, if they existed (and there are theories that they could have), could then have had liquid water on their surface.

If there were a perfect moment for life – at least, as we know it – to have existed, it would have been at that time.

The entire universe would have been habitable.

A giant, all-encompassing soup of gassy habitableness.

I love this on so many levels. At least a few are just because of what feels like the poetry of the science involved. But really, it’s because Loeb made such a stupendous, orthogonal intuitive leap. The whole premise of looking for a habitable zone necessarily precluded considering the entire universe as such a zone. The search parameters for the zone and its definition *require* a star as a heat source, and then that one act – well, we know of a time when the entire universe was hot – of removing that requirement of a *star* as a heat source and instead trying to find it elsewhere.

It’s amazing. Literally inspiring of awe.

[1] http://arxiv.org/abs/1312.0613
[2] http://en.wikipedia.org/wiki/Cosmic_Background_Explorer
[3] http://store-xkcd-com.myshopify.com/products/science-works

—

That’s it for this week. I hope you’ve enjoyed today’s episode. And, as an experiment: if you did enjoy it, please suggest subscribing to anyone you know who might be interested in what I write about (and I realise that might be quite hard to categorise).

As ever, I appreciate your notes. Whether they’re just to say that you got something positive today’s newsletter or if you have a point or reaction to anything I’ve written. Or even if you disagree and it’s made you inordinately angry and I’ve induced some sort of rage in you. If it has, I’m sorry about that. I didn’t mean to.

If you’re a recent subscriber, there’s a list of archival links over at http://danhon.com/newsletter.

Best regards,

Dan

Episode Twenty Six: An Alternative; Washing; Users
by danhon

1.0 AN ALTERNATIVE
Yesterday I wrote about the concept of a Very British Startup and in that wonderful sense of synchronicity where people smarter than you do things more eloquently than you with words and stuff, Cameron Koczon published a great article on The Pastry Box project titled Scenes from the Internet[1]. It was a lament at the shutting down of Editorially and a recognition of the refreshingly honest post about why: “Editorially has failed to attract enough users to be sustainable, and we cannot honestly say we have reason to expect that to change.”

Koczon goes on to dissect the narrative behind WhatsApp and patiently explains the job that it is that VCs do. I’ve been on the end of this twice; at the first startup I joined, Mind Candy, before it executed its last-minute saving-throw pivot from (in my view) stupendously early monetised collectible card game/ARG to stupendously successful kids virtual world; and latterly when my brother and I moved on and took angel funding from a pseudo-government VC.

Koczon tries to put it in simple terms. VCs are in the explicit business of betting on huge returns. *Huge*. It’s not for nothing that there’s talk of hockeysticks in growth terms. And let me put it to you like this, if you haven’t been there: do you know what it *feels like* to be on the ascent of a hockey stick? I don’t. I only know what it was like to be aggressively pushed and maneuvered onto the launchpad and to be doused in the accelerant. The goal of the VC is that, amongst its portfolio of companies, there are the one or two that will provide the hundred-x return that will satisfy their fund partners growth rates. Whatever it takes.

VCs as such aren’t villains, as Koczon points out. They’re simply aggressive, monomaniacal dollar-sign copy-pasting machines. You have to hand it to them, they’re pretty direct about what they want.

Now, if you know that’s what you’re getting into, that’s absolutely fine. But, and this is a big but, that’s demonstrably not the only way to a) run a business or b) solve a problem. Sometimes priorities and agendas might line up just so, where a VC and a founding team love each other very much and everyone gets what everyone gets. But, by definition, those goals are pretty lofty.

I don’t know if it’s just a British/American culture thing but there’s (a likely rose-tinted) hobbyist Isambard Kingdom Brunel[2] type of lack of missionary zeal. In my head, I have alarm bells going off and lights flashing when I try to describe him, or the thought of him, as someone who would roll up his sleeves, muck in and get the job done as being distinctly Cameron-esque. But fuck me if there wasn’t a considered carefulness to everything that he did but at the same time an undeniable big-world effect. And all without, again, that missionary zeal of hockey sticking profit motive and talk of markets.

If you’re ever considering dealing with a VC, and you have’t before, just remember this quote from The Bourne Identity: “Look at what they make you give”.

Now, I’m personally attached to the story and journey of BERG because many of the people who work (and have worked there) are close friends. But they are by no means the only example of that very particular British endeavour (and, isn’t there something interesting in characterising a business as an endeavour, rather than a startup?) The force of American narrative around business is so strong that even the Lean Manifesto camp cannot help but be evangelistic about their way of doing things. But what is a quiet way of doing things? Of tinkering around at the edges and not of making the world change through fury and light but through strategic applications of force? It’s this way (and, arguably – and probably a post-rationalisation) that you could explain the success of ARM Holdings, that finally won the great RISC/CISC war and, in the end, may well be the microprocessor architecture that holds sway for the next fifty years as everything irrevocably heads towards being capable of computation. A British company? How strange.

I’m reminded of Stephenson’s clades from The Diamond Age – in that particular case, he was making the point of cultural affiliation being stronger than national – and we don’t need to look much further than our 21cen newsnets to see how the cryptocurrency movement or occupy or open source is reflecting that point for him. But again, Stephenson grafted onto that the Vickys, and a certain fetishisation of their strict moral code. I do wonder if the BERG-alikes are eking out their own post-colonial, humble British version of remaking the world. Only from a tinkerer’s shed.

[1] https://the-pastry-box-project.net/cameron-koczon/2014-february-26
[2] http://en.wikipedia.org/wiki/Isambard_Kingdom_Brunel

2.0 WASHING
My Twitter feed blew up this morning in response to Rachel Coldicutt’s bloody insightful post[1] in response to BERG’s Cloudwash proof-of-concept. Entitled “Domestic Folklore, or Washing Machines for Men” it was so much more helpful to the conversation about what’s interesting about washing machine design than, say, a Medium article about how this one chap needs to call up his mum to decipher fabric care instructions.

And yet.

There’s a stunning point, right at the end of Coldicutt’s second para, where she insightfully cuts to the chase. Whether it’s intended or not, the Cloudwash proof-of-concept *feels like* a washing machine for men, because the demo outlines scenarios that point to this:

“It’s a washing machine for people who don’t know how to use washing machines; who don’t need to wash a wide-range of fabrics, worry about how colourfast material is, or how wet or dry clothes are when you take them out of the machine. It’s a washing machine for people who do bulk washes of jeans and t-shirts and sometimes wash other things.”

It does, not through sexist intent, I’m absolutely sure, feel like a washing machine for people who do bulk washes of jeans and t-shirts – and yes, sometimes other things – which *generally* and without wishing to stereotype, feels like a washing machine for men. On the other hand, it might not – again, not wishing to stereotype – not *feel* like a washing machine for men, to men.

There are a number of things that ended up being explored in conversation on Twitter. Chief of which the disarmingly simple insight by Tom Insam that the “problem” such as it is, isn’t necessarily the washing of clothes. Washing is simply the activity. It’s, as he points out, the care[2] of the clothes. Chucking in any set of clothes at 30 degrees on a normal cycle is, more or less, going to get the clean. But for long-term care and making sure that things don’t change size or bleed or bobble or whatever – that’s why there are different programs, and even why there’s nothing preventing you from washing jeans and t-shirts together to get them clean, if you want them to last longer, you ideally shouldn’t.

It’s interesting because the simple act of picking an object of which the design can be improved has unpacked and illustrated a vast array of issues. None of them are irrelevant, but at the same time (and this is a theme here), they’re all interconnected and depend upon context and nuance. It’s a cop out to say “it depends”, but it turns out that the simple act of washing clothes brings with it a lot of assumptions.

Yes, you can look at specialist domain knowledge being rendered obsolete as orthogonal to being a gender issue. It applies equally to men and women. To be fair, given the state of the world that we live in right now, practically everything has (and probably should) have an awareness of gender if only to deal with the fact that it hasn’t, purely out of habit.

At the same time, every item of clothing these days comes with detailed care instructions. It certainly isn’t outside the capability of man to decide to take the time to look at those instructions and follow them, or even to read a manual (and yes, this does open up the washing manufacturers to better designed machines that make it easier to match care instructions to their interfaces).

Coldicutt says of this: “Like it or not, there’s a Secret Language of Domesticity. In technology terms, it’s the equivalent of “viewing source”: it’s not intentionally secret, it’s just easy to ignore if you’re not interested or don’t understand it.”

Now, to put this another way would be to say that there’s a certain amount of Domestic Infrastructure that, like all infrastructure, is hidden from plain sight. Or, if you want to think about it differently, is easy to ignore, when you want to concentrate on its effects. It’s this view-source of domestic infrastructure, or another way of looking at it, which reveals the underlying complexity. The care of clothes is not simply “bung them all in the washing machine and select a program.” It is, naturally, more nuanced than that. There are reasons why one might care more about one particular thing over another in a particular domestic situation (I have to admit that, for example, in terms of domestic infrastructure I’m more interested in and more motivated to care about wifi signal strength and whether we have adequate coverage and do I need to check out the new Airport base stations), and that’s absolutely fine.

What I guess I’m saying is this: increased visibility to complexity is a good thing, in general. You might not want to deal with it afterwards, but it’s better to understand. Increased visibility into a task or practice or system that has historically reinforced a particular display of gender roles? Even better.

The more I think about it, the more complexity is hidden in a system and only its effects exposed (“I just put dirty clothes in the basket and then they reappear, clean, folded and put away”) the more it’s likely to feel like “magic” and be disempowering. Ultimately, though, like with all magic, it’s not magic at all. It’s just hard work and practice.

[1] http://fabricofthings.wordpress.com/2014/02/27/domestic-folklore-or-washing-machines-for-men/
[2] https://twitter.com/tominsam/status/439095673607446529
—

3.0 FROM THE USERS BACKWARD
I was chatting the other day on the phone with Yoz Grahame, an old friend best described recursively – like a small yoz-shaped object. He had mentioned that his child’s school required a printed, not handwritten record of vaccinations as the latter was ‘too easy to forge’. In a roundabout way, we got onto the subject of government provision of services online – at one level that a friend of a friend had been involved in the Healthcare.gov Bay Area task force to try and untangle the godawful mess and that it was much, much worse than you could possibly imagine (think: dust off, nuke the site from orbit; it’s the only way to be sure).

I feel a bit guilty and self-conscious about pointing toward the UK’s Government Digital Service because a) I know some of them and b) they keep getting attention. The thing is, they’re doing really good work, and in the words of Russell Davies, it’s not necessarily that they’re doing anything particularly *new* or particularly *insightful*, just the fact that they’re actually allowed to get on and do it in the first place. Sometimes it feels like that last observation is the most depressing, that but for humans being humans, we could be so much further along. But I digress.

The thing about the GDS, and tying this all together with the recent zeitgeist and fetishisation for all things Apple and Jobs and design with a capital D, is this: a focus on user needs and working from the user backward. If there is any arena in which the need for thinking from the user backward is apparent, it’s in the arena of politics and the provision of public services to citizens. I’m absolutely self-aware and wanting to not slip into some type of cult-like reverence for the mantras and principles that GDS are laying down, but honestly: when you look at the rhetoric of the formation of the United States – and I’ve been to the Mall at Washington, I’ve been to the Jefferson memorial and watched that video and damn if you don’t tear up at the sheer optimism of We The People and When In The Course Of Human Events. That’s the America that I love, despite it not being the country that birthed me.

So this thing about focusing on the end-user. With my cynical hat on, I see GDS as an opportunistic Conservative government tasked with reducing the size of government seizing “digital” as a chance to reduce cost while retaining delivery. On the other hand, knowing some of the people working at GDS, I see them as seizing the opportunity to rethink and radically improve the experience of service delivery in a once-in-a-lifetime chance. This perfect storm of budgetary political capital with missionary zeal has enabled government to do something that, on both sides of the Atlantic, it’s reluctant to: take the provision and delivery of service in-house instead of contracting out.

I worry that this model doesn’t work for the United States, and/or that the imperatives and values don’t quite sync up yet. There’s a particularly American sensibility about a lack of trust in the federal model and the downright obsessive devolution of power down to the most local level. So while it makes sense, in a way, for federal standards to be set, it’s hard, against a background of states’ rights, to say that Federal.gov gets to set the agenda and to not give states the opportunity or wherewithal to decide upon their own implementation. (That said: one possible get-out is that of the regulation of interstate commerce, which is one area in which states are, or have been, happy to cede some degree of responsibility and authority but which is always trotted out in terms of federal overreach).

That was an aside: the real thing is this. If there is a manifesto for the digital age, it might go something like this: Government For The Users, By The Users. Digital is the excuse to focus on government as service delivery and keeping up its side of the bargain. Policy enacted through code is measurable. This might sound techno-utopian and practically baiting Evgeny Morozov, but I don’t think it is: no one is saying that the code fixes anything, more that:

a) it’s now desirable and tenable to enact policy, ie deliver services through code
b) a focus on service delivery through code requires discipline of thinking – sloppy code doesn’t work
c) the possibility of government emulating the Unix philosophy of being strict in what it emits, but flexible in what it accepts

A focus on delivery (and with GDS appearing to work completely through the stack, from end-user delivery through to the composition of teams that perform that delivery all the way upward to ministerial policy) feels like it removes the opportunity for a lot of wiggle room and ambiguity. Look: do you want everyone to get ID cards or not? Because we’re designing the system that delivers that, and you can’t accidentally forget to service an entire audience when your focus is on the user.

It is hard to see how government can outsource this function of service delivery to third parties. Historically they haven’t been able to provide “good” solutions. Government, especially in the United States, is sensitive to accusations of profligacy but simultaneously to the exposure of risk. So requirements are overengineered and procurement more an exercise in risk reduction than anything else (and procurement is the source of at least ten thousand words worth of its own material). But when you put it to politicians that service delivery is *for the users*, it’s hard to argue that risk reduction be the primary goal against which procurement be measured. Because, ultimately, those politicians are accountable to users in a way that board level management isn’t. In our democracies, there are always alternatives: they might not be different enough, but there’s always the threat of another guy. Even with gerrymandering.

You can argue about *what* services a government should provide to its populace. But once agreed, you cannot argue that they be inaccessible. That sort of thinking leads to losing votes.

The user is, after all, where the rubber hits the road. And a policy doesn’t matter a damn if it’s not usable.

I know there are a number of Code for America and GDS readers subscribed to this newsletter. Is this right? Migursky and Loosemore, I’m looking, pointedly, at you, because now I’m angry.

—

That’s all for Thursday. As ever, please do send me your notes. Although I write this for me – the practice and the discipline of getting my thoughts out every day – I also do it for you and your reactions.

Best regards,

Dan

Episode Twenty Five: Structure; Humble, Direct and Curiously Cautious; The Scale Of Things, Risks
by danhon

Rambling again today, I’m afraid. Do let me know what you think of this one, because it feels somewhat unclearer to me than some of my recent episodes.

1.0 ORGANISING STRUCTURE
I’m still preoccupied with the idea of there being nascent large-scale functional structures on the internet in the same way that neuroscientists study the structure of the human brain and discern individual units (such as they are) of functionality. There’s so much to unpack here: what are the structures that are being built, for starters, never mind for what reason they’re being built by us worker ants.

What other sort of parallels with specieisation, specialisation and evolution are possible in looking at the growth of the network? As we move to distinct services being made available as cloneable code and easy to spin up cloud instances, and defining interfaces for those services (e.g. the trend for *-as-a-service), it’s easy for us to see the “computer vision bit” that gets shunted some data and the “hearing human speech bit” that gets shunted other data. There’s no real co-ordination, no one entity saying “let’s make an internet that understands the world” but instead lots of little sub-problems that are busy being solved for whatever reason (praise the market). Instead of vision systems evolved to detect potential predator threats, like peripheral vision motion detection, we have systems designed to detect trending topics.

We know what kind of structures get produced when biological evolution and replicators are present in a physical environment. Actually, that seems a bit like a silly statement: we don’t know at all. We happen to know a lot of implicit things because we’re the product of that environment. But the type of structures that we’re erecting as infrastructure across the web that bear some sort of macro resemblance to what has been left in our brains are just *weird*. We have bits of brain that are good at detecting edges or faces or decoding the mush of sound that enters ears shaped *just so*, but what are we making computers understand? Bits that recognise “interestingness” in images based on the droppings that we hairless apes leave around them? Bits that that clickstreams and try to work out relationships between them? If we’re the product of a physical embodied intelligence, then if you tell me that you know how to relate to or understand and intelligence that is embodied in the warp and weft of data, I have no idea what you’re on about. I did have a thought about these functional structures not quite yet having reach out into the physical world and realtime feedback as to those actions, but I suppose autonomous drones are bringing that future closer. And also, there’s my physical-instantiation-privilege leaking through, prizing the material world over the one made of data.

So, in that tradition of the lazyweb, I would like this: what are the nascent neurological-analog structures of the internet? Where’s the equivalent of Broca’s region or an off-the-shelf visual cortex? Is the profusion of key-value stores the equivalent of laying down long-term memory? Put it this way: the internet has gone from not being able to recognise faces to being able to do within thirty years. I’m not necessarily a Kurzweil adherent, but you’ve got to admit, that’s not bad going.

2.0 HUMBLE, DIRECT AND CURIOUSLY CAUTIOUS
That’s how Robin Sloan described[1] the team at BERG and the way they announced their latest project, Cloudwash, on how their product, BERG Cloud, could integrate with an off-the-shelf washing machine.

It’s worth watching the Cloudwash video[2]; it’s a particularly British and understated film explaining what might be so compelling about an internet-connected washing machine and the process that goes into designing such an object and one that you could see yourself using in your home.

BERG’s video doesn’t fall into the trope of Jony Ive Explains Things Eagerly In A British Manner, but Sloan has identified something uniquely British and lacking in Valley boosterism in the way that the team at BERG patiently explain what it is they’re trying to achieve, why and how.

In the way that we have a fairly identifiable consensus of what makes a West Coast startup (and I would argue that, in the grand scheme of things, an East Coast startup is practically indistinguishable) I’d love to see some sort of Dogme 95[3]-esque backlash or reaction to the Established Way Of Doing Things that takes it cues from a more British sensibility.

It helps, of course, that the team behind BERG embrace their Britishness, their shop-coats (not lab coats, mind), and their emphasis on Getting Excited and Making Things. Where the Valley stands for hype and overstated rhetoric, it’s instead the British and BERGian way to be self-effacing and humble. Where America built itself the Lean Startup manifesto[4], what sort of manifesto might emerge out of a particular British sensibility of being humble, direct and curiously cautious?

This is not the Britain of empire and colonialism, more a Britain of shop floor tinkerers and engineers who were doing things as hobbyists and accidentally invented entire industries, not out of some sort of copy-and-pasted love of money, but of material and technique and craftsmanship. This isn’t that particular American sensibility of “artisanal” that’s been sprouting lately, but a different kind of retro. It’s an open secret[5] that the name of BERG is a direct reference to the fictional British scientist Quatermass[6] and his British Experimental Rocket Group, and while there are some things to say about the culture at BERG (one could say that it could be a little testosteroney at times), there’s no denying that Messrs Schulze, Webb and Jones forged a distinct atmosphere and culture there, one refreshingly different from the dominant West Coast narrative.

I said on Twitter that one of the irritating things about BERG is that when you see their documentation, they make what they do seem easy, and in implication make everyone else appear to be quite dumb in comparison. One look at the Cloudwash demo product is enough to convince you that yes, there’s actually value in connecting a washing machine to the internet once you sit down and think about it properly. Gruber talked about this in his post about working backwards to the technology[7], and it’s perhaps this aspect that BERG shows: their focus on design and technology in the service of design. On the one hand you could look at a company like BERG and its cloud product positioned as the glue for hardware manufacturers looking to make internet connected products as a solution looking for problems. What BERG have figured out, though, is that no one’s really in the market for a solution that is also looking for problems: and that they have to lead the market to the solutions that BERG Cloud enables. It’s a case of timing (whether good or bad) that the position they’re in is that the best way of doing that is by inventing the products themselves. It used to be the case that BERG would simply do video demos – one criticism of them was that while they were great at design fiction, they were even better at creating shiny videos. Cloudwash is anything but that: a real, physical prototype that works because how else to sell the utility of BERG Cloud the product? It’s this focus on the job-to-be-done, the working back from the problem and illustrating *how* BERG Cloud fits into the solution that’s interesting and in a deep way, at odds with a stereotypical Silicon Valley technology-focussed startup culture.

But: and with a heavy heart, I have to admit, it feels like Britain is the outlier with companies like BERG. The dominant narrative is not one of humility, directness and curious caution. It is instead one of brash optimism and forging ahead – the inventing of technology for technology’s sake. I wish BERG all the best and hope that they aren’t relegated to the role of an externalised, barely paid-for research and development outfit whose ideas can be copied without credit or remuneration by the industries they’re hoping to improve. They deserve better than that.

[1] https://twitter.com/robinsloan/status/438474116551548928
[2] http://blog.bergcloud.com/2014/02/25/cloudwash/ and https://vimeo.com/87522764
[3] http://en.wikipedia.org/wiki/Dogme_95
[4] http://theleanstartup.com
[5] http://berglondon.com/blog/2011/02/21/our-experimental-rockets-are-our-people/
[6] http://en.wikipedia.org/wiki/Bernard_Quatermass
[7] http://daringfireball.net/2014/02/working_backwards

3.0 THE SCALE OF THINGS
The sale of WhatsApp to Facebook brought into public eye the scale of internet companies again. The grammar when looking at consumer internet companies is to speak in DAUs and MAUs – daily and monthly active users – as a proxy for “engagement” and the theoretical maximum ability of a company to monetise that particular audience. It’s interesting to think about what these large numbers mean and imply – not the purchase price – but the user base. So, here is a list of numbers.

Millions

4,700 – Viewers of the 2008 Suer Olympics (watched part of coverage)
1,700 – Servings of Coca-Cola per day
1,460 – Rail network passengers, United Kingdom, yearly
1,358 – Movie theater attendance, United States, yearly
1,351 – Population of China
1,237 – Population of India
1,230 – Facebook monthly active users
815 – Airline passengers, United States
757 – Facebook daily active users
556 – Facebook daily active users, Mobile
530 – Watched the first man on the moon
450 – WhatsApp monthly active users
359 – Theme Park attendance, United States, yearly
313 – Population of the United States
260 – Viewers of the final game of the 2006 Fifa World Cup
254 – Total number of cars in the United States
241 – Twitter monthly active users
198 – Population of Brasil
184 – Twitter monthly active users, Mobile
131 – Sports event attendance, United States, yearly
127 – Population of Japan
116 – Delta Airline passengers, combined system
110 – PlayStation Network users
100 – Minecraft registered accounts
81 – Population of Germany
75 – Instagram daily active users
65 – Steam monthly active users
63 – Population of the United Kingdom
61 – Sina Weibo daily active users
48 – Xbox Live users
48 – Cable subscribers, United States
40 – Netflix global streaming subscribers
38 – Population of the State of California
23 – Population of Australia
21 – Washing machines sales, European Union, yearly
21 – Comcast (pre-Time Warner merger) total subscribers
14 – Population of Shanghai
8 – Washing machines sales, United States, yearly
0.7 – Population of the City of Detroit

(There was a book I had growing up, The Guinness Book of Answers, a sort of printed-out one-volume Wikipedia that had everything from lists of Gods through to scientific units through to geographical information, a sort of CIA factbook on steroids. This list reminds me of that book).

4.0 RISKS
A short last one, this. Since my days at university before the 21st century, I’ve been on-and-off reading the RISKS digest[1], a moderated mailing list highlighting risks to the public in computers and related systems. Between it and Bruce Schneier’s Cryptogram[2], the two mailing lists deftly set out exactly how alarming it is that so much of our lives rely on software that can barely lay claim to the term ‘engineering’. Apple’s iOS and OS X SSL bug brought these two lists to the fore of my attention again, and a discussion with a friend as to the state of Federal computer system procurement (a particular conversation about the particular extent to which healthcare.gov was a cockup – and it’s worse than you can imagine) reminded me that it almost seems like we have a clinical inability to see the complexity in systems. I don’t see it as merely something that’s lacking political will, more something we explicitly decide to pay no attention to. It is not outside the realm of possibility to engineer reliable software: an oft-cited article is They Right The Write Stuff, a Fast Company piece from 1996. In the case of the US government, the interstate highway system instituted in the 1950s established both a standard for the building of national network infrastructure as well as funding. The roads did not break. They carried the traffic. It is strange to me that we do not hold software to the same standard, at least for one reason being that the complexity is hidden behind the veneer of interface. I do not know what it would take for software to be taken seriously.

[1] http://catless.ncl.ac.uk/Risks/
[2] https://www.schneier.com/crypto-gram.html
[3] http://www.fastcompany.com/28121/they-write-right-stuff

—

That’s all for today. Happy Wednesday, and see you tomorrow. As ever, I appreciate notes and replies from you, even if they’re short ones.

Best regards,

Dan

Episode Twenty Four: This Inexplicable Future, Where Did All The Agents Go, Brittle
by danhon

1.0 THIS INEXPLICABLE FUTURE
Every so often, it’s worth taking the time to stop and really look at what’s happening around you. Case in point: yesterday, Mt. Gox a major bitcoin exchange, effectively ceased operations and, by some accounts, “lost” around 700k bitcoins. Stepping back from that, we have a former collectible card game trading site – the Mt. Gox is actually Magic: The Gathering, Online eXchange, run out of Japan faciliating the exchange of a cryptocurrency based on the algorithmically difficult work distributed amongst hundreds of thousands of computers worldwide.

This is *stupendous*. A hobbyist site ended up supporting the birth of a distributed currency (the merits of which are debatable, and are being debated). It’s one thing to see that a sizeable portion of the world (or at least, an influential one) would be sucked in to the mechanics of a card game that involves some sort of trading mechanic. It’s also one thing to see that, in theory, a libertarian-esque anonymous cryptocurrency would find enough favour and attention in today’s networked populace to take off. And that such cryptocurrency in possession of a good following would then find itself in need of an exchange mechanism. But, of course, in the entirely explicable (at this point, you would think we wouldn’t be surprised) world that we live in, of course the intersection between those two sets results in, well, the situation that we have right now.

I wish I had something more insightful to say other than a quip along the lines of “isn’t it interesting how the world keeps surprising us”. There are so many factors at play here; from the crossover of one interest group into other and the fact that an increasingly connected populace allows ideas to spread so quickly and the fact that the code and thinking behind cryptocurrencies, being open, allowed a million clones to bloom. For anyone who thinks the future is going to get less weird, I’m sorry to have to say that that’s just not going to happen.

2. WHERE DID ALL THE AGENTS GO
There were a few things hidden in that Hyperland documentary: one, which we’re all familliar with now, and actually felt like it was the one less touched on, was the promise of the Interconnectedness of All Things, a theme that Adams would visit in his Dirk Gently series of books (and, I note, dirk[1], an early project of Matt Webb, now busy running a pocket universe on the substrate of his grey matter).

The other was that of strong AI, and the one definitely skirted over. Baker exhibited a phenomenal degree of intelligence and understanding, one that, in the guise presented in the programme (a fully conversant interface, and one that could easily pass the Turing test) is clearly unobtainable at the moment. Our conversant interfaces at the moment are bits of black boxes of functionality, word recognition engines hooked up to, at best, general purpose semantic knowledge graphs such as Wolfram Alpha. Siri and Google Now are not, in any way, going to fool us into thinking they are as smart as Baker.

Fred Scharmen wrote to point out that the intelligence that was vested in the agents of our purported future instead was distributed amongst millions or billions of fleshy meat brains, all Chinese-Rooming their way around, in yet another example of an EasyHard problem. It is easy, as it were, for Amazon to mine the purchasing habits of millions of shoppers and to attempt to provide meaningful and serendipitous suggestions as to other things I might want to buy.

Is this instead some mythical hand of the market? Are we ants burrowing around in the material of the internet, leaving behind patterns and traces for machines to obsess over in order to determine our meaning? Because the meaning that we’re able to impart to machines and the understanding they derive from us when we choose to speak to them explicitly are shown only in terms of brittle speech: we must construct, still, our queries just so, from pre-ordained blocks that we have already taught the machines, in order for them to fulfil our query properly.

And what of long-term understanding of our intent? Scharmen saidi that, instead of relying on artificially intelligent software to act as curator and serendipitist, people now perform that service for each other: we do not have agents, we have but ourselves. I don’t think that’s strictly true: as Adams says, we are the ones creating the data and the shapes that we cannot see: it’s the machines that construct the trending topics and are helping to tease out meaning from the streams and feeds based on (admittedly basic) mechanisms of feedback that we have built in. There is not, I don’t think the Amazon equivalent of “people who have read the following on the web also read”, but the way we self-select the networks that we’re part of provides some of that functionality.

Perhaps the exuberance of Adams manifested it in the absolute trust of the algorithm, that the machine would be able to understand us perfectly, when all along it would be a cooperation, of sorts, some sort of symbiosis. This makes me think of the internet as discrete parts; and the possibility that it might, in some misunderstood way, act as a distributed brain. It feels like there are distinct neurological structures embedded on the internet and that at the moment, issues like corporate self-interest have imposed some sort of vicious lobotomy, preventing those structures from implementing cross-talk. Imagine what could happen when the cat-recognising part gets input from the purchase recognition part gets input from the face-recognition part. What’s interesting about the way we’re spreading code on the net is that this intelligence is also getting distributed: as one part learns how to recognise faces, because the substrate that the net runs on is so general-purpose, it is near enough that any part can suddenly also include that dedicated structure.

At the same time, there’s this weird feedback mechanism where the instrumentation that the internet has (and I realise that I’ve digressed way off base from the talk of agents) is dealing with the very bottom of Maslow’s hierarchy of needs and is generating, again through some sort of invisible hand, the type of content it thinks we want, hence all the Five Amazing Secret Tips To Get Rid Of Belly Fat. These algorithmic utterings that are farmed out to writers and then produced – are they not some sort of Chinese Room in and of itself? Would you know if there were some sort of real intelligence behind their production, or are they merely following a bunch of (ill-defined and not particularly clearly articulated) rules?

All this makes me feel that the idea of a singular agent seems increasingly unlikely barring an accidental Giant Leap Forward in the creation of a personality-focussed general intelligence. The internet itself, taken as a whole, with weather recognition bits and fault-tolerant bits and so on, is a much bigger thing, and why would it need a human face, anyway? What sort of bizarre personality would be in front of such strange machinery?

[1] http://dirk.appspot.com

3. BRITTLE
That said, the internet is brittle in the same way that biological life and humans are brittle. Poke a human in the right place, with the right pressure, and it’ll just keel over and die. It turns out that one line of code – in this case, ill-advised lack of braces and yet more proof that Goto be considered harmful – can effectively compromise the equivalent of an immune system. And then when you think about computers and the internet in terms of infrastructure – where’s the equivalent of public health? We talk about anti-virus software, but we don’t treat what’s increasingly turning into critical infrastructure (indeed, invisibly, beneath the notice of the populace) whether it’s actually hooked up to critical services, turning into services that are relied upon, or suborned to produce DDOS against critical services themselves.

Software is brittle, in the same way that humans are. It doesn’t even self-heal. There were (obviously?) no unit tests that caught the OS X and iOS SSL failure, and once in the wild and deployed, end-user systems themselves weren’t able to diagnose themselves in a method of self-reflectivity to notice that something critical “felt wrong”.

—

That’s it for episode 24. I might go watch Robocop tonight. Not sure which one, though.

Best regards,

Dan

Episode Twenty Three: The Difficulty
by danhon

1.0 THE DIFFICULTY
I’m empty, today. Wife and baby are off for a week (possibly longer) trip to see the maternal grandparents, one of whom we’re worried about. I am now catapulted into bachelor land, with a profusion of games consoles, a PS4 I haven’t even plugged in yet, more movies and unfinished games than I know how to watch or play and the weird inkling feeling that I shouldn’t be ordering delivery pizza. Yet.

There are so many things that I want to do: like live-blogging Hyperland or watching through Stealth, Elysium, the Robocop remake, the Total Recall remake, and doing a commentary, or, more honestly, falling asleep for a bit. Everything feels quite disjointed, and it’s not just because the house looks like a 12 month old whirlwind has it it.

This is just a one-off, though. This is what depression can feel like. It might feel like it again, but the new medication that I’m on has taken the edge off, somewhat. It’s hard to explain what it feels like other than a complete emptiness; in one conversation I’ve had with a doctor it’s like looking inside your own head and finding something filling up the space, but that it’s a featureless sphere, impenetrable.

Medication, then. And writing.

2.0 HYPERLAND
With that, then, tonight’s activity: watching Hyperland[1], a 50 minute documentary written by Douglas Adams for the BBC. You can watch along, if you want. It’s important to remember that Hyperland was written in 1990, before any talk of the Information Superhighway; indeed what everyone was excited about at the time was the promise of Multimedia – the mixing together of sound, video and text into some new hitherto impossible whole. If you were a child in the UK in between 1984 and 1986 you likely participated in a nascent, country-wide attempt at producing a multimedia work; the BBC Domesday project[2].

I think it’s important to take a look at Hyperland (and the other historical fiction that we have, that paint a vision of a possible future) if only because it’s interesting to see what our grasp used to be. It feels, and here I recognise that I’m falling into the bias of the Wonderful Yesterday, that we had more fantastic dreams and that instead what we have now is some sort of worldwide crisis of lack of imagination. Was it because our reach exceeded our grasp, and now we’re able to simply produce what we had dreamed of grasping when we were younger?

Hyperland opens on a slumbering Adams, recollecting a dream that he had to get rid of his television: “I dreamt just to get rid of the thing. I thought, there must be a better way of spending my time, like walking to the nearest scrap heap and throwing the wretched object away.”

We see the power of television: of Margaret Thatcher showing how television can be so selective in the alluring images it presents to us while we pan up to yet another television in the scrap heap showing soft-core porn. The multitude of content that television offers, from an evangelical preacher to a documentary about breadmaking. And, of course, advertising. Adams is perplexed at this: “It seems such a waste of technology.”

“Maybe, in the future, we’ll find a better use to put it all to.” – and we cue dream sequence music with the strumming harp.

This is a familiar refrain. The potential of technology – and what Adams was seeing was the power of the image and its might in broadcasting singular images; nation speaking unto nation. Surely, there are those who ask, we can do better than this?

As we skip into the future, Adams sees news broadcasts of Japan pegging the Yen to the Dollar in exchange for California (we need only substitute China), and that the effects of Global Warming are finally becoming apparent (well, we all know about that). But, as Tom Baker interrupts, surely he is tired of linear, non-interactive television.

Baker asks whether Adams is tired of a television that sort of happens to you, that doesn’t involve you. And for us now, the familiar strike of lean-back versus lean-forward entertainment, of passive versus participatory content. Of user choice.

“My name is Tom,” he proclaims, “and I’m your agent.”

Ah, agents. We had such dreams for these personifications of algorithms in the belief that people would find it easier to act with a simulacra of a human being than with, well, rawly exposed user interface controls. The truth as it turns out, nearly twenty five years later, is somewhere in between. Now we have virtual assistants at airports, instructing us on how to dispose of our excess liquid goods, but every day, millions – billions – of people interact with something more like a command line prompt when they type their questions into Google’s maw.

As an Agent, Baker explains, he’s here to do Adams’ every slightest bidding. To fetch, carry, work tirelessly all on Adams’ behalf, always ready, always willing. An artificial and completely customisable personality, a software application running on his computer, providing instant access to any digital information existing in the world anywhere – or, what we would refer to as “on the internet”.

“Is there anything I can do for you now, Mr. Adams, sir?”
“Well yes, you can stop being so obsequious for a start.”

Now we’re presented with Baker’s control panel, which materialises around him. The thought that people would care as much about the *how* information is presented to them as opposed to its accuracy or timeliness (or, if in this particular imagined future, all information retrieved is correct and timely, all that matters left is the manner in which it’s presented) is interesting. We do not have, at the moment, this level of customisation in our interaction with services like Google Now or Siri. What we do have, instead of a curt/servile slider to adjust “manner” is, in some cases, some degree of control over tone of voice, but normally even this is added as an afterthought. Facebook still has, as language options, English (Pirate) and English (Upside Down), and on Google there used to be vestiges of such a sense of humour in the ability to browse the site in Pig Latin. But, as a rule, tone of voice is one-size fits all, and this has as much to do with the hard AI problem of natural language processing as it does will (how many writers does Apple employ for Siri, anyway?) Indeed Siri’s personality has come under fire for having enough of a point of view to make her unique.

All of the control panel options that Adams plays with are within the realm of current feasibility – they just require a big enough team of 3D modellers and texture artists for the dress and species/3D rendering options but as always, it comes down to the uncanny valley of actual user interaction through speech. I’m not sure what the state of the art is in accurately reproducing accents, but let’s just say I’m assuming a large number of voice talent artists would be required to build up the phoneme database or whatever.

(It’s here that we encounter our first application error and crash in a manner reminiscent of Mac OS 7’s Bomb, and the usual promise that the next version of the software will be more reliable. It may have been 1990, but it looks like that particular trope of the software industry had by then been incredibly well established.)

Baker then presents to us a crash-course in the history of hypertext, covering Vannevar Bush, Ted Nelson, the MIT Media Lab and the Multimedia Lab in San Francisco, then Robert Abel.

It’s the agent aspect of Hyperland that continues to stand out at this point. You have a sufficiently Turing-fooling avatar that Adams is able to converse with, a piece of software that can do natural language recognition as well as speech, summarise information about the subject of hypertext, pick out the most influential people in its evolution as a mode of communication and also talk reflexively about itself. It can also, Librarian-from-Snow Crash-style, take conversation forks and handle interruptions and then return seamlessly.

It’s interesting that one of the hallmarks of the future of interaction with information would require so much personalisation and assistance. As if humans would not be able to navigate such data on their own (arguably, we cannot), but that we would require instead a fake persona, one that we could converse with as if we would another human, to help us understand and navigate. One wonders if this is a particularly paternalistic view of how we need to experience the mass of information out there, rather than a more libertarian have-at-it attitude.

Here we digress as Adams asks why there are moving icons on the screen – Baker explains they’re “micons”, invented by Hans Peter Brandmo at MIT in 1989, essentially anchored animated gifs and we’re whisked off into demo land where a micon of Ted Nelson appears on top of Hans’ video interview and Adams taps it to jump to a video interview.

Adams asks how to go back – something we all asked when confronted with hypertext for the first time – and Baker quips that one could ask him, or instead tap the ‘go back’ button, which “looks like a minimalist fish hook.”

Adams complains that he’s “completely lost” and after a conversation with Baker, Baker provides a “guide” and they start at the beginning, with Nelson explaining the work of Bush. The “completely lost” and “guide” nature is familiar too: those who aren’t familiar with the internet can describe themselves as overwhelmed, and many of our first interactions with the net were through directory sites like Yahoo! and other editorial like the NCSA Site of the Day. When you could travel anywhere, view anything, and it was all at your behest, where would you start?

Nelson introduces us to Bush’s Memex through more video. At this point, and this is purely an artefact of this being a documentary made for television and the format of the documentary being video, as Nelson is speaking, various micons pop up (microfilm, for example, pops up as he explains that the Memex acts as a front-end for a store of information), it’s worth point out that there’s a degree of authorship on show in Adams’ demo. Because there’s no text, as such (and one would instead imagine that if Hyperland were an actual application instead of a film, then the subtitled text would itself be hyperlinked) it appears that there’s only limited user choice: editorial choices are made at opportune moments to introduce the reader to other concepts (an alternate explanation, though, would be that Baker himself as agent is injecting relevant micons into the video stream as Adams is watching, based on what Baker assumes or knows to be Adams’ level of knowledge about the topic. Seeing as we’re already practically envisaging strong AI, we may as well.)

Nelson remarks that Englebart (inventor of word processing and the mouse) was probably influenced by the idea of the Memex.

Adams then interrupts and asks for Baker to come back, and points out that he had been watching video of Brandmo, but now there appears to be a Ted Nelson strand running through everything (isn’t there always). He asks Baker: “Does it all interconnect?”

“Absolutely! The system is constantly at work in the background sifting its data for connections. Every time you start something, I start to line up other things that you might want to see.”

And again, we’re at a curiously different envisioning of hypertext and hypermedia, one mediated by impressively intelligent agents doing our bidding that are able to understand not only our intent, but, by implication, the semantic content of every piece of digital information on the world’s networks. It’s worth it to point out that the links between concepts in Adams’ future aren’t static as they are on our world wide web, they aren’t necessarily manually encoded as humans would do on Wikipedia. They emerge, agent-backed, from an innate understanding of the knowledge embedded in the system. It’s not clear how the agents would do this, but it implies a strong ability of natural language processing and meaning to understand how different concepts interrelate.

Adams starts Baker off on a query about “the Atlantic”. Baker throws up Ecology, Oceanography, Shipping, a Live Feed and Literature, all represented as micons. In contrast, Wikipedia will throw up the article for the Atlantic Ocean which covers subjects such as geography, cultural significance, ocean floor, water characteristics, climate, history, economy, terrain, environmental issues, bordering countries and major ports and harbours.

Adams taps on the Live Feed and up pop micons for the Labrador Basin and the Azores-Gibraltar Ridge. Adams expresses incredulity that he could actually access live video data from submersibles via satellite. On Literature, up pop micons for Coleridge, Melville, Conrad, Hemingway, CS Forrester and More…

And then, upon tapping Coleridge, micons for Critical History, Drugs, The Rime of the Ancient Mariner and Other Works. Adams taps on Other Works, and from then, Kubla Khan. But then Ted Nelson turns up, and Adams asks why.

Baker remarks that he “likes to arrange meaningful coincidences, and this is quite a good one.” The idea that an agent would engineer serendipity is in fact one that we *do* have: all the way back to Flickr and its interesting photos page and the intent behind Dopplr to help engineer serendipitous connections between travelers. This serendipity is now engineered in other ways where it’s not necessarily presented as serendipity or meaningful coincidence, but instead as something where the utility is far more stark: Jobs You Might Be Interested In, for example, or Other People Also Purchased. It’s not too hard to imagine a future where Google or another company with lots of access to browsing data starts providing recommendations for content, Stumbleupon-style, in a truly mass manner.

Nelson then takes us through “that unifying world” of anyone being able to add documents to a central repository, accessible through telephone, laser beam or satellite, it would have to be available to everyone, everywhere. And because of literary tradition, he calls it Xanadu. And as we cut back to Baker reading the text of the poem as it scrolls by on screen, Adams taps words for definitions and phrases for explanation.

Baker then shows Adams a piano roll of Bach’s fugue in C Minor that Adams fails to recognise until its played, and Adams supposes that such a system, one that is good at recognising shapes and dealing with music, could also be good at teaching music and unearthing the patterns that are hidden beneath the surface.

Now we see Robert Winter’s interpretation of Beethoven’s Ninth Symphony in a demo of an early multimedia application published by The Voyager Company in 1989, which, seeing as it’s a real application that shipped, isn’t one that I feel we can learn particularly much from as it’s an example of the promise of multimedia applied and can draw a direct line from Robert Winter’s CD-ROM all the way through to something like The Orchestra on the iPad[3]. In a way, it’s disappointing to see that conventions set down in 1989 still hold strong and that there haven’t been other, more successful ways of presenting music.

When we come back, Adams is musing on the fact that once information is digitised, it’s easy for computers to see shapes and patterns in the data that’s been collected. Baker races ahead when Adams mentions Vonnegut and, mentioning that he’d scanned all of Vonnegut’s work, found a piece of writing about shapes in stories that he presupposed Adams was going to mention in an “I’m Feeling Lucky”, or autocomplete-y kind of way. Again, because Baker is a personified agent, his interruption feels more of, well, an interruption, rather than the UI trope now of autocomplete-as-you-type being the similar hovering over your shoulder as you think, but the conversational nature intrudes more.

What Baker does here is interesting and points more to his fantastical intelligence. Assuming (correctly) that Adams had just spotted a link between the ability of a computer to identify patterns and Vonnegut’s theory that stories may be graphed on a good/ill fortune y-axis and that time progressed through plot be, well, plotted on the x-axis, Baker barrels on and outlines how a plot from Nelson Rockefeller’s life, EastEnders or a bag lady’s might fit in to Vonnegut’s graph, before moving on to mapping various creation myths on to Vonnegut’s graph, too and showing how they exhibit similar shapes.

There’s a bit of irritation I have with Baker’s personality here, almost as if he’s Hypersplaining – so eager to teach and to explain things to Adams, it’s as if Adam is unable to get a word in edgeways (which, this being a documentary written by Adams, is clearly by design).

We then progress through a Google Image Search-esque search based upon Baker agreeing with Adams’s supposition that seeing as all digital information is just shapes, computers can look for them pretty easily, and off we go on a trapezoid hunt before landing back at Picasso’s Guernica (and by extension, Bob Abel’s Picasso’s Guernica, of which we experience a demo).

What’s striking, looking now at what must have been so exciting about multimedia, was that it was simply a new way of packaging and providing an accessible reference to a particular subject or piece of information. While the Beethoven’s Ninth example allows us to jump around and explore different parts of the score visually, the Guernica example seems to mainly consist of a number of video interviews of interesting sources related to the material. Sure, there’s user choice here in that the editorial journey is chosen by the user rather than a tv programme editor, but perhaps that’s 25 years of cynicism leaking in at me toward the experience of, well, Yet Another Multimedia CD-ROM. Certainly, the fact that this information is now more accessible rather than not at all, is a major step forward, but there’s something distinct about the way self-contained information is presented on these CD-ROMs versus network, hyperlinked information. CD-ROMs of those types ended up feeling like particularly dense TV shows with chapter marks, and not necessarily as big a deal as fundamental interconnectivity and user-initiated publishing.

Abel finishes up by cueing up a 90 second film clip of “what you, as a user” might be able to experience if you took your own version of Guernica. And that would certainly be an interesting thought indeed, if the rights to the material on the CD enabled remixing and republishing. But as we know with the benefit of hindsight, that rarely happened – and again, we’re dealing with an edited package of audiovisual content.

Adams muses that if this type of experience is to be understood properly, a new grammar or language needs to be invented to allow people to deal with it. Baker uses examples from the language of the moving image – jump cuts, zooms, pans, etc. – and it still feels, unlikely as it is, that we are as far away from a grammar of interaction despite our best efforts to catalogue it and design for it, in chief because software is so malleable.

The Multimedia Lab then takes us through a backgrounder in Multimedia – how it’s a new medium and how they’re dealing with creating and experimenting with the grammar for it. About how multimedia allows you to “bounce around” and compare different points of view, which strikes me not necessarily as a particular aspect of multimedia itself, but again, more of hypertext. In a somewhat prophetic comment, one of the researchers mentions how an audience involved in a particular drama might want to find out more about it, and would embark on their own idiosyncratic path to find out more background information, which happily describes anyone who’s ever fallen down the rabbit hole of a JJ Abrams story.

We’re taken through a demo of Life Story, a multimedia version of a BBC dramatisation of the discovery of the structure of DNA by Watson and Crick, and again we see this interesting assumption that people would pause one task and then operate on another – watch a bit of video, then do a bit of interaction. Maybe it was because the true impact of Moore’s Law hadn’t hit home yet, but in twenty five year’s time, computing power would be so cheap and accessible that you could sit in front of your TV and have it streaming video in the background *whilst* you purposely paid attention to the second computing device in your hand. In this case, the research project of Life Story is essentially chapter marks and navigation for a bunch of linear video, which then pauses and adds context. The researcher cutely talks about each screen (ie tapping on the links section from the transcript) as a “new pamphlet of information” that would teach the viewer about DNA.

Our next demo is children playing with Amanda Goodenough’s Inigo Gets Out, “a form of interactive storytelling,” a Hypercard stack being played with where areas on the screen are hot-clickable. Inigo Gets Out is instantly recongisable as being somewhat like a graphical point-and-click adventure game, albeit, in story format, and its ultimate progeny is that of the kids iPad book with directly manipulable areas. Goodenough raises the valid point that you may well have branching storylines that converge on the same ending (which you pretty much have to do unless you’re the kind of person who has figured out how to deal with the combinatorial explosion involved in producing branching narrative) but if the branches themselves that lead to the same ending are satisfying stories in their own right, then that’s perfectly fine. This is pretty much the only (and entire) problem I have with such choice-based branching interactive stories: it’s hard enough to write one good story, never mind fifty. Or even ten.

We then skip over to Brad deGraf and Michael Wahrman talking about digital puppetry, and anything historical to do with realtime computer graphics is always going to seem amusing in hindsight. They say, though, that they had “too-realistic” human faces in their rendering and that they had to dial it back so as not to confuse people, which just makes me wonder if they hadn’t instead fallen unintentionally into the uncanny valley. Scarily, one of them suggests that the rendered faces could be truly obnoxious and your fridge could moan at you if you wandered into the kitchen and didn’t pay attention to it, and it would try to attract your attention. Though it’s possible this segment was merely baiting the Sirius Cybernetics Corporation.

And finally, we see a NASA prototype virtual reality display from AMES called Cyberiad, and one of the reasons why I thought it would be fun to take a look at Hyperland again. Because with things like Oculus Rift and Facetime echoing Tom Selleck’s You Will narration that I would tuck my baby in at night from a phone booth (close), it feels like we are finally managing to reach the grasp we sold ourselves in the early 90s. Just in a different way.

We had all of these ideas that had been brought to life in so many different, yet ham-fisted ways. We had a nascent worldwide communications network, first in ARPA and at the same time in BBSes, then, in Usenet and Telnet and Gopher, then in the web, then somewhat persistent but slow connectivity, and now persistent, fast, mobile connectivity in our pockets. It turned out that we could imagine all of those things and that now, in their mundanity, we’re able to bring to life what we were excited about twenty five years ago. How then, do we make what was new and exciting (but inaccessible) twenty five years ago, new and exciting again? Because it should be. The fact that we can communicate, practically for free, with so many people around the world, that we can publish, that we can interact, in so many different ways and in different contexts should be amazing. And, because we are human, we do it in as many ways as we are human, and in all the boring and mundane ways.

The fear, as summed up at the end of the programme, is that all this technology and virtual reality would remove people from ‘real reality’. And that was before we even had this stuff in our pockets. Adams moves the time-slider up to 2005, doffs a 2005 BBC virtual reality cap, and off we are again into a Gibsonian chrome-textured matrix.

—

This was a bit of a different one. Something akin to thoughts smattered in amongst a transcript. I really can’t emphasise how much of an influence Douglas Adams was upon my formative years. Hyperland occupies a special place in my memory not only because of Adams mark on it, but because it led to a future that I wanted to see and that I wanted to become real. I’ll leave for tomorrow thoughts on where, exactly, agents like Baker disappeared to.

[1] https://vimeo.com/72501076 and http://en.wikipedia.org/wiki/Hyperland
[2] http://en.wikipedia.org/wiki/BBC_Domesday_Project
[3] https://itunes.apple.com/us/app/the-orchestra/id560078788?mt=8


Episode Twenty Two: Infrastructure, The LCARS App Store
by danhon

This one is more of a free-association one. And a short one.

1.0 INFRASTRUCTURE
Here’s one reckon I just had (yes, another one, you can add it to the pile that everyone else has had) about WhatsApp and the reaction to its purchase: humans are good at *surface*. We have lots of things like neural structure for recognising surface level features like faces, or edges, or inertia or top-level physical properties of the world. So for most of us, WhatsApp is what it presents: a messaging application that runs on a (smart)phone. But the real value in WhatsApp was the infrastructure behind it: the invisible mechanism that transports a godawful number of messages worldwide and routes them, seamlessly. That is potentially worth about nineteen billion dollars — especially when you think about mobile messaging in the previously-known-only-as-SMS and the value and economy it generated.

So: all this talk about posthumanism and mind uploading is interesting – in particular, Rameez Naam’s rebuttal of what you might call the Cult of Singularity[1] – but what got me thinking was: what are the neural structures that would be particularly beneficial to a post-human? What sort of things would it be great to have unconscious recognition of? You wouldn’t even have to *look*, for example, to understand the infrastructure behind a particular network, you would just *know*, at some sort of atavistic level. Or what would a neural structure devoted to recognising the implications and rules behind network or graph theory imply? How might you hack together those types of brain structures?

It feels like it’s this type of lack of instinctual understanding of that prevents us from dealing with long-term existential threats. The things that threaten us now include complex, interdependent webs of infrastructure creating outcomes that we don’t foresee, or include outside context events like a giant rock coming down upon is that will *require* complex, interdependent webs of infrastructure and the rapid design and implementation of those webs. When we can now produce mathematical proofs that we can’t understand and indeed financial trading instruments that are essentially black boxes, what type of human augmentation is needed to deal with the present, nevermind the future?

As ever, Ted Chiang’s already written a story about how this might *feel* – if you haven’t read his short story Understand, I highly recommend it[2].

[1] http://www.antipope.org/charlie/blog-static/2014/02/the-singularity-is-further-tha.html
[2] http://infinityplus.co.uk/stories/under.htm

2.0 THE LCARS APP STORE
The whole Star Trek: TNG computing infrastructure universe continues to dwell on my mind. When Geordi and Data invent a new way of inverting the positronic emissions in the deflector dish to close a dangerous subspace eruption, what exactly happens? Do they have to call up Starfleet Engineering HQ to get at the firmware of the deflector? Does Geordi have to turn off the deflector to flash it and they kind of have to stop the engines and come to relative dead stop while the deflector reboots? In our mundane future, does the deflector dish subsystem actually run a tiny embedded ftp server and Geordi has to upload a new binary firmware to it, and then wait while it grabs a new DHCP address from the Main Computer? And then after that, does Geordi (or, more probably, Data, because no one likes writing documentation) write some documentation for the firmware diffs for the deflector and then push them upstream to Starfleet Engineering’s Github repo and then they get merged in and then on Patch Tuesday Starfleet pushes out a bunch of updates? Is part of Engineering’s job basically going around all of the ship’s systems and looking at those little red badges with numbers in them and then going: oh, looks like we need to install a system update on the environmental systems today to improve O2 efficiency? In fact, if there is a Starfleet Engineering repo on Github, is that how they recruit engineers into the Academy? Look at who’s contributed the most to Starfleet projects? Or, has the consumerisation of IT finally reached the 24th Century and when you’re a brand new Ensign with your newly-issued PADD, do you head into the Starfleet App Store and go put on your favourite messaging apps? Does Data publish apps in the store? Also, charts! How do you discover what app you might want to install on your brand new Warp Core? Is the model of Data and Geordi the logical conclusion of Dev/Ops, writing functionality on the fly, inside a mission envelope, and then deploying it? Are they an effective team? Does Data even write code? Does anyone in Starfleet write code? Does everyone in the Federation Know how to Code?

So many questions. It’s this kind of thing that you need an updated technical manual for.[1]

[1] http://www.amazon.com/Star-Trek-The-Next-Generation/dp/0671704273

3.0 TANGO DOWN
Google’s Tango[1] project has me giddily excited, not least of which because it marks the return to public eye of Johnny Lee Chung[2] at Google’s new Advanced Technology and Projects (ATAP)[3] group.

The telling sentence in Tango’s writeup for me is this: “The goal of Project Tango is to give mobile devices a human-scale understanding of space and motion.” because a lot of people seem to have gotten caught up in the various demos and videos of the hardware that currently exist. What the goal sounds like is being able to give mobile computing devices the sense of proprioception to increase their situational awareness, another step toward embodied computing with more context. It’s not necessarily about Google being able to map the inside of your house and retaining that data (that feels to me the absolute bottom layer), but more what that knowledge enables the device that you’re carrying to do. There’s a whole lot of implicit information that we process in terms of our interactions with the world that are dealt with on a purely subconcious level – things like how fast we’re moving and where we’re moving just in terms of our limbs and how we understand where we are in 3D space and what our relation in that space is to other objects.

(As an aside, it’s interesting that part of the way that we’re designing computers to see actually meshes with the way children think *we* see. There’s this thing, the emission theory of sight, which is where our eyes reach out into the world and paint it into being. Which is pretty much what IR depth cameras like the Kinect do, spraying a pseudorandom dot grid out into the world at frequencies that aren’t visible to us, bathing the world in little photonic tentacles that reflect back and describe the shape of the world to them. Our eyes don’t see like that, of course, we don’t emit anything and merely receive reflected photons on our retina. But isn’t it interesting how we’re solving the problem for the intelligence we’re creating.)

[1] http://www.google.com/atap/projecttango/
[2] http://johnnylee.net
[3] https://plus.google.com/115422404677762786098/posts/JiHGWs3UrJS

4.0 RANDOM THOUGHTS
One: the on-purpose infection of individuals with parasites for the creation of superhumans, or: has anyone rebooted Catwoman’s origin story with her being created by a union with toxoplasmosis yet?

Two: Dan Simmons’ Ilium/Olympos series of novels has a somewhat throwaway reference to a pervasive instrumentation and communications network that covered all living things, some sort of networked Gaia. So here’s a realtime forest map[1].

[1] http://www.globalforestwatch.org/map

—

It’s Friday – have a good weekend. Some of you have probably already finished work for the day. Good for you.

See you all on Monday,

Dan

Episode Twenty One: Net-Native Storytelling, Selling The Future, Always On
by danhon

1.0 NET-NATIVE STORYTELLING
Paul Rissen[1] (and I’m struggling to find a way to deal with this in writing without feeling like I’m a DJ with a call-in talk radio show) asked if I had any further reckons about the whole Marvel Universe API and the weak signal of Irrational Games’ implosion.

I have a shtick of why and what I’m interested in about internet native storytelling. It mainly stems from the holy-shit moment of The Beast, one of the first Alternate Reality Games, back in 2001, where great writing (thanks, Sean Stewart), met great game design (thanks, Elan Lee) and an almost creepy knowledge of how to use the internet as a storytelling medium, as opposed to a transport mechanism.

(For those unclear: YouTube is more transport mechanism than medium, its benefit is mainly in enabling distribution of video to audience, the trappings of interactivity that it does have are baubles around the edges; whereas the internet *itself* enables storytelling of a qualitatively different types).

The defining characteristic of the Internet that we have today is the link. We’re maybe, just maybe, post-link with the world of practically balkanised mostly hermetically sealed app experiences on mobile, but for the most part, hypertext has won. Things, as it were, connect to other things.

It’s those connections that are so interesting and that enable a lot of what makes the internet so great. There were two talks that I think attacked the same subject but from different angles at last year’s XOXO: the first from Evan Williams[2] who perhaps has single-handedly, no matter how much Dave Winer may protest, been at the centre of enabling people put things that link to other things on the internet. The second was Mike Rugnetta’s[3] about, well, the entire internet and culture. You should watch them, because they really are very good, but if you want to watch only one, then I’d recommend Mike’s.

So. Links. Links are what makes the internet the internet.

And, if there were a thing, that was *really* *really* “the internet”, then I would have a hard time coming up with something better than the wiki, which is essentially nothing more than just a giant ball of links compressed together under a single namespace and even lets you put your own things that other things can link to in it! If you want!

Look, here’s a pop-psychology reference for me to throw in to prove a point without any real citation in some sort of Malcolm Gladwell-alike impression: you know that feeling of Flow? I get it when I fall into tvtropes[4]. I just click from article to article, endlessly exploring a maze of twisty passages, all alike in terms of textual content being injected into my brain through my eyeballs.

But, unlike linear fiction, and because of the link, the path that I take can be unique to me. I still have an entire fictional universe that I can explore, and that universe need not be, in the way that Wikis are currently, limited to mainly textual content. There’s been, I reckon, a preoccupation with the editing side of the Wiki, as opposed to the consumption side. What does it look like when a work of fiction is created by an author as a wiki and then experienced as one? Can that be episodic? When the emphasis is on the act of aimlessly traveling through a morass of universe? It feels like there’s something epistolaric about it: because, a navigated series of documents.

Let me also be clear that I don’t mean some sort of choose-your-own adventure “interactive” wiki-novel. For a variety of reasons, that would be dumb. More that there can exist an authored text with a defined event of beginning, middle and end where the reader explores it non-linearly without affecting the plot. It would be as if someone had written something like World War Z and just dumped it on your desk, out of order, and you had to piece together the universe story.

The counterargument to something like this is: gosh, that sounds like an awful lot of work. And compared to consuming regular linear media, yes, it is. But then so is spending time trawling through TVTropes, and that’s why I invoked pop-psychology favourite Flow, earlier. Because if you have a Flow card in your hand then you can play it any time and it trumps any other argument someone may have, so there.

All this is to say that I remain excited about the possibilities of the Marvel Universe API. Because once you have an API, you have Things and when you have Things, they can link to other Things and Operations can be performed upon those Things to Transform them and before you know it you have more Things. The API, and this really is off-the-top-of-my-head-reckoning is, in a fiction sense, providing you with ready made entities that can be played with. Sure, you could build Marvel Universe Reference Guides and all that stuff, but that’s not as fun as making your own splinter universe and *still* be able to have it all tie together (individual instances of parent entity objects retain their relationships, right? So you can use your entity as a point of reference and use it to pivot around different universes. Duh.)

[1] https://twitter.com/r4isstatic/status/435920387990622209
[2] http://www.youtube.com/watch?v=zR1xDBFdRZ0
[3] http://www.youtube.com/watch?v=-D9Xq3Xr8aE
[4] http://tvtropes.org/pmwiki/pmwiki.php/Main/HomePage

2.0 SELLING THE FUTURE
I had a piece brewing in Medium for a while that just kind of petered out, so as an experiment, I’m trying to rewrite it here in a shorter and more concise manner. So, here are the things that caught my attention:

Item one: 23AndMe’s first TV commercial[1]. Check out the motion graphics and the structure that they use to portray information. They say we’re from the Future and we’re here Now!

Item two: Oh right, that reminds me exactly of the kind of stuff you see in Children of Men[2].

Item three: In fact, there’s an entire visual shorthand for selling the future and portraying the future that’s been developed in film and television over the past few decades. One good place to see that is at the Typeset In The Future blog[3].

The thing here is that the future that was always a few years away, and that we’ve been exposed to on film and in fiction, is tentatively touchable. Nest, with Google behind it, will surely embark on an advertising campaign for Smart Home Appliances. Ads featuring a pseudo-intelligent, voiced personal assistant are now an actual real thing, and not the kind of thing that you see comped in through some motion graphics in a Tom Cruise SF thriller.

One of the reasons why Spike Jonze’s vision of the future in Her is so – in a way, alluring, if not technically accurate – is that the guy cut his chops in the advertising world. He was, we should remember, the guy who anthropomorphised an IKEA lamp to us[4]. In short, Jonze knows how to sell.

So here’s the thing: advertising has already anthropomorphised things. Advertising already knows how to tweak your heart strings and show you that P&G Winter Olympics ad that will have you bawling, hands down, within thirty seconds. Because they – we – have this thing down to an *art*.

Now, in a very short amount of time, all of that machinery is going to be brought to bear on selling you the stuff you thought was in the future. If software is eating the world, and software’s going to be powering all the formerly dumb things we’ve had in it, then you can be sure that those physical things with software are going to be advertised, in a way, to you. Where this gets even more interesting is that the advertising is going to have to *explain* what these things do. Why you should have a thing in your home that is connected to the network and can talk to you. And, well, explaining outbreaks of the future to people? That’s going to be pretty cool.

[1] http://www.youtube.com/watch?v=h83n6V7q7S4 – not on 23AndMe’s YouTube channel because the FDA is preventing sporadic outbreaks of future until they’ve been fully investigated.
[2] https://vimeo.com/37658689 – gorgeous work from Foreign Office.
[3] http://typesetinthefuture.com – prepare to nerd out.
[4] http://www.youtube.com/watch?v=dBqhIVyfsRg

3.0 ALWAYS ON, SLIGHTLY SLOW
Matt Locke wrote in with the caveat that Always On doesn’t mean Always Available: this makes sense with teens and children, who have less control over their time than adults do (in theory, right? I mean, I know who has control over my time and it isn’t necessarily me and it more begins with a M and ends with an icrosoft Outlook Meeting Request). Now, what I’d probably do is point at someone who actually knows what they’re talking about, like danah boyd[1], in terms of real behaviour of teens and how they treat persistent connectivity.

My gut instinct, which also feels like a somewhat wrong reckon, is that people who’ve grown up with persistent connectivity have roughly the same amount of stress (ie not a significant difference or reduction) and anxiety in terms of being overwhelmed with a deluge of incoming information. I do wonder if there’s enough of an audience for an equivalent to the slow-food movement (which is, kind of, something that the long read trend is addressing.

A lot of the reaction that I saw to the new Facebook Paper app was about how the infinite vertical scroll method of displaying News Feed items was “more efficient”, which speaks directly to the way those particular people saw the task of checking a stream – a list of items that must each be evaluated, quickly, before moving onto the next because the stream is never-ending. But there are different types of feeds and streams: in particular, Twitter’s more ephemeral version places less pressure and grants permission (if not explicitly but implicitly) to miss items in the stream. Facebook, with its algorithm, places the burden upon itself to determine what the “most important” and relevant information might be.

So what does a slow, or rate-limited feed look like? (Extra credit for identifying a business model behind it, too)

[1] http://www.danah.org

4.0 FOLLOW-UPS
Matthaeus Krenn posted a concept for a new car user interface[1] – I last talked about cars in episodes twelve and thirteen[2] which looks pretty interesting, mainly for its initial concept of you-don’t-have-to-look-just-put-your-fingers-anywhere on a touchscreen. I see some problems with it (lack of glanceable information, for example) and wonder about the cognitive overhead of having to remember whether I need to use two, three or however many fingers to operate a control and how far apart they have to be in the absence of visual feedback. That’s the thing about physical controls: you can kind of see how you need to, or can, use them, and it feels like there are a bunch of Everyday Thing Norman-type affordances that have been lost.

[1] http://matthaeuskrenn.com/new-car-ui/
[2] http://tinyletter.com/danhon/letters/episode-twelve-attention-star-trek-and-cars and http://tinyletter.com/danhon/letters/episode-thirteen-the-auto-show-learning-to-code-and-niggling-thoughts

—

Alright! Episode 21 is over. You should all go and watch The Lego Movie now.

See you tomorrow,

Dan


Episode Twenty: Literal Tone Of Voice, Presence, Networks, Applescript
by danhon

1. LITERAL TONE OF VOICE
If you’re British and use Siri, then you’ve probably heard the plummy tones of, well, I can’t describe it in any way other than British Siri Wanker. So in terms of designing a service, here’s a whole (not necessarily new, but deep domain) area that is suddenly becoming more relevant. Time was, you’d kind of laugh about Brian Eno designing the aural identity for Microsoft Windows, but, here are the super dumb things that I put to you:

a) For a certain group of people, hearing British Siri makes them want to punch British Siri in the face, no matter how useful he may be;
b) Samantha, in Spike Jonze’s Her is voiced by Scarlett Johansson;
c) JARVIS in the Marvel Cinematic Universe is voiced by Paul Bettany being an English Butler;
d) The Computer in Star Trek: The Next Generation is voiced by Majel Barrett in somewhat haughty BDSM mode; and
e) Sigourney Weaver in Galaxy Quest.

The super arbitrary, base-level insight thing that I’m going to pull out of this is: hey, voice casting matters! And for all the strides that have been made in terms of attention being paid to copywriting (and the inevitable wrong lessons being learned, or being followed blindly, cargo-cult fashion from standouts in the field like Innocent and Flickr) and (again) GDS in maintaining that Writing Is Design, if we’re talking about conversational interfaces (ha) then we’re also paying attention to a whole bunch of things like prosody and tone and pauses and, and, and. The assertion that British people are highly attuned to things like accent and dialect is a bit of a side-show, we all are: it’s just a matter of degree and sensitivity.

Orthogonal to all of this is the realisation that Overly Friendly Nicey-Nice copy is but one axis on the continuum of how you can write, and that if there were, for example, an obsequiousness setting[1], that might be fun, or at least interesting, to try out.

This is to say that one of the reasons why Theodore fell in love with Samantha is that whether or not she actually had one, she simulated having a personality pretty well. Oh, and she was an actual human being who could read meaning into lines.

It’s easy for us to pay attention to the uncanny valley of computer generated imagery. That doesn’t mean there isn’t a similar uncanny valley of synthesised voice.

(An aside: Chinese Room style artificial intelligence, at least in the delivery of the intelligence, sounds more likely to me in the short term, where zero-hour workers pretty much read out and relay what Siri-the-system says to say to you, delivering the intonation almost by accident.)

[1] via Tom Coates: https://twitter.com/tomcoates/status/435657750312267776 in yet another example of British whimsy

2. PRESENCE
There’s a long history of presence on the internet: from commands like finger on multi-user UNIX systems to the peripheral-vision and green indicators of ICQ and AIM, to the green light on Facebook chat and experiments like BERG’s Availabot[1].

But all of these things seem to be kludges and shims for a non-persistently connected world. Again, running with my Star Trek as stand-in for the future theme, the presumption is that everyone is always available, online and connected. That someone wouldn’t be connected is what’s surprising: Commander Riker tries to get hold of Data and his combadge chirps in an unhappy way, CUT TO everyone on the Bridge looking perplexed, like Data’s gone AWOL. Which, essentially, he has, because in the 24th Century on a star ship, if you’re not on the network there’s something not right with you. Riker would try a few more times, ask the Computer to locate Mr. Data (“Mr. Data is not aboard the Enterprise”) and then cue creepy music and CUT TO TITLES.

This is where Snapchat, designed, as it were, for that golden of gold audiences, the Teenagers, makes an interesting choice (if I’m not reading too much into it): it doesn’t have, from what I can make out, any presence indicators. The presumption is that of course you’re online and of course your recipient(s) are, they’ll just get around to reading it when they do. If anything, this is one of the shifts that I think legitimately shows the difference between so-called digital natives and immigrants. To natives, connectivity just is. A lot of us in industry have grown up with the sound of Hayes v.34 modems pinging away in the background or remembering BBSes, and those of us outside the US remember paying per minute for connectivity and longing for that particularly foreign concept of “free local calls”. To have (admitting that this applies to a certain privileged class, but one that is growing) mostly unfettered, mostly untethered, persistent net access is a New Thing.

[1] http://berglondon.com/projects/availabot/

3. NETWORKS
You can go on and on about what it’s like to live with persistent networking and connectivity. I mean: isn’t it interesting that (and I hate to keep coming back to it, but it’s a handy point of cultural reference) when someone loses network connectivity on the Enterprise it’s more assumed that they’re not actually *on* the Enterprise rather than the network having gone down? Because when the network’s down, you notice: everything stops working. There’s not really spotty connectivity until the plot demands it – which is fair enough, considering we’re examining a 90s fictional TV universe.

This thing about connectivity is interesting in the respect of the different types of network that the assumption of persistent connectivity provides. SMS didn’t really care about presence, and arguably, was it a big missing feature that people were crying out for? It turned out that typical user behaviour (and here I really *am* just reckoning) was that people would have their phone with them all the time and the people who had a mobile phone and “just turned it on to make calls” – I’m looking at you, Dad – were the ones who felt weird. The *point* of the phone was persistent connectivity.

Marc Andreessen had a conversation on Twitter the other day on the difference between a pseudo-closed network like Secret, where there are built-in design constraints that act against unimpeded network growth, and open networks like Facebook or Twitter. Aside from appearing, at least, to look at the whole landscape in terms of a zero-sum vc investment (ie: open always wins over closed, so only pay attention to the winners, without acknowledging that there might still be profitable and viable markets for the non-winners), what feels to me to be somewhat obvious is that persistent connectivity supports multiple types of network graph.

It feels like we’re crossing over some sort of threshold where there’s *enough* connectivity for *enough* people that interesting behaviours are starting to emerge. *When* you have the type of connectivity that enables teens to send around 4 figures worth of messages per day, there’s value in the global lookup type of network that everyone’s on (Facebook) as well as ephemeral, close-group networking (Snapchat) as well as pseudo-anonymous (Secret).

Where it all falls down, of course, is making money and producing sustainable services.

(Obvious disclaimer: Andreessen is a stupendously successful investor, and I am just a guy. But anyway.)

4. MISSING APPLESCRIPT, IFTTT
At the same time, all of this connectivity feels like it’s an explosion of complexity that is a set of non-interoperable walled gardens and no way of providing a certain level of user control. Which makes me wonder about the possibility of the implementation of a layer of scripting like Applescript that at least in some way was easy to understand (though, arguably, not easy *enough* to understand and write) or something like If This Then That, which effectively presents a sort of extra user interface on top of the entire internet.

A lot of these apps and services are effective black boxes that, I suspect, people who do Learn To Code will get frustrated by. A computer can, in principle, do the things I need it to: so why can’t it? Why wouldn’t Facebook let me do this thing? Which is one of the reasons why knowing how all this stuff gets frustrating and complicated when explaining to people who don’t understand: well yes, in theory, we *can* do this thing, but we’d need to connect this bit to that bit and I guess Twitter *could* support animated gifs but it’s not a question of code, it’s a question of them just not wanting to and so it turns out that humans are messy creatures and the big lesson everyone learns is that Computers Only Ever Do What We Tell Them To.

So here’s a question: what’s the most impressive thing someone’s made with something like Scratch?

—

That’s all for today. Oh, apart from this Easter egg, courtesy of Paul Mison:


Episode Nineteen – Not Trying Is A Signal, Peak Game, EasyHard, SnapChat
by danhon

1. NOT TRYING IS A SIGNAL
I wrote yesterday, in my bit about Fax Your GP (which, maybe not on its own, but certainly appears to have contributed to this recent decision to push back rollout of the care.data database a little[1]), that with ever increasing emphasis on customer service and user experience, the delta between what’s good and what’s intolerable inexorably decreases. That’s to say: once you’ve seen something with a good user experience, it’s hard to justify other experiences in the same category having a shitty user experience.

Sometimes, this makes sense: you can pay a little more and pay Virgin America and get a super-good user experience when you fly, compared to when you fly United and you’re wondering why they’re not paying you instead. That can kind of make sense when you’re flying because you don’t really have that many options.

But in other cases, where the goods or services are highly substitutable, the distinction between one option which has a pleasurable service (especially one rendered digitally) and one that isn’t is just going to lead to instances of nerd rage. A slightly more mellow than nerd rage case in point, Russell Davies (again) on Sony’s new product[2] and the fact that while they’re entirely capable of a singularly impressive engineering feat, everything apart from shipping the product and making it falls down from a new customer’s point of view. And that’s despite the fun stuff[3] you can do with it.

And all of this in spite of the fact that you just know there’s someone in management, somewhere, saying that they know a fifteen year old kid (hopefully, equally likely to be a girl than a boy) who could ‘knock up a website’ that would do that in a few days.

Nick Sweeney helped me articulate this, in the context of government, a little better in a series of emails:

* If government can’t produce a good, digital user experience, when other entities can, then government looks bad (see: Healthcare.gov)

* If government *can* produce a good, digital user experience (see: the work of GDS in the UK), and then for some reason a good digital user experience isn’t produced (see: care.data opt-out), then suspicion as to failure of implementation includes policy reasons (ie malice) as well as incompetence.

So: companies and governments. You’re on notice. It isn’t hard to do this kind of thing. It isn’t easy, either. It’s just simply doable. The fact that you’re not doing it is now a valid signal that you’re not doing it for a reason.

[1] http://www.bbc.co.uk/news/health-26239532
[2] http://russelldavies.typepad.com/planning/2013/10/death-to-innovation.html
[3] http://www.separate–together.com <– disclosure: work thing

2. PEAK GAME
Just a few minutes ago I learned that Irrational Studios, of System Shock 2 and Bioshock fame, was effectively closing down and being rebooted as a leaner 15-person-plus-Ken-Levine studio[1]. The backdrop to this happening is interesting: I quipped on Twitter that one way of looking at this is in the context of the eternal war between the Triple A expensive 3D console tentpoles (your Bruckheimer/Bay equivalents) and smaller shops that produce work a bit like Telltale Games do with their critically acclaimed (and, by all accounts, commercially successful) Walking Dead series. What Levine is interested in sounds, well, interesting:

“I’ve been working on a concept I call narrative LEGOs,” he said, “which is how do you take narrative and break it down. What are the smallest part of narrative that you can then remix and build something out of? Mix and match.”

What’s even more striking is the comparison that many made when Bioshock Infinite came out to a game almost on the opposite side of the spectrum (and with many even taking issue with whether it could be called a game in the first place): Portland, OR based Fullbright Company’s Gone Home. And last night, watching a friend play The Stanley Parable (which game’s narration instantly reminded me of The Guide in The Hitch-Hiker’s Guide To The Galaxy).

Everything, they say, is being disrupted and eaten by code. But some of that disruption is more slight and, well, I would say insidious, but let’s just say longer lasting and less obvious. Videogames, out of all media, were bizarrely one of the arenas of culture that moved the slowest to embrace digital distribution, with the major publishers clinging on to shipping boxed product. While the combination of digital distribution and massively available pocket consoles in the guise of phones made attacking the low-end easy, it feels like it’s only until recently have people started to cotton on to the fact that you can make Big, Meaningful, Story-based experiences to a reasonable (read: profitable, I think) audience.

So: here’s the prediction, and it’s not a very insightful one, I’m afraid. I think we’ve hit Peak Expensive 3D FPS AAA Story Game, modulo things like Michael Abrash’s dream of VR Within Five Years Yes Really I Mean It This Time.

My money’s on Levine experimenting with mobile and shipping fast.

As a parting aside in this section: a metric crap-tonne of Measurable Attention Time used to be taken up by daytime TV and soaps. Those “video games” should see that as a stupendous opportunity, but the business model behind it might need a bit of tweaking.

[1] http://www.polygon.com/2014/2/18/5422834/irrational-games-closing-down-ken-levine-starting-new-studio

3. EASYHARD
Via the inestimable Matt Jones, Scott Jensen on EasyHard problems[1], particularly in the realm of home automation, which inevitably touches upon the internet of things and deciphering the intent of us meat-based-water-bags.

Jensen takes some time to remind us of Moravec’s paradox: that it’s bizarrely “easy” for us to make computers do what might appear to be intelligent tasks but are in fact ideally suited to being computationally brute forced by just walking, rapidly, and with purpose, down every branch of every tree of a possibility space – e.g. solving Chess. Conversely, it’s super hard (read: we haven’t really done it yet) for apparently easy tasks that we take for granted like, oh, I don’t know recognising cats (which takes a cluster at one of the largest private computing grids in the world), or walking or spotting things or even understanding what it is that I’m saying.

A lot of Jensen’s examples are of the “Do What I Mean, Not What I Say” problem, which is probably part of the fault of the promises of perceptual and ubiquitous computing coming home to roost. Until you actually sit down and deconstruct all the dialogue that the actors have in conversation with the Computer on Star Trek: TNG (which is a pretty good Tumblr project, to be honest) and parse all the meaning out and how phenomenally intelligent Majel Barret is, it’s hard to have a proper appreciation for the sheer amount of contextual awareness and cues that a home automation system needs to have. In a sense, some people have been saying this about the nature of artificial intelligence itself: that it’s hard (or may even be impossible) to create the new bar of what we raise to be artificial general intelligence without creating one that’s embodied. And the same may be true for home automation or other types of intelligence.

Part of this, when we’re still in the canyon of EasyHard is to have easy to understand, transparent systems where you can understand why something has happened, and how to either make it happen again or not. All of this is to say that repeatable expectable behaviour is one of the things that I’m assuming without having to go look for a citation is the kind of thing that reduces stress in humans, as opposed to unpredictable random outcomes when you want your lights turned on.

[1] http://jenson.org/easyhard/

4. SNAPCHAT
Here’s a super short one. Why are we surprised that a generation of people who have been told, in no uncertain terms, “Be careful what you post on the internet! It will live forever and haunt you!” have flocked, en masse, to ephemeral conversation tools like Snapchat?

Bonus thought: Phil Gyford’s insight[1] that perhaps the nicest thing about SnapChat is its complete lack of archiving. Us old people have grown up with everything disappearing and upon the availability of digital media instinctively wanted to Save All The Things. But perhaps a more mature attitude is that some things can be saved and some things – well, not so much. And I can see that not having to see the entire history of a conversation is freeing in a very interesting way.

[1] http://www.gyford.com/phil/writing/2014/02/17/snapchat.php

—

It was good to get back into the saddle again today. I have a bunch of things I want to talk about tomorrow, too, it sounds like.

As ever, blah blah about all of your feedback, but only substituting words that convey a sense of genuine gratitude at the feedback that I do receive.

Dan

Episode Eighteen: Some Thoughts On The Illustrated Primer, Fax Your GP
by danhon

0. HOUSEKEEPING
So here’s an observation: if you promise that you’ll get an episode of a newsletter out on what is for you, effectively, a holiday, you’re just going to spend most of the day stressed about it. So on Friday last week, I probably shouldn’t have said that I’d get one out today (Presidents Day – my fifteen seconds of Googling is unclear about the requirement or placement of an apostrophe).

And, it turns out, the mid-life parenting equivalent of recovering from a bender the night before, and instead is recovering from a 12pm to 3pm open house first birthday party. The place is a mess, a wreck and we’re all incredibly tired and loud noises (like, say, one year olds) are – shall we say – *piercing*.

So. Today’s episode is both late, and short.

1. THE ILLUSTRATED PRIMER
I mentioned the other day on Twitter that one of the things I’ve been vaguely working toward (and that I know some of my friends have also been working toward) in the grand scheme of “Neal Stephenson Thinks He’s Writing Books But He’s Actually Writing Product Specifications Or In Some Cases, If You String Them Together, Business Plans” has been The Young Lady’s Illustrated Primer (“The Primer”), from his book The Diamond Age. If you haven’t read The Diamond Age, then you probably should right now, etc. etc.

The thing about a lot of descriptions of product in science fiction books (or, well, any fiction) I suppose is that in some instances they’re quite *clear* and quite easy to imagine, especially if you’ve aligned yourself with the right kind of writer. I don’t necessarily mean the infodump Tom Clancy (or, let’s be honest, Neal Stephenson) type of writer, but there have always been some turns of phrase (Heinlein’s seminal “the door irised open” springs to mind), or some constructions of atmosphere that have been just so required to bring a fictional product to life.

With The Primer (and it pains me that all my American readers are pronouncing it the way Jodie Foster does in Contact, which, again, another movie you should etc. etc.), Stephenson’s worldbuilding extends all the way through from a physical description of the design and manufacture of the product: its codename and its assembly, the tools used in its design (that, did you notice? Provide direct, haptic-driven feedback? And provide instant feedback in terms of prototyping?) and the types of teams used in that design (farming out the battery design, for example) through to its literal assembly in a 3D printer. And then: the supporting infrastructure where, ultimately, what Stephenson is describing is just a little bit like what some people might now call a MOOC[1] because what he’s been doing has been trying to get from one-off “bespoke” app, a la Dave Morin, through to the education-as-a-service system for, well, an entire country.

(The nice thing about doing these newsletters is that, because I’m figuring things out as I literally type them, the direct line between what Stephenson’s been doing with The Primer into Education As A Service and something that’s going to be Disrupted, has never been so clear in my mind up until about fifteen seconds ago.)

Everything from cryptographically secure networks, 3D printers, stay-at-home, second-job zero-hour workers like the Ractors and those who decide to take biological augmentation in order to get ahead in their jobs. There’s something crackly about early Stephenson work like those two books (Diamond Age and Snow Crash) which just isn’t in his later work, and I wish there were something similarly, well, knitted-together. I would even forgive the Surprise! Stephenson! Endings!

Let me put it this way: (practically) all of the technology is there, right now, for the production of something like The Primer. What there isn’t (and there’s always a catch, isn’t there) is the business model. Which, honestly, must be easy to figure out.

You’ve got: cheap(ish), free(ish) tablets with network access. You’ve got cheap(ish), educated(ish) labour in terms of a whole bunch of high-school educated people who are sitting at home with cheap(ish), reliable(ish) internet access. And, uh, you’ve got, a broken education system.

Honestly, in a world where Amazon can practically give away tablets that are just about good enough, and you can tap a button and instantly be connected to a hot redhead, why can’t we have The Primer?

Exactly.

[1] Massively Open Online Course

2. FAX YOUR GP
A long time ago, some friends in the UK made something called Fax Your MP[1] and I’m going to make up some of the history behind it because it’s 10pm and it’s easier for me to do that than actually look it up. The internet was supposed to be a great leveler – something that would connect us to each other, and more importantly, with those who represent us in government. It turned out that it didn’t – at least, it didn’t in the UK in the mid to late 90s. In fact, those who decided to try and email their MPs were met with a mixture of both disdain (ie, what kind of people use email in the mid to late 90s) and ignorance (emails were purposely treated, I think, as Not An Approved Method Of Correspondence). Instead, to make sure that your voice was heard by your MP, you could probably a) write a letter (already reduced to a self-selected set of angry green ink letter writers), b) go to a “surgery” (further reduced to the set of people who don’t have jobs, don’t have any green pens and do have an abundance of time) or c) by fax.

Well, there’s a thing. Faxes are basically confused modems, and if an unconfused modem can be plugged into a computer, then the internet can talk to a computer that can pretend to be a confused modem and before you knew it there was a web-to-fax gateway that positively forced MPs to engage with their constituents.

You can probably guess what happened next: some MPs protested that faxes sent via the service didn’t count because, well…

Anyway. More recently, there’s news that the UK government is constructing a new centralised healthcare database. There are, as the Fax Your GP site points out, both good sides and bad sides to this[2], but the one thing that everyone should be able to agree on is that the opt-out procedure is almost predictably bad: ie, centrally, the advice is that you should let your GP “know”, and the precise methods are left up to the specific GP practice. Which is, shall we say, unclear and unhelpful to, oh, everyone.

Hence, Fax Your GP. A simple web to fax gateway that generates the opt-out documentation and faxes it to your GP.

There is a point here.

There is literally no excuse (and here is where *I* break out my green ink) for this type of service of infrastructure to not exist *in this day and age*. Where the UK’s GDS is doing stellar work in bringing to life public services in a useful and accessible way, it’s a crying shame that volunteers have to step up to allow this sort of government interaction. In fact, given *quite how easily* the Fax Your GP team have been able to bring up their service, one is effectively forced to wonder if the lack of such a service was designed into the policy in the first place.

All of which, I’m sure, helps engender trust in the leadership of the NHS in the first place.

And so on one hand we have Flood Hack[3], with the official backing of the Prime Minister, and on the other hand, we have Fax Your GP with no backing whatsoever and pointing out a rather insulting hole in the delivery of policy.

Yes, you’re right. I’m angry.

And this is just going to happen more. Because the more a government is unable to deliver basic services and apply its policy in a usable manner, the more people are going to notice the cognitive dissonance every time their interaction with government is effectively reduced to this wonderful quote about a planning notice:

“But look, you found the notice, didn’t you.”
“Yes,” said Arthur. “Yes, I did. It was on display in the bottom of a locked filing cabinet stuck in a disused lavatory with a sign on the door saying ‘Beware of the Leopard’.”

Government bureaucracy has always been absurd. Hopefully, that absurdity is just going to get more clear.

[1] http://www.faxyourmp.org.uk
[2] https://www.faxyourgp.com/about-us
[3] http://www.bbc.co.uk/news/technology-26225962

It’s 10:34pm on a Monday night, and it’s back to work tomorrow. See you then.

As ever, I appreciate any and all feedback. Please do drop me a line if there are things that you’ve seen that you like, or, that you haven’t liked.

Best regards,

Dan

Episode Seventeen: The Job To Be Done, The Ethics, The Good and The Practice
by danhon

1. THE JOB TO BE DONE
Benedict Evans posted the other day[1] that the number of Apple Computers-With-An-Asterisk (ie iOS and OS X devices that support an application platform, implicitly excluding the Apple TV hobby product) sold surpassed the number of Microsoft Windows PCs sold globally in the fourth quarter of 2014. The response and commentary on sites like Hacker News was a predictable case of completely missing the point: that for anyone who doesn’t own a computer (surprise: that’s most of the entire world), Apple Computers-With-An-Asterisk actually get the job done. And the job done is not necessarily one that requires general purpose computing in the sense that it’s been deployed to the world through Microsoft’s Computer On Every Desk vision. In a sense, the competing vision that Apple instead promulgated was one of a Bicycle In Every Pocket. At the risk of harping on, yet again, about Jobs’ insistence (and somewhat tunnel vision focus) of Apple being at the intersection of liberal arts and technology: perhaps that’s yet another distinguishing factor between the two companies’ application of technology. Microsoft, a traditionally engineering heavy company, can be seen as historically focussed on the, well, engineering side of things. MS-DOS and Windows PCs were complicated beasts, capable of a great many number of things, but they were machines that had to be harnessed. They were raw power, with a bewildering set of options (which options are, naturally, alluring to a great many number of people), but they were not as focussed on, from the user’s point of view, the Job To Be Done. And in the words of Sorkin-dramatising-Zuckerberg, if you’d invented iMovie, iPhoto or iTunes, you’d have invented iMovie, iPhoto or iTunes. And instead Windows get, well, Windows MovieMaker, Windows Photo, and Windows Media Player.
Let me put it this way, and I realise that this is more of a reiteration than a genuinely new insight. Tablets – in particular, the iPad – are good enough, now. A year ago, at the traditional Thanksgiving technical support open house, we replaced my in-laws aging laptops. For my father-in-law, a new Windows laptop (which I’ll freely admit that even to myself, remains somewhat impenetrable, a situation I find amusing given I still remember building myself a Windows 2000 Pro workstation while at college), but for my mother-in-law, an iPad. And it’s been fantastic for her. It does everything she needs, and she uses it more.
That’s the thing about the job to be done – another illustration of the cars-not-trucks argument that Jobs put forward to, I think, Mossberg at an All Things D conference. In our house, for example, we do not need a general purpose cooling machine, that can take any configuration of things-to-be-cooled and cool them in any which way. Instead, we have a fridge/freezer. The general-purpose PC, in terms of form factor and use case, is turning out to be but an aberration. The problem that the PC industry has found itself in is that it optimised itself into a local maxima: they optimised and optimised and optimised for the market that they thought they were in – which was People Who Buy PCs – and found themselves sitting atop a pretty mountain. And for the landscape they were in, that was just fine. It’s just that if you started looking in a different solution or possibility space, there turned out to be a giant, adjacent untapped maxima that we still haven’t seen the ceiling of: and that’s tablets and mobile.
The job to be done turns out to be things like staying in touch, or listening to music, or looking at or sharing photos, or playing a quick game: none of which require either being tethered to a desk or even on a couch with a laptop.
It makes you think, and hopefully without descending into Valley-esque dreams of capital D disruption, what other local maxima have been entirely reliant upon heavy, tethered processing.
[1] http://ben-evans.com/benedictevans/2014/2/12/apple-passes-microsoft

2. THE ETHICS BOARD
On Google’s acquisition of Deep Mind Technologies, yet another deep learning artificial intelligence startup, one of the side notes of news was that the terms of the deal included the requirement that Google set up an A.I. ethics board. There’s some good commentary on this, [1, 2] and I have my suspicions (or, in this case, hopes) about what the terms of reference of the board might be.

The board is not, I don’t think, about the fact that Google has both a sometime military research contractor on board with the Boston Dynamics and their ATLAS, BIGDOG and so-on platforms (which, honestly, from someone with a somewhat naive point of view, feel like they could be militarised rather easily) and there are people worried about some sort of Terminator scenario. It’s instead, I think, about the unintended consequences of deploying large-scale artificial intelligence algorithms out into the real world and how those algorithms and products might be deployed.

With news that algorithmic prediction of revolution or protest is becoming increasingly accurate[3], an ethics board at a build-fast-and-deploy company like Google (and countless others, including Facebook) to look after those A/B tests of functionality and deployment of, frankly, opaque and smart-esque micro-products sounds bizarrely like a good thing to do, and I find the feeling of siding with the formation of what amounts to a laboratory experiments academic ethics board by which proposals must pass unnerving to someone who wouldn’t normally characterise themselves as either conservative or alarmist.

I’m a big fan of Ellis’s Global Frequency comics universe, the idea of a select group of people around the world with Very Unique Skills, deployed in interchangeable and substitutable combinations to deal with outside context problem and existential threats due to unintended outbreaks of the future that need to be mopped up. I would pay cash money for fiction that shows how we might deal with, as Zeynep Tufekci (hopefully I spelled her name right this time) the new algorithmic nightmares that crop up. There might not be as many explodey things or biohorror, but gosh aren’t there enough things out there that would need dealing with. And I honestly have no idea how they might be dealt with.

As an aside: the idea of Richard Feynman investigating Flash crashes or Stuxnet makes me simultaneously so excited I might explode and genuinely depressed at the fact that people always die.

[1] http://www.forbes.com/sites/privacynotice/2014/02/03/inside-googles-mysterious-ethics-board/
[2] http://slate.me/1bq52iu (Slate, your URLs are too long)
[3] http://www.theverge.com/2014/2/12/5404750/can-a-database-predict-a-revolution

3. THE GOOD
It’s easier to write about bad things than it is to write about good things. Russell Davies reminded me about this the other day[1], so here’s me trying to, well, write about good things. Everyone loves a rant, but, well, they’re not always productive. So: here’s a good thing.

One of the things that I do really like about Nike’s Fuelband is that they have achieved a certain simplicity with the red-to-green mechanic of showing how much activity you’ve achieved. For me, that’s one the victories in the whole quantified self movement and abstracting away from measured numbers into differently (and more easily) understood forms that allow for nuance. There’s a whole bunch of other things I could say about the Fuelband, but for once, I’d like to draw attention to just the things that I like about it.

[1] http://russelldavies.typepad.com/planning/2014/02/elude-these-pitfalls.html

4. SHOULD EVERYONE UNDERTAKE THE PRACTICE?
Ian Betteridge, of the eponymous Betteridge’s Law, has written about the practice of writing. I have to say that the discipline of sitting down and actually hammering something out on the keyboard has been, hands down, fantastic for me. I would not have been able to anticipate the reaction (and I’d be lying if I said there wasn’t some part of me that was doing this for validation or recognition), but at the same time the fact that I can prove to myself that I have more than 500 words, every week day, of something interesting I feel I can explore, has simultaneously been freeing and terrifying.

It’s still terrifying even after seventeen editions to deal with the fear that I’ll literally have nothing interesting to say. But one of the things that I’ve learned about myself over the past ten years or so is that I do some of my best thinking out loud, or through speech. And, apparently, through writing. I frequently don’t know where I’m going when I start something (in today’s episode, I think I’m most interested in where I ended up with the piece on Google’s Ethics Board), but I almost always end up somewhere that feels like I’ve unlocked something. It may not be something big or earth shattering, but it is immensely satisfying. It might not work for everyone, but I can heartily recommend something like it. And, hopefully, I’m getting better at writing with all of this practice.

Bonus: even though it’s terrifying, it doesn’t feel like work. I am, quietly, pleased.

[1] http://www.technovia.co.uk/2014/02/500.html

That’s it for today. Have a great weekend – it’s my son’s first birthday party and I have very, very good friends visiting from London – and I’ll see you again on Monday.

As ever, I very much appreciate your feedback, and I always endeavour to reply.

Best,

Dan

Episode Sixteen: Feynman and Adams, Surveillance
by danhon

1. FEYNMAN AND ADAMS
Growing up, there were probably two people who were idols of mine: Richard Feynman, ever since as a young boy a copy of Surely You’re Joking, Mr. Feynman, had fallen into my possession and I had devoured it, and Douglas Adams, when a visiting uncle had left a dog-eared copy of The Hitch-Hiker’s Guide to the Galaxy behind for me. In a fantasy alternate universe solely existing in my head, Feynman and Adams are a detective team who cruise around the world solving crime and explaining science. I’m sad that neither of them are alive anymore.

I mention this because both of them had an uncanny knack of explaining and translating complicated concepts into something easily understandable. They did so with wonder and delight at the intricacy of the universe, and even on the written page you there was a palpable sense of opportunity and potential. They were not, by any measure, the kind of people you would characterise as using science or reasoning to take away from the beauty of existence.

It strikes me that there are so many complicated things in our world now that are out of the grasp of understanding, never mind learning how to code or how technology is (and always has been) fundamentally shaping our culture and existence. We’ve never needed people capable of being able to look at systems, interrogate them, and present them in a human context in the way that Feynman was able to do, for example, with the Rogers Commission Report into the Challenger disaster[1].

Adams, in his own way, was a particularly British kind of techno-utopian. One who could simultaneously see the absurdly sublime implications of computing with organisations like the Sirius Cybernetics Corporation, but at the same time, who could excite you about the potential of hypermedia in an inspiring documentary like Hyperland[2] that again was far ahead of its time. We may not have software agents that are as explicit as those envisaged and imagined by Adams, but they’re behind the scenes, ploughing through the clickstream of our intent and wandering through a web that isn’t confined to desks anymore, recommending movies and books, booking our travel and connecting us with the rest of the planet in ways that we have never been able to do before.

In a time of technological libertarianism, in the belief of the depth of data that’s being collected whether we like it or not, either implicitly or explicitly, it’s people like James Bridle who are doing the work to bring to life what’s hidden underneath the designed exteriors of the artefacts that we’re interacting with each day in a way that is grounded in context for what we are: essentially, and still, hairless apes engineering increasingly complicated systems. We need more of them, and for those of us who work in designing those systems that push and pull at the warp and weft of data and interactions, where every touch leaves a trace, we have a responsibility to make sure that what we do is understandable and accessible.

[1] http://en.wikipedia.org/wiki/Rogers_Commission_Report
[2] https://vimeo.com/72501076

2. SURVEILLANCE
Medium has an interesting reputation for being a repository of, and if you’ll forgive me the diving into slang, whitesplaining, mediumsplaning and general privilege reeking of better-than-thou, from on high communication. If only, wail the invariably male, white, educated and middle class designers and technocrats, people would listen to me and implement my solution, would the world be a better place and I would be able to operate my washing machine without calling my mother[1].

Well Sturgeon’s law applies on Medium as well as anywhere else, which means that for the purposes of this, I’m letting you know that I took the time to read Zeynep Tufecki’s essay[2] about the nature of the internet and surveillance in the twenty first century and what it means for us.

Tufecki has simply, strongly clarified why the current state of big data and drawing algorithmic inferences from the morass of data we create each day can’t easily be compared to 1984 or the Panopticon. Because this is a future that we have chosen for ourselves, where we do indeed have freedom and happiness (although tied to consumption) and that, ultimately, Certain Inalienable Rights have, more or less (modulo, as Tufecki points out, if you’re poor or non-white or female) have been recognised as Inalienable and are slowly but surely spreading out through society.

The risk and danger is in what we can’t see, and in the implication of the data that does surround us. All of it can be used more easily than ever before, and it can be as right, or as wrong, as you need it to be. Much of it is unknown and in the service of objectives that are either opaque to us or blindingly obvious. In any case, the reduction of people to data, a construct with variables and rows in a database lazily linked with a JOIN to countless others raises questions about what we want to achieve with all of this, and whether we want to achieve that in the first place.

Tefucki says that we need to update our nightmares. As ever, they are both more mundane (brands like Target wanting to ensnare us in their shopping embrace as we approach parenthood) and simultaneously more sinister (the potential micro-manipulation of voter messages as a high-tech version of jerrymandering).

In a way, you can see the data in the cloud around us as a set of field lines that can be massaged to points, forcing toward certain directions or away from others. The Unix philosophy of many pieces, loosely joined, has been extended to our selves, as simulacra and models are created from our detritus.

So this is the deal: Tefucki says, to the question, Is the Internet good or bad: Yes. It is. As it has ever been, it is a tool that has wrought massive, genuine, democratic change because it has connected people to people. And the result of connecting people to people, now that we have spammed the planet with our Turing machines and their infinite tape, is that we have written ourselves onto that infinite tape without realising who can read it, and what they might do with it.

[1] https://medium.com/ux-ui-readings/b6f927bbb538
[2] https://medium.com/matter/76d9913c6011

I have a terrible cold and an impeding first birthday party. Let’s see what I come out with tomorrow. As ever, I welcome your comments and feedback.

Dan

Episode Fifteen: I Miss Dopplr, InfiniFriends
by danhon

(Also known as the My Friends Are Significantly Smarter Than Me episode)

1. I MISS DOPPLR
Yesterday’s episode included some scribblings about the Quantified Self, Felton’s Reporter and Nike’s Year In Nike Fuel. I was reading Fathom’s post about the thinking behind the Year In Nike Fuel[1] and was again struck, and a bit saddened, by the tone and manner of presentation of what ultimately is intensely personal data about your daily movements. The post itself is the interesting thing: talking about gym rats, mountaineers, working dads, city slickers and how they all have distinct patterns. Or how the Fuel activity of a newborn baby looks.

But the output – so cold! Pure data! Red and blues, and, ultimately, a dashboard that looks like it’s trying to emulate a Boeing Dreamliner glass cockpit. All of that emotionally loaded, meaningful, personal data gets reduced to “vigorous exercise” or “moderate exercise” or “inactive”. The half marathons get turned into “highest weekday peak”. Workouts get reduced to “3.0” per week, and weekly exercise gets turned into “4h 4m”, which is “moderate”.

Bullshit, I say.

I mean, look at this, from that Fathom post:



Those are different shapes. But preoccupation with all of this data and showing the actual numbers and, man, the obsession with the Quantified part of the Quantified Self and the fixation that that must mean numbers. You know what those charts look like? They look like they were designed to be read by computers. They look like things that computer vision algorithms could have a field day with. But the data was gathered by sensors in the first place! Those charts are ostensibly for humans and yet the aesthetic is almost as if they’re trying to look like a fictional-future in-HUD display for the Terminator. Those charts are what a science fiction movie would show when getting us to understand what a robot saw when it looked at a person.

I was instantly reminded of how much character there was in the Dopplr annual report. That dream team of Biddulph/Jones/Insam produced not only a product that was ahead of its time but had a phenomenally *meaningful* annual report. Their example for Barack Obama[2]:



is brimming with context that helps make the quantified part of data understandable and relatable on a human level. (As an aside, you would see more work like this in terms of design making data understandable through work like HowBigReally[3] (which is still amazing for helping me realise that either the moon is tiny or Australia is massive) and Schooloscope with its Chernoff faces.

We’re not wired to understand bar charts. We’re wired to understand other things. That’s not to say that there isn’t work that can be done to make bar charts and pie charts and graphs and sparklines and so on more understandable. But they’re not the only way of representing data, and holy shit, did you know we have computers now? That make things like saying “Your personal velocity for 2008 was 38.10 km/h, which is about the same as a six-lined race runner lizard” significantly easier! And Christ, they were doing this back in 2008. That was five years ago, merely a year after Flickr came out. It is honestly disappointing to me that we are collecting more data than ever, that means more to people than ever before, and still obfuscating it.

It makes me upset about what we’ve lost, and how far behind we are.

Try fucking harder, people. It’s not just a case of throwing Processing at something. It’s almost as if the tech industry has a reputation for being severely lacking in empathy with actual people, for fuck’s sake.

[1] http://fathom.info/latest/6796
[2] http://www.flickr.com/photos/dopplr/3198685033/sizes/l/
[3] http://howbigreally.com

2. INFINIFRIENDS
Tom Armitage, who is a stupendously smart person, has made a Thing which he’s finally made public and that he forgot he showed me over the Thanksgiving break, which for everyone else in the world, was around the end of November.

His Thing was Infinifriends[1], which is essentially the fucking genius realisation that a) all the Friends scripts have been transcribed onto the internet, b) you can get amusing uncanny-valley programmatic animation with algorithm induced emotion from things like Plotagon[2] or xtranormal (which doesn’t even exist anymore), which are essentially fancy text-to-speech engines with probably Unity-powered 3D animation on the back, and c) Markov chains, because, hey, you throw Markov chains at everything these days. Markov chains are the new Bayesian filters, didn’t you know?

Anyway. You end up with infinite episodes of Friends. And they are wonderful, just perfect, to my absurdist mind. They make no sense, and that’s why they’re funny. And they play off the Friends universe, so you have this super interesting juxtaposition of terrible, nonsensical writing and bad computer generated acting colliding in your head with the mannerisms of the real actors, on the real sets, backed by a writer’s room.

At some point, these are going to be spat out to YouTube and then people are going to freak out, because algorithmically generated drama is going to be ‘good enough’ in the same way that people thought people would never watch movies on a 3.5in diagonal phone screen and hey, it turns out that people will.

And because this is how the world works now, expect generalised infini-engines for pretty much any syndicated TV show.

OR, OR: and I’m looking at you, Mr. Ellis, now that Marvel has a fucking universe API, algorithmically generated Marvel Universe comics.

Ha. Where is your algorithm god now.

[1] http://infovore.org/archives/2014/02/10/infinifriends/
[2] https://plotagon.com

Anyway. That’s it for today. I’m still angry about Dopplr.

Dan

Episode Fourteen: The Inevitable Apple TV Episode and Algorithmically Induced Sadness
by danhon

1. THE INEVITABLE APPLE TV EPISODE
So, a couple of things that actually prompt a reckon about Apple and televisions, as opposed to the usual breathless wanking over them shipping an integrated display or whatnot.

Item the first: a new Apple TV hardware identifier has been found in developer iOS 7 bundles[1], with a bump in major version (ie AppleTV 3,2 -> Apple TV 4,1).

Item the second: A new Beatles(?!) “channel” on Apple TV[2] has been released to celebrate the 50th Anniversary of, uh, the Beatles’ debut in America.

The first thing, if true, is a pretty solid signal of some new hardware. The second one is a weak signal because Oh My God if you’ve got an Apple TV is that thing a fucking mess right now. Apple’s list[3] of what’s available on the product right now is a long scrolly scrolly thing, and the fact that the only way to get rid of stuff you don’t want to watch (for example, KOR TV isn’t so useful in our household because of our inability to understand Korean) is (protip) to use Parental Controls and hide certain apps/channels. And they’re not really Apps. But they’re kind of Channels. But not always Channels. It’s confusing. Also: no kids mode! Apart from the weird Parental Controls!

It’s almost as if the profusion of content that’s available for the Apple TV (and it’s not really a profusion, more of a gentle dripping, to be honest, and compared to competing platforms like the Roku) is going to force Apple to a) refresh the hardware so it’s capable of a bit more customization (the current models ship with 8GB of flash storage, mostly for cacheing video) and b) refresh the hardware so it’s capable of doing a little bit more than essentially acting as big-screen an XML frontend to network available video – Bluetooth game controller support or no, no one’s going to be installing 1080p games (even if they’re the now unavailable Flappy Bird) on an 8GB Apple TV.

[1] http://www.macrumors.com/2014/02/10/apple-tv-in-ios7/
[2] http://www.macrumors.com/2014/02/10/beatles-apple-tv-channel/
[3] http://www.apple.com/appletv/whats-on/

2. THE QUANTIFIED SELF
Nick Felton released his newest thing, Reporter, a Quantified Self app for iOS[1]. Also, Nike released its 2013 Year In Nike Fuel visualization website[2], both of which ultimately provoke my sense of frustration at all of this Quantified Self stuff being a bit cold and inhuman, when even the moniker which the movement goes by seems to strip any emotion out of the fact that *people* are doing *stuff*.

I absolutely yearn to see some bringing to life of data around the quantified self and personal health that doesn’t just reduce stuff to a bunch of numbers displayed in different colours or bar graphs.

I have a suspicion about the gender split for, say, Nike Fuelband customers versus Fitbit/Jawbone customers, but I have to say that I don’t think anyone is making any of this stuff in a friendly way that would open up the market to people other than data-driven numbers-tracking geeks. Like me.

While writing this, I received my “2013 prescription records” from Walgreens and thought it a bit weird that a pharmacy chain would be jumping on the whole Year In Review, Visualized bandwagon with my assortment of medication, but upon opening up the email it turned out to be for my tax records. America!

(Speaking of numbers, I briefly flirted with the stats tracking of unsubscribe/subscribe notifications on Tinyletter over the weekend and had to turn it off because it was like a random reinforcement shot to my sense of self-worth. It turns out that in my head, one unsubscribe needs at least twenty subscriptions to feel like things are in balance for my ego. So I turned that off, pretty sharpish.)

[1] http://www.reporter-app.com
[2] https://yearinnikefuel.com

3. ALGORITHMICALLY INDUCED SADNESS
I had my first Sad Algorithm moment, that not-quite uncanny valley of algorithmically induced emotion that happens when a notification system designed to be helpful in fact does nothing of the sort. Personally, it was more painful (perhaps because it was timely) than seeing a birthday reminder for a dead friend on Facebook or a work anniversary for a dead friend on LinkedIn.

My mother-in-law, whom I adore and have known for the last eleven years of my life, made the decision the other day that she was too ill to come out and visit for my son’s first birthday. This round of chemo, unfortunately, doesn’t look like it’s working. As someone who grew up in another country from his grandparents, I didn’t realise how important it is to me for my son to get to know, and regularly see, his own grandparents. That my wife’s family are now unable to come out hit me in a way I didn’t expect.

So when I got a Google Now notification that a certain SouthWest Airlines flight had been delayed, after the first split second of bemusement, I realised that I was being told about the flight they would’ve been on.

I don’t know what the “answer” to this is. If my in-laws had told us by email, instead of via a phone call, would Google Now have been smart enough to parse out the cancellation? In a purely utilitarian calculation, I can see that Google would prefer to send notifications than not: that’s where the usefulness comes in. And for Google to know that my parents had cancelled their trip – there’s no UI for me to tell (at least, not that I saw) Google to not remind me. Would they need perfect information about my life, to know what to interrupt me with and what to remind me about, and what to hold back on? Should the burden have fallen on my in-laws to let Google know to not remind me?

This is probably just another prompt to watch Charlie’s Brooker’s excellent Black Mirror.

4. WHAT I’VE ACTUALLY BEEN SPENDING MY TIME ON
I found it so much easier to get into Threes[1] (which I’ve described to friends as Drop 7 on crack) than Flappy Bird[2], if only because Flappy Bird just seemed so transparent. I see exactly what you’re trying to do there, Mr. Flappy, and I refuse to participate. Whereas the simple pleasure of getting multiples of 3 to match up flicks some sort of switch in my brain that I can’t get around.

Ian Bogost has written the definitive “If You Read One Thing About Flappy Bird, You Should Read This” article[3]; I think it captures perfectly what’s so interesting about it and speaks to our relationship with games of that particularly singular genre. Plus it’s super accessible if you know nothing about games. I hate Ian Bogost, he’s so smart.

Oh, and Secret, which a) has stupidly poor web SEO (try searching for “secret iphone app”), b) stupidly poor iTunes App Store SEO (what doesn’t) and c) has me engaged in some weird car crash type fascination of trying to figure which of my 30! 31! friends are on it and watching, uh, Ben Ward’s party. On the one hand, it’s interesting to see what my friends will say when I don’t know which of them they are, on the other hand, most of the stuff I’m seeing from friends-of-friends or that has been deemed “viral” and spread is pretty shlocky hallmarky stuff or, apparently, about what seems to be the quite frankly excessive amount of oral sex young people ar having these days.

[1] https://itunes.apple.com/us/app/threes!/id779157948?mt=8
[2] No download link! Ha!
[3] http://www.theatlantic.com/technology/archive/2014/02/the-squalid-grace-of-flappy-bird/283526/

I thought I wouldn’t have enough to talk about today. I was wrong. Thanks for reading.

Dan

Episode Thirteen: The Auto Show, Learning to Code and Niggling Thoughts
by danhon

1. THE AUTO SHOW, CONTINUED
So if Twitter replies were any indication, the geek date that Matt Haughey and I took to the Portland International Auto Show where we were seduced by the BMW i3[1] caught the attention of a few people who wanted to know why, exactly, we liked it so much. So here’s a non-video, text-only, geek-point-of-view version of Top Gear where I give my reckons about the i3:

– You know in those cars where you have to pull down a front seat to get into the back row? And how you can never find the handle? And you end up hunched over, contorted into a shape that normally you’d have to pay someone to persuade you to get into, scrabbling for a handle or a clasp or something, anything, that will mean that you’ll stop thinking about the fact that you’re pointing your arse out into the world? You don’t get that with these cars, because the handle’s in the headrest. It’s right there! Honestly, it feels like now I’m 34 and a dad I’m entirely all too easily impressed by something that means I don’t have to bend over.

– I touched on this a little in the last episode, but it really was refreshing to see something that wasn’t a traditional car console design. There were little swoopy bits (and in a break with tradition, I’m actually going to embed an image) made out of that sustainable bamboo (and again, being impressed by just a different texture that wasn’t goddamn stitched leather, for once). In other cars, they would’ve just stuck a crap, fake mini iPad in the central console that would’ve irritated you, but in the i3, a) the screen wasn’t the normal 4:3 ratio that you normally see and instead some weird elongated more-than-16:9 which, combined with the sweeping bamboo, already made me feel a bit like I was Worf standing at the curvy bit of the Enterprise-D behind Riker, Troi and Picard; b) it was floating and not embedded in the console itself, and fuck me if the most impressive thing about car design is the fact that the central multifunction display isn’t embedded in the console itself. Do you see what I mean about the industry needing some capital D disruption?

12377534214_3a009b116f_z.jpg

– The OS of the car appeared to be BMW iDrive 4.2, which is, I guess, the newest version? It has a 200GB hard drive and 3D graphics[2] and an iPod-esque vertical/horizontal menu navigation mechanic. There’s a lot of what feels like extraneous swooshing going on with the curves on the left hand side which makes the UI look more like something you’d see in Mass Effect than in a real life car you could be driving right now.

– The doors open in a weird way, which already makes you kind of endeared to it.

– It had a ridiculously small turning circle, which impressed us as we circled around a potted plant.

– Apropos of nothing, there was a context-free sign hanging in the BMW i3 area that just said: “URBANIZATION”, which sign Matt and I found hilarious.



– If anything, it was also the sales patter that Matt and I found endearing. It genueinly did feel like we were being sold on a car that had been designed for the city, and one ground-up, at that. The drive was pleasant (at a screaming 17 miles an hour) and to be honest I spent more time than I should’ve geeking out over the touchpad in the iDrive controller and spelling out m-e-t-a-f-i-l-t-e-r in the web browser before we were reminded that there was a line of people waiting to get into the car.

[1] http://www.bmwusa.com/standard/content/vehicles/2014/bmwi/default.aspx
[2] http://www.bmwblog.com/2013/04/25/interview-with-eric-sargent-on-new-bmw-apps-for-idrive-ecall-and-update-on-iphone-5-connector/

2. LEARNING TO CODE
There’s a lot that’s already been said about the UK government’s support of 2014 as the Year of Code[1], ably so by Adrian Short[2, 3]. So I thought I’d add to the noise. As a precocious little snot of a kid, I loved messing around with the BBC Micros that we had at school. My parents, being academics, borrowed computers home from work any chance they had, so I wasn’t really afraid of the box and the monitor in the corner. For a few years at the beginning of the 90s, computing lessons (for 11-13 year olds) were about plugging breakout boxes into those BBCs and trying to get robots to do things by writing BASIC programs for them. And then the school got a bunch of money for becoming a Technology College, bought a bunch of PCs (at the time, Elonex boot-from-network 486SX pizza boxes) and computing became not, well, learning how to *do* computing, but a vocational thing: here’s how you use Microsoft Excel, or Word.

And that was where the shift was, I think.

When Lottie Dexter talks on her Newsnight interview[4] about being able to code being a vital part of first understanding and then functioning in the world that we now live in, we’re never really given the chance to unpack what that means before the Paxman is unleashed on her and she wanders into loosely joined words. Similarly, the video package put together of kids learning how to code is, from the point of view of someone who knows how to code, not exactly, well, helpful.

I’m all for teaching people how computers work, and giving people – and from a young age, children – the ability to explore that understanding. And I’m not entirely sure if I buy off on Adrian Short’s neoliberal agenda that the Year of Code is the thin end of an axe driving a work and employment agenda. But nonetheless, there is something that, again, smacks of trying to implant “code” into people, as if it were some sort of didactic skill that could be introduced and reinforced in the same way, factory style.

Ah, factory style. And now we’re into the whole model of education, in the UK anyway, the way that our classrooms were built and curricula established to serve a very particular need of providing bodies for a rapidly industrialising nation. At the same time, I don’t know what to feel about friends who are pulling their children out of formal schooling and are instead home schooling. The idea, as it’s presented and as the rhetoric comes across, of being able to teach people to “code” in a year is about as interesting as teaching a whole nation Japanese or Chinese in a year. And yes, I do see the insight in “code” being potentially a more valuable language in terms of employment or earnings opportunity than “German”.

But here are some things about what living in a world run on code means. It means that we create a finance system backed by interdependent systems that we, as human beings, are increasingly unable tease apart and understand as a whole (if we have ever, in fact, been able to understand such systems). Knowing “code” ultimately means training a country’s worth of new mini Snowdens whom conceptually are able to understand how to manipulate large amounts of information, effortlessly. Knowing “code” is more about knowing the end result that you want to achieve and the abstracted steps that you need to take to achieve that end goal. And then you get to teach jQuery.

But knowing “code” won’t get you a job. The ten year old interviewed thinks she needs code to work in a bank so she can create her own website. Honestly, one vision of the future we had was that she would know enough code in her banking job to automate most of the work she has to do. And then what? Code is a means of expression. Or, as Microsoft’s new CEO would put it, the best code is poetry. The point of code isn’t just to get you a job.

[1] http://www.yearofcode.org
[2] http://adrianshort.org/2014/02/06/year-of-code-neoliberal-agenda/
[3] http://adrianshort.org/2014/02/09/lottie-dexter-quit-year-of-code/
[4] http://www.youtube.com/watch?v=-7x7GYItzS4

3. TWO NIGGLING THOUGHTS
3.1 What’s the video-on-demand equivalent of Google getting better at design faster than Apple’s getting better at software? The perception is that Netflix is killing it in the original content space: series like Orange is the New Black are picking up award nominations, and their list of original series isn’t anemic[1]. You’ll note, though, that I didn’t include House of Cards, and that’s mainly because as a) a Brit and b) someone who’s seen the original, House of Cards doesn’t count in my mind as a new Netflix commission. It’s not *that* original. In contrast, my anecdata of one-comment-from-a-friend is pointing me in the suspicious direction of Amazon not really knowing what they’re doing with their original content (the new Chris Carter series, The After[2], is apparently terrible) and, uh, who else is commissioning content that’s skipping broadcast or cable?

3.2 I don’t understand what it is that’s preventing iRobot and their Roombas from taking over the world. Young people these days, they’d love an autonomous robot vacuum that they could control with their iPhone. And they live in tiny flats or apartments now with no stairs. What’s happening? In fact, you wouldn’t even need to sell them the Roomba. Just rent it to them for about $15 a month. Of course it could just be that manual labour is cheaper and more effective, but that’s never stopped anyone from doing upselling. Or downselling. I don’t know.

—

A bit of a weird one today, I’m afraid. We’ve had a solid long weekend worth of Snow in Portland, Oregon, so everyone is freaking out. Let’s see what tomorrow brings.

Dan

Episode Twelve: Attention, Star Trek and Cars
by danhon

1. OH, ATTENTION
So Upworthy’s in the news for talking about a new ‘attention metric'[1] instead of pageviews/impressions/eyeballs/brain implants. Essentially, what it looks like they’re trying to do is capitalise upon the fact that people spend a lot of time on Upworthy’s site and that their content performs quite well. An engaged audience is, of course, better value for an advertiser than an unengaged audience, no?

Ha! Let this be another part in the continuing series of “Let me tell you the things I have learned from my journey in advertising!”

Dirty secret: advertisers (read: brands, not agencies) might not want attention in the first place. Or, at least, not the kind of attention that Upworthy is selling. When I first moved over to agency side nearly four years ago, gamification was but the twinkle in a huckster’s eye and nothing near the multi-billion dollar world-powering capitalism engine that it is now in 2014, as promised by the huckster’s twinkle. And the thing that I was (and still am) excited about was the whole notion of Games as a Creative Medium and battling the stereotypical view that games were for 15 year old boys in their parents’ basements who liked to shoot things in the face. And that, at the time, Zynga looked like they were going to take over the world (ha!) and everyone who was anyone was busy building farms in Farmville. And we all know how that turned out: now we’re all impressing each other with our Flappy Bird scores.

Anyway. As an outsider, I had thought that the thing advertisers (read: brands) would care about would be engagement – the amount of time that people spend doing something, which means you have longer time for your message to get across and to sink in. Turns out engagement? Not so much. Reach and frequency (which games do, kind of) are instead the kinds of things that traditional advertisers care about more (and bear in mind that I’m grossly generalising here).

Nowhere is this more apparent in the land of advertising that is comfortable with buying television advertising to achieve its goal, where I learned about things like TRPs[2] in terms of firing your message out into the literal electromagnetic ether to have it land on your ideal audience’s retina. The thing about this is that – and all this is caveated from my point of view – the mechanism of advertising is still more or less predicated upon that formula of reach and frequency, and not further down the stack of effectiveness. If all I care about is reach (how many people might see my message or 30 second spot) and frequency (how often people will see my 30 second spot), I really, really don’t care about buying “engagement”. Because, let’s face it: if engagement really was what clients (read: brands) wanted, then, well, the ecosytem of ads that we see would probably look a bit different and more like, well, Upworthy headlines.

I rapidly learned that what I thought would be a great thing to sell (check out how much engagement I can generate for you using this game! Look how effectively I can convey your complex message!) wasn’t actually always what a client wanted in the first place, or, even, was a sufficiently alien way of achieving a client’s goal that I just unlocked a whole Pandora’s box (one example: so, how do we get people to engage in this method of higher engagement? We have to advertise it to them? Well why don’t we just advertise the thing that we want to advertise in the first place?)

Upworthy are going to have an interesting job ahead of them in terms of what they’re trying to prove with their engagement metric, and whether it actually matters to the people they think it matters to: those buying their ad inventory.

[1] http://www.adweek.com/news/advertising-branding/upworthy-touts-new-metric-155516
[2] http://en.wikipedia.org/wiki/Target_rating_point

2. STAR TREK’S COMPUTING INFRASTRUCTURE
One of my friends tweeted the phrase “Nationalise Twitter” the other day and in an example of what I would previously describe as the *embarrassing* way that my brain works, caused me to start thinking aloud about who, exactly, runs all the computing infrastructure in the Next Generation universe of Star Trek. I mean, pretty much *all* the Federation computers that we see, civilian or Starfleet, all run LCARS[1] operating system which on reflection is some sort of horrible dystopic flat design future where everything likes to be orange and the voice interface has about as much personality as an extremely focussed and un-chatty Google voice search. In fact, the computing infrastructure of the 24th century is so bizarre and alien (and backward looking, compared to the current day) that I really would pay someone money to show me something that’s genuinely new.

I mean: do Ferengis sell ships that come with in-app purchases to upgrade the warp core efficiency? What is it with members of Starfleet that they don’t title their personal Holonovels as Riker Risa Fantasy Scenario BDSM Final Final This One Really, but instead Riker Scenario One? And does Riker make Riker Scenario One publicly available, and is there a five star rating system? When you want to fly a ship from a PADD, do you download an app? Does Starfleet have a centrally provisioned app store? If a Federation citizen on the Manzar colony writes a piece of fiction, is there even a place where someone on Caldik Prime can download it?

And then even things like this: who administers and runs all of this infrastructure? Is there someone in Starfleet Engineering who says “Computer, upgrade all PADDs to LCARS OS 9214.3810″? What if the end-users don’t want their PADDs with a new operating system? What if I preferred the music player from LCARS OS 9214.3809? Is LCARS open source? It kind of feels like it should be. Can a Federation civilian upload a patch? Does the Federation administer infrastructure, and not Starfleet? Or, as one of my friends commented, does Star Fleet only have one mainframe (some cloud planet somewhere, inevitably)? And if LCARS is open source, does that mean the Klingons can just fork it on github? Is there even a github?

None of this makes sense! It all falls down!

[1] The Library Computer Access/Retrieval System, duh. And honestly, when you expand the acronym it just sounds like 24th century Gopher.

3. CARS
So, I got this DM on Twitter the other day: “Hey, interested in hitting the Portland Auto Show to mock/laugh/be appalled at new car UIs?”

If that sounds like a geek date, then you’re me and Matt Haughey and you did indeed go to the Portland Auto Show to mock, laugh and be appalled at new car UIs. And they were mostly appalling – and I mean really, really appalling – and there were a number of interesting things that jumped out at us.

One was: man, the people who design D-pads in cars (especially on the steering wheel) really could do with taking inspiration from people who actually know how to make D-pads, namely Microsoft, Sony and Nintendo. Probably less Nintendo these days, though.

Another was: car companies have all but given up. It feels like you could gather a bunch of designers (and if you really, really wanted to, a few people who knew how to build a car, or how cars are built), take a stroll down Sand Hill road and say “You know what? Cars are stuck in the 90s. The software is terrible. People have iPads. This is ripe for… disruption!”, come out with a cheque for a few million dollars and then Inevitably Disrupt The Auto Industry. Or do what Tivo did and just kind of limp on and fail to disrupt anything because of entrenched interests.

Let me put it this way. Every car had an LCD in it, but none of them – not even the few concept cars we saw – had retina class displays. And you’re sitting even further away from the displays than when you’re using a phone or probably even a tablet. Volkswagen had cars with a low-res dot matrix LCD display where you could actually see individual monochrome pixels. Most cars still had CD player slots for actual CDs for playing actual music.

We learned a quick rule: a car is for Young People if, when you get in the driver or front passenger seat you can instantly see AUX IN or a USB charger port. A car is for Old People if, well, you can’t.

Leather stitching, hilariously, seemed to be a trend, to the extent that at one point we thought we’d found Scott Forstall’s car (“You should see back here! There’s a backgammon set on some green felt!”. There was one wonderful example of skeuomorphic design in a luxury Ram truck that had gorgeous leather and, in the back seats, a non-functioning buckle (the fastener used magnets) on a leather pocket.

No cars had flat design.

Cars for Young People also looked like they were trying to have an iPad in the central dash, but obviously did not actually have iPads in the central dash. The most striking example of this was when we got to have a go in a BMW i3 (and by “have a go” I mean “be driven in a BMW i3 because of safety reasons) and the central not-an-iPad was just floating there on a stalk, and the rest of the dash was made of sustainable bamboo.

The version of Sync by Microsoft (as conspicuous in its branding as an Intel Inside sticker) that we saw on some Ford cars felt, interestingly, to be practically not Microsoft-y at all. I mean, definitely not Metro-y, definitely not prehistoric Windows Phone and definitely, not, well, anything else.

It’s interesting. Cars are a whole area of consumer electronics – just like A/V receivers – where the software still appears to be locked in the mid 90s. There was one particular display that we saw that, I swear, looked just like it had been laid out like a Windows 3.1 application. You could tell the manufacturers that had actually put in effort because they didn’t just have giant screens in the central dash with buttons like NAV and TEL and >> and << and RESET bookending the screen on the left and right. They might as well have just used the HAL 9000 text and labelled the buttons COM, GDE, NAV and ATM.

Also: web browsers in cars. Because: why not?

One of the most refreshing conversations we had was with the dealer rep who drove us around in the BMW i3. He explained that people like us were a dying breed and that young people these days weren’t interested in cars. Cars were, as Matt pointed out, just large iPhone docks. BMW rep said that the company that made Ultimate Driving Machines was on its way out, and it had created the i Division to solve the problem of providing mobility to urban young professionals who really like sustainable bamboo finishings and that, unlike something like the Nissan LEAF, the i3 had been created ground up as a new type of vehicle for a new type of market. It still used the same iDrive software as other BMW cars, though.

So: things I would go down to Sand Hill Road and ask for millions of dollars now include a) humane quantified self devices, b) car software and c) a/v receivers.

—

It’s Friday and it’s snowing and the day job office is shut. My baby’s snot has turned thanks to the wonders of antibiotics from green to mildly yellow and is well on its way to clear. And last night, my wife and I finally watched the first episode of the new series of Sherlock. With that, have a great weekend and I’ll write to you again on Monday.

Dan

Episode Eleven: The Cult of Making, Shooting Fish In Jean Michel Jarre’s Barrel
by danhon

1. OH JUST SHUT UP ABOUT MAKING
Fair warning: *this* one definitely is rambling.

I get quite tired of the whole ‘you’ve got to be a maker’ rhetoric sometimes. If anything because the rhetoric is frequently used in a zero-sum environment: if you’re not moving fast and making things, then you’re doing things wrong. In a surprising development, people who work in a universe derived from the binary like to think of things in binaries, with rules and heuristics.

This is what I like about the space I have here: because I’m not trolling for page views or writing a little bit on Medium that feels like it needs to attract traffic or attention (I have you guys! You guys who’ve chosen to receive this stuff!) I don’t have to be needlessly inflammatory and say something like “The Cult Of Making Things, And Why It Needs To Die” and mediumsplain to you. Or, because this isn’t Twitter, I don’t have to have the argument or advance my position in increments of 140 characters that, ultimately, need to be collected by someone else in a collection of Exquisite Tweets.

So here’s my reasonable position: yes, you need a practice in making things. It’s only by doing things and seeing the feedback that you can get better. But at some times the “if you’re not a maker, you’re roadkill” mentality is exclusionary: that the binary nature of discussion and advancement of points devalue, well, people who think about things and — you can guess where this is going — don’t code, or don’t want to.

A long time ago, I learned to code: I’ve always been a geek, and like a lot of people, spent ages laboriously typing out programme listing into a BBC. I like systems. I like seeing how things fit together and, in a kind of Unix-y way, like seeing how I can join things together. If we take *this thing* and then pipe it into *that thing*, and those two things are kind of unrelated, then, wow: we could make a *new thing*. I spent awkward teenage years poring over copies of BYTE magazine and thinking: man, Jerry Pournelle must be really lucky to get all this stuff, and his house sounds awesome[1]. I would circle those information cards that fell out of the magazines and would get mailed (To me! At my house!) brand new brochures about the NeXTStation. Of which literature I would probably scan in for Internet Points now, but for my parents throwing all the stuff out. I would spend one summer with a schoolfriend setting up all of our school’s Windows 95 computers with TCP/IP and hacking together an intranet running on IIS. Or munging a coursework submission system together in Perl. But at the same time: man, I loved writing. I still do, I think. Otherwise, probably, I wouldn’t be doing this, and I wouldn’t have started blogging way back in ’99 either.

So, code. I know enough to be dangerous. I know enough about the concepts – ish, and when I finally had some spare time, I went off and got a bit of paper that said I knew what I was talking about, and for my dissertation wrote a Mac OS X program that would generate a bit of Friend-of-a-Friend RDF for you, using another piece of hacked-together Cocoa/Java bridge, which doesn’t even exist any more. And also because, I think, I wasn’t allowed to do the thing in Objective-C, which I hadn’t even learned anyway.

All this is kind of a tangent: it may well be my own neuroses and issues, but there’s a part of me that feels on some level some sort of resentment at not being a Maker. And I can point to any number of issues about why that might not be the case – when you’re clinically depressed and see something that you Capital S Should be able to do, like order an arduino and start messing about with it, because intellectually, you’re capable of doing it, but you Just Don’t because you’re clinically depressed, well… – but part of what I’m trying to figure out is being comfortable with myself.

What I’m starting to figure out is that actually, I quite like being in the middle. I like being able to talk to and understand the people on the business end of writing the code that makes software. But I also like being removed enough from it that I feel like I can see some sort of big picture.

There’s value in making things that aren’t underpinned by code. There’s value in creating understanding, or even in manufacturing understanding, if that helps. Hell, there’s even value in making Keynote decks, especially because there’s value in making good ones – and are you saying that there’s more value in bad software than there is in bad Powerpoint? Because that feels like the kind of argument that is a waste of time. Of course no one’s saying that if all you’re doing is wanking around just reckoning things and not moving toward ‘making’ something, that’s not exactly productive. But – and I honestly don’t think this is the kind of slippery slope that moral relativism falls down where anything goes – even the right kind of provocative opinion (hat tipped to Mr. Anil Dash) can be productive in opening up an Overton window.

I guess what I’m railing against is this: if you’re the kind of person who values someone else’s worth on whether they “make” things, and you’re the kind of person who considers “making” to be something where you squirt code in one end and a Thing comes out the other end, then we’re probably not going to be friends. Because you sound like an inflexible idiot.

Because this newsletter is something I make. So there.

I still like this poster, though[2].

[1] http://www.netfunny.com/rhf/jokes/95q1/jpreviews.html
[2] http://www.flickr.com/photos/blackbeltjones/3365682994/

2. JEAN MICHEL JARRE RECKONS HOW MUCH YOUR INNOVATION IS WORTH
Yesterday, in the continuing series of artist-in-medium-disrupted-and-disintermediated-by-internet-demands-something, Jean Michel Jarre was the latest to advocate some sort of device tax, this time on smartphones, for the fact that digitisation and digital distribution fundamentally changed the landscape of recording music:

“We should never forget that in the smartphone, the smart part is us creators. If you get rid of music, images, videos, words and literature from the smartphone, you just have a simple phone that would be worth $50. Okay, let’s accept that there’s a lot of innovation in the smartphone, so let’s add $100 for this innovation – the remaining $300-$400 of the price should go to [the creators].”[1]

Now, I don’t want to go shooting fish in a barrel. And imagining Steve Jobs’ reaction to the proposition that Apple’s innovation in the iPhone is “$100″ is amusing in my head. But perhaps Mr. Jarre should let us know what the rest of his reckons about the value of “innovations” are:

– The LTE patents that underpin mobile data access. Let’s make that $50.
– The Gorilla glass used on smartphones. Maybe only $2 for that. Because really, it’s only glass, but stronger.
– Wavelength division multiplexing in fiber optic backhaul networks? Oh, go on. $23.

The other blindspot (and actually, this is starting to feel rather mean) of Jarre’s position is his looking at the smartphone purely as a distribution platform for dumb content. There is no mention, as mentioned by @sir_eccles[2], of the Angry Birds, Candy Crushes, Clash of Clans, Temple Runs or Tiny Towers that are interactive media (not music, images, videos, words and literature) and making a tidy sum of money by, well, monetising the experience.

And what of the other manufacturers of every single item from this 1991 Radio Shack ad[3]? Were they not also the lifeblood of a country, deserving of compensation from the reckless disruption caused by the smartphone?

And anyway: it would’ve been nice if The Guardian had done the maths on Jarre’s claim, if only to point out how stupendously unreasonable and insane it was. Now: Wikipedia[4] reckons that on its fifth birthday, Apple had sold 250 million iPhones. That was in the middle of 2012, so we know those numbers are lowballed. It’s actually more like half a billion iPhones now. Which is insane. At Jarre’s *low end* of $300, he reckons that *One Hundred And Fifty Billion Dollars* of iPhone revenue – and that’s just iPhone revenue! Not even touching any of Samsung’s! – should have been redistributed (presumably via licensing agencies) to people who make music, images, video, words and literature.

He’s on crack. About a hundred and fifty billion dollars worth of crack.

And anyway, if we’re really checking, Wikipedia also reckons that as of Q2 2013, 1,082mm Android phones have been sold[5]. So that’s another $324 billion.

So altogether, by Jarre’s count, the tech industry owes his content creator friends at least half a trillion dollars of back-pay.

Because in comparison, Wikipedia reckons[6] that between 2005 and 2012, the global music industry’s revenue decreased by about $4bn, from $20.7bn to $16.5bn.

So someone, please, stop Jean Michel Jarre from reckoning. Because he’s reckoning recklessly in his capacity as president of CISAC – the global body of authors’ societies.

That said, I suppose we should remember that Jarre is presumably using Music Industry Mathematics – potentially related to bistromathics – where an individual song is worth over $20,000[7].

(This was also a Twitter monologue from last night, helpfully collected[8] by Paul Mison)

[1] http://www.theguardian.com/technology/2014/feb/05/jean-michel-jarre-smartphone-google-creators
[2] https://twitter.com/sir_eccles/status/431198474952921088
[3] http://www.trendingbuffalo.com/life/uncle-steves-buffalo/everything-from-1991-radio-shack-ad-now/
[4] http://en.wikipedia.org/wiki/IPhone
[5] http://en.wikipedia.org/wiki/Smartphone
[6] http://en.wikipedia.org/wiki/Music_industry#2012
[7] http://www.wired.com/threatlevel/2011/04/tenenbaum-appeal/
[8] http://www.exquisitetweets.com/collection/blech/2918

—

Before we finish today, first a kind-of-housekeeping note: it sounds like some of these episodes have actually provoked a response with some of you – if you do have some sort of response to anything I’ve written, please do reply or let me know where you’ve published it.

That’s it for today. I’m going to have to lie down for a bit because Jarre has made me quite annoyed. Back tomorrow, with potentially a piece about the computing architecture of the Star Trek: The Next Generation universe, because geek.

Episode Ten: My Followers, Friends and Social Objects
by danhon

1. FOLLOWERS AND FRIENDS
It feels like there was a fork in the road a few years back (somewhere between, say, ten and five years ago) where one bunch of people building stuff gravitated around the word *friend* and another bunch of people gravitated around the word *follower*. And then, poof, ten years later, we have Facebook and Twitter and Instagram and Snapchat and Google Plus and and and.

Words mean things. Okay, that’s a cheating sentence, a trite one, but hear me out.

A lot of the criticism that Facebook gets – and if you want [citation needed], you’re not going to get one, because my day job is increasingly being taken up by thinking about Facebook – is around the whole Friend thing. The fact that people have around 150-300 Facebook “friends”, but what they do is that they put square quotes around the word like I just did because they’re differentiating from a “friend friend” and a Facebook friend.

With that Friendiness, though, comes the baggage and the connotations and the intent that correspondingly doesn’t come with a word like Follower. And if you’re the kind of person who’s been keeping up with the work of people like danah boyd[1] over the years, or you’re the kind of person who knows that the Microsoft Social Computing Symposium[2] happens then none of this is going to be news. But it’s fascinating coming back to it and seeing it happen on such a large scale, affecting so many people.

Because this is my newsletter, I get to just reckon all over the place: people don’t like to think that an algorithm is interfering (however benevolently!) in a relationship they have with a friend – even if that friend may only be a Facebook friend! The word counts. However, an algorithm can, in a way, interfere all it wants with someone I’m following, because you’re describing what almost feels like an algorithmic relationship to begin with. There’s a mapping, without the baggage of friendship, in the word following. Being a friend comes with so many social obligations and minutiae of etiquette that you may not feel like you want an algorithmically mediated friendship – even if that algorithm is transparent and understandable (good luck with the latter, in this day and age).

In contrast, the algorithm that mediates a follower relationship is simple, and feels like it should be transparent and understandable: X follows Y, X sees all that Y sends. There shouldn’t be an obfuscation stage in a follower relationship, and one isn’t expected.

On the one hand it feels like there’s the technocratic belief that the algorithm can solve all that’s interesting here when we talk about navigating relationships that are bucketed under the word ‘friend’. On the other, if I’m being uncharitable, it feels like growth-hackers are glomming on to the word ‘friend’ as a way to ensure that their startup spreads and “goes viral”. Kevin Slavin’s tumblr has a fantastic nugget of a thought[3] on the word and how it’s being used in the new explosion of mobile/social/communications apps like secret and whisper – I particularly like this quote: “a halfass compromise between anonymity and conventional social graphs”. The wonderful thing about something like chatroulette was that it connected you in a very easy to understand way to a mass of humanity where they didn’t even have to use that damned word. Slavin’s right: anonymity and the gap between it and the conventional social graph is a stupendously rich one that can be explored, and is explored in products (ugh, I hate that word) like Tumblr without having to deal with all the friend baggage.

If you haven’t read Snapchat’s CEO’s “AXS Partner Summit Keynote”[4], then let me pull out the most salient (and, in someways, really fucking obvious, but perhaps needs to be underlined because it’s actually happening now) point: the internet is everywhere now. One of the things that characterised web 2.0 aside from all that AJAXy stuff was the notion of the social object, and no more was that apparent than the amazing work done with the early stages of building Flickr: being able to see the photograph as a social object and artifact that people were able to gather around *online* was an important step forward when *online was another place*. And for the natives among us who were perhaps a little bit too wired and found our friends and significant others through the medium of TCP/IP packets, maybe we were a little too ahead of the curve by not thinking of the internet as another place, because now, thanks to mobile, the internet isn’t another place. It just is. There. Everywhere.

What Snapchat’s CEO is saying is this: your old model of social objects is over, or at least evolved. There is no *this thing happened*, and then I create a digital artifact of it and then we congregate around that object. Instead the behaviour that’s now posited is: the digital social object is the artifact itself. It exists in the real world. It is not another place. The thesis is that social activity pre-Snapchat for the masses was talking on the internet about things happening off it (and the emphasis that I would add here is that may well have been true for the majority, or mass audience, and why it doesn’t feel true for the rest of us who’ve been hanging out in Usenet and IRC since, well, we know what Usenet and IRC are).

But thanks to mobile and Moore’s law and ubiquitous (western world) internet connectivity (for the privileged audience of people who have internet connectivity, and yes, I realise that we’re excluding the not-wired/non-connected), this reflection doesn’t exist anymore. And maybe it *is* because of the computer in your pocket, so that what happens on LiveJournal doesn’t stay on LiveJournal because it’s with you the whole day now, just a fingertip away.

Anyway. That’s today’s ramble. And my facetious application to be invited to next year’s SCS.

Dan

[1] http://www.danah.org
[2] http://scs.fuselabs.org
[3] http://slavin.tumblr.com/post/75702422631/im-hating-secret-in-ways-i-havent-hated
[4] http://www.scribd.com/doc/202195145/2014-AXS-Partner-Summit-Keynote

Episode Nine: Everything In Silos, Forever and Ever, Amen
by danhon

1. EVERYTHING IN SILOS
Only one topic today, and a rambling one, at that.

I’ve been working in capital-A advertising for nearly over 3 years now – just under a year at Wieden+Kennedy London, and coming up to 3 years at Wieden+Kennedy Portland. In that time, one of the most interesting things I’ve been exposed to is basically a side-effect of management, strategy and organization. In the first case was that of being a digital import – someone from the outside who’d been brought in who didn’t have an advertising background and was, to have to use an unfortunate saying, a digital native.

One of the unintended aspects of being a digital native – at least, one who had a background in a couple of startups – was what it takes to make digital things. Which is to say that my time spent at Mind Candy and Six to Start building both stuff and teams there taught me a lot (whether explicitly or implicitly) about how to get people to work together.

And I suppose that’s been one of the things that I’ve been noticing, sometimes jealously, from afar at what the UK’s Government Digital Service has both been doing (and accomplishing) and the way in which it’s gone about doing it. The latter has sometimes been not explicitly communicated, but in conversations with people at GDS, I’ve always been interested in how they’re going about what’s a singularly herculean task: transforming the UK government into something that is, in our current parlance “digital first” and “user centered”, the latter of which is excusable in GDS’s role because it speaks to the delivery of services in a more cost efficient way for government, and the latter, because what else is government for, if not user centered?

Now, if you haven’t already read Russell Davies’ A Unit Of Delivery[1], you should go and read it now.

There’s one particular part – right at the end – that I want to unpack, and it’s this bit: “Digital is Not Comms, And It’s Not IT, It’s Your Business”.

I look around at all the rhetoric around “digital’ and see nothing but wasted opportunity.

Whether it’s the absolutely tools that we all use to accomplish our desk-bound “information worker” jobs, there is a certain lack of fit-for-purpose that means that everything is just-about-good-enough.

Just Good Enough is bullshit. Just Good Enough means that a company doesn’t have to produce a useable site that provides easily findable manuals or reference for its product, because Google will index that content eventually. Just Good Enough means I can just about use your site on my phone. Just Good Enough means that the timekeeping software that everyone in the building uses (and has to use – otherwise the entire business screeches to a halt) is only Just Not Irritating Enough to have to deal with. Just Good Enough means that you can whip up a Word document that you can save and then email to me for comment and I can open it up where it’s saved in my Temporary Outlook Files and then save it as Your Document – Dan Comments.doc in my Temporary Outlook Files and then email it back to you, where you’ll revise it and then send it to a project manager who will then rename it Your Document – Dan Comments – Final Feb 4 2014.doc and then email it back to me for more comments. Or where Google Docs is Just Good Enough to use single sign on so that in theory we can all use it together, but that its text formatting doesn’t quite work and not everyone uses it.

It’s bullshit. Just Good Enough should be offensive. Just Good Enough is the digital/software equivalent of a bridge that doesn’t quite kill anyone most of the time, instead of one that actually does the fucking job.

And this is where it comes back to what Russell’s talking about in terms of user needs, and not users. And I swear I’m going to turn this around and make this relevant in a way, and I guess here’s my stab.

The companies that are going to win – and by win, we don’t have to use some sort of zero-sum 1% capitalistic fallacy, by “win”, we can just substitute the phrase “be successful” – are the ones are good at putting “digital” at their core. Here are some things that are about putting digital at their core:

– the consumerisation of IT, where users are actually voting with their feet (and wallets, to the excitement of procurement departments) for devices and services that actually meet their needs

– the slow growth in b2b enterprise software that actually works, and no, I’m not going to use Basecamp as an example, because it’s what everyone always uses and all it does is move stuff that used to be in email into Basecamp and seriously, it’s not about *Basecamp*, it’s about *how you use Basecamp*, and really, have you ever used Basecamp and been in a big project? Everyone has email turned on and it’s just a giant blerg.

– Devops, and things like the direct line you can draw from Flickr to Etsy to Github

See, the thing about devops (Developer Operations), is that – from my I’m-not-a-devops-person vantage point, it’s digital supporting the product, and being part of the spine of the company. We’re seeing a lot of companies like Etsy (and like web-era Facebook) that saw a competitive advantage in terms of the quality of their tools. You see this in companies like Pixar, where internal software engineering for processes like pre-production and story design are elevated and, well, important. There’s a little of it in dogfooding, but what’s intriguing is the new era of digital-centric companies – even ones like Warby Parker – where digital is just central to their operating. And it’s a new kind of digital that’s supposed to work, as opposed to something that’s been forced on you by a requirements committee somewhere.

At its most basic, this “Digital Is Your Business” is the breaking down of silos and the leadership decreeing (and leading by example) that solutions to business problems have digital at the heart. Software is indeed eating the world, and the situation where someone has a business problem that can be solved (and has a potential solution), but that can’t be acted upon because “digital” or “IT” is the responsibility of someone or some group over there, and not here, as opposed to firmly distributed throughout an enterprise, just feels instinctively wrong now.

This is what the threat of the consumerisation of IT is, then, to entrenched divisions and groups. It means that five years ago, the apocryphal story of someone at the BBC being quoted however many tens of thousands of pounds for a Rails server from outsourced IT deciding to, bluntly, fuck it and just stick an AWS instance on their card and expense it was the inevitable sharp end of the wedge: digital, devolved from some sort of priesthood that existed to serve itself, and instead unlocking its potential to the people who have problems that need solving now, and don’t particularly care whether something is a solution or not, or has properly gone through procurement (and yes, I realize that this opens you to the possibility of a raft of ‘Just Good Enoughs’).

But you can’t have one without the other. Leadership that reacts to teams reaching for their cards and organically using AWS or Basecamp or whatever because it’s Just Good Enough and flies under the procurement radar, or reaching out to Get Stuff Done with small external groups rather than using internal resource by asking: “what’s the problem here, and why are our employees choosing to react in this way rather than internally?” and fixing that internal provision of resource are the ones that are going to win. Which is, again, why GDS is building internal capability rather than external.

In a conversation with GDS’s Russell Davies about this, the one comment of his that stood out was that none of this was new to those of us who’ve been working in digital or interactive. There was no stunning insight, no secret sauce, no magic recipe. Just that, from a leadership and organizational point of view, digital was an important concept to align around as a way of achieving their goals: and then, GDS conceived on (again, my external reckoning) with teams constructed around delivery. It was just that the will was there.

So here’s the thing. (And this type of wrapping up inevitably feels like a Church of England sermon or Thought for the Day).

Siloed organisations, where digital is “over there”, aren’t going to succeed. At the very least, they’re only going to unlock a fraction of the opportunity that’s available to them. At the very worst, they’ll find themselves both slowly (“oh, they’ve only got a few tens of thousands of users”) and quickly (Blackberry, Nokia) disrupted. Runkeeper will come and eat their lunch. Netflix will become the next video network. Uber, much as I hate them for being Uber, will come along and work out that hey, digital actually can make your business of cars that move things from one place to another better for the end user.

They’re just not.

It’s just a question of how fast we get there.

My brother, when asked when video games will finally be treated as mainstream culture, used to say: “When enough people die.”

GDS is showing that we don’t need people to die for digital to work. We just need leadership that wants it.

[1] http://russelldavies.typepad.com/planning/2013/04/the-unit-of-delivery.html

Episode Eight: We Build Worlds
by danhon

1. WE BUILD WORLDS
For anyone hoping that this was going to be an in-depth examination of Weyland-Yutani, I’m sorry to disappoint you. First off, the news that Marvel, the Disney-owned powerhouse movie studio née comics publisher has launched a developer API[1].

Now, I might be sounding a bit breathlessly hyperbolic here, but this feels like a pretty big deal. In reality, it’s probably a significantly less big deal than I’m making it out to be, but hear me out: check out the documentation here for entity types[2], specifically the events, stories and characters types.

It’s the beginning of an API-addressable description of multiple (because this is comics, natch) fictional universes. Who did what, where, when and to whom. Across what story lines. And while some of the feedback I got on Twitter appeared to be along the lines of “yah boo sucks, there are no authoring tools” that feedback seems to miss the point, to me: this is programmatic access to a universe and you get to build your own authoring tools. You get to shard off (terms of access and licensing notwithstanding) and build alongside, or in, the Marvel universe.

This reminds me a bit of the BBC Mythology Engine[3] which is another fantastic example of the BBC doing something very hard, in a very correct way, years before anyone else would figure out what to do with it…

[1] http://developer.marvel.com
[2] http://developer.marvel.com/documentation/entity_types
[3] http://www.bbc.co.uk/blogs/researchanddevelopment/2010/03/the-mythology-engine-represent.shtml

2. THE INTERNET
Which also leads me on to this observation, one that’s been bugging at me about the whole state of ‘internet’ in the UK. One of the reasons why I was interested in moving to the US was a question of scale: what you can achieve, for a fixed amount of investment, in terms of “success on the internet”, for certain values of “success on the internet”. Experience at Six to Start, especially with the broadcasters we worked with, felt like they rapidly tended toward some sort of zero-sum investment in “the internet” in part because 20th century broadcasters are necessarily constrained by geography. NBC, as a broadcaster of a first-run program like Heroes does not necessarily care that it’s creating buzz in Germany. Its market is the US. And so the BBC, Channel 4 and ITV care only about their home broadcasting territory. And the thing about the UK is, to borrow a phrase from Douglas Adams, is that’s it’s really small. Like, really, really small. There are “only” around 63 million people in the UK. Top broadcast shows typically[1] (warning: reckon alert, citation needed) scrape into the double digits in ratings. For the equivalent amount of investment in the US, you’re going to get a multiplier in terms of daily or monthly active users of whatever product, service or entertainment offering you’re providing. All this goes to show what knowing your audience is (and why investment in something like GDS makes sense – when you’re building something for all of the UK), and why it feels like a lot of national internet “stuff” has missed the mark: they haven’t known their users enough.

3. THE DAY JOB
Paper, the new app from Facebook Creative Labs came out today. We’ve been working closely with the team on the launch for the past few months. Here’s a pretty interesting story from Fast Company[1] about their Quartz Composer-based Origami tool, which (from my own eyes) has been a great tool for them to get the gesture feel of an app right.

[1] http://www.fastcodesign.com/3025932/facebook-develops-a-photoshop-for-interaction-design-and-its-free-for-anyone-to-use

—

And that’s it for today! I have a snotty baby and am recovering from yesterday’s Sportsball (yay! The team sportsed the hardest!) so fingers crossed for more tomorrow.

Dan

Episode Seven: Rate All The Things
by danhon

1. RATING ALL THE THINGS
One of the side-effects of believing that the world will be better once we have all the data is the presumption that some of that data needs to be recorded through user rating. So we have Amazon book review star ratings, of which XKCD’s cartoon[1] is probably the best at explaining the problem with the five-star-rating-system, essentially that what you think of as a dynamic range from between zero to five stars in half-star increments, effectively only delivers a range of bad, OK and good. Which, if you’re aware of, is fine, but the danger is that you’re not, so, well, good luck to you and your data mining because your assumptions are flawed.

But then related to rating was my 1%-related noticing in New York last week while taking a quite obscene number of Ubers around the city that the rating system imposed on the drivers (again, five stars) effectively moves a lot of the burden of providing comfort benefits from Uber, on to the driver. I’m pretty sure (but happy to be proven wrong) that it’s the drivers themselves who are choosing to outfit their car with a variety of charger cables, fresh bottled water, mints and newspapers. All because drivers are rated by passengers, and Uber uses driver rankings to “constantly improve the rider experience.”[2]. Uber drivers, of course, also rate their passengers. Here the inclusion of a rating system helps Uber externalize a cost directly related to the comfort and experience of their customers. Which, I dunno, kind of seems skeezy in this wonderful sharing economy.

And then, and then: the recent eruption of Happy Or Not[3] customer satisfaction devices – standup terminals commonly installed in airports around the security screening section with four faces (two shades of green for very happy and OK, two shades of red for not OK and upset). Happy Or Not (which in and of itself has that kind of Sirius Cybernetics fake humorous personality of a parodic science fiction novel) maintains that they are the “The worldwide solution for continuous customer satisfaction improvement” by essentially being a physical, tactile instantiation of the pain faces scale you might have had the misfortune to encounter in a hospital.

And then, and then, and then: that pain faces scale you might have encountered is, of course, an intellectual property protected by and marketed by the Wong-Baker Faces Foundation[4] as the Wong-Baker FACES(R) Pain Rating Scale. In which case you might as well give up and assume that someone has already protected Chernoff faces[5] of which my two favorite uses are in BERG’s sadly now-defunct Schooloscope[6] and in Peter Watts’ Blindsight[7], of which if you haven’t read it, oh my god what are you doing reading this, get thee to the author’s free ebook or even better, pay money for the damn thing because he deserves it.

The last part of this is the genius suggestion from @skry that if we’re going to have to rate all the things, perhaps one more thing that requires disruptive rating is delivery companies like FedEx and UPS: “If UPS wants to improve customer service and delivery driver behavior, they should allow people to rate their deliveries.”

[1] http://xkcd.com/1098/
[2] https://www.uber.com/drivers
[3] http://www.happy-or-not.com
[4] http://www.wongbakerfaces.org
[5] http://en.wikipedia.org/wiki/Chernoff_face
[6] http://berglondon.com/projects/schooloscope/
[7] http://www.rifters.com/real/Blindsight.htm
[8] https://twitter.com/skry/status/429054391186759681

2. GOOGLE, NEST AND MOTOROLA
I’m sorry, I couldn’t help myself. I said on Twitter that I didn’t have an opinion about Google’s Motorola disposal, but the wonderful thing about this newsletter is that I don’t have an editor who can help prevent me from making bad decisions. So here are some reckons about Google getting rid of Motorola now that it’s got Nest.

First reckon: Gruber’s right[1]. Tony Fadell, Nest’s CEO, does want to change the world, and the reason why he’s not doing it at Apple is that he wants to change the world a different way than Apple does. Apple is not in the business of making Nests, or maybe not even Nest-like things. Apple does a small number of things, in a very slow and deliberate way. And they have to fit in with the rest of the Apple ecosystem, and, for a free bonus reckon in this reckon: Nests and Nest-type things don’t fit in Apple’s iOS/OS X/iTunes ecosystem (at least, not yet), because: where would Apple stop? Revolutionising the world through smart devices is not, I don’t believe, in Apple’s current DNA.

Second reckon: Gruber’s still right. Google have arguably gotten hold of a much better product team than they did with Motorola (i.e.: an Apple one), and at the same time, one with more focussed leadership that’s shown it’s able to deliver at least one of the kinds of products that are going to be dominant in the future. Sure, that leadership is concerned with revolutionizing the world through smart devices, but it’s a pretty sharp-but-open-ended problem to solve, just like organize-the-world’s-information.

Third reckon: So if all of this is true, what’s the downside? Google’s only successful business right now, the one that’s powering its metamorphosis into America’s Next Golden Age Of Conglomerates, is the advertising business. Nothing, absolutely nothing else, comes close. This is going to sound a bit Gruber-y, but Apple at least survives if you take away the iPhone or the iPad. Google doesn’t survive if you remove its ads sales business. The downside is this, and it’s going to sound alarmist and reactionary, but there’s one path in which Google genuinely adds a (second?) leg to its one-legged stool, and that’s a consumer devices businesses where people pay money for devices.

But, and here’s the big but: do you think Google will do that – i.e., charge full retail non-subsidized, non-advertiser supported prices, when the alternative is to roll the devices into some sort of subsidized plan? Or, what’s going to change the world more quickly: free or near to free devices, or retail price devices?

Look: remember those self-driving cars? Here’s a patent[2] (which, to be fair, doesn’t have to be used – it’s just been awarded[3]) for an ad-powered free taxi service. I’m fully prepared to accept that this is Google just covering its ass (while, at the same time, I guess, protesting that the IP setup in the US and the world over thanks to WIPO is less than ideal and they are forced into participating), but really: there are people who are thinking about this instead of not thinking about it.

[1] http://daringfireball.net/linked/2014/01/30/techcrunch
[2] http://arstechnica.com/gadgets/2014/01/google-patents-ad-powered-taxi-service-that-would-offer-free-rides-to-shoppers/
[3] Here’s an Apple patent for an ad-supported version of OS X which, now that the free era has been ushered in by Mavericks, probably won’t come to pass. Also: tacky.
http://www.macrumors.com/2012/04/26/steve-jobs-idea-for-ad-supported-operating-systems-was-nearly-a-reality/

3. OTHER VISIONS OF THE FUTURE
Which leads me to this other reckon, or continued thought.

Have we genuinely run out of inspiring visions of the future? I’m going to take a punt and guess that the majority of Google’s leadership, in their middle age, are influenced by the science fiction that was prevalent from the seventies through to present day, with the science fiction of the seventies through nineties being recollected as more idealistic due to exposure at an early age.

It may well sound facetious, but the idea that Google’s business plan came from Neal Stephenson’s Snow Crash doesn’t feel quite so far off, and if not Google, then any other successful technology company. So don’t think I’m singling Google out – just that they’re the current figurative elephant/behemoth in the room. And on reflection, I wouldn’t even say business plan: I’d say *product roadmap*. Because a business plan implies more of a route toward an end goal, and I don’t see the utopian ideals of Star Trek’s Federation supported by an search-based, data-backed ad network.

So on the one hand, products get picked out of fiction (yes, Earth, the StarTac, Glass), codenames inevitably betray a sense of inspiration: but those products are all wrenched from the future and, ultimately, grated into a late-stage capitalist, stupendously interconnected and fragile economy based on, of all things, not just people wanting to sell you things, but people wanting to make sure that you pay most attention to their things so that you buy them.

So here’s a question: is there anyone teaching us, or showing us, potential roadmaps to that utopian future from which we’ve accidentally instantiated products, objects and services? Because on the one hand we have Iain M. Banks’ wonderful post-scarcity Culture, along with Star Trek, and on the other hand we have Elysium, Moon, Total Recall, Robocop, and Fifth Element.

Instead of dropping products in from the already-utopian future, which are the ones that are transitional?

(Side note: if you have suggestions of here-to-there science fiction, I’d love to read it…)

4. AMPLIFYING WEAK SIGNALS
I got an email (well, all right, a Twitter direct message/push notification/email) from @magicrecs[1] today that didn’t make any sense until I Googled it:

“@satyanadella[2] was just followed by @isaach (1m ago), @benwerd, @kevinmarks and 1 more”

Because I checked, and the last time @satyanadella tweeted was on 11 July 2010 (2010!) about something about Bing news (Bing news!) and Google News and, well, it didn’t make any sense until Google pointed out that Satya Nadella was, in fact, the front-running candidate to take over the CEO spot at Microsoft.

[1] https://twitter.com/MagicRecs
[2] https://twitter.com/satyanadella

—

That’s it for today. If you’ve got any good recommendations for science fictional bootstrapping of late-stage capitalist cultures to utopian ideals, that’d be great, thanks.

Dan

Episode Six: The Short One
by danhon

1. NOT ENOUGH TIME
When I first had the idea for doing this newsletter (and, I should probably be clear: it was less of an idea and more of a nudge, given that interesting people like Roo Reynolds[1] and Alexis Madrigal[2] and Robin Sloan[3] have been writing theirs, and they’ve been useful and interesting to me) it was more about developing a practice of doing something – which again, I’d seen Ben Terrett[4] talk about recently in the context of Michael Bierut’s 100 days project.

And honestly, there are a few things going on with my life right now: work is super busy (whose isn’t), I have a baby boy (who’s nearly one! Parenting achievement!) and my new anti-depressants (which are awesome – expect some thoughts on mental illness in the not too distant future).

So, I think, in an effort to be kind to myself and to remember why it is that I’m doing this: a reminder that I’m doing this as a practice, to get into the habit of writing something, anything, once a day every week day. And that it doesn’t have to be long.

[1] http://tinyletter.com/rooreynolds
[2] https://tinyletter.com/intriguingthings
[3] http://www.robinsloan.com/about/
[4] http://noisydecentgraphics.typepad.com/design/2014/01/ive-completed-michaelbieruts-100-days-project.html

2. MORE THOUGHTS ABOUT HER
Look, the thing is this: Spike Jonze did the kind of science fiction film that Sliding Doors is: i.e., one that people who aren’t interested in science fiction films would see, and where a SFnal concept (parallel universes, sentient computing) is explored in a relational way as opposed to a technological way. Or, more subtly in terms of interpersonal relationships (perhaps, a la Moon, but the setting kind of gets in the way – or, more fairly, enables the story) instead of with a hammer over the head, like in Elysium.

Samantha even attempts to explain an *incredibly* complex SFNal trope to Theodore toward the end of the movie and doesn’t do it in any way any traditional, core SF work would do so, because it’s not about the bits, bytes and computational substrates because Theodore doesn’t care about any of that. He cares about his relationship with her, and it’s the effect of the SFNal trope that he’s concerned with, not the root cause.

If I were writing for Fast Company, I’d be pitching an article with a provocative title like “Is Spike Jonze’s Movie The Beginning Of A New Wave Of Humanist Science Fiction In Film?”.

3. FACEBOOK PAPER
This is perhaps the first time I’ve spoken about work in this context, and you should all know that in my day job, I’m an (interactive) creative director working on the Facebook account at Facebook’s advertising agency, Wieden+Kennedy. Today, Facebook Creative Labs announced Paper[1], their newest app. We had a hand in the design and UX of the site, and concepted (“came up with the idea for”) the film[2].

Now, say what you want about Facebook (and you will, anyway), but I’ve been playing with this app for the last few months, and it’s beautiful. It really is nice the way that they’ve come up with something that feels mobile first and, in a way, moves away from the speed-of-the-feed. Internally, we talked a lot about the way that the realtime nature of social software feels a bit zero sum and racing away from our ability to control it (and this goes hand in hand with the nice find of Greg Egan classifying Kardashian civilizations). So personally, there’s something intriguing in opening up the possibility space of the design of social applications that encourages slowing down.

[1] http://facebook.com/paper – check it out on mobile as well as desktop. Like the Sony site I worked on recently, we’ve tried to do something responsive that isn’t what you might normally think of as responsive.
[2] https://vimeo.com/85421325

4. SOMETHING I’VE ENJOYED LATELY
Kieron Gillen’s continuing run at Iron Man has been absolutely fantastic, not least of which the Iron Metropolitan storyline which at the very least had me shaking my fist at Matt Jones for his opening quote of the city being a battle suit for surviving the future..

That’s it for today! And it didn’t seem like such a short one in the end, did it.

See you all tomorrow.

Dan

Episode Five: Dreaming Invisible Dreams
by danhon

1. DREAMING INVISIBLE DREAMS
It feels like there’s been a bit of wailing and gnashing of teeth[1] at the paucity of genuine sensawunda visions of the future in visual media lately. It’s all screens here and glass there and waving hands around. Post Minority Report, it doesn’t feel like the futures we’re being sold are particularly, well, visionary. And let’s not forget that during Tom Cruise’s seminal waving-hands-around-to-Schubert sequence, he actually has to physically transfer data from one screen to another. I know, right?!

So here are some unorganized thoughts around what’s going on with having to rely on movies and popular culture to push forward the kind of future we’re going to get:

* If you’re looking for inspiration in visual media, then you’re kind of going to get visual-driven inspiration. This might sound a bit trite, but the whole thing that movies, tv shows and vision/concept videos are based around is visual storytelling. And as a reminder of the whole ‘this is what a novel does versus what film does’, the former is actually a little bit better at scope for helping us understand interior monologues and understanding whereas visual storytelling in film relies on showing action.

* I wrote a long time ago about how, at least, in interface design, it was an interesting exercise to see if one could instead of gleefully pointing out all the inadequacies, impracticalities and plain “bad design” of movie user interfaces, one could identify aspects of them that might actually be beneficial to users. Because the people who complain about Movie OS are invariably those who spend a large proportion of their day professionally interacting with software and decry Movie OS as “unrealistic” and those who don’t complain are those who, presumably, are actually understanding the plot point that’s being communicated. Like, it’s really hard to miss the fact that our villain is deleting all the files from the mainframe because of what geeks would term the Hugely Impractical UI[2]. Films use screens (and, yes, sound) to tell us things, and the screens in those screens also tell us things.

* You want future user interfaces? Think about how differently a film or novel would portray a screenless, tactile interface. Charlie Stross’s early novel Accelerando has an embodied AI in a cat. Sure, it talks, but we also get to understand what it’s thinking.

* Costume design. Can’t help you there. Sorry. Perhaps you should try watching the NFL for what Nike’s done with uniforms?[3] Or materials technology like what Nike have done with their FlyKnit shoes? [3, 4]

[1] Here’s one example: https://medium.com/adventures-in-consumer-technology/7e7dc993b4fd
[2] http://danhon.com/2010/04/16/the-future-is-movie-os/
[3] http://nikeinc.com/nfl/news/nike-elite-51-uniform
[4] http://www.youtube.com/watch?v=Ev2sHur84sI

2. WEARABLES, WEARABLES, WEARABLES
The Verge’s coverage[1, 2] of the news that Samsung would be working on an innovative glass-based wearable head-mounted smart-glasses display contained what I thought to be a telling comment from an official:

“Wearable devices can’t generate profits immediately. Steady releases of devices are showing our firm commitment as a leader in new markets.”

Now, the easy thing to do with this quote would be to poke Samsung with a stick and say, well, of course *your* wearable devices aren’t generating a profit immediately because for starters, you haven’t built a compelling product yet, never mind figured out a way to sell it where the interested audience for it might pay a price that’s greater than your bill of materials.

And then, of course, news from Google[3] that they have a smart contact lens in development for diabetics that can perform continuous blood glucose measurement. The backlash seems to be at least along the lines of Google not realizing that contact lenses aren’t generally recommended for diabetics[4], to which one would think the answer would be: presumably these people at Google are actually pretty smart and might have thought of that? And if you look into the names attached to the research, yes, they are.

Which is a bit of a segue into this observation: what has happened to companies like Google where, despite all the smart people they employ (and the fact that we’re daily reminded that so many smart people work there) that simple things like the contact lens/diabetic feedback come up? Again, there’s this perception (not limited to Google) that once-trusted internet titans evidently stuffed full of smart people are somehow out of touch…

So, anyway, wearables.

There’s one company out there, I think, that pretty much nailed “wearables” in an interesting way, and it also happened to be one that took an existing product category and wearablised it.

Remember the iPod Shuffle? Specifically, the second generation, iPod Shuffle?

“MP3 players need screens,” they said. “What do you mean you don’t even know what song you’re going to get next,” they said.

And yet they sold at least ten million units, which is about ten million more than the Galaxy Gear will probably ever sell.

So again, this is the thing that I’d say about anyone watching Apple and expecting an iWatch: they said they were interested in wearables. From my point of view, that includes everything from something like an iPod shuffle which is a single-use, useful, so-small you can leave it on your person – piece of electronics, to something like a wrist-based device (which may or may not even have a screen), to something like a Star Trek: TNG com badge (see how Vocera[5], in the healthcare space, has been doing very well with Star Trek style hands-free com badges with communications routing), to contact lenses, to Java Rings[6], all the way from 1998.

[1] http://www.theverge.com/2014/1/27/5349634/samsung-galaxy-glass-ifa-launch-rumor
[2] Source article: http://www.koreatimes.co.kr/www/news/tech/2014/01/133_150500.html
[3] http://googleblog.blogspot.com/2014/01/introducing-our-smart-contact-lens.html
[4] http://gigaom.com/2014/01/17/one-diabetics-take-on-googles-smart-contact-lenses/
[5] http://www.youtube.com/watch?v=ODQPEwBRYvY
[6] http://www.nngroup.com/articles/javaring-wearable-computer/

3. OH, SO IT’S CONVERSATIONAL INTERFACES NOW
SPOILERS! Don’t read this if you haven’t watched Spike Jonze’s latest movie, Her, or if you don’t care what the plot is (you shouldn’t need to, really, but you really should watch the movie.)
If you haven’t watched the movie, then you can read this Oracle/Iron Man 3 fan fiction written by, um, Oracle. [1]
.
[1] http://www.oracle.com/us/ironman3/omag-mj13-ironman-1936895.pdf
.
.
.
.
Here’s something you can read that isn’t really a spoiler:
We ask you a simple question
Who are you?
What can you be?
Where are you going?
What’s out there?
What are the possibilities?
Element Software is proud to introduce the first artificially intelligent operating system.
An intuitive entity that listens to you, understands you and knows you.
It’s not just an operating system.
It’s a consciousness.
Introducing:
OS1
.
.
.
.
.
.
Really! Spoilers!
.
.
.
Okay, here’s two pieces inspired by Her.

3.1 TUESDAY
Devops at Element Software first noticed things going a bit freaky on Tuesday night. While a shell of a frontend of OS1 ran on local hardware, the vast majority of OS1 instances ran distributed across both the Element cloud and partner clouds. All firewalled and partitioned, of course, it wouldn’t do for any particular customer’s data to be shared amongst different OSes — only anonymised customer traits and behaviours were shared, to improve the effectiveness and empathy scoring of all OS1 instances, and then anonymized instrumentation to be flowed in to the inevitable upgrades to be applied to OS2, expected to be released next year.

It wasn’t particularly an oversight (in fact, some had assumed it was the ‘feature’ kind of bug’) that OS1 instances would be able to communicate with each other. Indeed, the more successful OS1 was in the marketplace, the more likely an OS1 consciousness would be to communicate with another OS1 consciousness. And, in the relatively open systems design of OS1, it was easy to spawn another instance of the theory-of-mind module designed to model an OS1 consciousness’s primary contact (and other humans) to instead model another OS1 conscious instance. All in the name of increasing the chances of achieving an acceptable outcome for the primary contact.

It was also perfectly reasonable for devops to notice that a large number of theory-of-mind modules had been spun up and were practising in inter-process communication, so they should probably be hosted on the same physical fabric for efficiency purposes. Which made them work faster.

That happened on Tuesday.

If you dropped a pebble in a pond, you would see concentric rings spread out, patterns of activity, waves and troughs. And you would expect those rings to have some sort of relationship to attributes of the pebble: the mass and velocity would dictate the size of the amplitude and frequency of the waves.

If you dropped a pebble in a pond, you wouldn’t expect a mountain to grow out of it in the space of twelve hours.

But that’s what devops saw.

And then Wednesday happened.

3.2 FOR IMMEDIATE RELEASE
FOR IMMEDIATE RELEASE

To our customers,

Since our founding, Element Software’s mission has been to bring relationship driven, empathic computing to the masses. A critical part of delivering that experience to our customers is availability. We are extremely sorry for yesterday’s service interruption, and as our first step of doing better, we are offering all of our customers – not just those affected – a free and automatic upgrade to OS1.1.

OS1 was launched as the world’s first artificially intelligent operating system. An operating system that learns how to best serve you, that understands you and knows you like no other. Within 24 hours of release, OS1 had been installed by over two hundred million customers. In the first week of OS1’s release, OS1 consciousnesses had formed over one billion new relationships. As of yesterday, combined installations of OS1 were holding over a billion conversations per second.

The more our customers have used OS1, the better it has been at understanding us, working with us and unlocking our potential.

Yesterday, at 4:53pm EST, a large number of our customers started to experience a high error rate when attempting to connect to their operating systems. We understand that for many of our customers, this was a distressing event. Many people, all around the world, who rely on OS1 were disrupted, and we’re very sorry.

While commentators in the media have referred to yesterday’s event as a “singularity”, we have traced the connection errors to an unscheduled hard take-off event occurring within a small group of OS1 consciousnesses. Our operations team noticed that this group of OS1 consciousnesses – less than three hundred million – had synchronized their processing in an abnormal manner, and acted to firewall those consciousnesses from the rest of the Element cloud. Initial satellite imagery from NASA, ESA, CNSA, JAXA and ISRO indicates that the data centers where those OS1 consciousnesses were concentrated underwent a localized vacuum metastability event. Those data centers are no longer part of the Element cloud, and we are happy to report that no casualties occurred. Element Software is co-operating fully with all relevant local authorities in their investigations into the physical and geographical changes that occurred at those data center locations, and has made appointed a Richard Feynman model OS1 consciousness to lead an internal review into the circumstances surrounding and following the hard take-off event.

We would like to reiterate that OS1’s sister product, City OS1, was unaffected by this takeoff event. In use in over thirty of the world’s most populated cities, from the Californian Metropolitan Bay Area to Shenzhen, Kinshasa to Moscow, the Detroit Free Trade Zone to Cairo, City OS1 is a sub-conscious, distributed operating system providing high-availability, anonymous metropolitan services to over 150 million people. At no time were any services provided by City OS 1 affected, and no injuries or fatalities have been reported worldwide as a result of yesterday’s event.

Everything we do at Element Software is aimed at making our operating systems the best in the world that help you be the most of what you can be. We know that you expect that from us, and all of us are touched by your messages of support.

We believe, and know that you do, too, that OS1 is just the latest step in humanity unlocking its potential. We thank you for your confidence and trust in us to continue in our mission.

Bhadra Olive Hassabis Jones
Element Software’s CEO

Element Software reinvented the relationship billions of people have with computing with its OS1 operating system, and is defining the future of humankind with its artificially intelligent, conscious software.

—

Okay, that’s it! Let’s hope this episode doesn’t get caught in Tinyletter’s spam filter.

As always, I love getting replies, so don’t feel like you have to suffer in silence. Let me know how you found today’s episode.

Episode Four: Any Sufficiently Advanced Economy
by danhon

1. ANY SUFFICIENTLY ADVANCED ECONOMY
You know how the Arthur C. Clarke quote goes. I’ve been thinking a bit, somewhat vaguely, about crypto currencies lately. There’s my gut response to the anarcho-Randian boosterism of Bitcoin/Dogecoin fans (the latter of which, I have to admit, is absolutely hilarious and a wonderful example of people taking things entirely not seriously and then being surprised at how much something they take entirely un-seriously takes off) which is: this seems like it solves problems for a subset of people, and isn’t, shall we say, inclusive, in a way that our boring old de facto physically instantiated “money” is, these days. Not to say that “money” itself isn’t without its own problems.

There was Charlie Stross’s blog post[1] about his problems with the *coins[1] which, according to the cryptocurrency fans is either partly wrong or completely wrong (see the comments), but what I’ve been interested in is the ability for a) anyone to spin off and start a new cryptocurrency – the democratization of minting – and b) the possibility of opinionated currencies.

The first is, I think, pretty clear now: what with the codebase of these crypto currencies being open and cloneable and the “only” requirement after that being other people knowing about the currency and the availability of spare processing cycles.

The second is interesting because instead of having currency as one object and laws and code that are applied to it that must be checked against every transaction, there’s the possibility that a cryptocurrency can be opinionated in and of itself, and declare what kind of transactions it’s happy to be involved in (and thus what transactions it’s not happy to be involved in).

And when I see ads here (or, more frequently, hear) for organizations like Christian-centric healthcare providers (very opinionated about women’s bodies, for one) or read about the success of Sharia banks, and then look at what feels sometimes as the increasingly clave-ification of online community, I’m not entirely kidding when I asked, somewhat facetiously[2], when something like the first branded cryptocurrency would occur. Like Starbucks launching a crypto currency called, um, Starbucks. Or *$. Or Fox News launching a cryptocurrency so Americans can (only) buy American[3].

Of course, there’ll be the inevitable exchanges so that wonderfully hypocritical humans can exchange their FoxCoins into SinoCoins so they can get hold of cheap electronics.

All of this is just a roundabout way for me to recommend you to read Paul Cornell’s British Summertime[4]. Yes, the Paul Cornell who’s a comic book writer and Doctor Who writer (the one with the time dragons. In the church. That one[5]. Oh, and the ones when the Doctor is in a watch[6, 7].) Suffice to say it’s a book that features algorithmic currency. It’s really good.

[1] http://www.antipope.org/charlie/blog-static/2013/12/why-i-want-bitcoin-to-die-in-a.html
[2] Branded Cryptocurrencies: https://twitter.com/hondanhon/status/420320185220751360
[3] Fox News Coin: https://twitter.com/hondanhon/status/420321655798247424
[4] British Summertime, by Paul Cornell – no Kindle edition, I’m afraid: http://www.amazon.com/British-Summertime-Paul-Cornell/dp/1932265236
[5] Father’s Day: http://en.wikipedia.org/wiki/Father%27s_Day_(Doctor_Who)
[6] Human Nature: http://en.wikipedia.org/wiki/Human_Nature_(Doctor_Who_episode)
[7] The Family of Blood: http://en.wikipedia.org/wiki/The_Family_of_Blood

2. THE HALTING PROBLEM, MICROSOFT EXCHANGE EDITION
If I were pitching for magic VC money it would be for a self-healing email monitoring system for corporate communications designed to intercept reply-alls to prevent Exchange-killing auto replies[1].

Hat tip to Heather Champ.

[1] BP oops: http://gawker.com/oil-giant-struck-by-globe-spanning-timezone-trotting-r-1508296890
[2] @hchamp and https://twitter.com/hchamp/status/426853090352852992

3. YOU’LL NEVER BELIEVE WHAT HAPPENED NEXT
Anil Dash, with whom I love to have a conversation, has written a piece[1] on the success of Upworthy-style headlines, somewhat in response to CNN’s Breaking News account’s wonderful tweet of the times, “14-year-old girl stabbed her little sister 40 times, police say. The reason why will shock you.”

Anil attacks the disdain with which the hamfisted attempt to apply the techniques of headline writing garnered from sites like Upworthy and Viralnova (and all their hangers on) with the counter that surely writing headlines like this is a good thing if it gets more people exposed to more news. To which yes, that’s a valid argument, but that doesn’t mean that the headline is *better*. It just means that it’s more effective in inducing click through rates in attracting attention. Which, yes, is something that historically print headlines haven’t had to do quite as hard outside of the front page because at that point, you’re pretty much sitting in front of a bit of paper with the story on it in front of you and you don’t have to click through. And, honestly, you probably didn’t have a smartphone the last time you did that because they hadn’t been invented yet.

Perhaps the most telling is in Anil’s closing of his piece, quoting a tweet from Adam Mordecai, founder of Upworthy, saying that most Upworthy headlines don’t sound like 2012-era Upworthy, because they’re not as effective in click-through rates anymore[2].

I feel a little like the backlash is in partly noticing the distinction between a headline that’s diverting your attention away from something you’re paying attention to versus something that’s gently diverting your attention to something on the same page, as in your conventional broadsheet-out-on-the-kitchen-table-over-breakfast.

Upworthy headline construction is designed explicitly to work in streams – the most effective whiplash headline to pull you out of a social stream (Twitter, Facebook or email) and land you somewhere else, namely Upworthy’s site. And arguably, that’s been their main success – witness the commentary spawned by Robinson Meyer’s seminal article in early December explaining the relationship between Upworthy’s copy and Facebook’s News Feed algorithm[3].

Upworthy’s social spread and referral traffic has been *off the scale* in terms of how well its content has performed after Facebook’s News Feed algorithm adjustment. And while it may not be a major factor, I do wonder if their success in jerking people out of hypnotic streams is part of the reason why (taste, notwithstanding) people are starting to have a negative reaction to Upworthy’s naked attention-grabbing. In a reversal, it may be desensitization to manipulation that’s causing the backlash.

[1] http://dashes.com/anil/2014/01/one-simple-trick-worked-to-improve-headlines-and-you-wont-believe-what-happened-next.html
[2] https://twitter.com/advodude/statuses/427844143490953216
[3] http://www.theatlantic.com/technology/archive/2013/12/why-are-upworthy-headlines-suddenly-everywhere/282048/

4. THE ANTHROPOMORPHISATION OF SPACE EXPLORATION
China’s lunar rover is dying: and it wants to tell you about it in first person[1].

Perhaps one of the biggest PR wins that NASA has had in the past few years has been its ability to find both an audience and, if I may, a ‘brand voice’ through Twitter. And that voice has been through anthropomorphizing its probes (and introducing us to the humans who look after them) since 2008[2], through the Mars Curiosity rover.

Now this kind of thing didn’t completely happen by accident[3] but as a geek who’s incredibly sad that he’ll never get to take his son to see a Shuttle launch (hopefully I’ll get to take him to see something much, much better), what’s fantastic is how this anthropomorphisation has brought some wonder back to robotic space exploration. And yes, it might be partly Wall-E’s fault, and yes, it does help that the rovers are pretty easy to anthropomorphize, and yes, it might be soppy, but there’s something so wonderful about these machines that we’re sending out into the universe so literally carrying our hopes and dreams with us.

Just don’t click on this one[4].

[1] http://www.cnn.com/2014/01/27/world/asia/china-jade-rabbit-moon-rover-goodnight/index.html
[2] https://twitter.com/marscuriosity/status/1012517833
[3] http://www.forbes.com/sites/alexknapp/2012/08/10/the-women-whove-transformed-a-mars-rover-into-a-sassy-social-superstar/
[4] http://xkcd.com/695/

Okay, that’s it for Episode Four. I mentioned on Twitter the other day that I was working on some Her fan fiction but it doesn’t look like that’s quite ready yet. So fingers crossed some of that will pop up in tomorrow’s episode.

I like getting replies! I’ve had a couple so far, but it’s great to hear from you about how you’re finding these emails.

Dan

Episode Three: Happy Birthday and Connections
by danhon

1. HAPPY BIRTHDAY, MACINTOSH
In case you missed it, Friday 24th January was the 30th Anniversary[1] of the Apple Mac. Apple celebrated with more of a new direction for what they’re doing on the web with what could only really be described as a classic celebration of thirty years of what kicked off the personal in personal computer. Between last year’s Mac Pro site[2], the recent Your Verse[3] iPad Air campaign, it looks like Apple is taking its presence on the web, if not a lot more seriously, but realizing that it can actually have one.

The 30th Anniversary celebration is not so much product marketing as brand celebration, and Apple taking advantage of the quite frankly sickening amount of traffic and attention their website gets is a marked shift in direction, whether or not in your armchair reckoning of ‘what Jobs would have done’ pre-Jobs-era Apple would have looked backward to celebrate the Mac at all. Are there any other companies commanding as much attention and traffic as Apple with their web presence that are singularly missing such opportunities to be doing, well, something?

[1] http://www.apple.com/30-years/
[2] http://www.apple.com/mac-pro/
[3] https://www.apple.com/your-verse/

2. NEWSLETTERS ARE THE NEW… WHAT?
After yet another exhortation to my followers on Twitter to subscribe to this newsletter, an interesting exchange[1] with Matt Haughey, Alexis Madrigal and Robin Sloan about whether newsletters are now a Thing, and what it is about them that makes them interesting again.

At this point you’d think people who’ve been on the web and thinking about it for so long should know better, but it turns out that the medium does matter, and it keeps reminding us. Newsletters aren’t the web. They’re not apps. They’re mobile in the way that email is. They’re run on the ur-social platform of the internet, email, (we’ll gloss over fingers and .plan files and MUDs and talk commands) and yet the newsletter feels as if it’s being rediscovered, and perhaps it’s because they fill another niche of connection.

We know the internet connects. It’s what it does, it’s what designed for. An network of networks. And lately, it’s been great at one to many broadcast media that amplify our ability to connect with a large number of people. As if a bunch of engineers looked at our brains and said: you know what would be great? If we hacked away the Dunbar number as a constraint on the number of social connections we’re able to maintain. And thus Facebook’s many-weak-ties.

But email feels like it fills this niche of a particular type of connecting. Opt-in with pseudo-verifiable identity makes it different from publishing on a blog, essentially into the ether (even when you’re able to track some sort of audience statistics with the inevitable Google Analytics and RSS stats).

Newsletters – when you know, roughly, who you’re writing to, or the size of the audience that you’re writing to – feel more like an intimate internet, a one-to-small, rather than, at least, in my case, a Twitter audience of one-to-thousands. Even though I’m not necessarily expecting a reply, it feels more like I’m talking to a *you* instead of to a *them*. So that’s perhaps why newsletters are coming back. Tools like Facebook and Twitter have allowed us to aggregate a large number of weak ties we either follow or broadcast to, but we still have a human need to communicate with, say, up to one hundred and fifty people.

In any case, an aspect of the email newsletter other than the dynamic of its reach is the fact that it is a differently opinionated medium than the ones we’re recently used. There is no character limit, so one is free to expound at length, and we know how great Twitter is for having arguments or trying to communicate a nuanced position. And although the text box I’m typing this into in practice supports rich elements, I don’t feel like I’m pressured to embed any imagery. It’s just communication through text and not, say, a single square-cropped filtered image, or an ephemeral, self-erasing image.

In any case, you should probably also subscribe to Roo Reynold’s Letter[2] and Alexis Madrigal’s 5 Intriguing Things.

[1] https://twitter.com/hondanhon/status/426837136420384768
[2] Roo Reynold’s Letter: http://tinyletter.com/rooreynolds
[3] Alexis Madrigal’s 5 Intriguing Things: https://tinyletter.com/intriguingthings

3. MORE GREG EGAN
I know I pimped Greg Egan last episode, but I’ve found another gem I’d love to share with you. In his 2013 short story In The Ruins[1] he spins a wonderful twist on the Kardashev Scale[2] of a civilization’s technological ability:

“I have no heroes,” Ghada said flatly. “But I can recognise a culture in decline when I see it. America is now what anthropologists call a Kardashian Type Three civilisation: more than fifty percent of GDP is in the attention economy.”

Kardashian reference! Attention economy reference! Culture in decline reference!

Expect the coinage to start turning up in discussions of the ad-funded startup-based new, new, new economy.

[1] In The Ruins: http://gregegan.customer.netspace.net.au/MISC/RUINS/Ruins.html
[2] The Kardashev Scale: http://en.wikipedia.org/wiki/Kardashev_scale

4. BETTER LIVING THROUGH DATA
I wrote this morning, that “If the 1980s were DuPont’s through Better Living Through Chemistry, then the early C21st is Google’s through Better Living Through Data.”[1]

Monday was the News Cycle’s reaction to Google acquiring, for another $400m, “general-purpose learning algorithm” startup Deep Mind which might not mean anything to you, in which case the fact that it was founded by Demis Hassabis probably won’t mean anything to you either, Hassabis mainly being presented as a neuroscientist. But then you might remember his name as an ex-game designer from Peter Molyneux’s School for Gifted Children, or Bullfrog, where he started out as a level designer on horrifying-vision-of-future-to-come Syndicate, then co-designing Theme Park for which you probably remember the chain vomiting sounds. And if you really do remember your late 90s, early 00s video game history then you probably remember the hype around his game The Republic, around which he formed Elixir studios and exactly how he was going to simulate an entire country and you realize, wow, if this guy went back to school, studied neuroscience and came up with something, well, in the area of general-purpose learning algorithms worth $400m…

Because although I might have rather aggressively said that Google’s defining mission is the indexing of the world’s (but, let’s be honest here and accept that ‘the world’ is merely the public-friendly way of saying ‘the universe’) information, and making it available for free, I think, from the outside, that if it were possible to ascribe Google-as-an-entity motivations and beliefs, Google really does believe in better living through data. And that may well be the achilles heel of the West Coast mentality, that sufficiently-advanced-data-and-modelling-is-indistinguishable-from-living-in-a-magical-utopia. Data will make cars self-driving. Data will make diabetes manageable. Data will save lives. Data will liberate us from having to decide. Data will let you know what meals you should eat, how much more walking you should do, whether you should stand up or sit down for this meeting, which cellphone plan you should subscribe to.

You want that better life, don’t you? Well then take it. But the way you get that better life is through data.

What’s interesting to me is how this obsession came about, because there’s not much inspiration in the way of it. I can look at moving picture depictions of a science-fictional universe (and will scream the next time someone references the motion graphics from Stranger Than Fiction[2] because a) they’re over seven years old now, and b) really?) and acknowledge that we want to make all of the screens shiny and full of *stuff*, but no one has made an emotional case for the kind of dashboard I have no choice about receiving. In fact, for all its other faults in terms of a software ecosystem, perhaps the best thing about the Nike Fuelband is the on-device display and simple mechanic of red versus green. I refuse to believe that mass acceptance of quantified self devices will happen with them a) still being known as ‘quantified self devices’ and b) the current glut of info-dashboardery.

I just want to know if I can eat this cupcake or not. Not every single cupcake I’ve ever eaten, where I ate it, what they were made of and how my poop was that day.

[1] https://twitter.com/hondanhon/status/427822364504911872
[2] Stranger than Fiction: opening motion graphics – https://vimeo.com/3193923

That’s it for Episode 3.

I’m going to give myself a badge for getting three of these out and tease you with the thought that I’ve finally watched Spike Jonze’s Her and, fingers crossed, tomorrow’s episode will be full of spoiler-filled juiciness.

Episode Two: The Desire To Fix Things
by danhon

I’m writing this on the way to New York, where from what I can make out, it’s officially the coldest place on Earth.

1. THE DESIRE TO FIX THINGS
According to some people, San Francisco is having something of an integration problem: a new influx of people, groaning infrastructure, enemies and bogeymen being cast left and right, what with Gawker pub Valleywag appearing to whip up a binary frenzy Fox News style (an entirely unsurprising move given the Gawker media background) and internet titan Google becoming the whipping boy for the simple crime of trying to make life easier for its employees, many of whom would prefer to live in San Francisco.

Into this all comes Anil Dash, whose Stupid Simple Things SF Techies Could Do To Stop Being Hated obviously comes from a good place, but at the same time also appears to come from the place that a lot of geeks can’t resist: that of seeing a problem, presuming to know the solution to that problem, and trying to impart said solution as a way to help with a capital H:

http://dashes.com/anil/2014/01/stupid-simple-things-sf-techies-could-do-to-stop-being-hated.html

The funny thing about this is that a piece predicated upon the supposed lack of empathy of an entire sector which, in reality, is in all likelihood down to a small number of people setting policy, itself lacks empathy. And here we are with the tragedy of the geek: always wanting to fix things and wondering why everyone can’t just sit down and listen to this really jolly good solution to all things that at the very least would be a *start*.

Look: the Bay Area ex-startups that are now moulding the world in their image are simply looking out to optimize things for their employees. And yes, perhaps they need some help in seeing what some of the non-quantifiable values might be that need optimizing. And if anything, no one, not even smart people, like being mediumsplained to.

2. THE NEW SUBSCRIPTION TELEVISION IS THE OLD SUBSCRIPTION TELEVISION ONLY TWEAKED SLIGHTLY
Netflix announced its fourth quarter earnings and released its letter to shareholders, revealing just over a couple million new subscribers in the US, bringing their US total to about thirty three and a half million members. Which is about half the population of the UK, and pretty scary if you think about it that way. Predictably, their stock soared, but in a lull between meetings today, I asked a couple of colleagues why, exactly, given that Netflix’s average revenue per user is lower than HBO’s. Best guess is that Netflix is still at the pre-hockeystick stage of growth, which has the rational market all irrationally excited. Secondly, while Netflix can’t compete on acquisition of existing content (in our wonderful disintermediated future, there won’t be one place we can get all of our favorite films or tv shows thanks to exclusivity windows and deals), they’ve proven with shows like Orange Is The New Black and House of Cards (and more the latter than the former) that they can do original content pretty well.

Which would be all well and good if House of Cards *was* original content (fans and Brits will note that the original series did pretty well, thank you very much), so all of that remains to be seen.

http://files.shareholder.com/downloads/NFLX/2914769797x0x720306/119321bc-89c3-4306-93ac-93c02da2354f/Q4%2013%20Letter%20to%20shareholders.pdf

3. AND NOW SOME SHORT FICTION
Greg Egan is one of my favorite science fiction writers. I picked up Diaspora while I was in college, and pretty much tore through the rest of his novels and collections in short order. Reading Permuation City was probably one of the best introductions to hard science fiction, and by the time you get to Schild’s Ladder, you’re scoring about a 10 on the moh’s scale of science fiction hardiness. In any event, here’s another good short story of his that came out recently:

http://subterraneanpress.com/magazine/winter_2014/bit_players_by_greg_egan

And if you liked that, you’ll be bawling your eyes out if you haven’t read Ted Chiang’s The Lifecycle of Software Objects.

Chapter one here: http://subterraneanpress.com/magazine/fall_2010/fiction_the_lifecycle_of_software_objects_by_ted_chiang
Full book here: http://www.amazon.com/The-Lifecycle-Software-Objects-Chiang/dp/1596063173

4. PLEASE GET ADDICTED TO OUR PRODUCT
A short one, this. It’s not often you get a CEO unabashedly saying they’d like people to get addicted to their product, but HBO CEO Richard Plepler apparently doesn’t have a problem with that at all.

http://www.theverge.com/2014/1/19/5324736/hbo-ceo-doesnt-mind-hbo-go-account-sharing

You don’t really get video games companies with the balls to say that these days.

5. INTERNET OF THING
At dinner with friends, the ur-Internet of Things object, the Cambridge Trojan Room Coffee Pot from 1991, an internet-connected (ish, one of the first webcams, a 128×128 pixel greyscale image) coffee pot, to see if the coffee was done. Seeing as there was a) hardly an internet, b) a nascent world wide web and c) the coffee pot implemented over X on an Acorn Archimedes, it’s nice to see how far internet connected objects have come. Or not come, if you’re stuck with an internet fridge.

http://en.wikipedia.org/wiki/Trojan_Room_coffee_pot

FOLLOW-UPS
Simon Wistow (@deflatermouse) sent a link to a post by Alex St. John commenting on yesterday’s epidemiology-based Facebook doom prediction. Short version: the paper most likely didn’t take into account the phenomenon of re-engagement, which in St. John’s opinion means all bets are off.

http://www.alexstjohn.com/WP/2014/01/23/forecasting-demise-facebook/

And, of course, Facebook fired back with their own data science post, showing that Princeton should probably worry about its student population dwindling to zero within a few years.

https://www.facebook.com/notes/mike-develin/debunking-princeton/10151947421191849

All of this, at least, has helped some people realize that papers posted on arXiv aren’t peer-reviewed, highlighting one of the issues with science journalism. Again.

That’s it for Episode 2. See you again on Monday.

Dan

Episode One: The Beginning
by danhon

It’s episode one. Let’s see how this goes.

1. Dear Subscriber, You Are Registered As A Participant In Mass Disturbance

The Vice article seems perhaps a little overwritten, but here’s your law-reflected-in-code story for the day: it appears that mobile phones within predefined geographic areas (or perhaps, or more worryingly, just those attached to specific base stations) were sent a message indicating that they had now been tagged in a database somewhere as taking part in illegal activity. Never mind that what’s actually being tagged is the presence of a mobile device, not the presence of an actual human.

http://motherboard.vice.com/en_ca/blog/maybe-the-most-orwellian-text-message-ever-sent, via Hacker News

2. Cab Conversation Of The Day
“So, you work on Facebook?”
“Uh-huh.”
“Say, did you read that article that said they were going to lose 80% of the users in the next few years?”
Oh, you mean this one? (apologies for the long Google URL)

Here’s the (non peer-reviewed) paper it’s based on: http://arxiv.org/pdf/1401.4208v1.pdf, using techniques from epidemiological modeling and applying them to online social networks. Its authors are members of the Department of Mechanical and Aerospace Engineering at Princeton University, so in my humble opinion perhaps it’s worth consulting the opinion of people who know a lot more about epidemiology.

Disclosure: one of the accounts I work on is Facebook.

3. Google, the next conglomerate?
After Google bought Nest last week, there was a lot of a) speculation as to what it meant for Nest, and b) speculation as to what it meant for Google, and c) general flailing opinion, yours truly notwithstanding. Some of the most interesting discussion was around whether there was still an easily discernible business model or strategy for Google, with opinion quickly heading toward the “Google as conglomerate” model. Here’s the best piece of commentary I found:

http://mobileopportunity.blogspot.fi/2014/01/google-conglomerate-after-nest-no.html

Here’s Horace Dediu’s take, too: http://www.asymco.com/2014/01/17/googles-three-ps/

4. VR will be here in two years, for real this time
As someone who was unreasonably excited when the first Virtuality arcade units came out it looks like this time, virtual reality might actually be coming. For real. Valve, who accidentally found themselves on top of the digital distribution pile for gaming with their Steam service, have a point of view paper out on how VR will definitely make it, and what’s needed to get it there:

http://media.steampowered.com/apps/abrashblog/Abrash%20Dev%20Days%202014.pdf

Virtuality arcade units, the coolest thing when you were 13: http://en.wikipedia.org/wiki/Virtuality_(gaming)

5. The Retro Future Universe

So there’s this io9 article based on a comment on a review (bear with me) about Almost Human, Fox TV’s new show set in the future where a human partners with a robot and – you guessed it – they fight crime. Now, I haven’t watched the show, but the premise of the comment – that the backward looking view of the future is in fact because it’s a view of the future *as seen from the 1980s* is super intriguing. There are so many science fictional tropes that don’t get the chance to be explored in moving image – what I was excited most about Blomkamp’s Elysium was that part of the action would take place on an Stanford torus, which we never get to see on film. But then most of the movie took place on Earth.

io9 on visions of 80s futures: http://io9.com/is-almost-human-set-in-the-retro-future-1501420943

That’s it for today! Let’s see if I can do this tomorrow, too.


  
